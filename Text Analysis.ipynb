{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0bd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2edc6",
   "metadata": {},
   "source": [
    "## 1. for URL_ID : 37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8946ca2b",
   "metadata": {},
   "source": [
    "## DATA CRAWLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "c7a7cf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\1649698333.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b39a798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text = driver.find_elements(By.TAG_NAME,'p')\n",
    "titles = []\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6e79d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Introduction',\n",
       " '“If anything kills over 10 million people in the next few decades, it will be a highly infectious virus rather than a war. Not missiles but microbes.” Bill Gates’s remarks at a TED conference in 2014, right after the world had avoided the Ebola outbreak. When the new, unprecedented, invisible virus hit us, it met an overwhelmed and unprepared healthcare system and oblivious population. This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities. For the past few years, artificial intelligence has proven to be of tangible potential in the healthcare sectors, clinical practices, translational medical and biomedical research.',\n",
       " 'After the first case was detected in China on December 31st 2019, it was an AI program developed by BlueDot that alerted the world about the pandemic. It was quick to realise AI’s ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus.',\n",
       " 'Many tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of cross-infection by using AI algorithms that can track patterns and extract some features to classify or categorise them.',\n",
       " 'So how does AI do that?',\n",
       " 'IBM Watson, a sophisticated AI that works on cloud computing and natural language processing, has prominently contributed to the healthcare sector on a global level. Being a conversational AI, since 2013, Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs.',\n",
       " 'Researchers at Google Inc. showed that an AI system can be trained on thousands of images to achieve physician-level sensitivity.',\n",
       " 'By identifying the molecular patterns associated with disease status and its subtypes, gene expression, and protein abundance levels, machine learning methods can detect fatal diseases like cancer at an early stage. Machine Learning (ML) techniques focus mainly on analyzing structured data, which can further help in clustering patients’ traits and infer the probability of disease outcomes. Since patient traits mainly include masses of data relating to age, gender, disease history, disease-specific data like diagnostic imaging and gene expressions, etc, ML can extract features from these data inputs by constructing data analytical algorithms.',\n",
       " 'ML algorithms are either supervised or unsupervised. Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases. Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters. Since patient traits are recorded in multiple dimensions, such as genes, principal component analysis(PCA) creates the apparatus to reduce these dimensions which humans could have not done alone.',\n",
       " 'Supervised learning considers the outcomes of the subjects together with the traits, and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event, expected value of a disease level or expected survival time, or risk of Down’s syndrome.',\n",
       " 'Biomarker panels that are mostly used to detect ovarian cancer, have outperformed the conventional statistical methods due to machine learning. In addition to this, the use of EHRs and Bayesian networks, which are a part of supervised machine learning algorithms, can predict clinical outcomes and mortality respectively.',\n",
       " 'Unstructured data such as clinical notes and texts are converted into machine-readable structured data with the help of natural language processing(NLP). NLP works with two components: text processing and classification. Text processing helps in identifying a series of disease-relevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases. Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients. Healthcare organizations use NLP-based chatbots to increase interactions with patients, keeping their mental health and wellness in check.',\n",
       " 'Deep learning is a modern extension of the classical neural network techniques which helps explore more complex non-linear patterns in data, using algorithms like convolution neural network, recurrent neural network, deep belief network, and deep neural network which enables more accurate clinical prediction. When it comes to genome interpretation, deep neural networks surpass the conventional methods of logistics regression and support vector machines.',\n",
       " 'Sepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patient’s risk score and identify the early stages of sepsis.',\n",
       " 'Another method known as the Learning-based Optimization of the Under Sampling Pattern( LOUPE) is based on integrating full resolution MRI scans with the convolutional neural network algorithm, which helps in creating more accurate reconstructions.',\n",
       " 'Robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery. Even after striking the right balance between human decisions and AI precision, robotic surgery reduces surgeon efficiency as they have to be manually operated through a console. Thus, autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs, cut tissues, etc., or robotic catheters that can navigate whether it is touching blood, tissue, or valve.',\n",
       " 'Researchers at Children’s National Hospital, Washington have already developed an AI called Smart Tissue Autonomous Robot (STAR), which performs a colon anastomosis on its own with the help of an ML-powered suturing tool, that automatically detects the patient’s breathing pattern to apply suture at the correct point.',\n",
       " 'Cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs. Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information, medications, and therapies.',\n",
       " 'How can It help in Biomedical research?',\n",
       " 'Since AI can analyze literature beyond readability, it can be used to concise biomedical research. With the help of ML algorithms and NLP, AI can accelerate screening and indexing of biomedical research, by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly. Taking it to the next level, AI systems like the computational modelling assistant (CMA) helps researchers to construct simulation models from the concepts they have in mind. Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and protein-protein interaction information extraction.',\n",
       " 'AI as precision medicine',\n",
       " 'Since precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile, the various AI devices pave the way to practice it more efficiently. With the help of ML, complex algorithms like large datasets can be used to predict and create an optimal treatment strategy.',\n",
       " 'Deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patient’s emotional state, food intake, or health monitoring. ',\n",
       " '“Omics” refers to the collective technologies that help in exploring the roles, relationships of various branches ending with the suffix “omics” such as genomics, proteomics, etc. Omics-based tests based on machine learning algorithms help find correlations and predict treatment responses, ultimately creating personalized treatments for individual patients. ',\n",
       " 'How it helps in psychology and neuro patients',\n",
       " 'For psychologists studying creativity,  AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon. Studies show that  AI can conduct therapy sessions, e-therapy sessions, and assessments autonomously, also assisting human practitioners before, during, or after sessions. The Detection and Computational Analysis of Psychological Signal project uses ML, computer vision, and NLP to analyze language, physical gestures, and social signals to identify cues for human distress. This ground-breaking technology assesses soldiers returning from combat and recognizes those who require further mental health support. In the future, it will combine data captured during face-to-face interviews with information on sleeping, eating, and online behaviours for a complete patient view.',\n",
       " 'Stroke identification',\n",
       " 'Stroke is another frequently occurring disease that affects more than 500 million people worldwide. Thrombus,  in the vessel cerebral infarction is the major (about 85%) cause of stroke occurrence. In recent years, AI techniques have been used in numerous stroke-related studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem. With AI at our disposal, large amounts of data with rich information, more complications and real-life clinical questions can be addressed in this arena. Currently, two ML algorithms- genetic fuzzy finite state machine and PCA were implemented to build a model building solution. These include a human activity recognition stage and a stroke onset detection stage. An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded. ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis.',\n",
       " 'Patient Monitoring',\n",
       " 'Today, the market for AI-based patient monitoring is impressive and monetarily enticing. It is evolving with artificial sensors, smart technologies and explores everything from brain-computer interfaces to nanorobotics. Companies with their smart-watches have engaged people to perform remote monitoring even when they are not “patients”. An obvious place to start is with wearable and embedded sensors, glucose monitors, pulse monitors, oximeters, and ECG monitors. With patient monitoring becoming crucial, AI finds numerous applications in chronic conditions, intensive care units, operating rooms, emergency rooms, and cardiac wards where timeless clinical decision-making can be measured in seconds. More advances have started to gain traction like smart prosthetics and implants. These play an impeccable role in patient management post-surgery or rehabilitation. Demographics, laboratory results and vital signs can also be used to predict cardiac arrest, transfer into the intensive care unit, or even death. In addition, an interpretable machine-learning model can assist anesthesiologists in predicting hypoxaemia events during surgery. This suggests that with deep-learning algorithms, raw patient-monitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decision-making.',\n",
       " ' Conclusion',\n",
       " 'Considering the vast range of tasks that an AI can do, it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels. Using sophisticated algorithms AI can bring a revolution in the healthcare sector. Even after facing challenges like whether the technology will be able to deliver the promises, ethical measures, training physicians to use it, standard regulations etc, the role of AI in transforming the clinical practices cannot be ignored. The biggest challenge is the integration of AI in daily practice. All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective.']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3dbec433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI in healthcare to Improve Patient Outcomes']"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "4929cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a3f17f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:48]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9cd90f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ID_37 = \" \".join((titles, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b1c37391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI in healthcare to Improve Patient Outcomes Introduction “If anything kills over 10 million people in the next few decades, it will be a highly infectious virus rather than a war. Not missiles but microbes.” Bill Gates’s remarks at a TED conference in 2014, right after the world had avoided the Ebola outbreak. When the new, unprecedented, invisible virus hit us, it met an overwhelmed and unprepared healthcare system and oblivious population. This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities. For the past few years, artificial intelligence has proven to be of tangible potential in the healthcare sectors, clinical practices, translational medical and biomedical research. After the first case was detected in China on December 31st 2019, it was an AI program developed by BlueDot that alerted the world about the pandemic. It was quick to realise AI’s ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus. Many tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of cross-infection by using AI algorithms that can track patterns and extract some features to classify or categorise them. So how does AI do that? IBM Watson, a sophisticated AI that works on cloud computing and natural language processing, has prominently contributed to the healthcare sector on a global level. Being a conversational AI, since 2013, Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs. Researchers at Google Inc. showed that an AI system can be trained on thousands of images to achieve physician-level sensitivity. By identifying the molecular patterns associated with disease status and its subtypes, gene expression, and protein abundance levels, machine learning methods can detect fatal diseases like cancer at an early stage. Machine Learning (ML) techniques focus mainly on analyzing structured data, which can further help in clustering patients’ traits and infer the probability of disease outcomes. Since patient traits mainly include masses of data relating to age, gender, disease history, disease-specific data like diagnostic imaging and gene expressions, etc, ML can extract features from these data inputs by constructing data analytical algorithms. ML algorithms are either supervised or unsupervised. Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases. Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters. Since patient traits are recorded in multiple dimensions, such as genes, principal component analysis(PCA) creates the apparatus to reduce these dimensions which humans could have not done alone. Supervised learning considers the outcomes of the subjects together with the traits, and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event, expected value of a disease level or expected survival time, or risk of Down’s syndrome. Biomarker panels that are mostly used to detect ovarian cancer, have outperformed the conventional statistical methods due to machine learning. In addition to this, the use of EHRs and Bayesian networks, which are a part of supervised machine learning algorithms, can predict clinical outcomes and mortality respectively. Unstructured data such as clinical notes and texts are converted into machine-readable structured data with the help of natural language processing(NLP). NLP works with two components: text processing and classification. Text processing helps in identifying a series of disease-relevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases. Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients. Healthcare organizations use NLP-based chatbots to increase interactions with patients, keeping their mental health and wellness in check. Deep learning is a modern extension of the classical neural network techniques which helps explore more complex non-linear patterns in data, using algorithms like convolution neural network, recurrent neural network, deep belief network, and deep neural network which enables more accurate clinical prediction. When it comes to genome interpretation, deep neural networks surpass the conventional methods of logistics regression and support vector machines. Sepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patient’s risk score and identify the early stages of sepsis. Another method known as the Learning-based Optimization of the Under Sampling Pattern( LOUPE) is based on integrating full resolution MRI scans with the convolutional neural network algorithm, which helps in creating more accurate reconstructions. Robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery. Even after striking the right balance between human decisions and AI precision, robotic surgery reduces surgeon efficiency as they have to be manually operated through a console. Thus, autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs, cut tissues, etc., or robotic catheters that can navigate whether it is touching blood, tissue, or valve. Researchers at Children’s National Hospital, Washington have already developed an AI called Smart Tissue Autonomous Robot (STAR), which performs a colon anastomosis on its own with the help of an ML-powered suturing tool, that automatically detects the patient’s breathing pattern to apply suture at the correct point. Cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs. Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information, medications, and therapies. How can It help in Biomedical research? Since AI can analyze literature beyond readability, it can be used to concise biomedical research. With the help of ML algorithms and NLP, AI can accelerate screening and indexing of biomedical research, by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly. Taking it to the next level, AI systems like the computational modelling assistant (CMA) helps researchers to construct simulation models from the concepts they have in mind. Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and protein-protein interaction information extraction. AI as precision medicine Since precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile, the various AI devices pave the way to practice it more efficiently. With the help of ML, complex algorithms like large datasets can be used to predict and create an optimal treatment strategy. Deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patient’s emotional state, food intake, or health monitoring.  “Omics” refers to the collective technologies that help in exploring the roles, relationships of various branches ending with the suffix “omics” such as genomics, proteomics, etc. Omics-based tests based on machine learning algorithms help find correlations and predict treatment responses, ultimately creating personalized treatments for individual patients.  How it helps in psychology and neuro patients For psychologists studying creativity,  AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon. Studies show that  AI can conduct therapy sessions, e-therapy sessions, and assessments autonomously, also assisting human practitioners before, during, or after sessions. The Detection and Computational Analysis of Psychological Signal project uses ML, computer vision, and NLP to analyze language, physical gestures, and social signals to identify cues for human distress. This ground-breaking technology assesses soldiers returning from combat and recognizes those who require further mental health support. In the future, it will combine data captured during face-to-face interviews with information on sleeping, eating, and online behaviours for a complete patient view. Stroke identification Stroke is another frequently occurring disease that affects more than 500 million people worldwide. Thrombus,  in the vessel cerebral infarction is the major (about 85%) cause of stroke occurrence. In recent years, AI techniques have been used in numerous stroke-related studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem. With AI at our disposal, large amounts of data with rich information, more complications and real-life clinical questions can be addressed in this arena. Currently, two ML algorithms- genetic fuzzy finite state machine and PCA were implemented to build a model building solution. These include a human activity recognition stage and a stroke onset detection stage. An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded. ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis. Patient Monitoring Today, the market for AI-based patient monitoring is impressive and monetarily enticing. It is evolving with artificial sensors, smart technologies and explores everything from brain-computer interfaces to nanorobotics. Companies with their smart-watches have engaged people to perform remote monitoring even when they are not “patients”. An obvious place to start is with wearable and embedded sensors, glucose monitors, pulse monitors, oximeters, and ECG monitors. With patient monitoring becoming crucial, AI finds numerous applications in chronic conditions, intensive care units, operating rooms, emergency rooms, and cardiac wards where timeless clinical decision-making can be measured in seconds. More advances have started to gain traction like smart prosthetics and implants. These play an impeccable role in patient management post-surgery or rehabilitation. Demographics, laboratory results and vital signs can also be used to predict cardiac arrest, transfer into the intensive care unit, or even death. In addition, an interpretable machine-learning model can assist anesthesiologists in predicting hypoxaemia events during surgery. This suggests that with deep-learning algorithms, raw patient-monitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decision-making.  Conclusion Considering the vast range of tasks that an AI can do, it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels. Using sophisticated algorithms AI can bring a revolution in the healthcare sector. Even after facing challenges like whether the technology will be able to deliver the promises, ethical measures, training physicians to use it, standard regulations etc, the role of AI in transforming the clinical practices cannot be ignored. The biggest challenge is the integration of AI in daily practice. All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective.'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_ID_37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fcdc7",
   "metadata": {},
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0297ccd",
   "metadata": {},
   "source": [
    "## Number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "712cb372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 sentences in the string.\n"
     ]
    }
   ],
   "source": [
    "# Spliting the string into sentences using periods as delimiters\n",
    "sentences = URL_ID_37.split(\".\")\n",
    "\n",
    "# Getting the count of sentences\n",
    "Sent_count = len(sentences)\n",
    "\n",
    "print(f\"There are {Sent_count} sentences in the string.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393589d",
   "metadata": {},
   "source": [
    "## Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57d1468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in the string is: 1780\n"
     ]
    }
   ],
   "source": [
    "#the number of words in the string\n",
    "\n",
    "word_list = URL_ID_37.split()\n",
    "\n",
    "num_words = len(word_list)\n",
    "\n",
    "print(\"The number of words in the string is:\",num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70340869",
   "metadata": {},
   "source": [
    "## Number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "76c2d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10316\n"
     ]
    }
   ],
   "source": [
    "#Sum of the total number of characters in each word\n",
    "words = URL_ID_37.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(total_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3db6c",
   "metadata": {},
   "source": [
    "# Removing the unwanted puncuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "053038be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI in healthcare to Improve Patient Outcomes Introduction If anything kills over 10 million people in the next few decades it will be a highly infectious virus rather than a war Not missiles but microbes Bill Gatess remarks at a TED conference in 2014 right after the world had avoided the Ebola outbreak When the new unprecedented invisible virus hit us it met an overwhelmed and unprepared healthcare system and oblivious population This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities For the past few years artificial intelligence has proven to be of tangible potential in the healthcare sectors clinical practices translational medical and biomedical research After the first case was detected in China on December 31st 2019 it was an AI program developed by BlueDot that alerted the world about the pandemic It was quick to realise AIs ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus Many tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of crossinfection by using AI algorithms that can track patterns and extract some features to classify or categorise them So how does AI do that? IBM Watson a sophisticated AI that works on cloud computing and natural language processing has prominently contributed to the healthcare sector on a global level Being a conversational AI since 2013 Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs Researchers at Google Inc showed that an AI system can be trained on thousands of images to achieve physicianlevel sensitivity By identifying the molecular patterns associated with disease status and its subtypes gene expression and protein abundance levels machine learning methods can detect fatal diseases like cancer at an early stage Machine Learning ML techniques focus mainly on analyzing structured data which can further help in clustering patients traits and infer the probability of disease outcomes Since patient traits mainly include masses of data relating to age gender disease history diseasespecific data like diagnostic imaging and gene expressions etc ML can extract features from these data inputs by constructing data analytical algorithms ML algorithms are either supervised or unsupervised Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters Since patient traits are recorded in multiple dimensions such as genes principal component analysisPCA creates the apparatus to reduce these dimensions which humans could have not done alone Supervised learning considers the outcomes of the subjects together with the traits and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event expected value of a disease level or expected survival time or risk of Downs syndrome Biomarker panels that are mostly used to detect ovarian cancer have outperformed the conventional statistical methods due to machine learning In addition to this the use of EHRs and Bayesian networks which are a part of supervised machine learning algorithms can predict clinical outcomes and mortality respectively Unstructured data such as clinical notes and texts are converted into machinereadable structured data with the help of natural language processingNLP NLP works with two components text processing and classification Text processing helps in identifying a series of diseaserelevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients Healthcare organizations use NLPbased chatbots to increase interactions with patients keeping their mental health and wellness in check Deep learning is a modern extension of the classical neural network techniques which helps explore more complex nonlinear patterns in data using algorithms like convolution neural network recurrent neural network deep belief network and deep neural network which enables more accurate clinical prediction When it comes to genome interpretation deep neural networks surpass the conventional methods of logistics regression and support vector machines Sepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patients risk score and identify the early stages of sepsis Another method known as the Learningbased Optimization of the Under Sampling Pattern LOUPE is based on integrating full resolution MRI scans with the convolutional neural network algorithm which helps in creating more accurate reconstructions Robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery Even after striking the right balance between human decisions and AI precision robotic surgery reduces surgeon efficiency as they have to be manually operated through a console Thus autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs cut tissues etc or robotic catheters that can navigate whether it is touching blood tissue or valve Researchers at Childrens National Hospital Washington have already developed an AI called Smart Tissue Autonomous Robot STAR which performs a colon anastomosis on its own with the help of an MLpowered suturing tool that automatically detects the patients breathing pattern to apply suture at the correct point Cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information medications and therapies How can It help in Biomedical research? Since AI can analyze literature beyond readability it can be used to concise biomedical research With the help of ML algorithms and NLP AI can accelerate screening and indexing of biomedical research by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly Taking it to the next level AI systems like the computational modelling assistant CMA helps researchers to construct simulation models from the concepts they have in mind Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and proteinprotein interaction information extraction AI as precision medicine Since precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile the various AI devices pave the way to practice it more efficiently With the help of ML complex algorithms like large datasets can be used to predict and create an optimal treatment strategy Deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patients emotional state food intake or health monitoring  Omics refers to the collective technologies that help in exploring the roles relationships of various branches ending with the suffix omics such as genomics proteomics etc Omicsbased tests based on machine learning algorithms help find correlations and predict treatment responses ultimately creating personalized treatments for individual patients  How it helps in psychology and neuro patients For psychologists studying creativity  AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon Studies show that  AI can conduct therapy sessions etherapy sessions and assessments autonomously also assisting human practitioners before during or after sessions The Detection and Computational Analysis of Psychological Signal project uses ML computer vision and NLP to analyze language physical gestures and social signals to identify cues for human distress This groundbreaking technology assesses soldiers returning from combat and recognizes those who require further mental health support In the future it will combine data captured during facetoface interviews with information on sleeping eating and online behaviours for a complete patient view Stroke identification Stroke is another frequently occurring disease that affects more than 500 million people worldwide Thrombus  in the vessel cerebral infarction is the major about 85 cause of stroke occurrence In recent years AI techniques have been used in numerous strokerelated studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem With AI at our disposal large amounts of data with rich information more complications and reallife clinical questions can be addressed in this arena Currently two ML algorithms genetic fuzzy finite state machine and PCA were implemented to build a model building solution These include a human activity recognition stage and a stroke onset detection stage An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis Patient Monitoring Today the market for AIbased patient monitoring is impressive and monetarily enticing It is evolving with artificial sensors smart technologies and explores everything from braincomputer interfaces to nanorobotics Companies with their smartwatches have engaged people to perform remote monitoring even when they are not patients An obvious place to start is with wearable and embedded sensors glucose monitors pulse monitors oximeters and ECG monitors With patient monitoring becoming crucial AI finds numerous applications in chronic conditions intensive care units operating rooms emergency rooms and cardiac wards where timeless clinical decisionmaking can be measured in seconds More advances have started to gain traction like smart prosthetics and implants These play an impeccable role in patient management postsurgery or rehabilitation Demographics laboratory results and vital signs can also be used to predict cardiac arrest transfer into the intensive care unit or even death In addition an interpretable machinelearning model can assist anesthesiologists in predicting hypoxaemia events during surgery This suggests that with deeplearning algorithms raw patientmonitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decisionmaking  Conclusion Considering the vast range of tasks that an AI can do it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels Using sophisticated algorithms AI can bring a revolution in the healthcare sector Even after facing challenges like whether the technology will be able to deliver the promises ethical measures training physicians to use it standard regulations etc the role of AI in transforming the clinical practices cannot be ignored The biggest challenge is the integration of AI in daily practice All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective'"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Regex \n",
    "\n",
    "import re\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_37 = re.sub(re_punt, \"\",URL_ID_37)\n",
    "URL_ID_37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b838e",
   "metadata": {},
   "source": [
    "### Saving the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7954b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"37.txt\", \"w\")\n",
    "file.write(URL_ID_37)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d8d97",
   "metadata": {},
   "source": [
    "### Downloading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"37.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69122736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  AI in healthcare to Improve Patient Outcomes I..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the Dataset\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/37.txt\",header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59fb883",
   "metadata": {},
   "source": [
    "# Normalising the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "598fdbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lwr = df[0].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1710a4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ai in healthcare to improve patient outcomes i...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lwr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884d491",
   "metadata": {},
   "source": [
    "# Tokenizatition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db03ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ai',\n",
       "  'in',\n",
       "  'healthcare',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'patient',\n",
       "  'outcomes',\n",
       "  'introduction',\n",
       "  'if',\n",
       "  'anything',\n",
       "  'kills',\n",
       "  'over',\n",
       "  '10',\n",
       "  'million',\n",
       "  'people',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  'few',\n",
       "  'decades',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'a',\n",
       "  'highly',\n",
       "  'infectious',\n",
       "  'virus',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'a',\n",
       "  'war',\n",
       "  'not',\n",
       "  'missiles',\n",
       "  'but',\n",
       "  'microbes',\n",
       "  'bill',\n",
       "  'gatess',\n",
       "  'remarks',\n",
       "  'at',\n",
       "  'a',\n",
       "  'ted',\n",
       "  'conference',\n",
       "  'in',\n",
       "  '2014',\n",
       "  'right',\n",
       "  'after',\n",
       "  'the',\n",
       "  'world',\n",
       "  'had',\n",
       "  'avoided',\n",
       "  'the',\n",
       "  'ebola',\n",
       "  'outbreak',\n",
       "  'when',\n",
       "  'the',\n",
       "  'new',\n",
       "  'unprecedented',\n",
       "  'invisible',\n",
       "  'virus',\n",
       "  'hit',\n",
       "  'us',\n",
       "  'it',\n",
       "  'met',\n",
       "  'an',\n",
       "  'overwhelmed',\n",
       "  'and',\n",
       "  'unprepared',\n",
       "  'healthcare',\n",
       "  'system',\n",
       "  'and',\n",
       "  'oblivious',\n",
       "  'population',\n",
       "  'this',\n",
       "  'public',\n",
       "  'health',\n",
       "  'emergency',\n",
       "  'demonstrated',\n",
       "  'our',\n",
       "  'lack',\n",
       "  'of',\n",
       "  'scientific',\n",
       "  'consideration',\n",
       "  'and',\n",
       "  'underlined',\n",
       "  'the',\n",
       "  'alarming',\n",
       "  'need',\n",
       "  'for',\n",
       "  'robust',\n",
       "  'innovations',\n",
       "  'in',\n",
       "  'our',\n",
       "  'health',\n",
       "  'and',\n",
       "  'medical',\n",
       "  'facilities',\n",
       "  'for',\n",
       "  'the',\n",
       "  'past',\n",
       "  'few',\n",
       "  'years',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'has',\n",
       "  'proven',\n",
       "  'to',\n",
       "  'be',\n",
       "  'of',\n",
       "  'tangible',\n",
       "  'potential',\n",
       "  'in',\n",
       "  'the',\n",
       "  'healthcare',\n",
       "  'sectors',\n",
       "  'clinical',\n",
       "  'practices',\n",
       "  'translational',\n",
       "  'medical',\n",
       "  'and',\n",
       "  'biomedical',\n",
       "  'research',\n",
       "  'after',\n",
       "  'the',\n",
       "  'first',\n",
       "  'case',\n",
       "  'was',\n",
       "  'detected',\n",
       "  'in',\n",
       "  'china',\n",
       "  'on',\n",
       "  'december',\n",
       "  '31st',\n",
       "  '2019',\n",
       "  'it',\n",
       "  'was',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'program',\n",
       "  'developed',\n",
       "  'by',\n",
       "  'bluedot',\n",
       "  'that',\n",
       "  'alerted',\n",
       "  'the',\n",
       "  'world',\n",
       "  'about',\n",
       "  'the',\n",
       "  'pandemic',\n",
       "  'it',\n",
       "  'was',\n",
       "  'quick',\n",
       "  'to',\n",
       "  'realise',\n",
       "  'ais',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'analyse',\n",
       "  'large',\n",
       "  'chunks',\n",
       "  'of',\n",
       "  'data',\n",
       "  'could',\n",
       "  'help',\n",
       "  'in',\n",
       "  'detecting',\n",
       "  'patterns',\n",
       "  'and',\n",
       "  'identifying',\n",
       "  'and',\n",
       "  'tracking',\n",
       "  'the',\n",
       "  'possible',\n",
       "  'carriers',\n",
       "  'of',\n",
       "  'the',\n",
       "  'virus',\n",
       "  'many',\n",
       "  'tracing',\n",
       "  'apps',\n",
       "  'use',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'tabs',\n",
       "  'on',\n",
       "  'the',\n",
       "  'people',\n",
       "  'who',\n",
       "  'have',\n",
       "  'been',\n",
       "  'infected',\n",
       "  'and',\n",
       "  'prevent',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'crossinfection',\n",
       "  'by',\n",
       "  'using',\n",
       "  'ai',\n",
       "  'algorithms',\n",
       "  'that',\n",
       "  'can',\n",
       "  'track',\n",
       "  'patterns',\n",
       "  'and',\n",
       "  'extract',\n",
       "  'some',\n",
       "  'features',\n",
       "  'to',\n",
       "  'classify',\n",
       "  'or',\n",
       "  'categorise',\n",
       "  'them',\n",
       "  'so',\n",
       "  'how',\n",
       "  'does',\n",
       "  'ai',\n",
       "  'do',\n",
       "  'that?',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'a',\n",
       "  'sophisticated',\n",
       "  'ai',\n",
       "  'that',\n",
       "  'works',\n",
       "  'on',\n",
       "  'cloud',\n",
       "  'computing',\n",
       "  'and',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'has',\n",
       "  'prominently',\n",
       "  'contributed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'healthcare',\n",
       "  'sector',\n",
       "  'on',\n",
       "  'a',\n",
       "  'global',\n",
       "  'level',\n",
       "  'being',\n",
       "  'a',\n",
       "  'conversational',\n",
       "  'ai',\n",
       "  'since',\n",
       "  '2013',\n",
       "  'watson',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'in',\n",
       "  'recommending',\n",
       "  'treatments',\n",
       "  'to',\n",
       "  'patients',\n",
       "  'suffering',\n",
       "  'from',\n",
       "  'cancer',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'that',\n",
       "  'they',\n",
       "  'get',\n",
       "  'the',\n",
       "  'best',\n",
       "  'treatment',\n",
       "  'at',\n",
       "  'optimum',\n",
       "  'costs',\n",
       "  'researchers',\n",
       "  'at',\n",
       "  'google',\n",
       "  'inc',\n",
       "  'showed',\n",
       "  'that',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'system',\n",
       "  'can',\n",
       "  'be',\n",
       "  'trained',\n",
       "  'on',\n",
       "  'thousands',\n",
       "  'of',\n",
       "  'images',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'physicianlevel',\n",
       "  'sensitivity',\n",
       "  'by',\n",
       "  'identifying',\n",
       "  'the',\n",
       "  'molecular',\n",
       "  'patterns',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'disease',\n",
       "  'status',\n",
       "  'and',\n",
       "  'its',\n",
       "  'subtypes',\n",
       "  'gene',\n",
       "  'expression',\n",
       "  'and',\n",
       "  'protein',\n",
       "  'abundance',\n",
       "  'levels',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'methods',\n",
       "  'can',\n",
       "  'detect',\n",
       "  'fatal',\n",
       "  'diseases',\n",
       "  'like',\n",
       "  'cancer',\n",
       "  'at',\n",
       "  'an',\n",
       "  'early',\n",
       "  'stage',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'ml',\n",
       "  'techniques',\n",
       "  'focus',\n",
       "  'mainly',\n",
       "  'on',\n",
       "  'analyzing',\n",
       "  'structured',\n",
       "  'data',\n",
       "  'which',\n",
       "  'can',\n",
       "  'further',\n",
       "  'help',\n",
       "  'in',\n",
       "  'clustering',\n",
       "  'patients',\n",
       "  'traits',\n",
       "  'and',\n",
       "  'infer',\n",
       "  'the',\n",
       "  'probability',\n",
       "  'of',\n",
       "  'disease',\n",
       "  'outcomes',\n",
       "  'since',\n",
       "  'patient',\n",
       "  'traits',\n",
       "  'mainly',\n",
       "  'include',\n",
       "  'masses',\n",
       "  'of',\n",
       "  'data',\n",
       "  'relating',\n",
       "  'to',\n",
       "  'age',\n",
       "  'gender',\n",
       "  'disease',\n",
       "  'history',\n",
       "  'diseasespecific',\n",
       "  'data',\n",
       "  'like',\n",
       "  'diagnostic',\n",
       "  'imaging',\n",
       "  'and',\n",
       "  'gene',\n",
       "  'expressions',\n",
       "  'etc',\n",
       "  'ml',\n",
       "  'can',\n",
       "  'extract',\n",
       "  'features',\n",
       "  'from',\n",
       "  'these',\n",
       "  'data',\n",
       "  'inputs',\n",
       "  'by',\n",
       "  'constructing',\n",
       "  'data',\n",
       "  'analytical',\n",
       "  'algorithms',\n",
       "  'ml',\n",
       "  'algorithms',\n",
       "  'are',\n",
       "  'either',\n",
       "  'supervised',\n",
       "  'or',\n",
       "  'unsupervised',\n",
       "  'unsupervised',\n",
       "  'learning',\n",
       "  'helps',\n",
       "  'in',\n",
       "  'extracting',\n",
       "  'features',\n",
       "  'and',\n",
       "  'clustering',\n",
       "  'similar',\n",
       "  'features',\n",
       "  'together',\n",
       "  'that',\n",
       "  'further',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'early',\n",
       "  'detection',\n",
       "  'of',\n",
       "  'diseases',\n",
       "  'clustering',\n",
       "  'and',\n",
       "  'principal',\n",
       "  'component',\n",
       "  'analysis',\n",
       "  'enable',\n",
       "  'grouping',\n",
       "  'or',\n",
       "  'clustering',\n",
       "  'of',\n",
       "  'similar',\n",
       "  'traits',\n",
       "  'together',\n",
       "  'that',\n",
       "  'are',\n",
       "  'further',\n",
       "  'used',\n",
       "  'to',\n",
       "  'maximize',\n",
       "  'or',\n",
       "  'minimize',\n",
       "  'the',\n",
       "  'similarity',\n",
       "  'between',\n",
       "  'the',\n",
       "  'patients',\n",
       "  'within',\n",
       "  'or',\n",
       "  'between',\n",
       "  'the',\n",
       "  'clusters',\n",
       "  'since',\n",
       "  'patient',\n",
       "  'traits',\n",
       "  'are',\n",
       "  'recorded',\n",
       "  'in',\n",
       "  'multiple',\n",
       "  'dimensions',\n",
       "  'such',\n",
       "  'as',\n",
       "  'genes',\n",
       "  'principal',\n",
       "  'component',\n",
       "  'analysispca',\n",
       "  'creates',\n",
       "  'the',\n",
       "  'apparatus',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'these',\n",
       "  'dimensions',\n",
       "  'which',\n",
       "  'humans',\n",
       "  'could',\n",
       "  'have',\n",
       "  'not',\n",
       "  'done',\n",
       "  'alone',\n",
       "  'supervised',\n",
       "  'learning',\n",
       "  'considers',\n",
       "  'the',\n",
       "  'outcomes',\n",
       "  'of',\n",
       "  'the',\n",
       "  'subjects',\n",
       "  'together',\n",
       "  'with',\n",
       "  'the',\n",
       "  'traits',\n",
       "  'and',\n",
       "  'further',\n",
       "  'correlates',\n",
       "  'the',\n",
       "  'inputs',\n",
       "  'with',\n",
       "  'the',\n",
       "  'outputs',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'the',\n",
       "  'probability',\n",
       "  'of',\n",
       "  'getting',\n",
       "  'a',\n",
       "  'particular',\n",
       "  'clinical',\n",
       "  'event',\n",
       "  'expected',\n",
       "  'value',\n",
       "  'of',\n",
       "  'a',\n",
       "  'disease',\n",
       "  'level',\n",
       "  'or',\n",
       "  'expected',\n",
       "  'survival',\n",
       "  'time',\n",
       "  'or',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'downs',\n",
       "  'syndrome',\n",
       "  'biomarker',\n",
       "  'panels',\n",
       "  'that',\n",
       "  'are',\n",
       "  'mostly',\n",
       "  'used',\n",
       "  'to',\n",
       "  'detect',\n",
       "  'ovarian',\n",
       "  'cancer',\n",
       "  'have',\n",
       "  'outperformed',\n",
       "  'the',\n",
       "  'conventional',\n",
       "  'statistical',\n",
       "  'methods',\n",
       "  'due',\n",
       "  'to',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'this',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'ehrs',\n",
       "  'and',\n",
       "  'bayesian',\n",
       "  'networks',\n",
       "  'which',\n",
       "  'are',\n",
       "  'a',\n",
       "  'part',\n",
       "  'of',\n",
       "  'supervised',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'can',\n",
       "  'predict',\n",
       "  'clinical',\n",
       "  'outcomes',\n",
       "  'and',\n",
       "  'mortality',\n",
       "  'respectively',\n",
       "  'unstructured',\n",
       "  'data',\n",
       "  'such',\n",
       "  'as',\n",
       "  'clinical',\n",
       "  'notes',\n",
       "  'and',\n",
       "  'texts',\n",
       "  'are',\n",
       "  'converted',\n",
       "  'into',\n",
       "  'machinereadable',\n",
       "  'structured',\n",
       "  'data',\n",
       "  'with',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processingnlp',\n",
       "  'nlp',\n",
       "  'works',\n",
       "  'with',\n",
       "  'two',\n",
       "  'components',\n",
       "  'text',\n",
       "  'processing',\n",
       "  'and',\n",
       "  'classification',\n",
       "  'text',\n",
       "  'processing',\n",
       "  'helps',\n",
       "  'in',\n",
       "  'identifying',\n",
       "  'a',\n",
       "  'series',\n",
       "  'of',\n",
       "  'diseaserelevant',\n",
       "  'keywords',\n",
       "  'in',\n",
       "  'clinical',\n",
       "  'notes',\n",
       "  'and',\n",
       "  'then',\n",
       "  'through',\n",
       "  'classification',\n",
       "  'are',\n",
       "  'further',\n",
       "  'categorized',\n",
       "  'into',\n",
       "  'normal',\n",
       "  'and',\n",
       "  'abnormal',\n",
       "  'cases',\n",
       "  'chest',\n",
       "  'screening',\n",
       "  'through',\n",
       "  'ml',\n",
       "  'and',\n",
       "  'nlp',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'find',\n",
       "  'abnormalities',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lungs',\n",
       "  'and',\n",
       "  'provide',\n",
       "  'treatment',\n",
       "  'to',\n",
       "  'covid',\n",
       "  'patients',\n",
       "  'healthcare',\n",
       "  'organizations',\n",
       "  'use',\n",
       "  'nlpbased',\n",
       "  'chatbots',\n",
       "  'to',\n",
       "  'increase',\n",
       "  'interactions',\n",
       "  'with',\n",
       "  'patients',\n",
       "  'keeping',\n",
       "  'their',\n",
       "  'mental',\n",
       "  'health',\n",
       "  'and',\n",
       "  'wellness',\n",
       "  'in',\n",
       "  'check',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'a',\n",
       "  'modern',\n",
       "  'extension',\n",
       "  'of',\n",
       "  'the',\n",
       "  'classical',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'techniques',\n",
       "  'which',\n",
       "  'helps',\n",
       "  'explore',\n",
       "  'more',\n",
       "  'complex',\n",
       "  'nonlinear',\n",
       "  'patterns',\n",
       "  'in',\n",
       "  'data',\n",
       "  'using',\n",
       "  'algorithms',\n",
       "  'like',\n",
       "  'convolution',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'recurrent',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'deep',\n",
       "  'belief',\n",
       "  'network',\n",
       "  'and',\n",
       "  'deep',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'which',\n",
       "  'enables',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'clinical',\n",
       "  'prediction',\n",
       "  'when',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'genome',\n",
       "  'interpretation',\n",
       "  'deep',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'surpass',\n",
       "  'the',\n",
       "  'conventional',\n",
       "  'methods',\n",
       "  'of',\n",
       "  'logistics',\n",
       "  'regression',\n",
       "  'and',\n",
       "  'support',\n",
       "  'vector',\n",
       "  'machines',\n",
       "  'sepsis',\n",
       "  'watch',\n",
       "  'is',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'system',\n",
       "  'trained',\n",
       "  'in',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'that',\n",
       "  'holds',\n",
       "  'the',\n",
       "  'capability',\n",
       "  'to',\n",
       "  'analyze',\n",
       "  'over',\n",
       "  '32',\n",
       "  'million',\n",
       "  'data',\n",
       "  'points',\n",
       "  'to',\n",
       "  'create',\n",
       "  'a',\n",
       "  'patients',\n",
       "  'risk',\n",
       "  'score',\n",
       "  'and',\n",
       "  'identify',\n",
       "  'the',\n",
       "  'early',\n",
       "  'stages',\n",
       "  'of',\n",
       "  'sepsis',\n",
       "  'another',\n",
       "  'method',\n",
       "  'known',\n",
       "  'as',\n",
       "  'the',\n",
       "  'learningbased',\n",
       "  'optimization',\n",
       "  'of',\n",
       "  'the',\n",
       "  'under',\n",
       "  'sampling',\n",
       "  'pattern',\n",
       "  'loupe',\n",
       "  'is',\n",
       "  'based',\n",
       "  'on',\n",
       "  'integrating',\n",
       "  'full',\n",
       "  'resolution',\n",
       "  'mri',\n",
       "  'scans',\n",
       "  'with',\n",
       "  'the',\n",
       "  'convolutional',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'algorithm',\n",
       "  'which',\n",
       "  'helps',\n",
       "  'in',\n",
       "  'creating',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'reconstructions',\n",
       "  'robotic',\n",
       "  'surgery',\n",
       "  'is',\n",
       "  'widely',\n",
       "  'considered',\n",
       "  'in',\n",
       "  'most',\n",
       "  'delicate',\n",
       "  'surgeries',\n",
       "  'like',\n",
       "  'gynaecology',\n",
       "  'and',\n",
       "  'prostate',\n",
       "  'surgery',\n",
       "  'even',\n",
       "  'after',\n",
       "  'striking',\n",
       "  'the',\n",
       "  'right',\n",
       "  'balance',\n",
       "  'between',\n",
       "  'human',\n",
       "  'decisions',\n",
       "  'and',\n",
       "  'ai',\n",
       "  'precision',\n",
       "  'robotic',\n",
       "  'surgery',\n",
       "  'reduces',\n",
       "  'surgeon',\n",
       "  'efficiency',\n",
       "  'as',\n",
       "  'they',\n",
       "  'have',\n",
       "  'to',\n",
       "  'be',\n",
       "  'manually',\n",
       "  'operated',\n",
       "  'through',\n",
       "  'a',\n",
       "  'console',\n",
       "  'thus',\n",
       "  'autonomous',\n",
       "  'robotic',\n",
       "  'surgery',\n",
       "  'is',\n",
       "  'on',\n",
       "  'the',\n",
       "  'rise',\n",
       "  'with',\n",
       "  'inventions',\n",
       "  'such',\n",
       "  'as',\n",
       "  'robotic',\n",
       "  'silicon',\n",
       "  'fingers',\n",
       "  'that',\n",
       "  'mimic',\n",
       "  'the',\n",
       "  'sense',\n",
       "  'of',\n",
       "  'touch',\n",
       "  'that',\n",
       "  'surgeons',\n",
       "  'need',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'organs',\n",
       "  'cut',\n",
       "  'tissues',\n",
       "  'etc',\n",
       "  'or',\n",
       "  'robotic',\n",
       "  'catheters',\n",
       "  'that',\n",
       "  'can',\n",
       "  'navigate',\n",
       "  'whether',\n",
       "  'it',\n",
       "  'is',\n",
       "  'touching',\n",
       "  'blood',\n",
       "  'tissue',\n",
       "  'or',\n",
       "  'valve',\n",
       "  'researchers',\n",
       "  'at',\n",
       "  'childrens',\n",
       "  'national',\n",
       "  'hospital',\n",
       "  'washington',\n",
       "  'have',\n",
       "  'already',\n",
       "  'developed',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'called',\n",
       "  'smart',\n",
       "  'tissue',\n",
       "  'autonomous',\n",
       "  'robot',\n",
       "  'star',\n",
       "  'which',\n",
       "  'performs',\n",
       "  'a',\n",
       "  'colon',\n",
       "  'anastomosis',\n",
       "  'on',\n",
       "  'its',\n",
       "  'own',\n",
       "  'with',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'an',\n",
       "  'mlpowered',\n",
       "  'suturing',\n",
       "  'tool',\n",
       "  'that',\n",
       "  'automatically',\n",
       "  'detects',\n",
       "  'the',\n",
       "  'patients',\n",
       "  'breathing',\n",
       "  'pattern',\n",
       "  'to',\n",
       "  'apply',\n",
       "  'suture',\n",
       "  'at',\n",
       "  'the',\n",
       "  'correct',\n",
       "  'point',\n",
       "  'cloud',\n",
       "  'computing',\n",
       "  'in',\n",
       "  'healthcare',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'in',\n",
       "  'retrieving',\n",
       "  'and',\n",
       "  'sharing',\n",
       "  'medical',\n",
       "  'records',\n",
       "  'safely',\n",
       "  'with',\n",
       "  'a',\n",
       "  'reduction',\n",
       "  'in',\n",
       "  'maintenance',\n",
       "  'costs',\n",
       "  'through',\n",
       "  'this',\n",
       "  'technology',\n",
       "  'doctors',\n",
       "  'and',\n",
       "  'various',\n",
       "  'healthcare',\n",
       "  'workers',\n",
       "  'have',\n",
       "  'access',\n",
       "  'to',\n",
       "  'detailed',\n",
       "  'patient',\n",
       "  'data',\n",
       "  'that',\n",
       "  'helps',\n",
       "  'in',\n",
       "  'speeding',\n",
       "  'up',\n",
       "  'analysis',\n",
       "  'ultimately',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'better',\n",
       "  'care',\n",
       "  'in',\n",
       "  'the',\n",
       "  'form',\n",
       "  'of',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'information',\n",
       "  'medications',\n",
       "  'and',\n",
       "  'therapies',\n",
       "  'how',\n",
       "  'can',\n",
       "  'it',\n",
       "  'help',\n",
       "  'in',\n",
       "  'biomedical',\n",
       "  'research?',\n",
       "  'since',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'analyze',\n",
       "  'literature',\n",
       "  'beyond',\n",
       "  'readability',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'to',\n",
       "  'concise',\n",
       "  'biomedical',\n",
       "  'research',\n",
       "  'with',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'ml',\n",
       "  'algorithms',\n",
       "  ...]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a7755",
   "metadata": {},
   "source": [
    "### converting to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "890401a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'in', 'healthcare', 'to', 'improve', 'patient', 'outcomes', 'introduction', 'if', 'anything', 'kills', 'over', '10', 'million', 'people', 'in', 'the', 'next', 'few', 'decades', 'it', 'will', 'be', 'a', 'highly', 'infectious', 'virus', 'rather', 'than', 'a', 'war', 'not', 'missiles', 'but', 'microbes', 'bill', 'gatess', 'remarks', 'at', 'a', 'ted', 'conference', 'in', '2014', 'right', 'after', 'the', 'world', 'had', 'avoided', 'the', 'ebola', 'outbreak', 'when', 'the', 'new', 'unprecedented', 'invisible', 'virus', 'hit', 'us', 'it', 'met', 'an', 'overwhelmed', 'and', 'unprepared', 'healthcare', 'system', 'and', 'oblivious', 'population', 'this', 'public', 'health', 'emergency', 'demonstrated', 'our', 'lack', 'of', 'scientific', 'consideration', 'and', 'underlined', 'the', 'alarming', 'need', 'for', 'robust', 'innovations', 'in', 'our', 'health', 'and', 'medical', 'facilities', 'for', 'the', 'past', 'few', 'years', 'artificial', 'intelligence', 'has', 'proven', 'to', 'be', 'of', 'tangible', 'potential', 'in', 'the', 'healthcare', 'sectors', 'clinical', 'practices', 'translational', 'medical', 'and', 'biomedical', 'research', 'after', 'the', 'first', 'case', 'was', 'detected', 'in', 'china', 'on', 'december', '31st', '2019', 'it', 'was', 'an', 'ai', 'program', 'developed', 'by', 'bluedot', 'that', 'alerted', 'the', 'world', 'about', 'the', 'pandemic', 'it', 'was', 'quick', 'to', 'realise', 'ais', 'ability', 'to', 'analyse', 'large', 'chunks', 'of', 'data', 'could', 'help', 'in', 'detecting', 'patterns', 'and', 'identifying', 'and', 'tracking', 'the', 'possible', 'carriers', 'of', 'the', 'virus', 'many', 'tracing', 'apps', 'use', 'ai', 'to', 'keep', 'tabs', 'on', 'the', 'people', 'who', 'have', 'been', 'infected', 'and', 'prevent', 'the', 'risk', 'of', 'crossinfection', 'by', 'using', 'ai', 'algorithms', 'that', 'can', 'track', 'patterns', 'and', 'extract', 'some', 'features', 'to', 'classify', 'or', 'categorise', 'them', 'so', 'how', 'does', 'ai', 'do', 'that?', 'ibm', 'watson', 'a', 'sophisticated', 'ai', 'that', 'works', 'on', 'cloud', 'computing', 'and', 'natural', 'language', 'processing', 'has', 'prominently', 'contributed', 'to', 'the', 'healthcare', 'sector', 'on', 'a', 'global', 'level', 'being', 'a', 'conversational', 'ai', 'since', '2013', 'watson', 'has', 'helped', 'in', 'recommending', 'treatments', 'to', 'patients', 'suffering', 'from', 'cancer', 'to', 'ensure', 'that', 'they', 'get', 'the', 'best', 'treatment', 'at', 'optimum', 'costs', 'researchers', 'at', 'google', 'inc', 'showed', 'that', 'an', 'ai', 'system', 'can', 'be', 'trained', 'on', 'thousands', 'of', 'images', 'to', 'achieve', 'physicianlevel', 'sensitivity', 'by', 'identifying', 'the', 'molecular', 'patterns', 'associated', 'with', 'disease', 'status', 'and', 'its', 'subtypes', 'gene', 'expression', 'and', 'protein', 'abundance', 'levels', 'machine', 'learning', 'methods', 'can', 'detect', 'fatal', 'diseases', 'like', 'cancer', 'at', 'an', 'early', 'stage', 'machine', 'learning', 'ml', 'techniques', 'focus', 'mainly', 'on', 'analyzing', 'structured', 'data', 'which', 'can', 'further', 'help', 'in', 'clustering', 'patients', 'traits', 'and', 'infer', 'the', 'probability', 'of', 'disease', 'outcomes', 'since', 'patient', 'traits', 'mainly', 'include', 'masses', 'of', 'data', 'relating', 'to', 'age', 'gender', 'disease', 'history', 'diseasespecific', 'data', 'like', 'diagnostic', 'imaging', 'and', 'gene', 'expressions', 'etc', 'ml', 'can', 'extract', 'features', 'from', 'these', 'data', 'inputs', 'by', 'constructing', 'data', 'analytical', 'algorithms', 'ml', 'algorithms', 'are', 'either', 'supervised', 'or', 'unsupervised', 'unsupervised', 'learning', 'helps', 'in', 'extracting', 'features', 'and', 'clustering', 'similar', 'features', 'together', 'that', 'further', 'leads', 'to', 'early', 'detection', 'of', 'diseases', 'clustering', 'and', 'principal', 'component', 'analysis', 'enable', 'grouping', 'or', 'clustering', 'of', 'similar', 'traits', 'together', 'that', 'are', 'further', 'used', 'to', 'maximize', 'or', 'minimize', 'the', 'similarity', 'between', 'the', 'patients', 'within', 'or', 'between', 'the', 'clusters', 'since', 'patient', 'traits', 'are', 'recorded', 'in', 'multiple', 'dimensions', 'such', 'as', 'genes', 'principal', 'component', 'analysispca', 'creates', 'the', 'apparatus', 'to', 'reduce', 'these', 'dimensions', 'which', 'humans', 'could', 'have', 'not', 'done', 'alone', 'supervised', 'learning', 'considers', 'the', 'outcomes', 'of', 'the', 'subjects', 'together', 'with', 'the', 'traits', 'and', 'further', 'correlates', 'the', 'inputs', 'with', 'the', 'outputs', 'to', 'predict', 'the', 'probability', 'of', 'getting', 'a', 'particular', 'clinical', 'event', 'expected', 'value', 'of', 'a', 'disease', 'level', 'or', 'expected', 'survival', 'time', 'or', 'risk', 'of', 'downs', 'syndrome', 'biomarker', 'panels', 'that', 'are', 'mostly', 'used', 'to', 'detect', 'ovarian', 'cancer', 'have', 'outperformed', 'the', 'conventional', 'statistical', 'methods', 'due', 'to', 'machine', 'learning', 'in', 'addition', 'to', 'this', 'the', 'use', 'of', 'ehrs', 'and', 'bayesian', 'networks', 'which', 'are', 'a', 'part', 'of', 'supervised', 'machine', 'learning', 'algorithms', 'can', 'predict', 'clinical', 'outcomes', 'and', 'mortality', 'respectively', 'unstructured', 'data', 'such', 'as', 'clinical', 'notes', 'and', 'texts', 'are', 'converted', 'into', 'machinereadable', 'structured', 'data', 'with', 'the', 'help', 'of', 'natural', 'language', 'processingnlp', 'nlp', 'works', 'with', 'two', 'components', 'text', 'processing', 'and', 'classification', 'text', 'processing', 'helps', 'in', 'identifying', 'a', 'series', 'of', 'diseaserelevant', 'keywords', 'in', 'clinical', 'notes', 'and', 'then', 'through', 'classification', 'are', 'further', 'categorized', 'into', 'normal', 'and', 'abnormal', 'cases', 'chest', 'screening', 'through', 'ml', 'and', 'nlp', 'has', 'helped', 'find', 'abnormalities', 'in', 'the', 'lungs', 'and', 'provide', 'treatment', 'to', 'covid', 'patients', 'healthcare', 'organizations', 'use', 'nlpbased', 'chatbots', 'to', 'increase', 'interactions', 'with', 'patients', 'keeping', 'their', 'mental', 'health', 'and', 'wellness', 'in', 'check', 'deep', 'learning', 'is', 'a', 'modern', 'extension', 'of', 'the', 'classical', 'neural', 'network', 'techniques', 'which', 'helps', 'explore', 'more', 'complex', 'nonlinear', 'patterns', 'in', 'data', 'using', 'algorithms', 'like', 'convolution', 'neural', 'network', 'recurrent', 'neural', 'network', 'deep', 'belief', 'network', 'and', 'deep', 'neural', 'network', 'which', 'enables', 'more', 'accurate', 'clinical', 'prediction', 'when', 'it', 'comes', 'to', 'genome', 'interpretation', 'deep', 'neural', 'networks', 'surpass', 'the', 'conventional', 'methods', 'of', 'logistics', 'regression', 'and', 'support', 'vector', 'machines', 'sepsis', 'watch', 'is', 'an', 'ai', 'system', 'trained', 'in', 'deep', 'learning', 'algorithms', 'that', 'holds', 'the', 'capability', 'to', 'analyze', 'over', '32', 'million', 'data', 'points', 'to', 'create', 'a', 'patients', 'risk', 'score', 'and', 'identify', 'the', 'early', 'stages', 'of', 'sepsis', 'another', 'method', 'known', 'as', 'the', 'learningbased', 'optimization', 'of', 'the', 'under', 'sampling', 'pattern', 'loupe', 'is', 'based', 'on', 'integrating', 'full', 'resolution', 'mri', 'scans', 'with', 'the', 'convolutional', 'neural', 'network', 'algorithm', 'which', 'helps', 'in', 'creating', 'more', 'accurate', 'reconstructions', 'robotic', 'surgery', 'is', 'widely', 'considered', 'in', 'most', 'delicate', 'surgeries', 'like', 'gynaecology', 'and', 'prostate', 'surgery', 'even', 'after', 'striking', 'the', 'right', 'balance', 'between', 'human', 'decisions', 'and', 'ai', 'precision', 'robotic', 'surgery', 'reduces', 'surgeon', 'efficiency', 'as', 'they', 'have', 'to', 'be', 'manually', 'operated', 'through', 'a', 'console', 'thus', 'autonomous', 'robotic', 'surgery', 'is', 'on', 'the', 'rise', 'with', 'inventions', 'such', 'as', 'robotic', 'silicon', 'fingers', 'that', 'mimic', 'the', 'sense', 'of', 'touch', 'that', 'surgeons', 'need', 'to', 'identify', 'organs', 'cut', 'tissues', 'etc', 'or', 'robotic', 'catheters', 'that', 'can', 'navigate', 'whether', 'it', 'is', 'touching', 'blood', 'tissue', 'or', 'valve', 'researchers', 'at', 'childrens', 'national', 'hospital', 'washington', 'have', 'already', 'developed', 'an', 'ai', 'called', 'smart', 'tissue', 'autonomous', 'robot', 'star', 'which', 'performs', 'a', 'colon', 'anastomosis', 'on', 'its', 'own', 'with', 'the', 'help', 'of', 'an', 'mlpowered', 'suturing', 'tool', 'that', 'automatically', 'detects', 'the', 'patients', 'breathing', 'pattern', 'to', 'apply', 'suture', 'at', 'the', 'correct', 'point', 'cloud', 'computing', 'in', 'healthcare', 'has', 'helped', 'in', 'retrieving', 'and', 'sharing', 'medical', 'records', 'safely', 'with', 'a', 'reduction', 'in', 'maintenance', 'costs', 'through', 'this', 'technology', 'doctors', 'and', 'various', 'healthcare', 'workers', 'have', 'access', 'to', 'detailed', 'patient', 'data', 'that', 'helps', 'in', 'speeding', 'up', 'analysis', 'ultimately', 'leading', 'to', 'better', 'care', 'in', 'the', 'form', 'of', 'more', 'accurate', 'information', 'medications', 'and', 'therapies', 'how', 'can', 'it', 'help', 'in', 'biomedical', 'research?', 'since', 'ai', 'can', 'analyze', 'literature', 'beyond', 'readability', 'it', 'can', 'be', 'used', 'to', 'concise', 'biomedical', 'research', 'with', 'the', 'help', 'of', 'ml', 'algorithms', 'and', 'nlp', 'ai', 'can', 'accelerate', 'screening', 'and', 'indexing', 'of', 'biomedical', 'research', 'by', 'ranking', 'the', 'literature', 'of', 'interest', 'which', 'allows', 'researchers', 'to', 'formulate', 'and', 'test', 'scientific', 'hypotheses', 'far', 'more', 'precisely', 'and', 'quickly', 'taking', 'it', 'to', 'the', 'next', 'level', 'ai', 'systems', 'like', 'the', 'computational', 'modelling', 'assistant', 'cma', 'helps', 'researchers', 'to', 'construct', 'simulation', 'models', 'from', 'the', 'concepts', 'they', 'have', 'in', 'mind', 'such', 'innovations', 'have', 'majorly', 'contributed', 'to', 'topics', 'such', 'as', 'tumour', 'suppressor', 'mechanisms', 'and', 'proteinprotein', 'interaction', 'information', 'extraction', 'ai', 'as', 'precision', 'medicine', 'since', 'precision', 'medicine', 'focuses', 'on', 'healthcare', 'interventions', 'to', 'individuals', 'or', 'groups', 'of', 'patients', 'based', 'on', 'their', 'profile', 'the', 'various', 'ai', 'devices', 'pave', 'the', 'way', 'to', 'practice', 'it', 'more', 'efficiently', 'with', 'the', 'help', 'of', 'ml', 'complex', 'algorithms', 'like', 'large', 'datasets', 'can', 'be', 'used', 'to', 'predict', 'and', 'create', 'an', 'optimal', 'treatment', 'strategy', 'deep', 'learning', 'and', 'neural', 'networks', 'can', 'be', 'used', 'to', 'process', 'data', 'in', 'healthcare', 'apps', 'and', 'keep', 'a', 'close', 'watch', 'on', 'the', 'patients', 'emotional', 'state', 'food', 'intake', 'or', 'health', 'monitoring', 'omics', 'refers', 'to', 'the', 'collective', 'technologies', 'that', 'help', 'in', 'exploring', 'the', 'roles', 'relationships', 'of', 'various', 'branches', 'ending', 'with', 'the', 'suffix', 'omics', 'such', 'as', 'genomics', 'proteomics', 'etc', 'omicsbased', 'tests', 'based', 'on', 'machine', 'learning', 'algorithms', 'help', 'find', 'correlations', 'and', 'predict', 'treatment', 'responses', 'ultimately', 'creating', 'personalized', 'treatments', 'for', 'individual', 'patients', 'how', 'it', 'helps', 'in', 'psychology', 'and', 'neuro', 'patients', 'for', 'psychologists', 'studying', 'creativity', 'ai', 'is', 'promising', 'new', 'classes', 'of', 'experiments', 'that', 'are', 'developing', 'data', 'structures', 'and', 'programs', 'and', 'exploring', 'novel', 'theories', 'on', 'a', 'new', 'horizon', 'studies', 'show', 'that', 'ai', 'can', 'conduct', 'therapy', 'sessions', 'etherapy', 'sessions', 'and', 'assessments', 'autonomously', 'also', 'assisting', 'human', 'practitioners', 'before', 'during', 'or', 'after', 'sessions', 'the', 'detection', 'and', 'computational', 'analysis', 'of', 'psychological', 'signal', 'project', 'uses', 'ml', 'computer', 'vision', 'and', 'nlp', 'to', 'analyze', 'language', 'physical', 'gestures', 'and', 'social', 'signals', 'to', 'identify', 'cues', 'for', 'human', 'distress', 'this', 'groundbreaking', 'technology', 'assesses', 'soldiers', 'returning', 'from', 'combat', 'and', 'recognizes', 'those', 'who', 'require', 'further', 'mental', 'health', 'support', 'in', 'the', 'future', 'it', 'will', 'combine', 'data', 'captured', 'during', 'facetoface', 'interviews', 'with', 'information', 'on', 'sleeping', 'eating', 'and', 'online', 'behaviours', 'for', 'a', 'complete', 'patient', 'view', 'stroke', 'identification', 'stroke', 'is', 'another', 'frequently', 'occurring', 'disease', 'that', 'affects', 'more', 'than', '500', 'million', 'people', 'worldwide', 'thrombus', 'in', 'the', 'vessel', 'cerebral', 'infarction', 'is', 'the', 'major', 'about', '85', 'cause', 'of', 'stroke', 'occurrence', 'in', 'recent', 'years', 'ai', 'techniques', 'have', 'been', 'used', 'in', 'numerous', 'strokerelated', 'studies', 'as', 'early', 'detection', 'and', 'timely', 'treatment', 'along', 'with', 'efficient', 'outcome', 'prediction', 'can', 'help', 'solve', 'the', 'problem', 'with', 'ai', 'at', 'our', 'disposal', 'large', 'amounts', 'of', 'data', 'with', 'rich', 'information', 'more', 'complications', 'and', 'reallife', 'clinical', 'questions', 'can', 'be', 'addressed', 'in', 'this', 'arena', 'currently', 'two', 'ml', 'algorithms', 'genetic', 'fuzzy', 'finite', 'state', 'machine', 'and', 'pca', 'were', 'implemented', 'to', 'build', 'a', 'model', 'building', 'solution', 'these', 'include', 'a', 'human', 'activity', 'recognition', 'stage', 'and', 'a', 'stroke', 'onset', 'detection', 'stage', 'an', 'alert', 'stroke', 'message', 'is', 'activated', 'as', 'soon', 'as', 'a', 'movement', 'significantly', 'different', 'from', 'the', 'normal', 'pattern', 'is', 'recorded', 'ml', 'methods', 'have', 'been', 'applied', 'to', 'neuroimaging', 'data', 'to', 'assist', 'disease', 'evaluation', 'and', 'predicting', 'stroke', 'treatment', 'for', 'the', 'diagnosis', 'patient', 'monitoring', 'today', 'the', 'market', 'for', 'aibased', 'patient', 'monitoring', 'is', 'impressive', 'and', 'monetarily', 'enticing', 'it', 'is', 'evolving', 'with', 'artificial', 'sensors', 'smart', 'technologies', 'and', 'explores', 'everything', 'from', 'braincomputer', 'interfaces', 'to', 'nanorobotics', 'companies', 'with', 'their', 'smartwatches', 'have', 'engaged', 'people', 'to', 'perform', 'remote', 'monitoring', 'even', 'when', 'they', 'are', 'not', 'patients', 'an', 'obvious', 'place', 'to', 'start', 'is', 'with', 'wearable', 'and', 'embedded', 'sensors', 'glucose', 'monitors', 'pulse', 'monitors', 'oximeters', 'and', 'ecg', 'monitors', 'with', 'patient', 'monitoring', 'becoming', 'crucial', 'ai', 'finds', 'numerous', 'applications', 'in', 'chronic', 'conditions', 'intensive', 'care', 'units', 'operating', 'rooms', 'emergency', 'rooms', 'and', 'cardiac', 'wards', 'where', 'timeless', 'clinical', 'decisionmaking', 'can', 'be', 'measured', 'in', 'seconds', 'more', 'advances', 'have', 'started', 'to', 'gain', 'traction', 'like', 'smart', 'prosthetics', 'and', 'implants', 'these', 'play', 'an', 'impeccable', 'role', 'in', 'patient', 'management', 'postsurgery', 'or', 'rehabilitation', 'demographics', 'laboratory', 'results', 'and', 'vital', 'signs', 'can', 'also', 'be', 'used', 'to', 'predict', 'cardiac', 'arrest', 'transfer', 'into', 'the', 'intensive', 'care', 'unit', 'or', 'even', 'death', 'in', 'addition', 'an', 'interpretable', 'machinelearning', 'model', 'can', 'assist', 'anesthesiologists', 'in', 'predicting', 'hypoxaemia', 'events', 'during', 'surgery', 'this', 'suggests', 'that', 'with', 'deeplearning', 'algorithms', 'raw', 'patientmonitoring', 'data', 'could', 'be', 'better', 'used', 'to', 'avoid', 'information', 'overload', 'and', 'alert', 'overload', 'while', 'enabling', 'more', 'accurate', 'clinical', 'prediction', 'and', 'timely', 'decisionmaking', 'conclusion', 'considering', 'the', 'vast', 'range', 'of', 'tasks', 'that', 'an', 'ai', 'can', 'do', 'it', 'is', 'evident', 'that', 'it', 'holds', 'deep', 'potential', 'in', 'improving', 'patient', 'outcomes', 'to', 'skyrocketing', 'levels', 'using', 'sophisticated', 'algorithms', 'ai', 'can', 'bring', 'a', 'revolution', 'in', 'the', 'healthcare', 'sector', 'even', 'after', 'facing', 'challenges', 'like', 'whether', 'the', 'technology', 'will', 'be', 'able', 'to', 'deliver', 'the', 'promises', 'ethical', 'measures', 'training', 'physicians', 'to', 'use', 'it', 'standard', 'regulations', 'etc', 'the', 'role', 'of', 'ai', 'in', 'transforming', 'the', 'clinical', 'practices', 'cannot', 'be', 'ignored', 'the', 'biggest', 'challenge', 'is', 'the', 'integration', 'of', 'ai', 'in', 'daily', 'practice', 'all', 'of', 'these', 'can', 'be', 'overcome', 'and', 'within', 'that', 'period', 'the', 'technologies', 'will', 'mature', 'making', 'the', 'system', 'far', 'more', 'enhanced', 'and', 'effective']\n"
     ]
    }
   ],
   "source": [
    "# remove single bracket from list with double brackets\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(tk_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "715b48ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683dda5",
   "metadata": {},
   "source": [
    "# Removing the stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf5908",
   "metadata": {},
   "source": [
    "### I combined all the given seven stopword text files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db15954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bb3047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHNSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WILLIAMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BROWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     SMITH\n",
       "1   JOHNSON\n",
       "2  WILLIAMS\n",
       "3     JONES\n",
       "4     BROWN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SW_list = pd.read_csv(\"C:/Users/hrush/Downloads/SW_LIST.txt\",header=None)\n",
    "SW_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8117a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             smith\n",
       "1           johnson\n",
       "2          williams\n",
       "3             jones\n",
       "4             brown\n",
       "            ...    \n",
       "14102         yours\n",
       "14103      yourself\n",
       "14104    yourselves\n",
       "14105             z\n",
       "14106          zero\n",
       "Name: 0, Length: 14107, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalising the cases\n",
    "SW_list=SW_list[0].str.lower()\n",
    "SW_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d450e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smith',\n",
       " 'johnson',\n",
       " 'williams',\n",
       " 'jones',\n",
       " 'brown',\n",
       " 'davis',\n",
       " 'miller',\n",
       " 'wilson',\n",
       " 'moore',\n",
       " 'taylor',\n",
       " 'anderson',\n",
       " 'thomas',\n",
       " 'jackson',\n",
       " 'white',\n",
       " 'harris',\n",
       " 'martin',\n",
       " 'thompson',\n",
       " 'garcia',\n",
       " 'martinez',\n",
       " 'robinson',\n",
       " 'clark',\n",
       " 'rodriguez',\n",
       " 'lewis',\n",
       " 'lee',\n",
       " 'walker',\n",
       " 'hall',\n",
       " 'allen',\n",
       " 'young',\n",
       " 'hernandez',\n",
       " 'king',\n",
       " 'wright',\n",
       " 'lopez',\n",
       " 'hill',\n",
       " 'scott',\n",
       " 'green',\n",
       " 'adams',\n",
       " 'baker',\n",
       " 'gonzalez',\n",
       " 'nelson',\n",
       " 'carter',\n",
       " 'mitchell',\n",
       " 'perez',\n",
       " 'roberts',\n",
       " 'turner',\n",
       " 'phillips',\n",
       " 'campbell',\n",
       " 'parker',\n",
       " 'evans',\n",
       " 'edwards',\n",
       " 'collins',\n",
       " 'stewart',\n",
       " 'sanchez',\n",
       " 'morris',\n",
       " 'rogers',\n",
       " 'reed',\n",
       " 'cook',\n",
       " 'morgan',\n",
       " 'bell',\n",
       " 'murphy',\n",
       " 'bailey',\n",
       " 'rivera',\n",
       " 'cooper',\n",
       " 'richardson',\n",
       " 'cox',\n",
       " 'howard',\n",
       " 'ward',\n",
       " 'torres',\n",
       " 'peterson',\n",
       " 'gray',\n",
       " 'ramirez',\n",
       " 'james',\n",
       " 'watson',\n",
       " 'brooks',\n",
       " 'kelly',\n",
       " 'sanders',\n",
       " 'price',\n",
       " 'bennett',\n",
       " 'wood',\n",
       " 'barnes',\n",
       " 'ross',\n",
       " 'henderson',\n",
       " 'coleman',\n",
       " 'jenkins',\n",
       " 'perry',\n",
       " 'powell',\n",
       " 'long',\n",
       " 'patterson',\n",
       " 'hughes',\n",
       " 'flores',\n",
       " 'washington',\n",
       " 'butler',\n",
       " 'simmons',\n",
       " 'foster',\n",
       " 'gonzales',\n",
       " 'bryant',\n",
       " 'alexander',\n",
       " 'russell',\n",
       " 'griffin',\n",
       " 'diaz',\n",
       " 'hayes',\n",
       " 'myers',\n",
       " 'ford',\n",
       " 'hamilton',\n",
       " 'graham',\n",
       " 'sullivan',\n",
       " 'wallace',\n",
       " 'woods',\n",
       " 'cole',\n",
       " 'west',\n",
       " 'jordan',\n",
       " 'owens',\n",
       " 'reynolds',\n",
       " 'fisher',\n",
       " 'ellis',\n",
       " 'harrison',\n",
       " 'gibson',\n",
       " 'mcdonald',\n",
       " 'cruz',\n",
       " 'marshall',\n",
       " 'ortiz',\n",
       " 'gomez',\n",
       " 'murray',\n",
       " 'freeman',\n",
       " 'wells',\n",
       " 'webb',\n",
       " 'simpson',\n",
       " 'stevens',\n",
       " 'tucker',\n",
       " 'porter',\n",
       " 'hunter',\n",
       " 'hicks',\n",
       " 'crawford',\n",
       " 'henry',\n",
       " 'boyd',\n",
       " 'mason',\n",
       " 'morales',\n",
       " 'kennedy',\n",
       " 'warren',\n",
       " 'dixon',\n",
       " 'ramos',\n",
       " 'reyes',\n",
       " 'burns',\n",
       " 'gordon',\n",
       " 'shaw',\n",
       " 'holmes',\n",
       " 'rice',\n",
       " 'robertson',\n",
       " 'hunt',\n",
       " 'black',\n",
       " 'daniels',\n",
       " 'palmer',\n",
       " 'mills',\n",
       " 'nichols',\n",
       " 'grant',\n",
       " 'knight',\n",
       " 'ferguson',\n",
       " 'rose',\n",
       " 'stone',\n",
       " 'hawkins',\n",
       " 'dunn',\n",
       " 'perkins',\n",
       " 'hudson',\n",
       " 'spencer',\n",
       " 'gardner',\n",
       " 'stephens',\n",
       " 'payne',\n",
       " 'pierce',\n",
       " 'berry',\n",
       " 'matthews',\n",
       " 'arnold',\n",
       " 'wagner',\n",
       " 'willis',\n",
       " 'ray',\n",
       " 'watkins',\n",
       " 'olson',\n",
       " 'carroll',\n",
       " 'duncan',\n",
       " 'snyder',\n",
       " 'hart',\n",
       " 'cunningham',\n",
       " 'bradley',\n",
       " 'lane',\n",
       " 'andrews',\n",
       " 'ruiz',\n",
       " 'harper',\n",
       " 'fox',\n",
       " 'riley',\n",
       " 'armstrong',\n",
       " 'carpenter',\n",
       " 'weaver',\n",
       " 'greene',\n",
       " 'lawrence',\n",
       " 'elliott',\n",
       " 'chavez',\n",
       " 'sims',\n",
       " 'austin',\n",
       " 'peters',\n",
       " 'kelley',\n",
       " 'franklin',\n",
       " 'lawson',\n",
       " 'fields',\n",
       " 'gutierrez',\n",
       " 'ryan',\n",
       " 'schmidt',\n",
       " 'carr',\n",
       " 'vasquez',\n",
       " 'castillo',\n",
       " 'wheeler',\n",
       " 'chapman',\n",
       " 'oliver',\n",
       " 'montgomery',\n",
       " 'richards',\n",
       " 'williamson',\n",
       " 'johnston',\n",
       " 'banks',\n",
       " 'meyer',\n",
       " 'bishop',\n",
       " 'mccoy',\n",
       " 'howell',\n",
       " 'alvarez',\n",
       " 'morrison',\n",
       " 'hansen',\n",
       " 'fernandez',\n",
       " 'garza',\n",
       " 'harvey',\n",
       " 'little',\n",
       " 'burton',\n",
       " 'stanley',\n",
       " 'nguyen',\n",
       " 'george',\n",
       " 'jacobs',\n",
       " 'reid',\n",
       " 'kim',\n",
       " 'fuller',\n",
       " 'lynch',\n",
       " 'dean',\n",
       " 'gilbert',\n",
       " 'garrett',\n",
       " 'romero',\n",
       " 'welch',\n",
       " 'larson',\n",
       " 'frazier',\n",
       " 'burke',\n",
       " 'hanson',\n",
       " 'day',\n",
       " 'mendoza',\n",
       " 'moreno',\n",
       " 'bowman',\n",
       " 'medina',\n",
       " 'fowler',\n",
       " 'brewer',\n",
       " 'hoffman',\n",
       " 'carlson',\n",
       " 'silva',\n",
       " 'pearson',\n",
       " 'holland',\n",
       " 'douglas',\n",
       " 'fleming',\n",
       " 'jensen',\n",
       " 'vargas',\n",
       " 'byrd',\n",
       " 'davidson',\n",
       " 'hopkins',\n",
       " 'may',\n",
       " 'terry',\n",
       " 'herrera',\n",
       " 'wade',\n",
       " 'soto',\n",
       " 'walters',\n",
       " 'curtis',\n",
       " 'neal',\n",
       " 'caldwell',\n",
       " 'lowe',\n",
       " 'jennings',\n",
       " 'barnett',\n",
       " 'graves',\n",
       " 'jimenez',\n",
       " 'horton',\n",
       " 'shelton',\n",
       " 'barrett',\n",
       " 'obrien',\n",
       " 'castro',\n",
       " 'sutton',\n",
       " 'gregory',\n",
       " 'mckinney',\n",
       " 'lucas',\n",
       " 'miles',\n",
       " 'craig',\n",
       " 'rodriquez',\n",
       " 'chambers',\n",
       " 'holt',\n",
       " 'lambert',\n",
       " 'fletcher',\n",
       " 'watts',\n",
       " 'bates',\n",
       " 'hale',\n",
       " 'rhodes',\n",
       " 'pena',\n",
       " 'beck',\n",
       " 'newman',\n",
       " 'haynes',\n",
       " 'mcdaniel',\n",
       " 'mendez',\n",
       " 'bush',\n",
       " 'vaughn',\n",
       " 'parks',\n",
       " 'dawson',\n",
       " 'santiago',\n",
       " 'norris',\n",
       " 'hardy',\n",
       " 'love',\n",
       " 'steele',\n",
       " 'curry',\n",
       " 'powers',\n",
       " 'schultz',\n",
       " 'barker',\n",
       " 'guzman',\n",
       " 'page',\n",
       " 'munoz',\n",
       " 'ball',\n",
       " 'keller',\n",
       " 'chandler',\n",
       " 'weber',\n",
       " 'leonard',\n",
       " 'walsh',\n",
       " 'lyons',\n",
       " 'ramsey',\n",
       " 'wolfe',\n",
       " 'schneider',\n",
       " 'mullins',\n",
       " 'benson',\n",
       " 'sharp',\n",
       " 'bowen',\n",
       " 'daniel',\n",
       " 'barber',\n",
       " 'cummings',\n",
       " 'hines',\n",
       " 'baldwin',\n",
       " 'griffith',\n",
       " 'valdez',\n",
       " 'hubbard',\n",
       " 'salazar',\n",
       " 'reeves',\n",
       " 'warner',\n",
       " 'stevenson',\n",
       " 'burgess',\n",
       " 'santos',\n",
       " 'tate',\n",
       " 'cross',\n",
       " 'garner',\n",
       " 'mann',\n",
       " 'mack',\n",
       " 'moss',\n",
       " 'thornton',\n",
       " 'dennis',\n",
       " 'mcgee',\n",
       " 'farmer',\n",
       " 'delgado',\n",
       " 'aguilar',\n",
       " 'vega',\n",
       " 'glover',\n",
       " 'manning',\n",
       " 'cohen',\n",
       " 'harmon',\n",
       " 'rodgers',\n",
       " 'robbins',\n",
       " 'newton',\n",
       " 'todd',\n",
       " 'blair',\n",
       " 'higgins',\n",
       " 'ingram',\n",
       " 'reese',\n",
       " 'cannon',\n",
       " 'strickland',\n",
       " 'townsend',\n",
       " 'potter',\n",
       " 'goodwin',\n",
       " 'walton',\n",
       " 'rowe',\n",
       " 'hampton',\n",
       " 'ortega',\n",
       " 'patton',\n",
       " 'swanson',\n",
       " 'joseph',\n",
       " 'francis',\n",
       " 'goodman',\n",
       " 'maldonado',\n",
       " 'yates',\n",
       " 'becker',\n",
       " 'erickson',\n",
       " 'hodges',\n",
       " 'rios',\n",
       " 'conner',\n",
       " 'adkins',\n",
       " 'webster',\n",
       " 'norman',\n",
       " 'malone',\n",
       " 'hammond',\n",
       " 'flowers',\n",
       " 'cobb',\n",
       " 'moody',\n",
       " 'quinn',\n",
       " 'blake',\n",
       " 'maxwell',\n",
       " 'pope',\n",
       " 'floyd',\n",
       " 'osborne',\n",
       " 'paul',\n",
       " 'mccarthy',\n",
       " 'guerrero',\n",
       " 'lindsey',\n",
       " 'estrada',\n",
       " 'sandoval',\n",
       " 'gibbs',\n",
       " 'tyler',\n",
       " 'gross',\n",
       " 'fitzgerald',\n",
       " 'stokes',\n",
       " 'doyle',\n",
       " 'sherman',\n",
       " 'saunders',\n",
       " 'wise',\n",
       " 'colon',\n",
       " 'gill',\n",
       " 'alvarado',\n",
       " 'greer',\n",
       " 'padilla',\n",
       " 'simon',\n",
       " 'waters',\n",
       " 'nunez',\n",
       " 'ballard',\n",
       " 'schwartz',\n",
       " 'mcbride',\n",
       " 'houston',\n",
       " 'christensen',\n",
       " 'klein',\n",
       " 'pratt',\n",
       " 'briggs',\n",
       " 'parsons',\n",
       " 'mclaughlin',\n",
       " 'zimmerman',\n",
       " 'french',\n",
       " 'buchanan',\n",
       " 'moran',\n",
       " 'copeland',\n",
       " 'roy',\n",
       " 'pittman',\n",
       " 'brady',\n",
       " 'mccormick',\n",
       " 'holloway',\n",
       " 'brock',\n",
       " 'poole',\n",
       " 'frank',\n",
       " 'logan',\n",
       " 'owen',\n",
       " 'bass',\n",
       " 'marsh',\n",
       " 'drake',\n",
       " 'wong',\n",
       " 'jefferson',\n",
       " 'park',\n",
       " 'morton',\n",
       " 'abbott',\n",
       " 'sparks',\n",
       " 'patrick',\n",
       " 'norton',\n",
       " 'huff',\n",
       " 'clayton',\n",
       " 'massey',\n",
       " 'lloyd',\n",
       " 'figueroa',\n",
       " 'carson',\n",
       " 'bowers',\n",
       " 'roberson',\n",
       " 'barton',\n",
       " 'tran',\n",
       " 'lamb',\n",
       " 'harrington',\n",
       " 'casey',\n",
       " 'boone',\n",
       " 'cortez',\n",
       " 'clarke',\n",
       " 'mathis',\n",
       " 'singleton',\n",
       " 'wilkins',\n",
       " 'cain',\n",
       " 'bryan',\n",
       " 'underwood',\n",
       " 'hogan',\n",
       " 'mckenzie',\n",
       " 'collier',\n",
       " 'luna',\n",
       " 'phelps',\n",
       " 'mcguire',\n",
       " 'allison',\n",
       " 'bridges',\n",
       " 'wilkerson',\n",
       " 'nash',\n",
       " 'summers',\n",
       " 'atkins',\n",
       " 'wilcox',\n",
       " 'pitts',\n",
       " 'conley',\n",
       " 'marquez',\n",
       " 'burnett',\n",
       " 'richard',\n",
       " 'cochran',\n",
       " 'chase',\n",
       " 'davenport',\n",
       " 'hood',\n",
       " 'gates',\n",
       " 'clay',\n",
       " 'ayala',\n",
       " 'sawyer',\n",
       " 'roman',\n",
       " 'vazquez',\n",
       " 'dickerson',\n",
       " 'hodge',\n",
       " 'acosta',\n",
       " 'flynn',\n",
       " 'espinoza',\n",
       " 'nicholson',\n",
       " 'monroe',\n",
       " 'wolf',\n",
       " 'morrow',\n",
       " 'kirk',\n",
       " 'randall',\n",
       " 'anthony',\n",
       " 'whitaker',\n",
       " 'oconnor',\n",
       " 'skinner',\n",
       " 'ware',\n",
       " 'molina',\n",
       " 'kirby',\n",
       " 'huffman',\n",
       " 'bradford',\n",
       " 'charles',\n",
       " 'gilmore',\n",
       " 'dominguez',\n",
       " 'oneal',\n",
       " 'bruce',\n",
       " 'lang',\n",
       " 'combs',\n",
       " 'kramer',\n",
       " 'heath',\n",
       " 'hancock',\n",
       " 'gallagher',\n",
       " 'gaines',\n",
       " 'shaffer',\n",
       " 'short',\n",
       " 'wiggins',\n",
       " 'mathews',\n",
       " 'mcclain',\n",
       " 'fischer',\n",
       " 'wall',\n",
       " 'small',\n",
       " 'melton',\n",
       " 'hensley',\n",
       " 'bond',\n",
       " 'dyer',\n",
       " 'cameron',\n",
       " 'grimes',\n",
       " 'contreras',\n",
       " 'christian',\n",
       " 'wyatt',\n",
       " 'baxter',\n",
       " 'snow',\n",
       " 'mosley',\n",
       " 'shepherd',\n",
       " 'larsen',\n",
       " 'hoover',\n",
       " 'beasley',\n",
       " 'glenn',\n",
       " 'petersen',\n",
       " 'whitehead',\n",
       " 'meyers',\n",
       " 'keith',\n",
       " 'garrison',\n",
       " 'vincent',\n",
       " 'shields',\n",
       " 'horn',\n",
       " 'savage',\n",
       " 'olsen',\n",
       " 'schroeder',\n",
       " 'hartman',\n",
       " 'woodard',\n",
       " 'mueller',\n",
       " 'kemp',\n",
       " 'deleon',\n",
       " 'booth',\n",
       " 'patel',\n",
       " 'calhoun',\n",
       " 'wiley',\n",
       " 'eaton',\n",
       " 'cline',\n",
       " 'navarro',\n",
       " 'harrell',\n",
       " 'lester',\n",
       " 'humphrey',\n",
       " 'parrish',\n",
       " 'duran',\n",
       " 'hutchinson',\n",
       " 'hess',\n",
       " 'dorsey',\n",
       " 'bullock',\n",
       " 'robles',\n",
       " 'beard',\n",
       " 'dalton',\n",
       " 'avila',\n",
       " 'vance',\n",
       " 'rich',\n",
       " 'blackwell',\n",
       " 'york',\n",
       " 'johns',\n",
       " 'blankenship',\n",
       " 'trevino',\n",
       " 'salinas',\n",
       " 'campos',\n",
       " 'pruitt',\n",
       " 'moses',\n",
       " 'callahan',\n",
       " 'golden',\n",
       " 'montoya',\n",
       " 'hardin',\n",
       " 'guerra',\n",
       " 'mcdowell',\n",
       " 'carey',\n",
       " 'stafford',\n",
       " 'gallegos',\n",
       " 'henson',\n",
       " 'wilkinson',\n",
       " 'booker',\n",
       " 'merritt',\n",
       " 'miranda',\n",
       " 'atkinson',\n",
       " 'orr',\n",
       " 'decker',\n",
       " 'hobbs',\n",
       " 'preston',\n",
       " 'tanner',\n",
       " 'knox',\n",
       " 'pacheco',\n",
       " 'stephenson',\n",
       " 'glass',\n",
       " 'rojas',\n",
       " 'serrano',\n",
       " 'marks',\n",
       " 'hickman',\n",
       " 'english',\n",
       " 'sweeney',\n",
       " 'strong',\n",
       " 'prince',\n",
       " 'mcclure',\n",
       " 'conway',\n",
       " 'walter',\n",
       " 'roth',\n",
       " 'maynard',\n",
       " 'farrell',\n",
       " 'lowery',\n",
       " 'hurst',\n",
       " 'nixon',\n",
       " 'weiss',\n",
       " 'trujillo',\n",
       " 'ellison',\n",
       " 'sloan',\n",
       " 'juarez',\n",
       " 'winters',\n",
       " 'mclean',\n",
       " 'randolph',\n",
       " 'leon',\n",
       " 'boyer',\n",
       " 'villarreal',\n",
       " 'mccall',\n",
       " 'gentry',\n",
       " 'carrillo',\n",
       " 'kent',\n",
       " 'ayers',\n",
       " 'lara',\n",
       " 'shannon',\n",
       " 'sexton',\n",
       " 'pace',\n",
       " 'hull',\n",
       " 'leblanc',\n",
       " 'browning',\n",
       " 'velasquez',\n",
       " 'leach',\n",
       " 'chang',\n",
       " 'house',\n",
       " 'sellers',\n",
       " 'herring',\n",
       " 'noble',\n",
       " 'foley',\n",
       " 'bartlett',\n",
       " 'mercado',\n",
       " 'landry',\n",
       " 'durham',\n",
       " 'walls',\n",
       " 'barr',\n",
       " 'mckee',\n",
       " 'bauer',\n",
       " 'rivers',\n",
       " 'everett',\n",
       " 'bradshaw',\n",
       " 'pugh',\n",
       " 'velez',\n",
       " 'rush',\n",
       " 'estes',\n",
       " 'dodson',\n",
       " 'morse',\n",
       " 'sheppard',\n",
       " 'weeks',\n",
       " 'camacho',\n",
       " 'bean',\n",
       " 'barron',\n",
       " 'livingston',\n",
       " 'middleton',\n",
       " 'spears',\n",
       " 'branch',\n",
       " 'blevins',\n",
       " 'chen',\n",
       " 'kerr',\n",
       " 'mcconnell',\n",
       " 'hatfield',\n",
       " 'harding',\n",
       " 'ashley',\n",
       " 'solis',\n",
       " 'herman',\n",
       " 'frost',\n",
       " 'giles',\n",
       " 'blackburn',\n",
       " 'william',\n",
       " 'pennington',\n",
       " 'woodward',\n",
       " 'finley',\n",
       " 'mcintosh',\n",
       " 'koch',\n",
       " 'best',\n",
       " 'solomon',\n",
       " 'mccullough',\n",
       " 'dudley',\n",
       " 'nolan',\n",
       " 'blanchard',\n",
       " 'rivas',\n",
       " 'brennan',\n",
       " 'mejia',\n",
       " 'kane',\n",
       " 'benton',\n",
       " 'joyce',\n",
       " 'buckley',\n",
       " 'haley',\n",
       " 'valentine',\n",
       " 'maddox',\n",
       " 'russo',\n",
       " 'mcknight',\n",
       " 'buck',\n",
       " 'moon',\n",
       " 'mcmillan',\n",
       " 'crosby',\n",
       " 'berg',\n",
       " 'dotson',\n",
       " 'mays',\n",
       " 'roach',\n",
       " 'church',\n",
       " 'chan',\n",
       " 'richmond',\n",
       " 'meadows',\n",
       " 'faulkner',\n",
       " 'oneill',\n",
       " 'knapp',\n",
       " 'kline',\n",
       " 'barry',\n",
       " 'ochoa',\n",
       " 'jacobson',\n",
       " 'gay',\n",
       " 'avery',\n",
       " 'hendricks',\n",
       " 'horne',\n",
       " 'shepard',\n",
       " 'hebert',\n",
       " 'cherry',\n",
       " 'cardenas',\n",
       " 'mcintyre',\n",
       " 'whitney',\n",
       " 'waller',\n",
       " 'holman',\n",
       " 'donaldson',\n",
       " 'cantu',\n",
       " 'terrell',\n",
       " 'morin',\n",
       " 'gillespie',\n",
       " 'fuentes',\n",
       " 'tillman',\n",
       " 'sanford',\n",
       " 'bentley',\n",
       " 'peck',\n",
       " 'key',\n",
       " 'salas',\n",
       " 'rollins',\n",
       " 'gamble',\n",
       " 'dickson',\n",
       " 'battle',\n",
       " 'santana',\n",
       " 'cabrera',\n",
       " 'cervantes',\n",
       " 'howe',\n",
       " 'hinton',\n",
       " 'hurley',\n",
       " 'spence',\n",
       " 'zamora',\n",
       " 'yang',\n",
       " 'mcneil',\n",
       " 'suarez',\n",
       " 'case',\n",
       " 'petty',\n",
       " 'gould',\n",
       " 'mcfarland',\n",
       " 'sampson',\n",
       " 'carver',\n",
       " 'bray',\n",
       " 'rosario',\n",
       " 'macdonald',\n",
       " 'stout',\n",
       " 'hester',\n",
       " 'melendez',\n",
       " 'dillon',\n",
       " 'farley',\n",
       " 'hopper',\n",
       " 'galloway',\n",
       " 'potts',\n",
       " 'bernard',\n",
       " 'joyner',\n",
       " 'stein',\n",
       " 'aguirre',\n",
       " 'osborn',\n",
       " 'mercer',\n",
       " 'bender',\n",
       " 'franco',\n",
       " 'rowland',\n",
       " 'sykes',\n",
       " 'benjamin',\n",
       " 'travis',\n",
       " 'pickett',\n",
       " 'crane',\n",
       " 'sears',\n",
       " 'mayo',\n",
       " 'dunlap',\n",
       " 'hayden',\n",
       " 'wilder',\n",
       " 'mckay',\n",
       " 'coffey',\n",
       " 'mccarty',\n",
       " 'ewing',\n",
       " 'cooley',\n",
       " 'vaughan',\n",
       " 'bonner',\n",
       " 'cotton',\n",
       " 'holder',\n",
       " 'stark',\n",
       " 'ferrell',\n",
       " 'cantrell',\n",
       " 'fulton',\n",
       " 'lynn',\n",
       " 'lott',\n",
       " 'calderon',\n",
       " 'rosa',\n",
       " 'pollard',\n",
       " 'hooper',\n",
       " 'burch',\n",
       " 'mullen',\n",
       " 'fry',\n",
       " 'riddle',\n",
       " 'levy',\n",
       " 'david',\n",
       " 'duke',\n",
       " 'odonnell',\n",
       " 'guy',\n",
       " 'michael',\n",
       " 'britt',\n",
       " 'frederick',\n",
       " 'daugherty',\n",
       " 'berger',\n",
       " 'dillard',\n",
       " 'alston',\n",
       " 'jarvis',\n",
       " 'frye',\n",
       " 'riggs',\n",
       " 'chaney',\n",
       " 'odom',\n",
       " 'duffy',\n",
       " 'fitzpatrick',\n",
       " 'valenzuela',\n",
       " 'merrill',\n",
       " 'mayer',\n",
       " 'alford',\n",
       " 'mcpherson',\n",
       " 'acevedo',\n",
       " 'donovan',\n",
       " 'barrera',\n",
       " 'albert',\n",
       " 'cote',\n",
       " 'reilly',\n",
       " 'compton',\n",
       " 'raymond',\n",
       " 'mooney',\n",
       " 'mcgowan',\n",
       " 'craft',\n",
       " 'cleveland',\n",
       " 'clemons',\n",
       " 'wynn',\n",
       " 'nielsen',\n",
       " 'baird',\n",
       " 'stanton',\n",
       " 'snider',\n",
       " 'rosales',\n",
       " 'bright',\n",
       " 'witt',\n",
       " 'stuart',\n",
       " 'hays',\n",
       " 'holden',\n",
       " 'rutledge',\n",
       " 'kinney',\n",
       " 'clements',\n",
       " 'castaneda',\n",
       " 'slater',\n",
       " 'hahn',\n",
       " 'emerson',\n",
       " 'conrad',\n",
       " 'burks',\n",
       " 'delaney',\n",
       " 'pate',\n",
       " 'lancaster',\n",
       " 'sweet',\n",
       " 'justice',\n",
       " 'tyson',\n",
       " 'sharpe',\n",
       " 'whitfield',\n",
       " 'talley',\n",
       " 'macias',\n",
       " 'irwin',\n",
       " 'burris',\n",
       " 'ratliff',\n",
       " 'mccray',\n",
       " 'madden',\n",
       " 'kaufman',\n",
       " 'beach',\n",
       " 'goff',\n",
       " 'cash',\n",
       " 'bolton',\n",
       " 'mcfadden',\n",
       " 'levine',\n",
       " 'good',\n",
       " 'byers',\n",
       " 'kirkland',\n",
       " 'kidd',\n",
       " 'workman',\n",
       " 'carney',\n",
       " 'dale',\n",
       " 'mcleod',\n",
       " 'holcomb',\n",
       " 'england',\n",
       " 'finch',\n",
       " 'head',\n",
       " 'burt',\n",
       " 'hendrix',\n",
       " 'sosa',\n",
       " 'haney',\n",
       " 'franks',\n",
       " 'sargent',\n",
       " 'nieves',\n",
       " 'downs',\n",
       " 'rasmussen',\n",
       " 'bird',\n",
       " 'hewitt',\n",
       " 'lindsay',\n",
       " 'le',\n",
       " 'foreman',\n",
       " 'valencia',\n",
       " 'oneil',\n",
       " 'delacruz',\n",
       " 'vinson',\n",
       " 'dejesus',\n",
       " 'hyde',\n",
       " 'forbes',\n",
       " 'gilliam',\n",
       " 'guthrie',\n",
       " 'wooten',\n",
       " 'huber',\n",
       " 'barlow',\n",
       " 'boyle',\n",
       " 'mcmahon',\n",
       " 'buckner',\n",
       " 'rocha',\n",
       " 'puckett',\n",
       " 'langley',\n",
       " 'knowles',\n",
       " 'cooke',\n",
       " 'velazquez',\n",
       " 'whitley',\n",
       " 'noel',\n",
       " 'vang',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conerting the stopword object to a list\n",
    "sw_list = SW_list.tolist()\n",
    "sw_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39dd24",
   "metadata": {},
   "source": [
    "## Cleaning using Stop Words Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47240cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec077ba9",
   "metadata": {},
   "source": [
    "## Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "272a5b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_COUNT=len(tk_words)\n",
    "WORD_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59bb08d",
   "metadata": {},
   "source": [
    "# 1.Calculate score by counting with positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cda233c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abundant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>youthful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>zeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>zenith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>zest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>zippy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2006 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0            a+\n",
       "1        abound\n",
       "2       abounds\n",
       "3     abundance\n",
       "4      abundant\n",
       "...         ...\n",
       "2001   youthful\n",
       "2002       zeal\n",
       "2003     zenith\n",
       "2004       zest\n",
       "2005      zippy\n",
       "\n",
       "[2006 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the positive_words Dataset\n",
    "positive_words = pd.read_table(r'C:\\Users\\hrush\\Downloads\\positive-words.txt',header = None)\n",
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee182db",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words=positive_words[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e6b312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'accessable',\n",
       " 'accessible',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclamation',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accommodative',\n",
       " 'accomodative',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'achievable',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achievible',\n",
       " 'acumen',\n",
       " 'adaptable',\n",
       " 'adaptive',\n",
       " 'adequate',\n",
       " 'adjustable',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admiring',\n",
       " 'admiringly',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adorer',\n",
       " 'adoring',\n",
       " 'adoringly',\n",
       " 'adroit',\n",
       " 'adroitly',\n",
       " 'adulate',\n",
       " 'adulation',\n",
       " 'adulatory',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advantageously',\n",
       " 'advantages',\n",
       " 'adventuresome',\n",
       " 'adventurous',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'affability',\n",
       " 'affable',\n",
       " 'affably',\n",
       " 'affectation',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affluence',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'affordably',\n",
       " 'afordable',\n",
       " 'agile',\n",
       " 'agilely',\n",
       " 'agility',\n",
       " 'agreeable',\n",
       " 'agreeableness',\n",
       " 'agreeably',\n",
       " 'all-around',\n",
       " 'alluring',\n",
       " 'alluringly',\n",
       " 'altruistic',\n",
       " 'altruistically',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'ambitious',\n",
       " 'ambitiously',\n",
       " 'ameliorate',\n",
       " 'amenable',\n",
       " 'amenity',\n",
       " 'amiability',\n",
       " 'amiabily',\n",
       " 'amiable',\n",
       " 'amicability',\n",
       " 'amicable',\n",
       " 'amicably',\n",
       " 'amity',\n",
       " 'ample',\n",
       " 'amply',\n",
       " 'amuse',\n",
       " 'amusing',\n",
       " 'amusingly',\n",
       " 'angel',\n",
       " 'angelic',\n",
       " 'apotheosis',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'applaud',\n",
       " 'appreciable',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciative',\n",
       " 'appreciatively',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'ardent',\n",
       " 'ardently',\n",
       " 'ardor',\n",
       " 'articulate',\n",
       " 'aspiration',\n",
       " 'aspirations',\n",
       " 'aspire',\n",
       " 'assurance',\n",
       " 'assurances',\n",
       " 'assure',\n",
       " 'assuredly',\n",
       " 'assuring',\n",
       " 'astonish',\n",
       " 'astonished',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astonishment',\n",
       " 'astound',\n",
       " 'astounded',\n",
       " 'astounding',\n",
       " 'astoundingly',\n",
       " 'astutely',\n",
       " 'attentive',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attractively',\n",
       " 'attune',\n",
       " 'audible',\n",
       " 'audibly',\n",
       " 'auspicious',\n",
       " 'authentic',\n",
       " 'authoritative',\n",
       " 'autonomous',\n",
       " 'available',\n",
       " 'aver',\n",
       " 'avid',\n",
       " 'avidly',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'awards',\n",
       " 'awe',\n",
       " 'awed',\n",
       " 'awesome',\n",
       " 'awesomely',\n",
       " 'awesomeness',\n",
       " 'awestruck',\n",
       " 'awsome',\n",
       " 'backbone',\n",
       " 'balanced',\n",
       " 'bargain',\n",
       " 'beauteous',\n",
       " 'beautiful',\n",
       " 'beautifullly',\n",
       " 'beautifully',\n",
       " 'beautify',\n",
       " 'beauty',\n",
       " 'beckon',\n",
       " 'beckoned',\n",
       " 'beckoning',\n",
       " 'beckons',\n",
       " 'believable',\n",
       " 'believeable',\n",
       " 'beloved',\n",
       " 'benefactor',\n",
       " 'beneficent',\n",
       " 'beneficial',\n",
       " 'beneficially',\n",
       " 'beneficiary',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'benevolence',\n",
       " 'benevolent',\n",
       " 'benifits',\n",
       " 'best',\n",
       " 'best-known',\n",
       " 'best-performing',\n",
       " 'best-selling',\n",
       " 'better',\n",
       " 'better-known',\n",
       " 'better-than-expected',\n",
       " 'beutifully',\n",
       " 'blameless',\n",
       " 'bless',\n",
       " 'blessing',\n",
       " 'bliss',\n",
       " 'blissful',\n",
       " 'blissfully',\n",
       " 'blithe',\n",
       " 'blockbuster',\n",
       " 'bloom',\n",
       " 'blossom',\n",
       " 'bolster',\n",
       " 'bonny',\n",
       " 'bonus',\n",
       " 'bonuses',\n",
       " 'boom',\n",
       " 'booming',\n",
       " 'boost',\n",
       " 'boundless',\n",
       " 'bountiful',\n",
       " 'brainiest',\n",
       " 'brainy',\n",
       " 'brand-new',\n",
       " 'brave',\n",
       " 'bravery',\n",
       " 'bravo',\n",
       " 'breakthrough',\n",
       " 'breakthroughs',\n",
       " 'breathlessness',\n",
       " 'breathtaking',\n",
       " 'breathtakingly',\n",
       " 'breeze',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'brighter',\n",
       " 'brightest',\n",
       " 'brilliance',\n",
       " 'brilliances',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'brisk',\n",
       " 'brotherly',\n",
       " 'bullish',\n",
       " 'buoyant',\n",
       " 'cajole',\n",
       " 'calm',\n",
       " 'calming',\n",
       " 'calmness',\n",
       " 'capability',\n",
       " 'capable',\n",
       " 'capably',\n",
       " 'captivate',\n",
       " 'captivating',\n",
       " 'carefree',\n",
       " 'cashback',\n",
       " 'cashbacks',\n",
       " 'catchy',\n",
       " 'celebrate',\n",
       " 'celebrated',\n",
       " 'celebration',\n",
       " 'celebratory',\n",
       " 'champ',\n",
       " 'champion',\n",
       " 'charisma',\n",
       " 'charismatic',\n",
       " 'charitable',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'charmingly',\n",
       " 'chaste',\n",
       " 'cheaper',\n",
       " 'cheapest',\n",
       " 'cheer',\n",
       " 'cheerful',\n",
       " 'cheery',\n",
       " 'cherish',\n",
       " 'cherished',\n",
       " 'cherub',\n",
       " 'chic',\n",
       " 'chivalrous',\n",
       " 'chivalry',\n",
       " 'civility',\n",
       " 'civilize',\n",
       " 'clarity',\n",
       " 'classic',\n",
       " 'classy',\n",
       " 'clean',\n",
       " 'cleaner',\n",
       " 'cleanest',\n",
       " 'cleanliness',\n",
       " 'cleanly',\n",
       " 'clear',\n",
       " 'clear-cut',\n",
       " 'cleared',\n",
       " 'clearer',\n",
       " 'clearly',\n",
       " 'clears',\n",
       " 'clever',\n",
       " 'cleverly',\n",
       " 'cohere',\n",
       " 'coherence',\n",
       " 'coherent',\n",
       " 'cohesive',\n",
       " 'colorful',\n",
       " 'comely',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comfortably',\n",
       " 'comforting',\n",
       " 'comfy',\n",
       " 'commend',\n",
       " 'commendable',\n",
       " 'commendably',\n",
       " 'commitment',\n",
       " 'commodious',\n",
       " 'compact',\n",
       " 'compactly',\n",
       " 'compassion',\n",
       " 'compassionate',\n",
       " 'compatible',\n",
       " 'competitive',\n",
       " 'complement',\n",
       " 'complementary',\n",
       " 'complemented',\n",
       " 'complements',\n",
       " 'compliant',\n",
       " 'compliment',\n",
       " 'complimentary',\n",
       " 'comprehensive',\n",
       " 'conciliate',\n",
       " 'conciliatory',\n",
       " 'concise',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'congenial',\n",
       " 'congratulate',\n",
       " 'congratulation',\n",
       " 'congratulations',\n",
       " 'congratulatory',\n",
       " 'conscientious',\n",
       " 'considerate',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'constructive',\n",
       " 'consummate',\n",
       " 'contentment',\n",
       " 'continuity',\n",
       " 'contrasty',\n",
       " 'contribution',\n",
       " 'convenience',\n",
       " 'convenient',\n",
       " 'conveniently',\n",
       " 'convience',\n",
       " 'convienient',\n",
       " 'convient',\n",
       " 'convincing',\n",
       " 'convincingly',\n",
       " 'cool',\n",
       " 'coolest',\n",
       " 'cooperative',\n",
       " 'cooperatively',\n",
       " 'cornerstone',\n",
       " 'correct',\n",
       " 'correctly',\n",
       " 'cost-effective',\n",
       " 'cost-saving',\n",
       " 'counter-attack',\n",
       " 'counter-attacks',\n",
       " 'courage',\n",
       " 'courageous',\n",
       " 'courageously',\n",
       " 'courageousness',\n",
       " 'courteous',\n",
       " 'courtly',\n",
       " 'covenant',\n",
       " 'cozy',\n",
       " 'creative',\n",
       " 'credence',\n",
       " 'credible',\n",
       " 'crisp',\n",
       " 'crisper',\n",
       " 'cure',\n",
       " 'cure-all',\n",
       " 'cushy',\n",
       " 'cute',\n",
       " 'cuteness',\n",
       " 'danke',\n",
       " 'danken',\n",
       " 'daring',\n",
       " 'daringly',\n",
       " 'darling',\n",
       " 'dashing',\n",
       " 'dauntless',\n",
       " 'dawn',\n",
       " 'dazzle',\n",
       " 'dazzled',\n",
       " 'dazzling',\n",
       " 'dead-cheap',\n",
       " 'dead-on',\n",
       " 'decency',\n",
       " 'decent',\n",
       " 'decisive',\n",
       " 'decisiveness',\n",
       " 'dedicated',\n",
       " 'defeat',\n",
       " 'defeated',\n",
       " 'defeating',\n",
       " 'defeats',\n",
       " 'defender',\n",
       " 'deference',\n",
       " 'deft',\n",
       " 'deginified',\n",
       " 'delectable',\n",
       " 'delicacy',\n",
       " 'delicate',\n",
       " 'delicious',\n",
       " 'delight',\n",
       " 'delighted',\n",
       " 'delightful',\n",
       " 'delightfully',\n",
       " 'delightfulness',\n",
       " 'dependable',\n",
       " 'dependably',\n",
       " 'deservedly',\n",
       " 'deserving',\n",
       " 'desirable',\n",
       " 'desiring',\n",
       " 'desirous',\n",
       " 'destiny',\n",
       " 'detachable',\n",
       " 'devout',\n",
       " 'dexterous',\n",
       " 'dexterously',\n",
       " 'dextrous',\n",
       " 'dignified',\n",
       " 'dignify',\n",
       " 'dignity',\n",
       " 'diligence',\n",
       " 'diligent',\n",
       " 'diligently',\n",
       " 'diplomatic',\n",
       " 'dirt-cheap',\n",
       " 'distinction',\n",
       " 'distinctive',\n",
       " 'distinguished',\n",
       " 'diversified',\n",
       " 'divine',\n",
       " 'divinely',\n",
       " 'dominate',\n",
       " 'dominated',\n",
       " 'dominates',\n",
       " 'dote',\n",
       " 'dotingly',\n",
       " 'doubtless',\n",
       " 'dreamland',\n",
       " 'dumbfounded',\n",
       " 'dumbfounding',\n",
       " 'dummy-proof',\n",
       " 'durable',\n",
       " 'dynamic',\n",
       " 'eager',\n",
       " 'eagerly',\n",
       " 'eagerness',\n",
       " 'earnest',\n",
       " 'earnestly',\n",
       " 'earnestness',\n",
       " 'ease',\n",
       " 'eased',\n",
       " 'eases',\n",
       " 'easier',\n",
       " 'easiest',\n",
       " 'easiness',\n",
       " 'easing',\n",
       " 'easy',\n",
       " 'easy-to-use',\n",
       " 'easygoing',\n",
       " 'ebullience',\n",
       " 'ebullient',\n",
       " 'ebulliently',\n",
       " 'ecenomical',\n",
       " 'economical',\n",
       " 'ecstasies',\n",
       " 'ecstasy',\n",
       " 'ecstatic',\n",
       " 'ecstatically',\n",
       " 'edify',\n",
       " 'educated',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'effectiveness',\n",
       " 'effectual',\n",
       " 'efficacious',\n",
       " 'efficient',\n",
       " 'efficiently',\n",
       " 'effortless',\n",
       " 'effortlessly',\n",
       " 'effusion',\n",
       " 'effusive',\n",
       " 'effusively',\n",
       " 'effusiveness',\n",
       " 'elan',\n",
       " 'elate',\n",
       " 'elated',\n",
       " 'elatedly',\n",
       " 'elation',\n",
       " 'electrify',\n",
       " 'elegance',\n",
       " 'elegant',\n",
       " 'elegantly',\n",
       " 'elevate',\n",
       " 'elite',\n",
       " 'eloquence',\n",
       " 'eloquent',\n",
       " 'eloquently',\n",
       " 'embolden',\n",
       " 'eminence',\n",
       " 'eminent',\n",
       " 'empathize',\n",
       " 'empathy',\n",
       " 'empower',\n",
       " 'empowerment',\n",
       " 'enchant',\n",
       " 'enchanted',\n",
       " 'enchanting',\n",
       " 'enchantingly',\n",
       " 'encourage',\n",
       " 'encouragement',\n",
       " 'encouraging',\n",
       " 'encouragingly',\n",
       " 'endear',\n",
       " 'endearing',\n",
       " 'endorse',\n",
       " 'endorsed',\n",
       " 'endorsement',\n",
       " 'endorses',\n",
       " 'endorsing',\n",
       " 'energetic',\n",
       " 'energize',\n",
       " 'energy-efficient',\n",
       " 'energy-saving',\n",
       " 'engaging',\n",
       " 'engrossing',\n",
       " 'enhance',\n",
       " 'enhanced',\n",
       " 'enhancement',\n",
       " 'enhances',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyably',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enjoyment',\n",
       " 'enjoys',\n",
       " 'enlighten',\n",
       " 'enlightenment',\n",
       " 'enliven',\n",
       " 'ennoble',\n",
       " 'enough',\n",
       " 'enrapt',\n",
       " 'enrapture',\n",
       " 'enraptured',\n",
       " 'enrich',\n",
       " 'enrichment',\n",
       " 'enterprising',\n",
       " 'entertain',\n",
       " 'entertaining',\n",
       " 'entertains',\n",
       " 'enthral',\n",
       " 'enthrall',\n",
       " 'enthralled',\n",
       " 'enthuse',\n",
       " 'enthusiasm',\n",
       " 'enthusiast',\n",
       " 'enthusiastic',\n",
       " 'enthusiastically',\n",
       " 'entice',\n",
       " 'enticed',\n",
       " 'enticing',\n",
       " 'enticingly',\n",
       " 'entranced',\n",
       " 'entrancing',\n",
       " 'entrust',\n",
       " 'enviable',\n",
       " 'enviably',\n",
       " 'envious',\n",
       " 'enviously',\n",
       " 'enviousness',\n",
       " 'envy',\n",
       " 'equitable',\n",
       " 'ergonomical',\n",
       " 'err-free',\n",
       " 'erudite',\n",
       " 'ethical',\n",
       " 'eulogize',\n",
       " 'euphoria',\n",
       " 'euphoric',\n",
       " 'euphorically',\n",
       " 'evaluative',\n",
       " 'evenly',\n",
       " 'eventful',\n",
       " 'everlasting',\n",
       " 'evocative',\n",
       " 'exalt',\n",
       " 'exaltation',\n",
       " 'exalted',\n",
       " 'exaltedly',\n",
       " 'exalting',\n",
       " 'exaltingly',\n",
       " 'examplar',\n",
       " 'examplary',\n",
       " 'excallent',\n",
       " 'exceed',\n",
       " 'exceeded',\n",
       " 'exceeding',\n",
       " 'exceedingly',\n",
       " 'exceeds',\n",
       " 'excel',\n",
       " 'exceled',\n",
       " 'excelent',\n",
       " 'excellant',\n",
       " 'excelled',\n",
       " 'excellence',\n",
       " 'excellency',\n",
       " 'excellent',\n",
       " 'excellently',\n",
       " 'excels',\n",
       " 'exceptional',\n",
       " 'exceptionally',\n",
       " 'excite',\n",
       " 'excited',\n",
       " 'excitedly',\n",
       " 'excitedness',\n",
       " 'excitement',\n",
       " 'excites',\n",
       " 'exciting',\n",
       " 'excitingly',\n",
       " 'exellent',\n",
       " 'exemplar',\n",
       " 'exemplary',\n",
       " 'exhilarate',\n",
       " 'exhilarating',\n",
       " 'exhilaratingly',\n",
       " 'exhilaration',\n",
       " 'exonerate',\n",
       " 'expansive',\n",
       " 'expeditiously',\n",
       " 'expertly',\n",
       " 'exquisite',\n",
       " 'exquisitely',\n",
       " 'extol',\n",
       " 'extoll',\n",
       " 'extraordinarily',\n",
       " 'extraordinary',\n",
       " 'exuberance',\n",
       " 'exuberant',\n",
       " 'exuberantly',\n",
       " 'exult',\n",
       " 'exultant',\n",
       " 'exultation',\n",
       " 'exultingly',\n",
       " 'eye-catch',\n",
       " 'eye-catching',\n",
       " 'eyecatch',\n",
       " 'eyecatching',\n",
       " 'fabulous',\n",
       " 'fabulously',\n",
       " 'facilitate',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fairness',\n",
       " 'faith',\n",
       " 'faithful',\n",
       " 'faithfully',\n",
       " 'faithfulness',\n",
       " 'fame',\n",
       " 'famed',\n",
       " 'famous',\n",
       " 'famously',\n",
       " 'fancier',\n",
       " 'fancinating',\n",
       " 'fancy',\n",
       " 'fanfare',\n",
       " 'fans',\n",
       " 'fantastic',\n",
       " 'fantastically',\n",
       " 'fascinate',\n",
       " 'fascinating',\n",
       " 'fascinatingly',\n",
       " 'fascination',\n",
       " 'fashionable',\n",
       " 'fashionably',\n",
       " 'fast',\n",
       " 'fast-growing',\n",
       " 'fast-paced',\n",
       " 'faster',\n",
       " 'fastest',\n",
       " 'fastest-growing',\n",
       " 'faultless',\n",
       " 'fav',\n",
       " 'fave',\n",
       " 'favor',\n",
       " 'favorable',\n",
       " 'favored',\n",
       " 'favorite',\n",
       " 'favorited',\n",
       " 'favour',\n",
       " 'fearless',\n",
       " 'fearlessly',\n",
       " 'feasible',\n",
       " 'feasibly',\n",
       " 'feat',\n",
       " 'feature-rich',\n",
       " 'fecilitous',\n",
       " 'feisty',\n",
       " 'felicitate',\n",
       " 'felicitous',\n",
       " 'felicity',\n",
       " 'fertile',\n",
       " 'fervent',\n",
       " 'fervently',\n",
       " 'fervid',\n",
       " 'fervidly',\n",
       " 'fervor',\n",
       " 'festive',\n",
       " 'fidelity',\n",
       " 'fiery',\n",
       " 'fine',\n",
       " 'fine-looking',\n",
       " 'finely',\n",
       " 'finer',\n",
       " 'finest',\n",
       " 'firmer',\n",
       " 'first-class',\n",
       " 'first-in-class',\n",
       " 'first-rate',\n",
       " 'flashy',\n",
       " 'flatter',\n",
       " 'flattering',\n",
       " 'flatteringly',\n",
       " 'flawless',\n",
       " 'flawlessly',\n",
       " 'flexibility',\n",
       " 'flexible',\n",
       " 'flourish',\n",
       " 'flourishing',\n",
       " 'fluent',\n",
       " 'flutter',\n",
       " 'fond',\n",
       " 'fondly',\n",
       " 'fondness',\n",
       " 'foolproof',\n",
       " 'foremost',\n",
       " 'foresight',\n",
       " 'formidable',\n",
       " 'fortitude',\n",
       " 'fortuitous',\n",
       " 'fortuitously',\n",
       " 'fortunate',\n",
       " 'fortunately',\n",
       " 'fortune',\n",
       " 'fragrant',\n",
       " 'free',\n",
       " 'freed',\n",
       " 'freedom',\n",
       " 'freedoms',\n",
       " 'fresh',\n",
       " 'fresher',\n",
       " 'freshest',\n",
       " 'friendliness',\n",
       " 'friendly',\n",
       " 'frolic',\n",
       " 'frugal',\n",
       " 'fruitful',\n",
       " 'ftw',\n",
       " 'fulfillment',\n",
       " 'fun',\n",
       " 'futurestic',\n",
       " 'futuristic',\n",
       " 'gaiety',\n",
       " 'gaily',\n",
       " 'gain',\n",
       " 'gained',\n",
       " 'gainful',\n",
       " 'gainfully',\n",
       " 'gaining',\n",
       " 'gains',\n",
       " 'gallant',\n",
       " 'gallantly',\n",
       " 'galore',\n",
       " 'geekier',\n",
       " 'geeky',\n",
       " 'gem',\n",
       " 'gems',\n",
       " 'generosity',\n",
       " 'generous',\n",
       " 'generously',\n",
       " 'genial',\n",
       " 'genius',\n",
       " 'gentle',\n",
       " 'gentlest',\n",
       " 'genuine',\n",
       " 'gifted',\n",
       " 'glad',\n",
       " 'gladden',\n",
       " 'gladly',\n",
       " 'gladness',\n",
       " 'glamorous',\n",
       " 'glee',\n",
       " 'gleeful',\n",
       " 'gleefully',\n",
       " 'glimmer',\n",
       " 'glimmering',\n",
       " 'glisten',\n",
       " 'glistening',\n",
       " 'glitter',\n",
       " 'glitz',\n",
       " 'glorify',\n",
       " 'glorious',\n",
       " 'gloriously',\n",
       " 'glory',\n",
       " 'glow',\n",
       " 'glowing',\n",
       " 'glowingly',\n",
       " 'god-given',\n",
       " 'god-send',\n",
       " 'godlike',\n",
       " 'godsend',\n",
       " 'gold',\n",
       " 'golden',\n",
       " 'good',\n",
       " 'goodly',\n",
       " 'goodness',\n",
       " 'goodwill',\n",
       " 'goood',\n",
       " 'gooood',\n",
       " 'gorgeous',\n",
       " 'gorgeously',\n",
       " 'grace',\n",
       " 'graceful',\n",
       " 'gracefully',\n",
       " 'gracious',\n",
       " 'graciously',\n",
       " 'graciousness',\n",
       " 'grand',\n",
       " 'grandeur',\n",
       " 'grateful',\n",
       " 'gratefully',\n",
       " 'gratification',\n",
       " 'gratified',\n",
       " 'gratifies',\n",
       " 'gratify',\n",
       " 'gratifying',\n",
       " 'gratifyingly',\n",
       " 'gratitude',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greatness',\n",
       " 'grin',\n",
       " 'groundbreaking',\n",
       " 'guarantee',\n",
       " 'guidance',\n",
       " 'guiltless',\n",
       " 'gumption',\n",
       " 'gush',\n",
       " 'gusto',\n",
       " 'gutsy',\n",
       " 'hail',\n",
       " 'halcyon',\n",
       " 'hale',\n",
       " 'hallmark',\n",
       " 'hallmarks',\n",
       " 'hallowed',\n",
       " 'handier',\n",
       " 'handily',\n",
       " 'hands-down',\n",
       " 'handsome',\n",
       " 'handsomely',\n",
       " 'handy',\n",
       " 'happier',\n",
       " 'happily',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard-working',\n",
       " 'hardier',\n",
       " 'hardy',\n",
       " 'harmless',\n",
       " 'harmonious',\n",
       " 'harmoniously',\n",
       " 'harmonize',\n",
       " 'harmony',\n",
       " 'headway',\n",
       " 'heal',\n",
       " 'healthful',\n",
       " 'healthy',\n",
       " 'hearten',\n",
       " 'heartening',\n",
       " 'heartfelt',\n",
       " 'heartily',\n",
       " 'heartwarming',\n",
       " 'heaven',\n",
       " 'heavenly',\n",
       " 'helped',\n",
       " 'helpful',\n",
       " 'helping',\n",
       " 'hero',\n",
       " 'heroic',\n",
       " 'heroically',\n",
       " 'heroine',\n",
       " 'heroize',\n",
       " 'heros',\n",
       " 'high-quality',\n",
       " 'high-spirited',\n",
       " 'hilarious',\n",
       " 'holy',\n",
       " 'homage',\n",
       " 'honest',\n",
       " 'honesty',\n",
       " 'honor',\n",
       " 'honorable',\n",
       " 'honored',\n",
       " 'honoring',\n",
       " 'hooray',\n",
       " 'hopeful',\n",
       " 'hospitable',\n",
       " 'hot',\n",
       " 'hotcake',\n",
       " 'hotcakes',\n",
       " 'hottest',\n",
       " 'hug',\n",
       " 'humane',\n",
       " 'humble',\n",
       " 'humility',\n",
       " 'humor',\n",
       " 'humorous',\n",
       " 'humorously',\n",
       " 'humour',\n",
       " 'humourous',\n",
       " 'ideal',\n",
       " 'idealize',\n",
       " 'ideally',\n",
       " 'idol',\n",
       " 'idolize',\n",
       " 'idolized',\n",
       " 'idyllic',\n",
       " 'illuminate',\n",
       " 'illuminati',\n",
       " 'illuminating',\n",
       " 'illumine',\n",
       " 'illustrious',\n",
       " 'ilu',\n",
       " 'imaculate',\n",
       " 'imaginative',\n",
       " 'immaculate',\n",
       " 'immaculately',\n",
       " 'immense',\n",
       " 'impartial',\n",
       " 'impartiality',\n",
       " 'impartially',\n",
       " 'impassioned',\n",
       " 'impeccable',\n",
       " 'impeccably',\n",
       " 'important',\n",
       " 'impress',\n",
       " 'impressed',\n",
       " 'impresses',\n",
       " 'impressive',\n",
       " 'impressively',\n",
       " 'impressiveness',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'improves',\n",
       " 'improving',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'indebted',\n",
       " 'individualized',\n",
       " 'indulgence',\n",
       " 'indulgent',\n",
       " 'industrious',\n",
       " 'inestimable',\n",
       " 'inestimably',\n",
       " 'inexpensive',\n",
       " 'infallibility',\n",
       " 'infallible',\n",
       " 'infallibly',\n",
       " 'influential',\n",
       " 'ingenious',\n",
       " 'ingeniously',\n",
       " 'ingenuity',\n",
       " 'ingenuous',\n",
       " 'ingenuously',\n",
       " 'innocuous',\n",
       " 'innovation',\n",
       " 'innovative',\n",
       " 'inpressed',\n",
       " 'insightful',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fe927f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f8e31",
   "metadata": {},
   "source": [
    "## 2.Calculate score by counting with negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547be4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-faced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>zaps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>zealot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>zealous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>zealously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4783 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0        2-faced\n",
       "1        2-faces\n",
       "2       abnormal\n",
       "3        abolish\n",
       "4     abominable\n",
       "...          ...\n",
       "4778        zaps\n",
       "4779      zealot\n",
       "4780     zealous\n",
       "4781   zealously\n",
       "4782      zombie\n",
       "\n",
       "[4783 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the negative_words Dataset\n",
    "negative_words = pd.read_table(r'C:\\Users\\hrush\\Downloads\\negative-words.txt',encoding='latin-1',header = None)\n",
    "negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe54cf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced',\n",
       " '2-faces',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'aborts',\n",
       " 'abrade',\n",
       " 'abrasive',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abscond',\n",
       " 'absence',\n",
       " 'absent-minded',\n",
       " 'absentee',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'absurdness',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuses',\n",
       " 'abusive',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'accidental',\n",
       " 'accost',\n",
       " 'accursed',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accusingly',\n",
       " 'acerbate',\n",
       " 'acerbic',\n",
       " 'acerbically',\n",
       " 'ache',\n",
       " 'ached',\n",
       " 'aches',\n",
       " 'achey',\n",
       " 'aching',\n",
       " 'acrid',\n",
       " 'acridly',\n",
       " 'acridness',\n",
       " 'acrimonious',\n",
       " 'acrimoniously',\n",
       " 'acrimony',\n",
       " 'adamant',\n",
       " 'adamantly',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addicts',\n",
       " 'admonish',\n",
       " 'admonisher',\n",
       " 'admonishingly',\n",
       " 'admonishment',\n",
       " 'admonition',\n",
       " 'adulterate',\n",
       " 'adulterated',\n",
       " 'adulteration',\n",
       " 'adulterier',\n",
       " 'adversarial',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afflictive',\n",
       " 'affront',\n",
       " 'afraid',\n",
       " 'aggravate',\n",
       " 'aggravating',\n",
       " 'aggravation',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressiveness',\n",
       " 'aggressor',\n",
       " 'aggrieve',\n",
       " 'aggrieved',\n",
       " 'aggrivation',\n",
       " 'aghast',\n",
       " 'agonies',\n",
       " 'agonize',\n",
       " 'agonizing',\n",
       " 'agonizingly',\n",
       " 'agony',\n",
       " 'aground',\n",
       " 'ail',\n",
       " 'ailing',\n",
       " 'ailment',\n",
       " 'aimless',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarmingly',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienation',\n",
       " 'allegation',\n",
       " 'allegations',\n",
       " 'allege',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'aloof',\n",
       " 'altercation',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'ambush',\n",
       " 'amiss',\n",
       " 'amputate',\n",
       " 'anarchism',\n",
       " 'anarchist',\n",
       " 'anarchistic',\n",
       " 'anarchy',\n",
       " 'anemic',\n",
       " 'anger',\n",
       " 'angrily',\n",
       " 'angriness',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'animosity',\n",
       " 'annihilate',\n",
       " 'annihilation',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyances',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoyingly',\n",
       " 'annoys',\n",
       " 'anomalous',\n",
       " 'anomaly',\n",
       " 'antagonism',\n",
       " 'antagonist',\n",
       " 'antagonistic',\n",
       " 'antagonize',\n",
       " 'anti-',\n",
       " 'anti-american',\n",
       " 'anti-israeli',\n",
       " 'anti-occupation',\n",
       " 'anti-proliferation',\n",
       " 'anti-semites',\n",
       " 'anti-social',\n",
       " 'anti-us',\n",
       " 'anti-white',\n",
       " 'antipathy',\n",
       " 'antiquated',\n",
       " 'antithetical',\n",
       " 'anxieties',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'anxiousness',\n",
       " 'apathetic',\n",
       " 'apathetically',\n",
       " 'apathy',\n",
       " 'apocalypse',\n",
       " 'apocalyptic',\n",
       " 'apologist',\n",
       " 'apologists',\n",
       " 'appal',\n",
       " 'appall',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'appallingly',\n",
       " 'apprehension',\n",
       " 'apprehensions',\n",
       " 'apprehensive',\n",
       " 'apprehensively',\n",
       " 'arbitrary',\n",
       " 'arcane',\n",
       " 'archaic',\n",
       " 'arduous',\n",
       " 'arduously',\n",
       " 'argumentative',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrogantly',\n",
       " 'ashamed',\n",
       " 'asinine',\n",
       " 'asininely',\n",
       " 'asinininity',\n",
       " 'askance',\n",
       " 'asperse',\n",
       " 'aspersion',\n",
       " 'aspersions',\n",
       " 'assail',\n",
       " 'assassin',\n",
       " 'assassinate',\n",
       " 'assault',\n",
       " 'assult',\n",
       " 'astray',\n",
       " 'asunder',\n",
       " 'atrocious',\n",
       " 'atrocities',\n",
       " 'atrocity',\n",
       " 'atrophy',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'audacious',\n",
       " 'audaciously',\n",
       " 'audaciousness',\n",
       " 'audacity',\n",
       " 'audiciously',\n",
       " 'austere',\n",
       " 'authoritarian',\n",
       " 'autocrat',\n",
       " 'autocratic',\n",
       " 'avalanche',\n",
       " 'avarice',\n",
       " 'avaricious',\n",
       " 'avariciously',\n",
       " 'avenge',\n",
       " 'averse',\n",
       " 'aversion',\n",
       " 'aweful',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awfulness',\n",
       " 'awkward',\n",
       " 'awkwardness',\n",
       " 'ax',\n",
       " 'babble',\n",
       " 'back-logged',\n",
       " 'back-wood',\n",
       " 'back-woods',\n",
       " 'backache',\n",
       " 'backaches',\n",
       " 'backaching',\n",
       " 'backbite',\n",
       " 'backbiting',\n",
       " 'backward',\n",
       " 'backwardness',\n",
       " 'backwood',\n",
       " 'backwoods',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'baffle',\n",
       " 'baffled',\n",
       " 'bafflement',\n",
       " 'baffling',\n",
       " 'bait',\n",
       " 'balk',\n",
       " 'banal',\n",
       " 'banalize',\n",
       " 'bane',\n",
       " 'banish',\n",
       " 'banishment',\n",
       " 'bankrupt',\n",
       " 'barbarian',\n",
       " 'barbaric',\n",
       " 'barbarically',\n",
       " 'barbarity',\n",
       " 'barbarous',\n",
       " 'barbarously',\n",
       " 'barren',\n",
       " 'baseless',\n",
       " 'bash',\n",
       " 'bashed',\n",
       " 'bashful',\n",
       " 'bashing',\n",
       " 'bastard',\n",
       " 'bastards',\n",
       " 'battered',\n",
       " 'battering',\n",
       " 'batty',\n",
       " 'bearish',\n",
       " 'beastly',\n",
       " 'bedlam',\n",
       " 'bedlamite',\n",
       " 'befoul',\n",
       " 'beg',\n",
       " 'beggar',\n",
       " 'beggarly',\n",
       " 'begging',\n",
       " 'beguile',\n",
       " 'belabor',\n",
       " 'belated',\n",
       " 'beleaguer',\n",
       " 'belie',\n",
       " 'belittle',\n",
       " 'belittled',\n",
       " 'belittling',\n",
       " 'bellicose',\n",
       " 'belligerence',\n",
       " 'belligerent',\n",
       " 'belligerently',\n",
       " 'bemoan',\n",
       " 'bemoaning',\n",
       " 'bemused',\n",
       " 'bent',\n",
       " 'berate',\n",
       " 'bereave',\n",
       " 'bereavement',\n",
       " 'bereft',\n",
       " 'berserk',\n",
       " 'beseech',\n",
       " 'beset',\n",
       " 'besiege',\n",
       " 'besmirch',\n",
       " 'bestial',\n",
       " 'betray',\n",
       " 'betrayal',\n",
       " 'betrayals',\n",
       " 'betrayer',\n",
       " 'betraying',\n",
       " 'betrays',\n",
       " 'bewail',\n",
       " 'beware',\n",
       " 'bewilder',\n",
       " 'bewildered',\n",
       " 'bewildering',\n",
       " 'bewilderingly',\n",
       " 'bewilderment',\n",
       " 'bewitch',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'biases',\n",
       " 'bicker',\n",
       " 'bickering',\n",
       " 'bid-rigging',\n",
       " 'bigotries',\n",
       " 'bigotry',\n",
       " 'bitch',\n",
       " 'bitchy',\n",
       " 'biting',\n",
       " 'bitingly',\n",
       " 'bitter',\n",
       " 'bitterly',\n",
       " 'bitterness',\n",
       " 'bizarre',\n",
       " 'blab',\n",
       " 'blabber',\n",
       " 'blackmail',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blameworthy',\n",
       " 'bland',\n",
       " 'blandish',\n",
       " 'blaspheme',\n",
       " 'blasphemous',\n",
       " 'blasphemy',\n",
       " 'blasted',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'blather',\n",
       " 'bleak',\n",
       " 'bleakly',\n",
       " 'bleakness',\n",
       " 'bleed',\n",
       " 'bleeding',\n",
       " 'bleeds',\n",
       " 'blemish',\n",
       " 'blind',\n",
       " 'blinding',\n",
       " 'blindingly',\n",
       " 'blindside',\n",
       " 'blister',\n",
       " 'blistering',\n",
       " 'bloated',\n",
       " 'blockage',\n",
       " 'blockhead',\n",
       " 'bloodshed',\n",
       " 'bloodthirsty',\n",
       " 'bloody',\n",
       " 'blotchy',\n",
       " 'blow',\n",
       " 'blunder',\n",
       " 'blundering',\n",
       " 'blunders',\n",
       " 'blunt',\n",
       " 'blur',\n",
       " 'bluring',\n",
       " 'blurred',\n",
       " 'blurring',\n",
       " 'blurry',\n",
       " 'blurs',\n",
       " 'blurt',\n",
       " 'boastful',\n",
       " 'boggle',\n",
       " 'bogus',\n",
       " 'boil',\n",
       " 'boiling',\n",
       " 'boisterous',\n",
       " 'bomb',\n",
       " 'bombard',\n",
       " 'bombardment',\n",
       " 'bombastic',\n",
       " 'bondage',\n",
       " 'bonkers',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boredom',\n",
       " 'bores',\n",
       " 'boring',\n",
       " 'botch',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothering',\n",
       " 'bothers',\n",
       " 'bothersome',\n",
       " 'bowdlerize',\n",
       " 'boycott',\n",
       " 'braggart',\n",
       " 'bragger',\n",
       " 'brainless',\n",
       " 'brainwash',\n",
       " 'brash',\n",
       " 'brashly',\n",
       " 'brashness',\n",
       " 'brat',\n",
       " 'bravado',\n",
       " 'brazen',\n",
       " 'brazenly',\n",
       " 'brazenness',\n",
       " 'breach',\n",
       " 'break',\n",
       " 'break-up',\n",
       " 'break-ups',\n",
       " 'breakdown',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'breakup',\n",
       " 'breakups',\n",
       " 'bribery',\n",
       " 'brimstone',\n",
       " 'bristle',\n",
       " 'brittle',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broken-hearted',\n",
       " 'brood',\n",
       " 'browbeat',\n",
       " 'bruise',\n",
       " 'bruised',\n",
       " 'bruises',\n",
       " 'bruising',\n",
       " 'brusque',\n",
       " 'brutal',\n",
       " 'brutalising',\n",
       " 'brutalities',\n",
       " 'brutality',\n",
       " 'brutalize',\n",
       " 'brutalizing',\n",
       " 'brutally',\n",
       " 'brute',\n",
       " 'brutish',\n",
       " 'bs',\n",
       " 'buckle',\n",
       " 'bug',\n",
       " 'bugging',\n",
       " 'buggy',\n",
       " 'bugs',\n",
       " 'bulkier',\n",
       " 'bulkiness',\n",
       " 'bulky',\n",
       " 'bulkyness',\n",
       " 'bull****',\n",
       " 'bull----',\n",
       " 'bullies',\n",
       " 'bullshit',\n",
       " 'bullshyt',\n",
       " 'bully',\n",
       " 'bullying',\n",
       " 'bullyingly',\n",
       " 'bum',\n",
       " 'bump',\n",
       " 'bumped',\n",
       " 'bumping',\n",
       " 'bumpping',\n",
       " 'bumps',\n",
       " 'bumpy',\n",
       " 'bungle',\n",
       " 'bungler',\n",
       " 'bungling',\n",
       " 'bunk',\n",
       " 'burden',\n",
       " 'burdensome',\n",
       " 'burdensomely',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burns',\n",
       " 'bust',\n",
       " 'busts',\n",
       " 'busybody',\n",
       " 'butcher',\n",
       " 'butchery',\n",
       " 'buzzing',\n",
       " 'byzantine',\n",
       " 'cackle',\n",
       " 'calamities',\n",
       " 'calamitous',\n",
       " 'calamitously',\n",
       " 'calamity',\n",
       " 'callous',\n",
       " 'calumniate',\n",
       " 'calumniation',\n",
       " 'calumnies',\n",
       " 'calumnious',\n",
       " 'calumniously',\n",
       " 'calumny',\n",
       " 'cancer',\n",
       " 'cancerous',\n",
       " 'cannibal',\n",
       " 'cannibalize',\n",
       " 'capitulate',\n",
       " 'capricious',\n",
       " 'capriciously',\n",
       " 'capriciousness',\n",
       " 'capsize',\n",
       " 'careless',\n",
       " 'carelessness',\n",
       " 'caricature',\n",
       " 'carnage',\n",
       " 'carp',\n",
       " 'cartoonish',\n",
       " 'cash-strapped',\n",
       " 'castigate',\n",
       " 'castrated',\n",
       " 'casualty',\n",
       " 'cataclysm',\n",
       " 'cataclysmal',\n",
       " 'cataclysmic',\n",
       " 'cataclysmically',\n",
       " 'catastrophe',\n",
       " 'catastrophes',\n",
       " 'catastrophic',\n",
       " 'catastrophically',\n",
       " 'catastrophies',\n",
       " 'caustic',\n",
       " 'caustically',\n",
       " 'cautionary',\n",
       " 'cave',\n",
       " 'censure',\n",
       " 'chafe',\n",
       " 'chaff',\n",
       " 'chagrin',\n",
       " 'challenging',\n",
       " 'chaos',\n",
       " 'chaotic',\n",
       " 'chasten',\n",
       " 'chastise',\n",
       " 'chastisement',\n",
       " 'chatter',\n",
       " 'chatterbox',\n",
       " 'cheap',\n",
       " 'cheapen',\n",
       " 'cheaply',\n",
       " 'cheat',\n",
       " 'cheated',\n",
       " 'cheater',\n",
       " 'cheating',\n",
       " 'cheats',\n",
       " 'checkered',\n",
       " 'cheerless',\n",
       " 'cheesy',\n",
       " 'chide',\n",
       " 'childish',\n",
       " 'chill',\n",
       " 'chilly',\n",
       " 'chintzy',\n",
       " 'choke',\n",
       " 'choleric',\n",
       " 'choppy',\n",
       " 'chore',\n",
       " 'chronic',\n",
       " 'chunky',\n",
       " 'clamor',\n",
       " 'clamorous',\n",
       " 'clash',\n",
       " 'cliche',\n",
       " 'cliched',\n",
       " 'clique',\n",
       " 'clog',\n",
       " 'clogged',\n",
       " 'clogs',\n",
       " 'cloud',\n",
       " 'clouding',\n",
       " 'cloudy',\n",
       " 'clueless',\n",
       " 'clumsy',\n",
       " 'clunky',\n",
       " 'coarse',\n",
       " 'cocky',\n",
       " 'coerce',\n",
       " 'coercion',\n",
       " 'coercive',\n",
       " 'cold',\n",
       " 'coldly',\n",
       " 'collapse',\n",
       " 'collude',\n",
       " 'collusion',\n",
       " 'combative',\n",
       " 'combust',\n",
       " 'comical',\n",
       " 'commiserate',\n",
       " 'commonplace',\n",
       " 'commotion',\n",
       " 'commotions',\n",
       " 'complacent',\n",
       " 'complain',\n",
       " 'complained',\n",
       " 'complaining',\n",
       " 'complains',\n",
       " 'complaint',\n",
       " 'complaints',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'complication',\n",
       " 'complicit',\n",
       " 'compulsion',\n",
       " 'compulsive',\n",
       " 'concede',\n",
       " 'conceded',\n",
       " 'conceit',\n",
       " 'conceited',\n",
       " 'concen',\n",
       " 'concens',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerns',\n",
       " 'concession',\n",
       " 'concessions',\n",
       " 'condemn',\n",
       " 'condemnable',\n",
       " 'condemnation',\n",
       " 'condemned',\n",
       " 'condemns',\n",
       " 'condescend',\n",
       " 'condescending',\n",
       " 'condescendingly',\n",
       " 'condescension',\n",
       " 'confess',\n",
       " 'confession',\n",
       " 'confessions',\n",
       " 'confined',\n",
       " 'conflict',\n",
       " 'conflicted',\n",
       " 'conflicting',\n",
       " 'conflicts',\n",
       " 'confound',\n",
       " 'confounded',\n",
       " 'confounding',\n",
       " 'confront',\n",
       " 'confrontation',\n",
       " 'confrontational',\n",
       " 'confuse',\n",
       " 'confused',\n",
       " 'confuses',\n",
       " 'confusing',\n",
       " 'confusion',\n",
       " 'confusions',\n",
       " 'congested',\n",
       " 'congestion',\n",
       " 'cons',\n",
       " 'conscons',\n",
       " 'conservative',\n",
       " 'conspicuous',\n",
       " 'conspicuously',\n",
       " 'conspiracies',\n",
       " 'conspiracy',\n",
       " 'conspirator',\n",
       " 'conspiratorial',\n",
       " 'conspire',\n",
       " 'consternation',\n",
       " 'contagious',\n",
       " 'contaminate',\n",
       " 'contaminated',\n",
       " 'contaminates',\n",
       " 'contaminating',\n",
       " 'contamination',\n",
       " 'contempt',\n",
       " 'contemptible',\n",
       " 'contemptuous',\n",
       " 'contemptuously',\n",
       " 'contend',\n",
       " 'contention',\n",
       " 'contentious',\n",
       " 'contort',\n",
       " 'contortions',\n",
       " 'contradict',\n",
       " 'contradiction',\n",
       " 'contradictory',\n",
       " 'contrariness',\n",
       " 'contravene',\n",
       " 'contrive',\n",
       " 'contrived',\n",
       " 'controversial',\n",
       " 'controversy',\n",
       " 'convoluted',\n",
       " 'corrode',\n",
       " 'corrosion',\n",
       " 'corrosions',\n",
       " 'corrosive',\n",
       " 'corrupt',\n",
       " 'corrupted',\n",
       " 'corrupting',\n",
       " 'corruption',\n",
       " 'corrupts',\n",
       " 'corruptted',\n",
       " 'costlier',\n",
       " 'costly',\n",
       " 'counter-productive',\n",
       " 'counterproductive',\n",
       " 'coupists',\n",
       " 'covetous',\n",
       " 'coward',\n",
       " 'cowardly',\n",
       " 'crabby',\n",
       " 'crack',\n",
       " 'cracked',\n",
       " 'cracks',\n",
       " 'craftily',\n",
       " 'craftly',\n",
       " 'crafty',\n",
       " 'cramp',\n",
       " 'cramped',\n",
       " 'cramping',\n",
       " 'cranky',\n",
       " 'crap',\n",
       " 'crappy',\n",
       " 'craps',\n",
       " 'crash',\n",
       " 'crashed',\n",
       " 'crashes',\n",
       " 'crashing',\n",
       " 'crass',\n",
       " 'craven',\n",
       " 'cravenly',\n",
       " 'craze',\n",
       " 'crazily',\n",
       " 'craziness',\n",
       " 'crazy',\n",
       " 'creak',\n",
       " 'creaking',\n",
       " 'creaks',\n",
       " 'credulous',\n",
       " 'creep',\n",
       " 'creeping',\n",
       " 'creeps',\n",
       " 'creepy',\n",
       " 'crept',\n",
       " 'crime',\n",
       " 'criminal',\n",
       " 'cringe',\n",
       " 'cringed',\n",
       " 'cringes',\n",
       " 'cripple',\n",
       " 'crippled',\n",
       " 'cripples',\n",
       " 'crippling',\n",
       " 'crisis',\n",
       " 'critic',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'criticisms',\n",
       " 'criticize',\n",
       " 'criticized',\n",
       " 'criticizing',\n",
       " 'critics',\n",
       " 'cronyism',\n",
       " 'crook',\n",
       " 'crooked',\n",
       " 'crooks',\n",
       " 'crowded',\n",
       " 'crowdedness',\n",
       " 'crude',\n",
       " 'cruel',\n",
       " 'crueler',\n",
       " 'cruelest',\n",
       " 'cruelly',\n",
       " 'cruelness',\n",
       " 'cruelties',\n",
       " 'cruelty',\n",
       " 'crumble',\n",
       " 'crumbling',\n",
       " 'crummy',\n",
       " 'crumple',\n",
       " 'crumpled',\n",
       " 'crumples',\n",
       " 'crush',\n",
       " 'crushed',\n",
       " 'crushing',\n",
       " 'cry',\n",
       " 'culpable',\n",
       " 'culprit',\n",
       " 'cumbersome',\n",
       " 'cunt',\n",
       " 'cunts',\n",
       " 'cuplrit',\n",
       " 'curse',\n",
       " 'cursed',\n",
       " 'curses',\n",
       " 'curt',\n",
       " 'cuss',\n",
       " 'cussed',\n",
       " 'cutthroat',\n",
       " 'cynical',\n",
       " 'cynicism',\n",
       " 'd*mn',\n",
       " 'damage',\n",
       " 'damaged',\n",
       " 'damages',\n",
       " 'damaging',\n",
       " 'damn',\n",
       " 'damnable',\n",
       " 'damnably',\n",
       " 'damnation',\n",
       " 'damned',\n",
       " 'damning',\n",
       " 'damper',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'dangerousness',\n",
       " 'dark',\n",
       " 'darken',\n",
       " 'darkened',\n",
       " 'darker',\n",
       " 'darkness',\n",
       " 'dastard',\n",
       " 'dastardly',\n",
       " 'daunt',\n",
       " 'daunting',\n",
       " 'dauntingly',\n",
       " 'dawdle',\n",
       " 'daze',\n",
       " 'dazed',\n",
       " 'dead',\n",
       " 'deadbeat',\n",
       " 'deadlock',\n",
       " 'deadly',\n",
       " 'deadweight',\n",
       " 'deaf',\n",
       " 'dearth',\n",
       " 'death',\n",
       " 'debacle',\n",
       " 'debase',\n",
       " 'debasement',\n",
       " 'debaser',\n",
       " 'debatable',\n",
       " 'debauch',\n",
       " 'debaucher',\n",
       " 'debauchery',\n",
       " 'debilitate',\n",
       " 'debilitating',\n",
       " 'debility',\n",
       " 'debt',\n",
       " 'debts',\n",
       " 'decadence',\n",
       " 'decadent',\n",
       " 'decay',\n",
       " 'decayed',\n",
       " 'deceit',\n",
       " 'deceitful',\n",
       " 'deceitfully',\n",
       " 'deceitfulness',\n",
       " 'deceive',\n",
       " 'deceiver',\n",
       " 'deceivers',\n",
       " 'deceiving',\n",
       " 'deception',\n",
       " 'deceptive',\n",
       " 'deceptively',\n",
       " 'declaim',\n",
       " 'decline',\n",
       " 'declines',\n",
       " 'declining',\n",
       " 'decrement',\n",
       " 'decrepit',\n",
       " 'decrepitude',\n",
       " 'decry',\n",
       " 'defamation',\n",
       " 'defamations',\n",
       " 'defamatory',\n",
       " 'defame',\n",
       " 'defect',\n",
       " 'defective',\n",
       " 'defects',\n",
       " 'defensive',\n",
       " 'defiance',\n",
       " 'defiant',\n",
       " 'defiantly',\n",
       " 'deficiencies',\n",
       " 'deficiency',\n",
       " 'deficient',\n",
       " 'defile',\n",
       " 'defiler',\n",
       " 'deform',\n",
       " 'deformed',\n",
       " 'defrauding',\n",
       " 'defunct',\n",
       " 'defy',\n",
       " 'degenerate',\n",
       " 'degenerately',\n",
       " 'degeneration',\n",
       " 'degradation',\n",
       " 'degrade',\n",
       " 'degrading',\n",
       " 'degradingly',\n",
       " 'dehumanization',\n",
       " 'dehumanize',\n",
       " 'deign',\n",
       " 'deject',\n",
       " 'dejected',\n",
       " 'dejectedly',\n",
       " 'dejection',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delaying',\n",
       " 'delays',\n",
       " 'delinquency',\n",
       " 'delinquent',\n",
       " 'delirious',\n",
       " 'delirium',\n",
       " 'delude',\n",
       " 'deluded',\n",
       " 'deluge',\n",
       " 'delusion',\n",
       " 'delusional',\n",
       " 'delusions',\n",
       " 'demean',\n",
       " 'demeaning',\n",
       " 'demise',\n",
       " 'demolish',\n",
       " 'demolisher',\n",
       " 'demon',\n",
       " 'demonic',\n",
       " 'demonize',\n",
       " 'demonized',\n",
       " 'demonizes',\n",
       " 'demonizing',\n",
       " 'demoralize',\n",
       " 'demoralizing',\n",
       " 'demoralizingly',\n",
       " 'denial',\n",
       " 'denied',\n",
       " 'denies',\n",
       " 'denigrate',\n",
       " 'denounce',\n",
       " 'dense',\n",
       " 'dent',\n",
       " 'dented',\n",
       " 'dents',\n",
       " 'denunciate',\n",
       " 'denunciation',\n",
       " 'denunciations',\n",
       " 'deny',\n",
       " 'denying',\n",
       " 'deplete',\n",
       " 'deplorable',\n",
       " 'deplorably',\n",
       " 'deplore',\n",
       " 'deploring',\n",
       " 'deploringly',\n",
       " 'deprave',\n",
       " 'depraved',\n",
       " 'depravedly',\n",
       " 'deprecate',\n",
       " 'depress',\n",
       " 'depressed',\n",
       " 'depressing',\n",
       " 'depressingly',\n",
       " 'depression',\n",
       " 'depressions',\n",
       " 'deprive',\n",
       " 'deprived',\n",
       " 'deride',\n",
       " 'derision',\n",
       " 'derisive',\n",
       " 'derisively',\n",
       " 'derisiveness',\n",
       " 'derogatory',\n",
       " 'desecrate',\n",
       " 'desert',\n",
       " 'desertion',\n",
       " 'desiccate',\n",
       " 'desiccated',\n",
       " 'desititute',\n",
       " 'desolate',\n",
       " 'desolately',\n",
       " 'desolation',\n",
       " 'despair',\n",
       " 'despairing',\n",
       " 'despairingly',\n",
       " 'desperate',\n",
       " 'desperately',\n",
       " 'desperation',\n",
       " 'despicable',\n",
       " 'despicably',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words = negative_words[0].tolist()\n",
    "negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90f6474c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tk_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m NEGATIVE_SCORE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Tk_word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mTk_words\u001b[49m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Tk_word \u001b[38;5;129;01min\u001b[39;00m negative_words:\n\u001b[0;32m      4\u001b[0m       NEGATIVE_SCORE \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tk_words' is not defined"
     ]
    }
   ],
   "source": [
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae33ee1",
   "metadata": {},
   "source": [
    "### 3.Polarity Score = (POSITIVE_SCORE – NEGATIVE_SCORE) / ((POSITIVE_SCORE + NEGATIVE_SCORE) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af042ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6ecadde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POLARITY_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2223b",
   "metadata": {},
   "source": [
    "### 4.Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abc00035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25f45390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "SUBJECTIVITY_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263357d",
   "metadata": {},
   "source": [
    "### 5.Average Sentence Length = the number of words / the number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ccc83c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e765458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "The_number_of_words = num_words\n",
    "The_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6bee6dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.116883116883116"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences) #The_number_of_sentences= sent_count =77\n",
    "AVG_SENTENCE_LENGTH "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a11f1",
   "metadata": {},
   "source": [
    "#### The number of complex words in URL_ID_37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f9e675bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n"
     ]
    }
   ],
   "source": [
    "def has_more_than_two_syllables(word):\n",
    "    vowels = 'aeiouy'\n",
    "    syllables = 0\n",
    "    in_vowel_group = False\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            if not in_vowel_group:\n",
    "                syllables += 1\n",
    "                in_vowel_group = True\n",
    "        else:\n",
    "            in_vowel_group = False\n",
    "    return syllables > 2\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list))) # word List is the no of words in text\n",
    "\n",
    "print(more_than_two_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6b586a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "The_number_of_complex_words = more_than_two_syllables\n",
    "\n",
    "The_number_of_complex_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4241172",
   "metadata": {},
   "source": [
    "### 6.Percentage of Complex words = the number of complex words / the number of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "efab452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43650126156433977"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "PERCENTAGE_OF_COMPLEX_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb729b3",
   "metadata": {},
   "source": [
    "### 7.Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a186f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.421353751378982"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "FOG_INDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24446429",
   "metadata": {},
   "source": [
    "### 8.Average Number of Words Per Sentence = the total number of words / the total number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7dd7c6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.116883116883116"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a023fbb",
   "metadata": {},
   "source": [
    "### 9.Complex words count are words in the text that contain more than two syllables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e72ea64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "COMPLEX_WORD_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee652b",
   "metadata": {},
   "source": [
    "## 10.Word count\n",
    "### We count the total cleaned words present in the text by removing the stop words (using stopwords class of nltk package)\n",
    "### and removing any punctuations like ? ! , . from the word before counting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2b5a22d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_COUNT = Total_words_after_cleaning\n",
    "WORD_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ec375",
   "metadata": {},
   "source": [
    "### 11.Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "22803105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 4, 1, 2, 3, 2, 4, 1, 2, 1, 2, 1, 3, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 5, 2, 2, 1, 1, 1, 1, 2, 1, 3, 1, 2, 2, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 4, 1, 1, 1, 5, 4, 2, 1, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 5, 5, 1, 2, 2, 3, 3, 2, 1, 1, 4, 6, 1, 3, 1, 3, 1, 1, 2, 5, 1, 2, 2, 1, 3, 5, 1, 1, 1, 1, 2, 5, 5, 1, 2, 1, 1, 1, 3, 4, 1, 1, 4, 2, 3, 3, 5, 3, 1, 5, 3, 1, 1, 1, 2, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 2, 3, 1, 3, 1, 2, 1, 1, 3, 1, 3, 1, 1, 2, 1, 4, 1, 3, 1, 3, 2, 1, 1, 2, 2, 1, 1, 3, 2, 1, 4, 1, 2, 1, 3, 3, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 2, 2, 2, 1, 2, 1, 1, 1, 5, 1, 2, 1, 3, 1, 1, 1, 2, 1, 2, 2, 3, 1, 2, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 2, 3, 1, 3, 4, 3, 1, 3, 3, 1, 1, 4, 2, 1, 1, 2, 2, 2, 1, 6, 1, 2, 1, 2, 1, 1, 1, 4, 3, 1, 3, 3, 1, 2, 1, 3, 1, 1, 1, 1, 1, 3, 1, 3, 1, 4, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 4, 5, 4, 1, 4, 1, 4, 2, 4, 1, 4, 2, 1, 1, 2, 2, 4, 1, 3, 4, 2, 3, 3, 2, 1, 2, 2, 3, 2, 2, 1, 1, 2, 2, 3, 3, 1, 3, 2, 2, 1, 3, 2, 2, 1, 1, 2, 1, 1, 3, 3, 2, 1, 2, 1, 4, 1, 4, 4, 2, 3, 2, 2, 3, 1, 1, 2, 3, 1, 2, 2, 4, 2, 7, 2, 2, 4, 3, 1, 2, 4, 1, 1, 1, 2, 3, 1, 2, 2, 2, 1, 3, 2, 4, 3, 1, 3, 2, 3, 3, 1, 5, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 1, 2, 2, 1, 2, 4, 1, 4, 3, 1, 3, 3, 3, 3, 3, 1, 3, 1, 3, 2, 3, 1, 2, 2, 1, 1, 4, 1, 4, 1, 4, 3, 1, 3, 2, 1, 3, 1, 2, 2, 3, 2, 2, 2, 1, 3, 4, 1, 1, 2, 3, 3, 3, 2, 1, 4, 1, 3, 2, 4, 1, 2, 2, 2, 1, 2, 3, 3, 3, 3, 1, 3, 1, 1, 2, 3, 1, 1, 2, 1, 2, 3, 1, 2, 1, 1, 3, 1, 2, 1, 4, 1, 2, 1, 4, 3, 2, 2, 3, 1, 1, 4, 2, 1, 2, 3, 2, 1, 1, 1, 1, 2, 4, 2, 1, 2, 1, 1, 1, 2, 4, 2, 2, 4, 1, 5, 4, 2, 2, 1, 3, 3, 1, 4, 1, 1, 1, 2, 1, 1, 1, 4, 2, 1, 2, 1, 1, 1, 3, 3, 3, 3, 1, 2, 3, 3, 1, 3, 4, 2, 2, 1, 1, 3, 1, 1, 1, 2, 2, 2, 7, 2, 2, 1, 1, 1, 1, 3, 4, 3, 1, 1, 1, 1, 3, 1, 3, 1, 6, 1, 3, 1, 1, 4, 1, 2, 1, 7, 2, 1, 3, 1, 1, 1, 2, 6, 2, 2, 4, 2, 2, 1, 3, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 3, 3, 1, 2, 3, 4, 6, 2, 1, 2, 1, 4, 5, 1, 3, 3, 2, 2, 2, 1, 2, 1, 1, 2, 3, 1, 1, 2, 4, 1, 1, 3, 3, 2, 3, 1, 1, 3, 2, 2, 4, 2, 1, 2, 2, 3, 2, 5, 3, 2, 3, 3, 2, 2, 3, 2, 1, 2, 3, 2, 1, 2, 2, 4, 3, 4, 1, 1, 1, 1, 3, 6, 2, 3, 2, 2, 1, 5, 2, 1, 3, 4, 1, 2, 2, 3, 2, 1, 1, 1, 1, 1, 2, 1, 2, 3, 3, 1, 1, 1, 4, 1, 3, 2, 1, 3, 2, 2, 1, 3, 1, 3, 1, 2, 1, 3, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 4, 5, 1, 1, 1, 2, 2, 1, 1, 1, 1, 4, 1, 5, 1, 1, 1, 1, 6, 3, 2, 3, 1, 1, 1, 3, 2, 4, 5, 3, 2, 1, 2, 3, 1, 1, 4, 3, 2, 4, 1, 3, 2, 1, 2, 2, 1, 1, 3, 3, 2, 4, 1, 1, 4, 3, 2, 2, 3, 4, 1, 1, 2, 1, 1, 3, 3, 2, 1, 3, 1, 6, 3, 2, 1, 1, 1, 2, 1, 4, 1, 1, 3, 3, 2, 1, 2, 1, 2, 1, 2, 1, 3, 1, 1, 3, 2, 1, 3, 1, 1, 3, 3, 1, 1, 4, 2, 1, 1, 3, 2, 3, 1, 2, 4, 1, 2, 4, 3, 3, 2, 3, 3, 1, 1, 1, 1, 3, 5, 2, 1, 1, 2, 1, 2, 5, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 1, 6, 2, 1, 3, 3, 2, 1, 1, 3, 1, 1, 2, 2, 2, 3, 1, 4, 1, 1, 1, 4, 1, 2, 3, 2, 2, 1, 1, 4, 1, 5, 1, 2, 1, 3, 2, 1, 4, 4, 2, 2, 2, 1, 3, 3, 2, 1, 1, 1, 3, 1, 3, 4, 3, 1, 2, 2, 1, 1, 1, 1, 2, 4, 5, 5, 1, 4, 1, 1, 1, 1, 1, 5, 3, 2, 1, 1, 3, 5, 2, 5, 1, 1, 1, 1, 1, 3, 5, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 5, 3, 1, 3, 1, 5, 3, 1, 2, 1, 5, 1, 3, 1, 2, 4, 1, 4, 1, 1, 4, 2, 1, 2, 3, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 6, 3, 3, 1, 1, 4, 1, 2, 5, 2, 1, 1, 2, 1, 2, 1, 1, 1, 5, 2, 2, 3, 1, 2, 1, 1, 3, 3, 3, 1, 6, 5, 5, 4, 1, 1, 4, 4, 2, 4, 4, 2, 1, 4, 5, 1, 5, 1, 2, 1, 3, 1, 1, 2, 3, 1, 4, 1, 2, 2, 1, 1, 1, 3, 1, 2, 4, 1, 1, 1, 1, 1, 2, 3, 2, 2, 3, 1, 1, 1, 1, 2, 1, 3, 1, 3, 3, 2, 2, 3, 1, 3, 2, 1, 1, 1, 1, 2, 2, 1, 4, 1, 1, 2, 1, 2, 1, 1, 1, 3, 5, 2, 2, 3, 1, 2, 4, 1, 2, 1, 1, 4, 4, 1, 1, 1, 3, 1, 2, 5, 1, 4, 1, 2, 1, 1, 2, 2, 1, 1, 3, 4, 1, 2, 1, 1, 1, 3, 3, 3, 1, 1, 5, 1, 2, 3, 3, 4, 3, 4, 3, 1, 5, 3, 1, 1, 1, 1, 2, 1, 3, 3, 1, 3, 2, 4, 1, 1, 3, 1, 1, 1, 4, 1, 2, 4, 2, 2, 1, 2, 1, 3, 2, 3, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 2, 3, 3, 3, 1, 3, 6, 2, 3, 2, 5, 3, 2, 1, 2, 3, 1, 4, 1, 6, 2, 1, 4, 2, 2, 1, 1, 3, 3, 1, 1, 1, 3, 4, 2, 3, 1, 3, 2, 1, 3, 1, 1, 2, 2, 1, 5, 3, 2, 3, 3, 1, 2, 1, 3, 2, 1, 4, 2, 2, 2, 2, 1, 1, 3, 1, 1, 3, 2, 2, 2, 5, 4, 1, 5, 1, 3, 3, 1, 3, 5, 1, 1, 3, 3, 2, 2, 7, 2, 1, 3, 3, 3, 4, 1, 2, 2, 1, 1, 3, 3, 3, 2, 1, 1, 2, 3, 4, 1, 1, 2, 3, 1, 3, 1, 2, 4, 1, 2, 2, 1, 3, 2, 2, 1, 1, 4, 4, 2, 1, 2, 4, 1, 2, 3, 2, 1, 4, 4, 4, 1, 1, 2, 1, 2, 1, 1, 1, 2, 3, 2, 3, 1, 2, 1, 1, 5, 2, 5, 1, 4, 3, 4, 1, 1, 2, 1, 1, 3, 2, 1, 1, 3, 3, 1, 3, 2, 3, 1, 1, 2, 3, 1, 2, 1, 2, 3, 4, 2, 3, 1, 2, 3, 5, 2, 1, 1, 2, 2, 4, 2, 1, 2, 2, 3, 1, 3, 1, 2, 1, 1, 3, 4, 3, 1, 1, 2, 2, 1, 3, 1, 2, 2, 2, 2, 1, 6, 2, 1, 2, 4, 6, 1, 3, 2, 3, 1, 1, 4, 3, 4, 2, 1, 2, 1, 1, 3, 4, 1, 4, 1, 4, 3, 1, 1, 3, 1, 5, 2, 1, 4, 1, 2, 3, 1, 5, 3, 1, 5, 3, 1, 2, 2, 2, 2, 3, 1, 2, 3, 4, 2, 1, 1, 2, 1, 3, 1, 4, 2, 1, 1, 1, 1, 4, 1, 2, 2, 3, 3, 2, 3, 4, 1, 1, 3, 1, 3, 4, 3, 3, 1, 1, 4, 5, 1, 2, 4, 4, 2, 2, 4, 2, 3, 2, 1, 3, 1, 2, 3, 3, 6, 1, 1, 3, 1, 2, 2, 2, 2, 1, 1, 2, 3, 2, 1, 3, 1, 2, 2, 1, 1, 4, 2, 1, 3, 4, 3, 1, 7, 4, 4, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 3, 2, 2, 2, 1, 4, 2, 2, 1, 2, 2, 1, 4, 1, 5, 6, 2, 1, 2, 7, 1, 3, 5, 2, 2, 2, 1, 2, 1, 1, 5, 3, 1, 7, 2, 2, 1, 2, 1, 1, 3, 5, 4, 1, 2, 4, 2, 3, 2, 4, 3, 4, 1, 2, 6, 4, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 4, 1, 3, 3, 3, 1, 3, 2, 1, 4, 3, 1, 1, 1, 1, 5, 1, 1, 4, 2, 1, 2, 2, 2, 2, 2, 1, 3, 1, 1, 2, 1, 3, 1, 3, 3, 4, 3, 3, 1, 2, 1, 2, 5, 1, 1, 2, 1, 1, 1, 3, 1, 3, 2, 2, 1, 3, 1, 2, 3, 1, 1, 5, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 4, 1, 2, 1, 3, 1, 4, 1, 3, 2, 1, 1, 1, 2, 2, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = \"aeiou\"\n",
    "    vowel_count = 0\n",
    "    \n",
    "    # Count the number of vowels in the word\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            vowel_count += 1\n",
    "    \n",
    "    # Handle exceptions for words ending with \"es\" or \"ed\"\n",
    "    if word[-2:] in [\"es\", \"ed\"]:\n",
    "        vowel_count -= 1\n",
    "    \n",
    "    # Handle words with no vowels\n",
    "    if vowel_count == 0:\n",
    "        vowel_count = 1\n",
    "    \n",
    "    return vowel_count\n",
    "\n",
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "print(syllable_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b589eb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3749"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0876257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3749"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "SYLLABLE_PER_WORD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e010ab",
   "metadata": {},
   "source": [
    "### 12.Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "4eab1109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "\n",
    "# Looping through each word in the text\n",
    "for word in URL_ID_37.split():\n",
    "    # Converting the word to lowercase for case-insensitive matching\n",
    "    word = word.lower()\n",
    "    # If the word matches one of our target words, increment its count in the dictionary\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "# Printing the counts of each word\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Calculating the total count\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1003ae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSONAL_PRONOUNS=total_count\n",
    "PERSONAL_PRONOUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6a574",
   "metadata": {},
   "source": [
    "## 13.Average Word Length\n",
    "#### Sum of the total number of characters in each word/Total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f510ac2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.795505617977528"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "AVG_WORD_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793afecd",
   "metadata": {},
   "source": [
    "# 2.for URL_ID :38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b6da1caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\3076817897.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "23d62570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0bb85ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Human minds, a fascination in itself carrying the potential of tinkering nature with the pixie dust intelligence, creating and solving the mysteries and wonders with anything but admiration. However, no matter how captivating a human mind can be, it could sometimes be appalled. It could be the hunger or maybe the desire to want more, to go beyond and unravel the limitations, or maybe something like pure greed. Humans have never stopped and always keep evolving when it comes to intelligence and this is what makes them the supreme.',\n",
       " 'Intelligence calls out for supremacy and so, what if there was to evolve something that opposed a challenge to the very human minds, to their capabilities while making them question their own importance among themselves? Artificial Intelligence came as a revolution, havoc when it first came to the light. The concept of making machines does work on their own, like granting machines –The Intelligence.',\n",
       " 'The idea of making machines work like humans came back in the 19s. Back then people didn’t believe in such a thing as making a non-living thing work, think, and carry tasks on its own, not to mention, to actually surpass humans themselves in those skills. The facts are it did. By 1997. The greatest chess player, Garry Kasparov was defeated in a chess game by a machine and this is where exactly, a top skilled human lost to a mere machine created by another who by himself could’ve never defeated him. It was a rule of power, of betterment, of skills, and the granted supremacy. Were AI and Machines just tools? Equipment?  Something that helped an unskilled person with his mind and intelligence creates something that could do the skilled work for him with perfection and precision? Well initially it was, however, as time passed as humans got drawn to the puzzle of AI, a lot changed. Human research went deeper and deeper and as a result, the machines evolved with it.',\n",
       " 'At present, AI & Machines is a growing field. As it develops and improves, it has become a part of the industrial revolution. In industries, most of the laborious work that was once taken care of by humans was now replaced by machines. Naturally, with the evolution in machines, its precision, mass productivity, quality control, time efficiencies, and all the other factors made it a better choice. A choice over humans.',\n",
       " 'This led to fear, a fear of a not-so-distant future, a future where maybe machines will be so evolved that they’ll take over the need of a human employee leading to unemployment. With the population increase around the world, it became the new tech threat for the labor market. Then again… how true is it? Does AI really oppose a threat? Will adapting to technology make millions of people lose their jobs? Will it lead to mass unemployment? Will the machines really surpass humans? Will, the creation take over the creator?',\n",
       " 'No matter how fearful the future with AI may seem, in reality, it is not that scary. Truth is AI is the present reality, it is the key that holds the power to unlock a whole next level of human evolution. Technology is growing. There was a time where technology was just an idea, but today that idea has been implemented, it’s working and is carried out. Nobody could stop the advancement and growth of Artificial Intelligence, it’s a wave that is already flowing and we as the present generation and the generations to come to have to learn, to learn to swim in this flow and avoid drowning.',\n",
       " 'Many jobs will be replaced by machines, as AI evolves it’ll keep challenging human minds and their skills. With the present COVID 19 situation, contactless cashiers to robots delivering packages have already taken over the usual routine tasks. The jobs of Secretaries, Schedulers, and book-keeper are at risk too. Manufacturing units, agriculture, food services, retail, transportation & logistic, and hospitality are all a part of the AI-affected automation. At an estimation, it is said that around 20 million jobs, especially including manufacturing will be lost to robots. As AI, robotics, 3D printing, and genetics make their way in, even the architects, medical docs, and music composers feel threatened by technology. Making us question that will AI even edge us out of our brain jobs too? Now that can be terrifying.',\n",
       " 'However, as much as machines will be replacing few jobs, they’ll also be creating new jobs.  With the economic growth, innovation, and investment around 133 million jobs are said to be generated. These newly enhanced jobs are to create benefits and amplify one’s creativity, strategy, and entrepreneurial skills. So what is the catch?',\n",
       " 'Well, it’s the skills. Even though AI is creating 3 times more jobs than it is destroying, it’s the skills that count. AI surged in new job opportunities, opportunities like Senior Data Scientist, Mobile Application Developer, and SEO specialist. These jobs were once never heard of but now with AI it’s born, however, to do these jobs or for its qualification, one needs high-level skills and to acquire those skills can be an expensive and time-consuming task. The future generation might be able to cope up with it but the real struggle is to be faced by the present two generations. It’s the vulnerability between the skill gap and unemployment and the youths are the ones to be crushed the most.',\n",
       " 'Therefore, as the advancement of AI becomes inevitable there remains no choice but to adapt, learn, equip ourselves and grow with it. The companies have to work together to build an AI-ready workplace. They should collaborate with the government, educators, and non-profit organizations and work together to bring out policies that could help understand the technologies’ impacts faster while also providing the employees some security. The economic and business planning should be made considerable for minimizing the impact on local jobs and properly maximizing the opportunities.',\n",
       " 'The employees should be provided with proper tools to carry along with the new opportunities while acquiring AI-based skills for their day-to-day work. New skills should be identified and implemented for the upskilling and continual learning initiatives. Employees will have to maximize their Robotic Quotient and learn core skills. They’ll have to adapt to new working models and understand their roles in the coming future. ',\n",
       " 'Howsoever, it’s not like AI will totally take over control, even though AI proves to be a better choice, it still has its limitations at present. First, it’s expensive, secondly, manufacturing machines in bulk is not good for the environment. Machines are also very high maintenance, therefore human labor will often come cheaper and so will be considered over machines. Underdeveloped countries will find it hard to equip their people with the upskilling and reskilling required for AI workplace and so for AI to play a role in those countries, might take years. AI can also be risky and unethical, as it’s hard to figure out who to be held responsible for in cases where an AI went wrong.',\n",
       " 'No matter, how advanced AI gets, there are some skills where humans will always have an upper hand i.e., soft skills. Skills like teamwork, communication, creativity, and critical thinking are something that AI hasn’t been able to beat us up to yet and so the value of creativity, leadership, and emotional intelligence has increased. Although, with machines coming in between humans causing the lack of human-to-human interaction, the humans seem to fade away a little.',\n",
       " 'With this era, comes the need for good leaders. Leaders who are capable of handling both machines and humans together, the ones who are organized enough to manage the skilled and the unskilled employees while providing the unskilled trainees with proper training. Leaders who hold profound soft skills and encourage teamwork while working along with machines. The ones who are patient, calm, and optimized.  ',\n",
       " 'In conclusion, yes AI and machines are going to be very challenging but there’s nothing humans haven’t overcome. Adaptation and up-gradation are going to be the primary factor for survival. As we witness the onset of the 4th industrial revolution, let’s buckle up our seats and race along the highway with the essential fuels (skills) so as to not let ourselves eliminated. After all, this is an unending race with infinity as the end, all we could do is try not to run out of fuel. Try not to be outdated. ']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ee9d286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c4781a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:31]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "599c5eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human minds, a fascination in itself carrying the potential of tinkering nature with the pixie dust intelligence, creating and solving the mysteries and wonders with anything but admiration. However, no matter how captivating a human mind can be, it could sometimes be appalled. It could be the hunger or maybe the desire to want more, to go beyond and unravel the limitations, or maybe something like pure greed. Humans have never stopped and always keep evolving when it comes to intelligence and this is what makes them the supreme. Intelligence calls out for supremacy and so, what if there was to evolve something that opposed a challenge to the very human minds, to their capabilities while making them question their own importance among themselves? Artificial Intelligence came as a revolution, havoc when it first came to the light. The concept of making machines does work on their own, like granting machines –The Intelligence. The idea of making machines work like humans came back in the 19s. Back then people didn’t believe in such a thing as making a non-living thing work, think, and carry tasks on its own, not to mention, to actually surpass humans themselves in those skills. The facts are it did. By 1997. The greatest chess player, Garry Kasparov was defeated in a chess game by a machine and this is where exactly, a top skilled human lost to a mere machine created by another who by himself could’ve never defeated him. It was a rule of power, of betterment, of skills, and the granted supremacy. Were AI and Machines just tools? Equipment?  Something that helped an unskilled person with his mind and intelligence creates something that could do the skilled work for him with perfection and precision? Well initially it was, however, as time passed as humans got drawn to the puzzle of AI, a lot changed. Human research went deeper and deeper and as a result, the machines evolved with it. At present, AI & Machines is a growing field. As it develops and improves, it has become a part of the industrial revolution. In industries, most of the laborious work that was once taken care of by humans was now replaced by machines. Naturally, with the evolution in machines, its precision, mass productivity, quality control, time efficiencies, and all the other factors made it a better choice. A choice over humans. This led to fear, a fear of a not-so-distant future, a future where maybe machines will be so evolved that they’ll take over the need of a human employee leading to unemployment. With the population increase around the world, it became the new tech threat for the labor market. Then again… how true is it? Does AI really oppose a threat? Will adapting to technology make millions of people lose their jobs? Will it lead to mass unemployment? Will the machines really surpass humans? Will, the creation take over the creator? No matter how fearful the future with AI may seem, in reality, it is not that scary. Truth is AI is the present reality, it is the key that holds the power to unlock a whole next level of human evolution. Technology is growing. There was a time where technology was just an idea, but today that idea has been implemented, it’s working and is carried out. Nobody could stop the advancement and growth of Artificial Intelligence, it’s a wave that is already flowing and we as the present generation and the generations to come to have to learn, to learn to swim in this flow and avoid drowning. Many jobs will be replaced by machines, as AI evolves it’ll keep challenging human minds and their skills. With the present COVID 19 situation, contactless cashiers to robots delivering packages have already taken over the usual routine tasks. The jobs of Secretaries, Schedulers, and book-keeper are at risk too. Manufacturing units, agriculture, food services, retail, transportation & logistic, and hospitality are all a part of the AI-affected automation. At an estimation, it is said that around 20 million jobs, especially including manufacturing will be lost to robots. As AI, robotics, 3D printing, and genetics make their way in, even the architects, medical docs, and music composers feel threatened by technology. Making us question that will AI even edge us out of our brain jobs too? Now that can be terrifying. However, as much as machines will be replacing few jobs, they’ll also be creating new jobs.  With the economic growth, innovation, and investment around 133 million jobs are said to be generated. These newly enhanced jobs are to create benefits and amplify one’s creativity, strategy, and entrepreneurial skills. So what is the catch? Well, it’s the skills. Even though AI is creating 3 times more jobs than it is destroying, it’s the skills that count. AI surged in new job opportunities, opportunities like Senior Data Scientist, Mobile Application Developer, and SEO specialist. These jobs were once never heard of but now with AI it’s born, however, to do these jobs or for its qualification, one needs high-level skills and to acquire those skills can be an expensive and time-consuming task. The future generation might be able to cope up with it but the real struggle is to be faced by the present two generations. It’s the vulnerability between the skill gap and unemployment and the youths are the ones to be crushed the most. Therefore, as the advancement of AI becomes inevitable there remains no choice but to adapt, learn, equip ourselves and grow with it. The companies have to work together to build an AI-ready workplace. They should collaborate with the government, educators, and non-profit organizations and work together to bring out policies that could help understand the technologies’ impacts faster while also providing the employees some security. The economic and business planning should be made considerable for minimizing the impact on local jobs and properly maximizing the opportunities. The employees should be provided with proper tools to carry along with the new opportunities while acquiring AI-based skills for their day-to-day work. New skills should be identified and implemented for the upskilling and continual learning initiatives. Employees will have to maximize their Robotic Quotient and learn core skills. They’ll have to adapt to new working models and understand their roles in the coming future.  Howsoever, it’s not like AI will totally take over control, even though AI proves to be a better choice, it still has its limitations at present. First, it’s expensive, secondly, manufacturing machines in bulk is not good for the environment. Machines are also very high maintenance, therefore human labor will often come cheaper and so will be considered over machines. Underdeveloped countries will find it hard to equip their people with the upskilling and reskilling required for AI workplace and so for AI to play a role in those countries, might take years. AI can also be risky and unethical, as it’s hard to figure out who to be held responsible for in cases where an AI went wrong. No matter, how advanced AI gets, there are some skills where humans will always have an upper hand i.e., soft skills. Skills like teamwork, communication, creativity, and critical thinking are something that AI hasn’t been able to beat us up to yet and so the value of creativity, leadership, and emotional intelligence has increased. Although, with machines coming in between humans causing the lack of human-to-human interaction, the humans seem to fade away a little. With this era, comes the need for good leaders. Leaders who are capable of handling both machines and humans together, the ones who are organized enough to manage the skilled and the unskilled employees while providing the unskilled trainees with proper training. Leaders who hold profound soft skills and encourage teamwork while working along with machines. The ones who are patient, calm, and optimized.   In conclusion, yes AI and machines are going to be very challenging but there’s nothing humans haven’t overcome. Adaptation and up-gradation are going to be the primary factor for survival. As we witness the onset of the 4th industrial revolution, let’s buckle up our seats and race along the highway with the essential fuels (skills) so as to not let ourselves eliminated. After all, this is an unending race with infinity as the end, all we could do is try not to run out of fuel. Try not to be outdated. '"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "36f269c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ID_38 = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e8aa77c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70 sentences in the string.\n"
     ]
    }
   ],
   "source": [
    "# Spliting the string into sentences using periods as delimiters\n",
    "sentences = URL_ID_38.split(\".\")\n",
    "\n",
    "# Getting the count of sentences\n",
    "Sent_count = len(sentences)\n",
    "\n",
    "print(f\"There are {Sent_count} sentences in the string.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dd40c95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in the string is: 1401\n"
     ]
    }
   ],
   "source": [
    "#the number of words in the string\n",
    "\n",
    "word_list = URL_ID_38.split()\n",
    "\n",
    "num_words = len(word_list)\n",
    "\n",
    "print(\"The number of words in the string is:\",num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ec76dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6997\n"
     ]
    }
   ],
   "source": [
    "#Sum of the total number of characters in each word\n",
    "words = URL_ID_38.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e6d46c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_38 = re.sub(re_punt, \"\",URL_ID_38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ac3afb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"38.txt\", \"w\")\n",
    "file.write(URL_ID_38)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8aca7975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 14:37:06] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 14:37:19] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 14:37:27] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"38.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fe438460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human minds a fascination in itself carrying t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Human minds a fascination in itself carrying t..."
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/38.txt\",header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "69388f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lwr = df[0].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d45ea6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    human minds a fascination in itself carrying t...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d27eb344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human',\n",
       "  'minds',\n",
       "  'a',\n",
       "  'fascination',\n",
       "  'in',\n",
       "  'itself',\n",
       "  'carrying',\n",
       "  'the',\n",
       "  'potential',\n",
       "  'of',\n",
       "  'tinkering',\n",
       "  'nature',\n",
       "  'with',\n",
       "  'the',\n",
       "  'pixie',\n",
       "  'dust',\n",
       "  'intelligence',\n",
       "  'creating',\n",
       "  'and',\n",
       "  'solving',\n",
       "  'the',\n",
       "  'mysteries',\n",
       "  'and',\n",
       "  'wonders',\n",
       "  'with',\n",
       "  'anything',\n",
       "  'but',\n",
       "  'admiration',\n",
       "  'however',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'how',\n",
       "  'captivating',\n",
       "  'a',\n",
       "  'human',\n",
       "  'mind',\n",
       "  'can',\n",
       "  'be',\n",
       "  'it',\n",
       "  'could',\n",
       "  'sometimes',\n",
       "  'be',\n",
       "  'appalled',\n",
       "  'it',\n",
       "  'could',\n",
       "  'be',\n",
       "  'the',\n",
       "  'hunger',\n",
       "  'or',\n",
       "  'maybe',\n",
       "  'the',\n",
       "  'desire',\n",
       "  'to',\n",
       "  'want',\n",
       "  'more',\n",
       "  'to',\n",
       "  'go',\n",
       "  'beyond',\n",
       "  'and',\n",
       "  'unravel',\n",
       "  'the',\n",
       "  'limitations',\n",
       "  'or',\n",
       "  'maybe',\n",
       "  'something',\n",
       "  'like',\n",
       "  'pure',\n",
       "  'greed',\n",
       "  'humans',\n",
       "  'have',\n",
       "  'never',\n",
       "  'stopped',\n",
       "  'and',\n",
       "  'always',\n",
       "  'keep',\n",
       "  'evolving',\n",
       "  'when',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'this',\n",
       "  'is',\n",
       "  'what',\n",
       "  'makes',\n",
       "  'them',\n",
       "  'the',\n",
       "  'supreme',\n",
       "  'intelligence',\n",
       "  'calls',\n",
       "  'out',\n",
       "  'for',\n",
       "  'supremacy',\n",
       "  'and',\n",
       "  'so',\n",
       "  'what',\n",
       "  'if',\n",
       "  'there',\n",
       "  'was',\n",
       "  'to',\n",
       "  'evolve',\n",
       "  'something',\n",
       "  'that',\n",
       "  'opposed',\n",
       "  'a',\n",
       "  'challenge',\n",
       "  'to',\n",
       "  'the',\n",
       "  'very',\n",
       "  'human',\n",
       "  'minds',\n",
       "  'to',\n",
       "  'their',\n",
       "  'capabilities',\n",
       "  'while',\n",
       "  'making',\n",
       "  'them',\n",
       "  'question',\n",
       "  'their',\n",
       "  'own',\n",
       "  'importance',\n",
       "  'among',\n",
       "  'themselves?',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'came',\n",
       "  'as',\n",
       "  'a',\n",
       "  'revolution',\n",
       "  'havoc',\n",
       "  'when',\n",
       "  'it',\n",
       "  'first',\n",
       "  'came',\n",
       "  'to',\n",
       "  'the',\n",
       "  'light',\n",
       "  'the',\n",
       "  'concept',\n",
       "  'of',\n",
       "  'making',\n",
       "  'machines',\n",
       "  'does',\n",
       "  'work',\n",
       "  'on',\n",
       "  'their',\n",
       "  'own',\n",
       "  'like',\n",
       "  'granting',\n",
       "  'machines',\n",
       "  'the',\n",
       "  'intelligence',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'making',\n",
       "  'machines',\n",
       "  'work',\n",
       "  'like',\n",
       "  'humans',\n",
       "  'came',\n",
       "  'back',\n",
       "  'in',\n",
       "  'the',\n",
       "  '19s',\n",
       "  'back',\n",
       "  'then',\n",
       "  'people',\n",
       "  'didnt',\n",
       "  'believe',\n",
       "  'in',\n",
       "  'such',\n",
       "  'a',\n",
       "  'thing',\n",
       "  'as',\n",
       "  'making',\n",
       "  'a',\n",
       "  'nonliving',\n",
       "  'thing',\n",
       "  'work',\n",
       "  'think',\n",
       "  'and',\n",
       "  'carry',\n",
       "  'tasks',\n",
       "  'on',\n",
       "  'its',\n",
       "  'own',\n",
       "  'not',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'to',\n",
       "  'actually',\n",
       "  'surpass',\n",
       "  'humans',\n",
       "  'themselves',\n",
       "  'in',\n",
       "  'those',\n",
       "  'skills',\n",
       "  'the',\n",
       "  'facts',\n",
       "  'are',\n",
       "  'it',\n",
       "  'did',\n",
       "  'by',\n",
       "  '1997',\n",
       "  'the',\n",
       "  'greatest',\n",
       "  'chess',\n",
       "  'player',\n",
       "  'garry',\n",
       "  'kasparov',\n",
       "  'was',\n",
       "  'defeated',\n",
       "  'in',\n",
       "  'a',\n",
       "  'chess',\n",
       "  'game',\n",
       "  'by',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'and',\n",
       "  'this',\n",
       "  'is',\n",
       "  'where',\n",
       "  'exactly',\n",
       "  'a',\n",
       "  'top',\n",
       "  'skilled',\n",
       "  'human',\n",
       "  'lost',\n",
       "  'to',\n",
       "  'a',\n",
       "  'mere',\n",
       "  'machine',\n",
       "  'created',\n",
       "  'by',\n",
       "  'another',\n",
       "  'who',\n",
       "  'by',\n",
       "  'himself',\n",
       "  'couldve',\n",
       "  'never',\n",
       "  'defeated',\n",
       "  'him',\n",
       "  'it',\n",
       "  'was',\n",
       "  'a',\n",
       "  'rule',\n",
       "  'of',\n",
       "  'power',\n",
       "  'of',\n",
       "  'betterment',\n",
       "  'of',\n",
       "  'skills',\n",
       "  'and',\n",
       "  'the',\n",
       "  'granted',\n",
       "  'supremacy',\n",
       "  'were',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'just',\n",
       "  'tools?',\n",
       "  'equipment?',\n",
       "  'something',\n",
       "  'that',\n",
       "  'helped',\n",
       "  'an',\n",
       "  'unskilled',\n",
       "  'person',\n",
       "  'with',\n",
       "  'his',\n",
       "  'mind',\n",
       "  'and',\n",
       "  'intelligence',\n",
       "  'creates',\n",
       "  'something',\n",
       "  'that',\n",
       "  'could',\n",
       "  'do',\n",
       "  'the',\n",
       "  'skilled',\n",
       "  'work',\n",
       "  'for',\n",
       "  'him',\n",
       "  'with',\n",
       "  'perfection',\n",
       "  'and',\n",
       "  'precision?',\n",
       "  'well',\n",
       "  'initially',\n",
       "  'it',\n",
       "  'was',\n",
       "  'however',\n",
       "  'as',\n",
       "  'time',\n",
       "  'passed',\n",
       "  'as',\n",
       "  'humans',\n",
       "  'got',\n",
       "  'drawn',\n",
       "  'to',\n",
       "  'the',\n",
       "  'puzzle',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'changed',\n",
       "  'human',\n",
       "  'research',\n",
       "  'went',\n",
       "  'deeper',\n",
       "  'and',\n",
       "  'deeper',\n",
       "  'and',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'the',\n",
       "  'machines',\n",
       "  'evolved',\n",
       "  'with',\n",
       "  'it',\n",
       "  'at',\n",
       "  'present',\n",
       "  'ai',\n",
       "  'machines',\n",
       "  'is',\n",
       "  'a',\n",
       "  'growing',\n",
       "  'field',\n",
       "  'as',\n",
       "  'it',\n",
       "  'develops',\n",
       "  'and',\n",
       "  'improves',\n",
       "  'it',\n",
       "  'has',\n",
       "  'become',\n",
       "  'a',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'industrial',\n",
       "  'revolution',\n",
       "  'in',\n",
       "  'industries',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'laborious',\n",
       "  'work',\n",
       "  'that',\n",
       "  'was',\n",
       "  'once',\n",
       "  'taken',\n",
       "  'care',\n",
       "  'of',\n",
       "  'by',\n",
       "  'humans',\n",
       "  'was',\n",
       "  'now',\n",
       "  'replaced',\n",
       "  'by',\n",
       "  'machines',\n",
       "  'naturally',\n",
       "  'with',\n",
       "  'the',\n",
       "  'evolution',\n",
       "  'in',\n",
       "  'machines',\n",
       "  'its',\n",
       "  'precision',\n",
       "  'mass',\n",
       "  'productivity',\n",
       "  'quality',\n",
       "  'control',\n",
       "  'time',\n",
       "  'efficiencies',\n",
       "  'and',\n",
       "  'all',\n",
       "  'the',\n",
       "  'other',\n",
       "  'factors',\n",
       "  'made',\n",
       "  'it',\n",
       "  'a',\n",
       "  'better',\n",
       "  'choice',\n",
       "  'a',\n",
       "  'choice',\n",
       "  'over',\n",
       "  'humans',\n",
       "  'this',\n",
       "  'led',\n",
       "  'to',\n",
       "  'fear',\n",
       "  'a',\n",
       "  'fear',\n",
       "  'of',\n",
       "  'a',\n",
       "  'notsodistant',\n",
       "  'future',\n",
       "  'a',\n",
       "  'future',\n",
       "  'where',\n",
       "  'maybe',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'be',\n",
       "  'so',\n",
       "  'evolved',\n",
       "  'that',\n",
       "  'theyll',\n",
       "  'take',\n",
       "  'over',\n",
       "  'the',\n",
       "  'need',\n",
       "  'of',\n",
       "  'a',\n",
       "  'human',\n",
       "  'employee',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'unemployment',\n",
       "  'with',\n",
       "  'the',\n",
       "  'population',\n",
       "  'increase',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'it',\n",
       "  'became',\n",
       "  'the',\n",
       "  'new',\n",
       "  'tech',\n",
       "  'threat',\n",
       "  'for',\n",
       "  'the',\n",
       "  'labor',\n",
       "  'market',\n",
       "  'then',\n",
       "  'again',\n",
       "  'how',\n",
       "  'true',\n",
       "  'is',\n",
       "  'it?',\n",
       "  'does',\n",
       "  'ai',\n",
       "  'really',\n",
       "  'oppose',\n",
       "  'a',\n",
       "  'threat?',\n",
       "  'will',\n",
       "  'adapting',\n",
       "  'to',\n",
       "  'technology',\n",
       "  'make',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'people',\n",
       "  'lose',\n",
       "  'their',\n",
       "  'jobs?',\n",
       "  'will',\n",
       "  'it',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'mass',\n",
       "  'unemployment?',\n",
       "  'will',\n",
       "  'the',\n",
       "  'machines',\n",
       "  'really',\n",
       "  'surpass',\n",
       "  'humans?',\n",
       "  'will',\n",
       "  'the',\n",
       "  'creation',\n",
       "  'take',\n",
       "  'over',\n",
       "  'the',\n",
       "  'creator?',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'how',\n",
       "  'fearful',\n",
       "  'the',\n",
       "  'future',\n",
       "  'with',\n",
       "  'ai',\n",
       "  'may',\n",
       "  'seem',\n",
       "  'in',\n",
       "  'reality',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'that',\n",
       "  'scary',\n",
       "  'truth',\n",
       "  'is',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'the',\n",
       "  'present',\n",
       "  'reality',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'key',\n",
       "  'that',\n",
       "  'holds',\n",
       "  'the',\n",
       "  'power',\n",
       "  'to',\n",
       "  'unlock',\n",
       "  'a',\n",
       "  'whole',\n",
       "  'next',\n",
       "  'level',\n",
       "  'of',\n",
       "  'human',\n",
       "  'evolution',\n",
       "  'technology',\n",
       "  'is',\n",
       "  'growing',\n",
       "  'there',\n",
       "  'was',\n",
       "  'a',\n",
       "  'time',\n",
       "  'where',\n",
       "  'technology',\n",
       "  'was',\n",
       "  'just',\n",
       "  'an',\n",
       "  'idea',\n",
       "  'but',\n",
       "  'today',\n",
       "  'that',\n",
       "  'idea',\n",
       "  'has',\n",
       "  'been',\n",
       "  'implemented',\n",
       "  'its',\n",
       "  'working',\n",
       "  'and',\n",
       "  'is',\n",
       "  'carried',\n",
       "  'out',\n",
       "  'nobody',\n",
       "  'could',\n",
       "  'stop',\n",
       "  'the',\n",
       "  'advancement',\n",
       "  'and',\n",
       "  'growth',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'its',\n",
       "  'a',\n",
       "  'wave',\n",
       "  'that',\n",
       "  'is',\n",
       "  'already',\n",
       "  'flowing',\n",
       "  'and',\n",
       "  'we',\n",
       "  'as',\n",
       "  'the',\n",
       "  'present',\n",
       "  'generation',\n",
       "  'and',\n",
       "  'the',\n",
       "  'generations',\n",
       "  'to',\n",
       "  'come',\n",
       "  'to',\n",
       "  'have',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'to',\n",
       "  'swim',\n",
       "  'in',\n",
       "  'this',\n",
       "  'flow',\n",
       "  'and',\n",
       "  'avoid',\n",
       "  'drowning',\n",
       "  'many',\n",
       "  'jobs',\n",
       "  'will',\n",
       "  'be',\n",
       "  'replaced',\n",
       "  'by',\n",
       "  'machines',\n",
       "  'as',\n",
       "  'ai',\n",
       "  'evolves',\n",
       "  'itll',\n",
       "  'keep',\n",
       "  'challenging',\n",
       "  'human',\n",
       "  'minds',\n",
       "  'and',\n",
       "  'their',\n",
       "  'skills',\n",
       "  'with',\n",
       "  'the',\n",
       "  'present',\n",
       "  'covid',\n",
       "  '19',\n",
       "  'situation',\n",
       "  'contactless',\n",
       "  'cashiers',\n",
       "  'to',\n",
       "  'robots',\n",
       "  'delivering',\n",
       "  'packages',\n",
       "  'have',\n",
       "  'already',\n",
       "  'taken',\n",
       "  'over',\n",
       "  'the',\n",
       "  'usual',\n",
       "  'routine',\n",
       "  'tasks',\n",
       "  'the',\n",
       "  'jobs',\n",
       "  'of',\n",
       "  'secretaries',\n",
       "  'schedulers',\n",
       "  'and',\n",
       "  'bookkeeper',\n",
       "  'are',\n",
       "  'at',\n",
       "  'risk',\n",
       "  'too',\n",
       "  'manufacturing',\n",
       "  'units',\n",
       "  'agriculture',\n",
       "  'food',\n",
       "  'services',\n",
       "  'retail',\n",
       "  'transportation',\n",
       "  'logistic',\n",
       "  'and',\n",
       "  'hospitality',\n",
       "  'are',\n",
       "  'all',\n",
       "  'a',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'aiaffected',\n",
       "  'automation',\n",
       "  'at',\n",
       "  'an',\n",
       "  'estimation',\n",
       "  'it',\n",
       "  'is',\n",
       "  'said',\n",
       "  'that',\n",
       "  'around',\n",
       "  '20',\n",
       "  'million',\n",
       "  'jobs',\n",
       "  'especially',\n",
       "  'including',\n",
       "  'manufacturing',\n",
       "  'will',\n",
       "  'be',\n",
       "  'lost',\n",
       "  'to',\n",
       "  'robots',\n",
       "  'as',\n",
       "  'ai',\n",
       "  'robotics',\n",
       "  '3d',\n",
       "  'printing',\n",
       "  'and',\n",
       "  'genetics',\n",
       "  'make',\n",
       "  'their',\n",
       "  'way',\n",
       "  'in',\n",
       "  'even',\n",
       "  'the',\n",
       "  'architects',\n",
       "  'medical',\n",
       "  'docs',\n",
       "  'and',\n",
       "  'music',\n",
       "  'composers',\n",
       "  'feel',\n",
       "  'threatened',\n",
       "  'by',\n",
       "  'technology',\n",
       "  'making',\n",
       "  'us',\n",
       "  'question',\n",
       "  'that',\n",
       "  'will',\n",
       "  'ai',\n",
       "  'even',\n",
       "  'edge',\n",
       "  'us',\n",
       "  'out',\n",
       "  'of',\n",
       "  'our',\n",
       "  'brain',\n",
       "  'jobs',\n",
       "  'too?',\n",
       "  'now',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'terrifying',\n",
       "  'however',\n",
       "  'as',\n",
       "  'much',\n",
       "  'as',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'be',\n",
       "  'replacing',\n",
       "  'few',\n",
       "  'jobs',\n",
       "  'theyll',\n",
       "  'also',\n",
       "  'be',\n",
       "  'creating',\n",
       "  'new',\n",
       "  'jobs',\n",
       "  'with',\n",
       "  'the',\n",
       "  'economic',\n",
       "  'growth',\n",
       "  'innovation',\n",
       "  'and',\n",
       "  'investment',\n",
       "  'around',\n",
       "  '133',\n",
       "  'million',\n",
       "  'jobs',\n",
       "  'are',\n",
       "  'said',\n",
       "  'to',\n",
       "  'be',\n",
       "  'generated',\n",
       "  'these',\n",
       "  'newly',\n",
       "  'enhanced',\n",
       "  'jobs',\n",
       "  'are',\n",
       "  'to',\n",
       "  'create',\n",
       "  'benefits',\n",
       "  'and',\n",
       "  'amplify',\n",
       "  'ones',\n",
       "  'creativity',\n",
       "  'strategy',\n",
       "  'and',\n",
       "  'entrepreneurial',\n",
       "  'skills',\n",
       "  'so',\n",
       "  'what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'catch?',\n",
       "  'well',\n",
       "  'its',\n",
       "  'the',\n",
       "  'skills',\n",
       "  'even',\n",
       "  'though',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'creating',\n",
       "  '3',\n",
       "  'times',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'than',\n",
       "  'it',\n",
       "  'is',\n",
       "  'destroying',\n",
       "  'its',\n",
       "  'the',\n",
       "  'skills',\n",
       "  'that',\n",
       "  'count',\n",
       "  'ai',\n",
       "  'surged',\n",
       "  'in',\n",
       "  'new',\n",
       "  'job',\n",
       "  'opportunities',\n",
       "  'opportunities',\n",
       "  'like',\n",
       "  'senior',\n",
       "  'data',\n",
       "  'scientist',\n",
       "  'mobile',\n",
       "  'application',\n",
       "  'developer',\n",
       "  'and',\n",
       "  'seo',\n",
       "  'specialist',\n",
       "  'these',\n",
       "  'jobs',\n",
       "  'were',\n",
       "  'once',\n",
       "  'never',\n",
       "  'heard',\n",
       "  'of',\n",
       "  'but',\n",
       "  'now',\n",
       "  'with',\n",
       "  'ai',\n",
       "  'its',\n",
       "  'born',\n",
       "  'however',\n",
       "  'to',\n",
       "  'do',\n",
       "  'these',\n",
       "  'jobs',\n",
       "  'or',\n",
       "  'for',\n",
       "  'its',\n",
       "  'qualification',\n",
       "  'one',\n",
       "  'needs',\n",
       "  'highlevel',\n",
       "  'skills',\n",
       "  'and',\n",
       "  'to',\n",
       "  'acquire',\n",
       "  'those',\n",
       "  'skills',\n",
       "  'can',\n",
       "  'be',\n",
       "  'an',\n",
       "  'expensive',\n",
       "  'and',\n",
       "  'timeconsuming',\n",
       "  'task',\n",
       "  'the',\n",
       "  'future',\n",
       "  'generation',\n",
       "  'might',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'cope',\n",
       "  'up',\n",
       "  'with',\n",
       "  'it',\n",
       "  'but',\n",
       "  'the',\n",
       "  'real',\n",
       "  'struggle',\n",
       "  'is',\n",
       "  'to',\n",
       "  'be',\n",
       "  'faced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'present',\n",
       "  'two',\n",
       "  'generations',\n",
       "  'its',\n",
       "  'the',\n",
       "  'vulnerability',\n",
       "  'between',\n",
       "  'the',\n",
       "  'skill',\n",
       "  'gap',\n",
       "  'and',\n",
       "  'unemployment',\n",
       "  'and',\n",
       "  'the',\n",
       "  'youths',\n",
       "  'are',\n",
       "  'the',\n",
       "  'ones',\n",
       "  'to',\n",
       "  'be',\n",
       "  'crushed',\n",
       "  'the',\n",
       "  'most',\n",
       "  'therefore',\n",
       "  'as',\n",
       "  'the',\n",
       "  'advancement',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'becomes',\n",
       "  'inevitable',\n",
       "  'there',\n",
       "  'remains',\n",
       "  'no',\n",
       "  'choice',\n",
       "  'but',\n",
       "  'to',\n",
       "  'adapt',\n",
       "  'learn',\n",
       "  'equip',\n",
       "  'ourselves',\n",
       "  'and',\n",
       "  'grow',\n",
       "  'with',\n",
       "  'it',\n",
       "  'the',\n",
       "  'companies',\n",
       "  'have',\n",
       "  'to',\n",
       "  'work',\n",
       "  'together',\n",
       "  'to',\n",
       "  'build',\n",
       "  'an',\n",
       "  'aiready',\n",
       "  'workplace',\n",
       "  'they',\n",
       "  'should',\n",
       "  'collaborate',\n",
       "  'with',\n",
       "  'the',\n",
       "  'government',\n",
       "  'educators',\n",
       "  'and',\n",
       "  'nonprofit',\n",
       "  'organizations',\n",
       "  'and',\n",
       "  'work',\n",
       "  'together',\n",
       "  'to',\n",
       "  'bring',\n",
       "  'out',\n",
       "  'policies',\n",
       "  'that',\n",
       "  'could',\n",
       "  'help',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'technologies',\n",
       "  'impacts',\n",
       "  'faster',\n",
       "  'while',\n",
       "  'also',\n",
       "  'providing',\n",
       "  'the',\n",
       "  'employees',\n",
       "  'some',\n",
       "  'security',\n",
       "  'the',\n",
       "  'economic',\n",
       "  'and',\n",
       "  'business',\n",
       "  'planning',\n",
       "  'should',\n",
       "  'be',\n",
       "  'made',\n",
       "  'considerable',\n",
       "  'for',\n",
       "  'minimizing',\n",
       "  'the',\n",
       "  'impact',\n",
       "  'on',\n",
       "  'local',\n",
       "  'jobs',\n",
       "  'and',\n",
       "  'properly',\n",
       "  'maximizing',\n",
       "  'the',\n",
       "  'opportunities',\n",
       "  'the',\n",
       "  'employees',\n",
       "  'should',\n",
       "  'be',\n",
       "  'provided',\n",
       "  'with',\n",
       "  'proper',\n",
       "  'tools',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'along',\n",
       "  'with',\n",
       "  'the',\n",
       "  'new',\n",
       "  'opportunities',\n",
       "  ...]]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b9dd1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'minds', 'a', 'fascination', 'in', 'itself', 'carrying', 'the', 'potential', 'of', 'tinkering', 'nature', 'with', 'the', 'pixie', 'dust', 'intelligence', 'creating', 'and', 'solving', 'the', 'mysteries', 'and', 'wonders', 'with', 'anything', 'but', 'admiration', 'however', 'no', 'matter', 'how', 'captivating', 'a', 'human', 'mind', 'can', 'be', 'it', 'could', 'sometimes', 'be', 'appalled', 'it', 'could', 'be', 'the', 'hunger', 'or', 'maybe', 'the', 'desire', 'to', 'want', 'more', 'to', 'go', 'beyond', 'and', 'unravel', 'the', 'limitations', 'or', 'maybe', 'something', 'like', 'pure', 'greed', 'humans', 'have', 'never', 'stopped', 'and', 'always', 'keep', 'evolving', 'when', 'it', 'comes', 'to', 'intelligence', 'and', 'this', 'is', 'what', 'makes', 'them', 'the', 'supreme', 'intelligence', 'calls', 'out', 'for', 'supremacy', 'and', 'so', 'what', 'if', 'there', 'was', 'to', 'evolve', 'something', 'that', 'opposed', 'a', 'challenge', 'to', 'the', 'very', 'human', 'minds', 'to', 'their', 'capabilities', 'while', 'making', 'them', 'question', 'their', 'own', 'importance', 'among', 'themselves?', 'artificial', 'intelligence', 'came', 'as', 'a', 'revolution', 'havoc', 'when', 'it', 'first', 'came', 'to', 'the', 'light', 'the', 'concept', 'of', 'making', 'machines', 'does', 'work', 'on', 'their', 'own', 'like', 'granting', 'machines', 'the', 'intelligence', 'the', 'idea', 'of', 'making', 'machines', 'work', 'like', 'humans', 'came', 'back', 'in', 'the', '19s', 'back', 'then', 'people', 'didnt', 'believe', 'in', 'such', 'a', 'thing', 'as', 'making', 'a', 'nonliving', 'thing', 'work', 'think', 'and', 'carry', 'tasks', 'on', 'its', 'own', 'not', 'to', 'mention', 'to', 'actually', 'surpass', 'humans', 'themselves', 'in', 'those', 'skills', 'the', 'facts', 'are', 'it', 'did', 'by', '1997', 'the', 'greatest', 'chess', 'player', 'garry', 'kasparov', 'was', 'defeated', 'in', 'a', 'chess', 'game', 'by', 'a', 'machine', 'and', 'this', 'is', 'where', 'exactly', 'a', 'top', 'skilled', 'human', 'lost', 'to', 'a', 'mere', 'machine', 'created', 'by', 'another', 'who', 'by', 'himself', 'couldve', 'never', 'defeated', 'him', 'it', 'was', 'a', 'rule', 'of', 'power', 'of', 'betterment', 'of', 'skills', 'and', 'the', 'granted', 'supremacy', 'were', 'ai', 'and', 'machines', 'just', 'tools?', 'equipment?', 'something', 'that', 'helped', 'an', 'unskilled', 'person', 'with', 'his', 'mind', 'and', 'intelligence', 'creates', 'something', 'that', 'could', 'do', 'the', 'skilled', 'work', 'for', 'him', 'with', 'perfection', 'and', 'precision?', 'well', 'initially', 'it', 'was', 'however', 'as', 'time', 'passed', 'as', 'humans', 'got', 'drawn', 'to', 'the', 'puzzle', 'of', 'ai', 'a', 'lot', 'changed', 'human', 'research', 'went', 'deeper', 'and', 'deeper', 'and', 'as', 'a', 'result', 'the', 'machines', 'evolved', 'with', 'it', 'at', 'present', 'ai', 'machines', 'is', 'a', 'growing', 'field', 'as', 'it', 'develops', 'and', 'improves', 'it', 'has', 'become', 'a', 'part', 'of', 'the', 'industrial', 'revolution', 'in', 'industries', 'most', 'of', 'the', 'laborious', 'work', 'that', 'was', 'once', 'taken', 'care', 'of', 'by', 'humans', 'was', 'now', 'replaced', 'by', 'machines', 'naturally', 'with', 'the', 'evolution', 'in', 'machines', 'its', 'precision', 'mass', 'productivity', 'quality', 'control', 'time', 'efficiencies', 'and', 'all', 'the', 'other', 'factors', 'made', 'it', 'a', 'better', 'choice', 'a', 'choice', 'over', 'humans', 'this', 'led', 'to', 'fear', 'a', 'fear', 'of', 'a', 'notsodistant', 'future', 'a', 'future', 'where', 'maybe', 'machines', 'will', 'be', 'so', 'evolved', 'that', 'theyll', 'take', 'over', 'the', 'need', 'of', 'a', 'human', 'employee', 'leading', 'to', 'unemployment', 'with', 'the', 'population', 'increase', 'around', 'the', 'world', 'it', 'became', 'the', 'new', 'tech', 'threat', 'for', 'the', 'labor', 'market', 'then', 'again', 'how', 'true', 'is', 'it?', 'does', 'ai', 'really', 'oppose', 'a', 'threat?', 'will', 'adapting', 'to', 'technology', 'make', 'millions', 'of', 'people', 'lose', 'their', 'jobs?', 'will', 'it', 'lead', 'to', 'mass', 'unemployment?', 'will', 'the', 'machines', 'really', 'surpass', 'humans?', 'will', 'the', 'creation', 'take', 'over', 'the', 'creator?', 'no', 'matter', 'how', 'fearful', 'the', 'future', 'with', 'ai', 'may', 'seem', 'in', 'reality', 'it', 'is', 'not', 'that', 'scary', 'truth', 'is', 'ai', 'is', 'the', 'present', 'reality', 'it', 'is', 'the', 'key', 'that', 'holds', 'the', 'power', 'to', 'unlock', 'a', 'whole', 'next', 'level', 'of', 'human', 'evolution', 'technology', 'is', 'growing', 'there', 'was', 'a', 'time', 'where', 'technology', 'was', 'just', 'an', 'idea', 'but', 'today', 'that', 'idea', 'has', 'been', 'implemented', 'its', 'working', 'and', 'is', 'carried', 'out', 'nobody', 'could', 'stop', 'the', 'advancement', 'and', 'growth', 'of', 'artificial', 'intelligence', 'its', 'a', 'wave', 'that', 'is', 'already', 'flowing', 'and', 'we', 'as', 'the', 'present', 'generation', 'and', 'the', 'generations', 'to', 'come', 'to', 'have', 'to', 'learn', 'to', 'learn', 'to', 'swim', 'in', 'this', 'flow', 'and', 'avoid', 'drowning', 'many', 'jobs', 'will', 'be', 'replaced', 'by', 'machines', 'as', 'ai', 'evolves', 'itll', 'keep', 'challenging', 'human', 'minds', 'and', 'their', 'skills', 'with', 'the', 'present', 'covid', '19', 'situation', 'contactless', 'cashiers', 'to', 'robots', 'delivering', 'packages', 'have', 'already', 'taken', 'over', 'the', 'usual', 'routine', 'tasks', 'the', 'jobs', 'of', 'secretaries', 'schedulers', 'and', 'bookkeeper', 'are', 'at', 'risk', 'too', 'manufacturing', 'units', 'agriculture', 'food', 'services', 'retail', 'transportation', 'logistic', 'and', 'hospitality', 'are', 'all', 'a', 'part', 'of', 'the', 'aiaffected', 'automation', 'at', 'an', 'estimation', 'it', 'is', 'said', 'that', 'around', '20', 'million', 'jobs', 'especially', 'including', 'manufacturing', 'will', 'be', 'lost', 'to', 'robots', 'as', 'ai', 'robotics', '3d', 'printing', 'and', 'genetics', 'make', 'their', 'way', 'in', 'even', 'the', 'architects', 'medical', 'docs', 'and', 'music', 'composers', 'feel', 'threatened', 'by', 'technology', 'making', 'us', 'question', 'that', 'will', 'ai', 'even', 'edge', 'us', 'out', 'of', 'our', 'brain', 'jobs', 'too?', 'now', 'that', 'can', 'be', 'terrifying', 'however', 'as', 'much', 'as', 'machines', 'will', 'be', 'replacing', 'few', 'jobs', 'theyll', 'also', 'be', 'creating', 'new', 'jobs', 'with', 'the', 'economic', 'growth', 'innovation', 'and', 'investment', 'around', '133', 'million', 'jobs', 'are', 'said', 'to', 'be', 'generated', 'these', 'newly', 'enhanced', 'jobs', 'are', 'to', 'create', 'benefits', 'and', 'amplify', 'ones', 'creativity', 'strategy', 'and', 'entrepreneurial', 'skills', 'so', 'what', 'is', 'the', 'catch?', 'well', 'its', 'the', 'skills', 'even', 'though', 'ai', 'is', 'creating', '3', 'times', 'more', 'jobs', 'than', 'it', 'is', 'destroying', 'its', 'the', 'skills', 'that', 'count', 'ai', 'surged', 'in', 'new', 'job', 'opportunities', 'opportunities', 'like', 'senior', 'data', 'scientist', 'mobile', 'application', 'developer', 'and', 'seo', 'specialist', 'these', 'jobs', 'were', 'once', 'never', 'heard', 'of', 'but', 'now', 'with', 'ai', 'its', 'born', 'however', 'to', 'do', 'these', 'jobs', 'or', 'for', 'its', 'qualification', 'one', 'needs', 'highlevel', 'skills', 'and', 'to', 'acquire', 'those', 'skills', 'can', 'be', 'an', 'expensive', 'and', 'timeconsuming', 'task', 'the', 'future', 'generation', 'might', 'be', 'able', 'to', 'cope', 'up', 'with', 'it', 'but', 'the', 'real', 'struggle', 'is', 'to', 'be', 'faced', 'by', 'the', 'present', 'two', 'generations', 'its', 'the', 'vulnerability', 'between', 'the', 'skill', 'gap', 'and', 'unemployment', 'and', 'the', 'youths', 'are', 'the', 'ones', 'to', 'be', 'crushed', 'the', 'most', 'therefore', 'as', 'the', 'advancement', 'of', 'ai', 'becomes', 'inevitable', 'there', 'remains', 'no', 'choice', 'but', 'to', 'adapt', 'learn', 'equip', 'ourselves', 'and', 'grow', 'with', 'it', 'the', 'companies', 'have', 'to', 'work', 'together', 'to', 'build', 'an', 'aiready', 'workplace', 'they', 'should', 'collaborate', 'with', 'the', 'government', 'educators', 'and', 'nonprofit', 'organizations', 'and', 'work', 'together', 'to', 'bring', 'out', 'policies', 'that', 'could', 'help', 'understand', 'the', 'technologies', 'impacts', 'faster', 'while', 'also', 'providing', 'the', 'employees', 'some', 'security', 'the', 'economic', 'and', 'business', 'planning', 'should', 'be', 'made', 'considerable', 'for', 'minimizing', 'the', 'impact', 'on', 'local', 'jobs', 'and', 'properly', 'maximizing', 'the', 'opportunities', 'the', 'employees', 'should', 'be', 'provided', 'with', 'proper', 'tools', 'to', 'carry', 'along', 'with', 'the', 'new', 'opportunities', 'while', 'acquiring', 'aibased', 'skills', 'for', 'their', 'daytoday', 'work', 'new', 'skills', 'should', 'be', 'identified', 'and', 'implemented', 'for', 'the', 'upskilling', 'and', 'continual', 'learning', 'initiatives', 'employees', 'will', 'have', 'to', 'maximize', 'their', 'robotic', 'quotient', 'and', 'learn', 'core', 'skills', 'theyll', 'have', 'to', 'adapt', 'to', 'new', 'working', 'models', 'and', 'understand', 'their', 'roles', 'in', 'the', 'coming', 'future', 'howsoever', 'its', 'not', 'like', 'ai', 'will', 'totally', 'take', 'over', 'control', 'even', 'though', 'ai', 'proves', 'to', 'be', 'a', 'better', 'choice', 'it', 'still', 'has', 'its', 'limitations', 'at', 'present', 'first', 'its', 'expensive', 'secondly', 'manufacturing', 'machines', 'in', 'bulk', 'is', 'not', 'good', 'for', 'the', 'environment', 'machines', 'are', 'also', 'very', 'high', 'maintenance', 'therefore', 'human', 'labor', 'will', 'often', 'come', 'cheaper', 'and', 'so', 'will', 'be', 'considered', 'over', 'machines', 'underdeveloped', 'countries', 'will', 'find', 'it', 'hard', 'to', 'equip', 'their', 'people', 'with', 'the', 'upskilling', 'and', 'reskilling', 'required', 'for', 'ai', 'workplace', 'and', 'so', 'for', 'ai', 'to', 'play', 'a', 'role', 'in', 'those', 'countries', 'might', 'take', 'years', 'ai', 'can', 'also', 'be', 'risky', 'and', 'unethical', 'as', 'its', 'hard', 'to', 'figure', 'out', 'who', 'to', 'be', 'held', 'responsible', 'for', 'in', 'cases', 'where', 'an', 'ai', 'went', 'wrong', 'no', 'matter', 'how', 'advanced', 'ai', 'gets', 'there', 'are', 'some', 'skills', 'where', 'humans', 'will', 'always', 'have', 'an', 'upper', 'hand', 'ie', 'soft', 'skills', 'skills', 'like', 'teamwork', 'communication', 'creativity', 'and', 'critical', 'thinking', 'are', 'something', 'that', 'ai', 'hasnt', 'been', 'able', 'to', 'beat', 'us', 'up', 'to', 'yet', 'and', 'so', 'the', 'value', 'of', 'creativity', 'leadership', 'and', 'emotional', 'intelligence', 'has', 'increased', 'although', 'with', 'machines', 'coming', 'in', 'between', 'humans', 'causing', 'the', 'lack', 'of', 'humantohuman', 'interaction', 'the', 'humans', 'seem', 'to', 'fade', 'away', 'a', 'little', 'with', 'this', 'era', 'comes', 'the', 'need', 'for', 'good', 'leaders', 'leaders', 'who', 'are', 'capable', 'of', 'handling', 'both', 'machines', 'and', 'humans', 'together', 'the', 'ones', 'who', 'are', 'organized', 'enough', 'to', 'manage', 'the', 'skilled', 'and', 'the', 'unskilled', 'employees', 'while', 'providing', 'the', 'unskilled', 'trainees', 'with', 'proper', 'training', 'leaders', 'who', 'hold', 'profound', 'soft', 'skills', 'and', 'encourage', 'teamwork', 'while', 'working', 'along', 'with', 'machines', 'the', 'ones', 'who', 'are', 'patient', 'calm', 'and', 'optimized', 'in', 'conclusion', 'yes', 'ai', 'and', 'machines', 'are', 'going', 'to', 'be', 'very', 'challenging', 'but', 'theres', 'nothing', 'humans', 'havent', 'overcome', 'adaptation', 'and', 'upgradation', 'are', 'going', 'to', 'be', 'the', 'primary', 'factor', 'for', 'survival', 'as', 'we', 'witness', 'the', 'onset', 'of', 'the', '4th', 'industrial', 'revolution', 'lets', 'buckle', 'up', 'our', 'seats', 'and', 'race', 'along', 'the', 'highway', 'with', 'the', 'essential', 'fuels', 'skills', 'so', 'as', 'to', 'not', 'let', 'ourselves', 'eliminated', 'after', 'all', 'this', 'is', 'an', 'unending', 'race', 'with', 'infinity', 'as', 'the', 'end', 'all', 'we', 'could', 'do', 'is', 'try', 'not', 'to', 'run', 'out', 'of', 'fuel', 'try', 'not', 'to', 'be', 'outdated']\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(tk_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "95e885d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1399"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3d4a677a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smith',\n",
       " 'johnson',\n",
       " 'williams',\n",
       " 'jones',\n",
       " 'brown',\n",
       " 'davis',\n",
       " 'miller',\n",
       " 'wilson',\n",
       " 'moore',\n",
       " 'taylor',\n",
       " 'anderson',\n",
       " 'thomas',\n",
       " 'jackson',\n",
       " 'white',\n",
       " 'harris',\n",
       " 'martin',\n",
       " 'thompson',\n",
       " 'garcia',\n",
       " 'martinez',\n",
       " 'robinson',\n",
       " 'clark',\n",
       " 'rodriguez',\n",
       " 'lewis',\n",
       " 'lee',\n",
       " 'walker',\n",
       " 'hall',\n",
       " 'allen',\n",
       " 'young',\n",
       " 'hernandez',\n",
       " 'king',\n",
       " 'wright',\n",
       " 'lopez',\n",
       " 'hill',\n",
       " 'scott',\n",
       " 'green',\n",
       " 'adams',\n",
       " 'baker',\n",
       " 'gonzalez',\n",
       " 'nelson',\n",
       " 'carter',\n",
       " 'mitchell',\n",
       " 'perez',\n",
       " 'roberts',\n",
       " 'turner',\n",
       " 'phillips',\n",
       " 'campbell',\n",
       " 'parker',\n",
       " 'evans',\n",
       " 'edwards',\n",
       " 'collins',\n",
       " 'stewart',\n",
       " 'sanchez',\n",
       " 'morris',\n",
       " 'rogers',\n",
       " 'reed',\n",
       " 'cook',\n",
       " 'morgan',\n",
       " 'bell',\n",
       " 'murphy',\n",
       " 'bailey',\n",
       " 'rivera',\n",
       " 'cooper',\n",
       " 'richardson',\n",
       " 'cox',\n",
       " 'howard',\n",
       " 'ward',\n",
       " 'torres',\n",
       " 'peterson',\n",
       " 'gray',\n",
       " 'ramirez',\n",
       " 'james',\n",
       " 'watson',\n",
       " 'brooks',\n",
       " 'kelly',\n",
       " 'sanders',\n",
       " 'price',\n",
       " 'bennett',\n",
       " 'wood',\n",
       " 'barnes',\n",
       " 'ross',\n",
       " 'henderson',\n",
       " 'coleman',\n",
       " 'jenkins',\n",
       " 'perry',\n",
       " 'powell',\n",
       " 'long',\n",
       " 'patterson',\n",
       " 'hughes',\n",
       " 'flores',\n",
       " 'washington',\n",
       " 'butler',\n",
       " 'simmons',\n",
       " 'foster',\n",
       " 'gonzales',\n",
       " 'bryant',\n",
       " 'alexander',\n",
       " 'russell',\n",
       " 'griffin',\n",
       " 'diaz',\n",
       " 'hayes',\n",
       " 'myers',\n",
       " 'ford',\n",
       " 'hamilton',\n",
       " 'graham',\n",
       " 'sullivan',\n",
       " 'wallace',\n",
       " 'woods',\n",
       " 'cole',\n",
       " 'west',\n",
       " 'jordan',\n",
       " 'owens',\n",
       " 'reynolds',\n",
       " 'fisher',\n",
       " 'ellis',\n",
       " 'harrison',\n",
       " 'gibson',\n",
       " 'mcdonald',\n",
       " 'cruz',\n",
       " 'marshall',\n",
       " 'ortiz',\n",
       " 'gomez',\n",
       " 'murray',\n",
       " 'freeman',\n",
       " 'wells',\n",
       " 'webb',\n",
       " 'simpson',\n",
       " 'stevens',\n",
       " 'tucker',\n",
       " 'porter',\n",
       " 'hunter',\n",
       " 'hicks',\n",
       " 'crawford',\n",
       " 'henry',\n",
       " 'boyd',\n",
       " 'mason',\n",
       " 'morales',\n",
       " 'kennedy',\n",
       " 'warren',\n",
       " 'dixon',\n",
       " 'ramos',\n",
       " 'reyes',\n",
       " 'burns',\n",
       " 'gordon',\n",
       " 'shaw',\n",
       " 'holmes',\n",
       " 'rice',\n",
       " 'robertson',\n",
       " 'hunt',\n",
       " 'black',\n",
       " 'daniels',\n",
       " 'palmer',\n",
       " 'mills',\n",
       " 'nichols',\n",
       " 'grant',\n",
       " 'knight',\n",
       " 'ferguson',\n",
       " 'rose',\n",
       " 'stone',\n",
       " 'hawkins',\n",
       " 'dunn',\n",
       " 'perkins',\n",
       " 'hudson',\n",
       " 'spencer',\n",
       " 'gardner',\n",
       " 'stephens',\n",
       " 'payne',\n",
       " 'pierce',\n",
       " 'berry',\n",
       " 'matthews',\n",
       " 'arnold',\n",
       " 'wagner',\n",
       " 'willis',\n",
       " 'ray',\n",
       " 'watkins',\n",
       " 'olson',\n",
       " 'carroll',\n",
       " 'duncan',\n",
       " 'snyder',\n",
       " 'hart',\n",
       " 'cunningham',\n",
       " 'bradley',\n",
       " 'lane',\n",
       " 'andrews',\n",
       " 'ruiz',\n",
       " 'harper',\n",
       " 'fox',\n",
       " 'riley',\n",
       " 'armstrong',\n",
       " 'carpenter',\n",
       " 'weaver',\n",
       " 'greene',\n",
       " 'lawrence',\n",
       " 'elliott',\n",
       " 'chavez',\n",
       " 'sims',\n",
       " 'austin',\n",
       " 'peters',\n",
       " 'kelley',\n",
       " 'franklin',\n",
       " 'lawson',\n",
       " 'fields',\n",
       " 'gutierrez',\n",
       " 'ryan',\n",
       " 'schmidt',\n",
       " 'carr',\n",
       " 'vasquez',\n",
       " 'castillo',\n",
       " 'wheeler',\n",
       " 'chapman',\n",
       " 'oliver',\n",
       " 'montgomery',\n",
       " 'richards',\n",
       " 'williamson',\n",
       " 'johnston',\n",
       " 'banks',\n",
       " 'meyer',\n",
       " 'bishop',\n",
       " 'mccoy',\n",
       " 'howell',\n",
       " 'alvarez',\n",
       " 'morrison',\n",
       " 'hansen',\n",
       " 'fernandez',\n",
       " 'garza',\n",
       " 'harvey',\n",
       " 'little',\n",
       " 'burton',\n",
       " 'stanley',\n",
       " 'nguyen',\n",
       " 'george',\n",
       " 'jacobs',\n",
       " 'reid',\n",
       " 'kim',\n",
       " 'fuller',\n",
       " 'lynch',\n",
       " 'dean',\n",
       " 'gilbert',\n",
       " 'garrett',\n",
       " 'romero',\n",
       " 'welch',\n",
       " 'larson',\n",
       " 'frazier',\n",
       " 'burke',\n",
       " 'hanson',\n",
       " 'day',\n",
       " 'mendoza',\n",
       " 'moreno',\n",
       " 'bowman',\n",
       " 'medina',\n",
       " 'fowler',\n",
       " 'brewer',\n",
       " 'hoffman',\n",
       " 'carlson',\n",
       " 'silva',\n",
       " 'pearson',\n",
       " 'holland',\n",
       " 'douglas',\n",
       " 'fleming',\n",
       " 'jensen',\n",
       " 'vargas',\n",
       " 'byrd',\n",
       " 'davidson',\n",
       " 'hopkins',\n",
       " 'may',\n",
       " 'terry',\n",
       " 'herrera',\n",
       " 'wade',\n",
       " 'soto',\n",
       " 'walters',\n",
       " 'curtis',\n",
       " 'neal',\n",
       " 'caldwell',\n",
       " 'lowe',\n",
       " 'jennings',\n",
       " 'barnett',\n",
       " 'graves',\n",
       " 'jimenez',\n",
       " 'horton',\n",
       " 'shelton',\n",
       " 'barrett',\n",
       " 'obrien',\n",
       " 'castro',\n",
       " 'sutton',\n",
       " 'gregory',\n",
       " 'mckinney',\n",
       " 'lucas',\n",
       " 'miles',\n",
       " 'craig',\n",
       " 'rodriquez',\n",
       " 'chambers',\n",
       " 'holt',\n",
       " 'lambert',\n",
       " 'fletcher',\n",
       " 'watts',\n",
       " 'bates',\n",
       " 'hale',\n",
       " 'rhodes',\n",
       " 'pena',\n",
       " 'beck',\n",
       " 'newman',\n",
       " 'haynes',\n",
       " 'mcdaniel',\n",
       " 'mendez',\n",
       " 'bush',\n",
       " 'vaughn',\n",
       " 'parks',\n",
       " 'dawson',\n",
       " 'santiago',\n",
       " 'norris',\n",
       " 'hardy',\n",
       " 'love',\n",
       " 'steele',\n",
       " 'curry',\n",
       " 'powers',\n",
       " 'schultz',\n",
       " 'barker',\n",
       " 'guzman',\n",
       " 'page',\n",
       " 'munoz',\n",
       " 'ball',\n",
       " 'keller',\n",
       " 'chandler',\n",
       " 'weber',\n",
       " 'leonard',\n",
       " 'walsh',\n",
       " 'lyons',\n",
       " 'ramsey',\n",
       " 'wolfe',\n",
       " 'schneider',\n",
       " 'mullins',\n",
       " 'benson',\n",
       " 'sharp',\n",
       " 'bowen',\n",
       " 'daniel',\n",
       " 'barber',\n",
       " 'cummings',\n",
       " 'hines',\n",
       " 'baldwin',\n",
       " 'griffith',\n",
       " 'valdez',\n",
       " 'hubbard',\n",
       " 'salazar',\n",
       " 'reeves',\n",
       " 'warner',\n",
       " 'stevenson',\n",
       " 'burgess',\n",
       " 'santos',\n",
       " 'tate',\n",
       " 'cross',\n",
       " 'garner',\n",
       " 'mann',\n",
       " 'mack',\n",
       " 'moss',\n",
       " 'thornton',\n",
       " 'dennis',\n",
       " 'mcgee',\n",
       " 'farmer',\n",
       " 'delgado',\n",
       " 'aguilar',\n",
       " 'vega',\n",
       " 'glover',\n",
       " 'manning',\n",
       " 'cohen',\n",
       " 'harmon',\n",
       " 'rodgers',\n",
       " 'robbins',\n",
       " 'newton',\n",
       " 'todd',\n",
       " 'blair',\n",
       " 'higgins',\n",
       " 'ingram',\n",
       " 'reese',\n",
       " 'cannon',\n",
       " 'strickland',\n",
       " 'townsend',\n",
       " 'potter',\n",
       " 'goodwin',\n",
       " 'walton',\n",
       " 'rowe',\n",
       " 'hampton',\n",
       " 'ortega',\n",
       " 'patton',\n",
       " 'swanson',\n",
       " 'joseph',\n",
       " 'francis',\n",
       " 'goodman',\n",
       " 'maldonado',\n",
       " 'yates',\n",
       " 'becker',\n",
       " 'erickson',\n",
       " 'hodges',\n",
       " 'rios',\n",
       " 'conner',\n",
       " 'adkins',\n",
       " 'webster',\n",
       " 'norman',\n",
       " 'malone',\n",
       " 'hammond',\n",
       " 'flowers',\n",
       " 'cobb',\n",
       " 'moody',\n",
       " 'quinn',\n",
       " 'blake',\n",
       " 'maxwell',\n",
       " 'pope',\n",
       " 'floyd',\n",
       " 'osborne',\n",
       " 'paul',\n",
       " 'mccarthy',\n",
       " 'guerrero',\n",
       " 'lindsey',\n",
       " 'estrada',\n",
       " 'sandoval',\n",
       " 'gibbs',\n",
       " 'tyler',\n",
       " 'gross',\n",
       " 'fitzgerald',\n",
       " 'stokes',\n",
       " 'doyle',\n",
       " 'sherman',\n",
       " 'saunders',\n",
       " 'wise',\n",
       " 'colon',\n",
       " 'gill',\n",
       " 'alvarado',\n",
       " 'greer',\n",
       " 'padilla',\n",
       " 'simon',\n",
       " 'waters',\n",
       " 'nunez',\n",
       " 'ballard',\n",
       " 'schwartz',\n",
       " 'mcbride',\n",
       " 'houston',\n",
       " 'christensen',\n",
       " 'klein',\n",
       " 'pratt',\n",
       " 'briggs',\n",
       " 'parsons',\n",
       " 'mclaughlin',\n",
       " 'zimmerman',\n",
       " 'french',\n",
       " 'buchanan',\n",
       " 'moran',\n",
       " 'copeland',\n",
       " 'roy',\n",
       " 'pittman',\n",
       " 'brady',\n",
       " 'mccormick',\n",
       " 'holloway',\n",
       " 'brock',\n",
       " 'poole',\n",
       " 'frank',\n",
       " 'logan',\n",
       " 'owen',\n",
       " 'bass',\n",
       " 'marsh',\n",
       " 'drake',\n",
       " 'wong',\n",
       " 'jefferson',\n",
       " 'park',\n",
       " 'morton',\n",
       " 'abbott',\n",
       " 'sparks',\n",
       " 'patrick',\n",
       " 'norton',\n",
       " 'huff',\n",
       " 'clayton',\n",
       " 'massey',\n",
       " 'lloyd',\n",
       " 'figueroa',\n",
       " 'carson',\n",
       " 'bowers',\n",
       " 'roberson',\n",
       " 'barton',\n",
       " 'tran',\n",
       " 'lamb',\n",
       " 'harrington',\n",
       " 'casey',\n",
       " 'boone',\n",
       " 'cortez',\n",
       " 'clarke',\n",
       " 'mathis',\n",
       " 'singleton',\n",
       " 'wilkins',\n",
       " 'cain',\n",
       " 'bryan',\n",
       " 'underwood',\n",
       " 'hogan',\n",
       " 'mckenzie',\n",
       " 'collier',\n",
       " 'luna',\n",
       " 'phelps',\n",
       " 'mcguire',\n",
       " 'allison',\n",
       " 'bridges',\n",
       " 'wilkerson',\n",
       " 'nash',\n",
       " 'summers',\n",
       " 'atkins',\n",
       " 'wilcox',\n",
       " 'pitts',\n",
       " 'conley',\n",
       " 'marquez',\n",
       " 'burnett',\n",
       " 'richard',\n",
       " 'cochran',\n",
       " 'chase',\n",
       " 'davenport',\n",
       " 'hood',\n",
       " 'gates',\n",
       " 'clay',\n",
       " 'ayala',\n",
       " 'sawyer',\n",
       " 'roman',\n",
       " 'vazquez',\n",
       " 'dickerson',\n",
       " 'hodge',\n",
       " 'acosta',\n",
       " 'flynn',\n",
       " 'espinoza',\n",
       " 'nicholson',\n",
       " 'monroe',\n",
       " 'wolf',\n",
       " 'morrow',\n",
       " 'kirk',\n",
       " 'randall',\n",
       " 'anthony',\n",
       " 'whitaker',\n",
       " 'oconnor',\n",
       " 'skinner',\n",
       " 'ware',\n",
       " 'molina',\n",
       " 'kirby',\n",
       " 'huffman',\n",
       " 'bradford',\n",
       " 'charles',\n",
       " 'gilmore',\n",
       " 'dominguez',\n",
       " 'oneal',\n",
       " 'bruce',\n",
       " 'lang',\n",
       " 'combs',\n",
       " 'kramer',\n",
       " 'heath',\n",
       " 'hancock',\n",
       " 'gallagher',\n",
       " 'gaines',\n",
       " 'shaffer',\n",
       " 'short',\n",
       " 'wiggins',\n",
       " 'mathews',\n",
       " 'mcclain',\n",
       " 'fischer',\n",
       " 'wall',\n",
       " 'small',\n",
       " 'melton',\n",
       " 'hensley',\n",
       " 'bond',\n",
       " 'dyer',\n",
       " 'cameron',\n",
       " 'grimes',\n",
       " 'contreras',\n",
       " 'christian',\n",
       " 'wyatt',\n",
       " 'baxter',\n",
       " 'snow',\n",
       " 'mosley',\n",
       " 'shepherd',\n",
       " 'larsen',\n",
       " 'hoover',\n",
       " 'beasley',\n",
       " 'glenn',\n",
       " 'petersen',\n",
       " 'whitehead',\n",
       " 'meyers',\n",
       " 'keith',\n",
       " 'garrison',\n",
       " 'vincent',\n",
       " 'shields',\n",
       " 'horn',\n",
       " 'savage',\n",
       " 'olsen',\n",
       " 'schroeder',\n",
       " 'hartman',\n",
       " 'woodard',\n",
       " 'mueller',\n",
       " 'kemp',\n",
       " 'deleon',\n",
       " 'booth',\n",
       " 'patel',\n",
       " 'calhoun',\n",
       " 'wiley',\n",
       " 'eaton',\n",
       " 'cline',\n",
       " 'navarro',\n",
       " 'harrell',\n",
       " 'lester',\n",
       " 'humphrey',\n",
       " 'parrish',\n",
       " 'duran',\n",
       " 'hutchinson',\n",
       " 'hess',\n",
       " 'dorsey',\n",
       " 'bullock',\n",
       " 'robles',\n",
       " 'beard',\n",
       " 'dalton',\n",
       " 'avila',\n",
       " 'vance',\n",
       " 'rich',\n",
       " 'blackwell',\n",
       " 'york',\n",
       " 'johns',\n",
       " 'blankenship',\n",
       " 'trevino',\n",
       " 'salinas',\n",
       " 'campos',\n",
       " 'pruitt',\n",
       " 'moses',\n",
       " 'callahan',\n",
       " 'golden',\n",
       " 'montoya',\n",
       " 'hardin',\n",
       " 'guerra',\n",
       " 'mcdowell',\n",
       " 'carey',\n",
       " 'stafford',\n",
       " 'gallegos',\n",
       " 'henson',\n",
       " 'wilkinson',\n",
       " 'booker',\n",
       " 'merritt',\n",
       " 'miranda',\n",
       " 'atkinson',\n",
       " 'orr',\n",
       " 'decker',\n",
       " 'hobbs',\n",
       " 'preston',\n",
       " 'tanner',\n",
       " 'knox',\n",
       " 'pacheco',\n",
       " 'stephenson',\n",
       " 'glass',\n",
       " 'rojas',\n",
       " 'serrano',\n",
       " 'marks',\n",
       " 'hickman',\n",
       " 'english',\n",
       " 'sweeney',\n",
       " 'strong',\n",
       " 'prince',\n",
       " 'mcclure',\n",
       " 'conway',\n",
       " 'walter',\n",
       " 'roth',\n",
       " 'maynard',\n",
       " 'farrell',\n",
       " 'lowery',\n",
       " 'hurst',\n",
       " 'nixon',\n",
       " 'weiss',\n",
       " 'trujillo',\n",
       " 'ellison',\n",
       " 'sloan',\n",
       " 'juarez',\n",
       " 'winters',\n",
       " 'mclean',\n",
       " 'randolph',\n",
       " 'leon',\n",
       " 'boyer',\n",
       " 'villarreal',\n",
       " 'mccall',\n",
       " 'gentry',\n",
       " 'carrillo',\n",
       " 'kent',\n",
       " 'ayers',\n",
       " 'lara',\n",
       " 'shannon',\n",
       " 'sexton',\n",
       " 'pace',\n",
       " 'hull',\n",
       " 'leblanc',\n",
       " 'browning',\n",
       " 'velasquez',\n",
       " 'leach',\n",
       " 'chang',\n",
       " 'house',\n",
       " 'sellers',\n",
       " 'herring',\n",
       " 'noble',\n",
       " 'foley',\n",
       " 'bartlett',\n",
       " 'mercado',\n",
       " 'landry',\n",
       " 'durham',\n",
       " 'walls',\n",
       " 'barr',\n",
       " 'mckee',\n",
       " 'bauer',\n",
       " 'rivers',\n",
       " 'everett',\n",
       " 'bradshaw',\n",
       " 'pugh',\n",
       " 'velez',\n",
       " 'rush',\n",
       " 'estes',\n",
       " 'dodson',\n",
       " 'morse',\n",
       " 'sheppard',\n",
       " 'weeks',\n",
       " 'camacho',\n",
       " 'bean',\n",
       " 'barron',\n",
       " 'livingston',\n",
       " 'middleton',\n",
       " 'spears',\n",
       " 'branch',\n",
       " 'blevins',\n",
       " 'chen',\n",
       " 'kerr',\n",
       " 'mcconnell',\n",
       " 'hatfield',\n",
       " 'harding',\n",
       " 'ashley',\n",
       " 'solis',\n",
       " 'herman',\n",
       " 'frost',\n",
       " 'giles',\n",
       " 'blackburn',\n",
       " 'william',\n",
       " 'pennington',\n",
       " 'woodward',\n",
       " 'finley',\n",
       " 'mcintosh',\n",
       " 'koch',\n",
       " 'best',\n",
       " 'solomon',\n",
       " 'mccullough',\n",
       " 'dudley',\n",
       " 'nolan',\n",
       " 'blanchard',\n",
       " 'rivas',\n",
       " 'brennan',\n",
       " 'mejia',\n",
       " 'kane',\n",
       " 'benton',\n",
       " 'joyce',\n",
       " 'buckley',\n",
       " 'haley',\n",
       " 'valentine',\n",
       " 'maddox',\n",
       " 'russo',\n",
       " 'mcknight',\n",
       " 'buck',\n",
       " 'moon',\n",
       " 'mcmillan',\n",
       " 'crosby',\n",
       " 'berg',\n",
       " 'dotson',\n",
       " 'mays',\n",
       " 'roach',\n",
       " 'church',\n",
       " 'chan',\n",
       " 'richmond',\n",
       " 'meadows',\n",
       " 'faulkner',\n",
       " 'oneill',\n",
       " 'knapp',\n",
       " 'kline',\n",
       " 'barry',\n",
       " 'ochoa',\n",
       " 'jacobson',\n",
       " 'gay',\n",
       " 'avery',\n",
       " 'hendricks',\n",
       " 'horne',\n",
       " 'shepard',\n",
       " 'hebert',\n",
       " 'cherry',\n",
       " 'cardenas',\n",
       " 'mcintyre',\n",
       " 'whitney',\n",
       " 'waller',\n",
       " 'holman',\n",
       " 'donaldson',\n",
       " 'cantu',\n",
       " 'terrell',\n",
       " 'morin',\n",
       " 'gillespie',\n",
       " 'fuentes',\n",
       " 'tillman',\n",
       " 'sanford',\n",
       " 'bentley',\n",
       " 'peck',\n",
       " 'key',\n",
       " 'salas',\n",
       " 'rollins',\n",
       " 'gamble',\n",
       " 'dickson',\n",
       " 'battle',\n",
       " 'santana',\n",
       " 'cabrera',\n",
       " 'cervantes',\n",
       " 'howe',\n",
       " 'hinton',\n",
       " 'hurley',\n",
       " 'spence',\n",
       " 'zamora',\n",
       " 'yang',\n",
       " 'mcneil',\n",
       " 'suarez',\n",
       " 'case',\n",
       " 'petty',\n",
       " 'gould',\n",
       " 'mcfarland',\n",
       " 'sampson',\n",
       " 'carver',\n",
       " 'bray',\n",
       " 'rosario',\n",
       " 'macdonald',\n",
       " 'stout',\n",
       " 'hester',\n",
       " 'melendez',\n",
       " 'dillon',\n",
       " 'farley',\n",
       " 'hopper',\n",
       " 'galloway',\n",
       " 'potts',\n",
       " 'bernard',\n",
       " 'joyner',\n",
       " 'stein',\n",
       " 'aguirre',\n",
       " 'osborn',\n",
       " 'mercer',\n",
       " 'bender',\n",
       " 'franco',\n",
       " 'rowland',\n",
       " 'sykes',\n",
       " 'benjamin',\n",
       " 'travis',\n",
       " 'pickett',\n",
       " 'crane',\n",
       " 'sears',\n",
       " 'mayo',\n",
       " 'dunlap',\n",
       " 'hayden',\n",
       " 'wilder',\n",
       " 'mckay',\n",
       " 'coffey',\n",
       " 'mccarty',\n",
       " 'ewing',\n",
       " 'cooley',\n",
       " 'vaughan',\n",
       " 'bonner',\n",
       " 'cotton',\n",
       " 'holder',\n",
       " 'stark',\n",
       " 'ferrell',\n",
       " 'cantrell',\n",
       " 'fulton',\n",
       " 'lynn',\n",
       " 'lott',\n",
       " 'calderon',\n",
       " 'rosa',\n",
       " 'pollard',\n",
       " 'hooper',\n",
       " 'burch',\n",
       " 'mullen',\n",
       " 'fry',\n",
       " 'riddle',\n",
       " 'levy',\n",
       " 'david',\n",
       " 'duke',\n",
       " 'odonnell',\n",
       " 'guy',\n",
       " 'michael',\n",
       " 'britt',\n",
       " 'frederick',\n",
       " 'daugherty',\n",
       " 'berger',\n",
       " 'dillard',\n",
       " 'alston',\n",
       " 'jarvis',\n",
       " 'frye',\n",
       " 'riggs',\n",
       " 'chaney',\n",
       " 'odom',\n",
       " 'duffy',\n",
       " 'fitzpatrick',\n",
       " 'valenzuela',\n",
       " 'merrill',\n",
       " 'mayer',\n",
       " 'alford',\n",
       " 'mcpherson',\n",
       " 'acevedo',\n",
       " 'donovan',\n",
       " 'barrera',\n",
       " 'albert',\n",
       " 'cote',\n",
       " 'reilly',\n",
       " 'compton',\n",
       " 'raymond',\n",
       " 'mooney',\n",
       " 'mcgowan',\n",
       " 'craft',\n",
       " 'cleveland',\n",
       " 'clemons',\n",
       " 'wynn',\n",
       " 'nielsen',\n",
       " 'baird',\n",
       " 'stanton',\n",
       " 'snider',\n",
       " 'rosales',\n",
       " 'bright',\n",
       " 'witt',\n",
       " 'stuart',\n",
       " 'hays',\n",
       " 'holden',\n",
       " 'rutledge',\n",
       " 'kinney',\n",
       " 'clements',\n",
       " 'castaneda',\n",
       " 'slater',\n",
       " 'hahn',\n",
       " 'emerson',\n",
       " 'conrad',\n",
       " 'burks',\n",
       " 'delaney',\n",
       " 'pate',\n",
       " 'lancaster',\n",
       " 'sweet',\n",
       " 'justice',\n",
       " 'tyson',\n",
       " 'sharpe',\n",
       " 'whitfield',\n",
       " 'talley',\n",
       " 'macias',\n",
       " 'irwin',\n",
       " 'burris',\n",
       " 'ratliff',\n",
       " 'mccray',\n",
       " 'madden',\n",
       " 'kaufman',\n",
       " 'beach',\n",
       " 'goff',\n",
       " 'cash',\n",
       " 'bolton',\n",
       " 'mcfadden',\n",
       " 'levine',\n",
       " 'good',\n",
       " 'byers',\n",
       " 'kirkland',\n",
       " 'kidd',\n",
       " 'workman',\n",
       " 'carney',\n",
       " 'dale',\n",
       " 'mcleod',\n",
       " 'holcomb',\n",
       " 'england',\n",
       " 'finch',\n",
       " 'head',\n",
       " 'burt',\n",
       " 'hendrix',\n",
       " 'sosa',\n",
       " 'haney',\n",
       " 'franks',\n",
       " 'sargent',\n",
       " 'nieves',\n",
       " 'downs',\n",
       " 'rasmussen',\n",
       " 'bird',\n",
       " 'hewitt',\n",
       " 'lindsay',\n",
       " 'le',\n",
       " 'foreman',\n",
       " 'valencia',\n",
       " 'oneil',\n",
       " 'delacruz',\n",
       " 'vinson',\n",
       " 'dejesus',\n",
       " 'hyde',\n",
       " 'forbes',\n",
       " 'gilliam',\n",
       " 'guthrie',\n",
       " 'wooten',\n",
       " 'huber',\n",
       " 'barlow',\n",
       " 'boyle',\n",
       " 'mcmahon',\n",
       " 'buckner',\n",
       " 'rocha',\n",
       " 'puckett',\n",
       " 'langley',\n",
       " 'knowles',\n",
       " 'cooke',\n",
       " 'velazquez',\n",
       " 'whitley',\n",
       " 'noel',\n",
       " 'vang',\n",
       " ...]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fe00f230",
   "metadata": {},
   "outputs": [],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "133ac249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_COUNT=len(tk_words)\n",
    "WORD_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e73397a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3e66fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "911aba4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "POLARITY_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4ddef77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1b5a180a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "SUBJECTIVITY_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0635d4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "34df3b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "The_number_of_words = num_words\n",
    "The_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3bf4955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.014285714285716"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences) #The_number_of_sentences= sent_count =77\n",
    "AVG_SENTENCE_LENGTH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ed6286e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list))) # word List is the no of words in text\n",
    "\n",
    "print(more_than_two_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3e64adc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "The_number_of_complex_words = more_than_two_syllables\n",
    "\n",
    "The_number_of_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "556e0aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3111888111888112"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "PERCENTAGE_OF_COMPLEX_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bbd71876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.13018981018981"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "FOG_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0d63d96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.014285714285716"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b73005ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "COMPLEX_WORD_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6164aa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_COUNT = Total_words_after_cleaning\n",
    "WORD_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "965b7ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 1, 5, 1, 2, 2, 1, 4, 1, 3, 3, 1, 1, 3, 1, 5, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 5, 3, 1, 2, 1, 4, 1, 2, 1, 1, 1, 1, 2, 3, 1, 3, 1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 3, 1, 5, 1, 2, 3, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 3, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 3, 4, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 2, 5, 2, 2, 1, 4, 2, 1, 4, 2, 3, 4, 4, 2, 1, 1, 5, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 4, 1, 3, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 4, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 2, 1, 3, 1, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 3, 1, 1, 1, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 2, 3, 3, 1, 1, 1, 2, 2, 1, 1, 1, 1, 5, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 3, 1, 3, 1, 3, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 3, 1, 3, 1, 1, 3, 1, 1, 1, 1, 4, 5, 1, 4, 1, 1, 1, 5, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 5, 1, 3, 1, 4, 1, 4, 3, 2, 2, 6, 1, 1, 1, 2, 2, 2, 1, 1, 2, 3, 1, 3, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 4, 3, 1, 3, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 4, 3, 1, 4, 1, 1, 5, 4, 3, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 2, 1, 3, 1, 2, 1, 1, 1, 1, 2, 3, 1, 2, 1, 3, 1, 3, 2, 3, 1, 3, 2, 2, 1, 1, 1, 2, 1, 1, 4, 1, 1, 2, 2, 2, 2, 1, 1, 4, 2, 2, 1, 3, 1, 2, 1, 3, 1, 3, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 5, 3, 1, 2, 2, 1, 1, 2, 2, 3, 1, 1, 1, 3, 1, 2, 1, 3, 1, 2, 4, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 4, 1, 1, 1, 4, 4, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 2, 5, 1, 1, 5, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 2, 3, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 5, 3, 3, 1, 2, 4, 2, 2, 3, 2, 2, 1, 3, 4, 1, 1, 1, 1, 5, 3, 1, 5, 2, 1, 1, 2, 5, 2, 5, 2, 3, 3, 5, 1, 3, 1, 4, 2, 1, 1, 1, 1, 1, 2, 6, 1, 1, 5, 1, 1, 2, 1, 3, 1, 3, 1, 4, 3, 5, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 3, 2, 2, 1, 1, 2, 1, 3, 3, 1, 1, 2, 3, 2, 3, 1, 3, 2, 1, 4, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 3, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 4, 1, 5, 1, 3, 3, 1, 3, 1, 2, 2, 1, 1, 4, 2, 1, 2, 1, 2, 1, 3, 3, 1, 2, 2, 4, 2, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 6, 5, 2, 3, 2, 3, 3, 4, 4, 1, 1, 4, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 7, 2, 2, 3, 1, 1, 1, 4, 2, 1, 1, 1, 1, 4, 1, 5, 1, 1, 3, 5, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 5, 1, 1, 5, 3, 1, 1, 1, 1, 4, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 2, 5, 2, 3, 1, 3, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 1, 2, 1, 2, 3, 1, 2, 5, 1, 1, 3, 4, 1, 3, 6, 1, 1, 3, 1, 1, 2, 3, 1, 2, 1, 3, 1, 5, 2, 2, 2, 2, 3, 1, 3, 2, 3, 1, 4, 1, 3, 2, 2, 1, 2, 5, 1, 4, 1, 2, 1, 2, 1, 1, 2, 4, 1, 6, 1, 3, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 5, 2, 4, 1, 1, 1, 2, 3, 1, 1, 1, 2, 1, 4, 1, 3, 1, 1, 3, 1, 4, 3, 6, 2, 1, 2, 1, 4, 2, 3, 4, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 3, 2, 1, 1, 1, 2, 3, 4, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 5, 1, 2, 1, 1, 4, 2, 5, 2, 1, 1, 1, 1, 2, 1, 1, 4, 2, 2, 2, 1, 1, 5, 4, 2, 2, 1, 2, 2, 3, 1, 1, 1, 1, 3, 2, 3, 4, 3, 1, 1, 1, 1, 1, 3, 2, 3, 1, 1, 3, 1, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 4, 1, 2, 2, 1, 1, 2, 1, 1, 1, 4, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 3, 6, 4, 1, 3, 2, 2, 3, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 4, 1, 5, 5, 1, 4, 2, 1, 2, 2, 1, 3, 2, 3, 1, 1, 1, 5, 5, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 3, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 1, 1, 2, 3, 3, 1, 3, 1, 1, 1, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 3, 1, 1, 1, 5, 3, 2, 2, 2, 1, 3, 1, 1, 1, 2, 3, 1, 1, 4, 1, 4, 1, 1, 1, 2, 2, 2, 1, 1, 1, 3, 1, 2, 2, 2, 2, 4, 4, 1, 5, 2, 2, 1, 1, 1, 2, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 4, 5, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 4, 2, 1, 1, 1, 1, 1, 1, 3, 5, 1, 1, 1, 1, 1, 3, 2, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "print(syllable_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "612fcdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2525"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2635a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2525"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "SYLLABLE_PER_WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f64fd0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 15\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 3\n",
      "Total count: 18\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_38.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8e7ad9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSONAL_PRONOUNS=total_count\n",
    "PERSONAL_PRONOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e747b38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.994289793004996"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "AVG_WORD_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479870d",
   "metadata": {},
   "source": [
    "# 3.for URL_ID :39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c9b0e91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\4205329568.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c10f441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text = driver.find_elements(By.TAG_NAME,'p')\n",
    "titles = []\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a8c95647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Introduction',\n",
       " 'AI is rapidly evolving in the employment sector, particularly in matters involving business and finance. Finance, management, economics, and accounting are now among the most popular university courses globally; particularly at the graduate level, due to their high employability. However, the evolution of machinery in industries is changing that. According to research, 230,000 jobs in these sectors may be replaced by AI agents in the next 5 years. This is due to the nature of the work, as employees are responsible for tasks such as data analysis and keeping track of numerical information; which machines excel at. Large, complicated data sets can be analyzed faster and more efficiently by AI-powered computers than by people. Algorithmic trading procedures that produce automated deals are less likely to be produced without minute errors when undertaken by humans. In such matters involving industrial work, a subsection of artificial intelligence is used; namely, machine learning.',\n",
       " 'Machine learning is a term used for the application of artificial intelligence (AI) in systems, which involves them assimilating and processing information by gaining experience. It is mainly concerned with the development of technology and computer programs.',\n",
       " ' Its improvement process is mainly divided into seven steps; which start with the collection of data. This data can be collected from an internal database or perhaps an IoT structure. The second and most time-consuming step is cleaning, preparing, and rearranging the data; which involves the recognition of outliers, trends, and missing information so that the outcome is as accurate as possible. The third step consists of formatting data; which is useful if you source your information from a variety of sources. Step four is where AI comes into place. Self-service data processing tools may be useful if they provide intelligent services for matching data attributes from distinct databases and intelligently integrating them. The data is then arranged to better represent a specific pattern. Lastly, the data is divided into two sets: one for training the algorithm and one for analysis.',\n",
       " 'There are three types of machine learning; supervised, unsupervised, and reinforcement learning. The most common of the bunch is supervised machine learning; which is based on accurately labeled data. The machine is given a collection of information, including the outcome of the operation. The rest of the information is referred to as ‘input features’, which ‘supervises’ the machine by guiding it to establish the connections between the variants.',\n",
       " 'In the case of unsupervised learning, the machine isn’t given labeled sets of data to be divided into, allowing it to recognize and create its own patterns within the information provided. Since computers have the capabilities of identifying distinguished similarities, this method helps with the classifying of such data.',\n",
       " 'Reinforcement learning comprises experience-based learning. Similar to people, they learn due to a reward and punishment system based on their actions.',\n",
       " 'These variations of system learning have recently been integrated into business and finance, which is elaborated on in the following passages.',\n",
       " 'Machine learning in finance and banking',\n",
       " 'There are many ways in which machine learning is used in finance and banking. The most common place it is used is to detect any frauds. Fraud is the most common problem in financial service companies and it accounts for billions of dollars in misfortune each year. The most common frauds are credit or debit card usage by a stranger, document forgery, and mortgage fraud.',\n",
       " 'Usually, finance companies keep an enormous amount of their data stored online, and it increases the risk of information being accessed without authorization. With expanding innovative headway, misrepresentation in the monetary business is currently viewed as a high danger to significant information. Fraud recognition frameworks in the past were planned dependent on a bunch of rules, which could be effortlessly be bypassed by current fraudsters. Therefore, most companies today leverage machine learning to combat fraudulent financial transactions.',\n",
       " ' Machine learning works by looking over enormous informational indexes to distinguish unique or suspicious activities for additional examination by security groups. It works by looking at an exchange against other information focuses – like the client’s record history, IP address, area, and so forth.  Depending on the type of exchange taking place, the program can automatically refuse a withdrawal or purchase until the person makes a decision.',\n",
       " 'Examples of fraud detection software used by banks include Feedzai, Data visor, and Teradata',\n",
       " 'Machine learning is also used in algorithmic trading, portfolio management, loan underwriting, chatbots, and improving customer service.',\n",
       " 'Algorithmic trading is an interaction for executing orders using computerized and pre-modified exchanging guidelines to represent factors like value, timing, and volume. An algorithm is a set of directions for solving a problem. Computer calculations send little parts of the full request to the market over the long run.',\n",
       " 'In contrast to human dealers, algorithmic exchanging can investigate enormous volumes of information every day and therefore make thousands of trades every day. Machine learning settles on quick exchanging choices, which gives human traders a benefit over the market normal. Likewise, algorithmic exchanging doesn’t settle on exchanging choices dependent on feelings, which is a typical constraint among human dealers whose judgment might be influenced by feelings or individual desires. The exchanging technique is generally utilized by multifaceted investment administrators and monetary foundations to automate trading activities.',\n",
       " 'In the banking industry, organizations access a large number of shopper information, with which machine learning can be prepared to work in order to simplify the underwriting process. Machine learning calculations can settle on speedy choices on endorsing and credit scoring, and save organizations both time and monetary assets that are utilized by people.',\n",
       " 'Data scientists can train algorithms on how to analyze millions of consumer data to coordinate with information records, search for interesting special cases, and settle on a choice on whether a shopper meets all requirements for an advance or protection. For instance, the calculation can be prepared on the most proficient method to examine shopper information, like age, pay, occupation, and the buyer’s credit conduct.',\n",
       " 'The benefits of machine learning',\n",
       " 'As with any form of revolutionary technology, the usage of machine learning has been debated over as its beneficial properties have been weighed against the possible disadvantages. It’s been observed that upon correct usage, it may be used to solve a wide range of business challenges and anticipate complicated customer behavior. We’ve also seen several of the largest IT conglomerates, such as Google, Amazon, and Microsoft, introduce Cloud Machine Learning platforms.',\n",
       " 'In terms of business, ML can aid businesses by identifying consumer’s demands and formulate a pattern based on them; allowing companies to reach out to such consumers and maximize their sales. It eliminates the need for expenses on some maintenance by reducing the risks associated with unexpected breakdowns and minimizes wasteful costs to the firms.  Historical data, a process visualization tool, a flexible analytical environment, and a feedback loop may all be used to build an ML architecture. The input of data is another agitating chore for businesses in the present, which is where machine learning can step in for manual labor. This eradicates the possibility of errors caused by manual labor causing disruptions and provides employees with extra time to handle other tasks.',\n",
       " 'In the financial sector, machine learning is already utilized for portfolio management, algorithmic trading, loan underwriting, and fraud detection. Chatbots and other conversational interfaces for security, customer support, and sentiment analysis will be among the future uses of ML in banking. Another aspect of business involving artificial intelligence includes image recognition, which entails a system or program that recognizes objects, people, places, and movements in photos. It identifies photographs using an imaging system and machine recognition tech with artificial intelligence and programmed algorithms.',\n",
       " 'The downfalls of machine learning',\n",
       " 'With all the benefits of its advancement, machine learning isn’t the most perfect thing. There are several disadvantages which are information acquisition, time and resources and high errors, and wrong interpretations. One of the major hurdles is the amount of finance needed to invest in machine learning for it to be a successful project. More issues have to do with the fact that AI requires gigantic informational indexes to train on, and these ought to be unbiased, and of good quality. There can likewise be times where they have to wait for that new information to be produced. Machine learning needs sufficient opportunity to do the calculations to learn and adequately to satisfy their accuracy and relevancy. It also needs huge resources to work. This can mean extra requirements for the computer to work. Another significant problem is the capacity to precisely decipher the results produced by the calculations. You should likewise cautiously pick the algorithms to get the wanted results.',\n",
       " 'Conclusion',\n",
       " 'There have been various reports in the past and current years which claim that a significant piece of the human labor force will be replaced via robots and machines in the years to come. With excessive innovative work being led in the field of computerized reasoning, many dread that a significant job crisis will unfurl since numerous positions are all the more precisely and productively performed with the use of machines. In countries like Japan, mainly computer programs and AI is used in the secondary and tertiary sectors. From cleaning the house to depositing money in banks, everything is done by AI. However, AI cannot replace humans in the future. Humans have several capabilities which, even after several technological advancements a machine would not be able to have. These capabilities include creative thinking and creative problem solving, and human connection. For example, when a child goes to a doctor to get an injection, a nurse always relaxes the child to not be afraid of the needle. A machine’s touch would not be able to soothe a child. Another example could be how humans tend to share things with each other and be open about it, a machine will not be able to do so since it is only programmed to things it has been told to do. Like computers, AI will not replace us but would however complement us to make daily work easier and less time-consuming. Without humans themselves, there is no future for AI.']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cdfe3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:42]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "29c0e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4081ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ID_39 = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f9d76dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 85 sentences in the string.\n",
      "The number of words in the string is: 1684\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_39.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_39.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "23fd5f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9308\n"
     ]
    }
   ],
   "source": [
    "words = URL_ID_39.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cd105dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_39 = re.sub(re_punt, \"\",URL_ID_39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "07a71fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_39 = re.sub(re_punt, \"\",URL_ID_39)\n",
    "\n",
    "file = open(\"39.txt\", \"w\")\n",
    "file.write(URL_ID_39)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f6acd2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 15:25:34] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 15:25:57] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"39.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "62dbecd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction AI is rapidly evolving in the emp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Introduction AI is rapidly evolving in the emp..."
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/39.txt\",header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b23411da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lwr = df[0].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "3ce53586",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tk_words = list(df_lwr.str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "883d0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1683\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3ff9259b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1083"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "            \n",
    "WORD_COUNT=len(tk_words)\n",
    "WORD_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d6ff80b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b773389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "602dbe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE:\", POLARITY_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "460c3bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE:\",SUBJECTIVITY_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f1b51f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b8b0ee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.48235294117647"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences) #The_number_of_sentences= sent_count =77\n",
    "AVG_SENTENCE_LENGTH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2d51f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list))) # word List is the no of words in text\n",
    "print(more_than_two_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5d894712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43674976915974145"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "PERCENTAGE_OF_COMPLEX_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "67c19703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.767641084134485"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "FOG_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "847076d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.48235294117647"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d7b1d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n",
      "1083\n"
     ]
    }
   ],
   "source": [
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "562c3087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3434"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "feea405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 2\n",
      "Total count: 2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_39.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5032e0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.527315914489312"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "AVG_WORD_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257809d6",
   "metadata": {},
   "source": [
    "# 4. For URL_ID 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "34f6efe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\569118667.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2bc1aee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "00683e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Anything that could give rise to smarter-than-human intelligence – in the form of Artificial Intelligence, brain-computer interfaces, or neuroscience-based human intelligence enhancement – wins hands down beyond contest as doing the most to change the world. Nothing else is even in the same league.” ',\n",
       " '–Eliezer Yudkowsky, AI Researcher',\n",
       " 'There’s no denying robots and automation are increasingly part of our daily lives. Just look around the grocery store, or the highway, they are everywhere. This makes us wonder what if AI can replace human intelligence? What can we do to make ourselves relevant tomorrow? Let us try to find the answers to all these questions and more.',\n",
       " 'Let’s first understand what is Artificial Intelligence –',\n",
       " 'Artificial Intelligence or AI basically machines displaying intelligence. This can be seen from a machine playing chess or a robot answering questions on Facebook. Artificial Intelligence can be further broken down into many different types. There are AIs designed to do specific tasks, such as detecting a specific type of cancer. However, there are also AIs that can do multiple tasks, such as driving a car. There are many types of AIs. Among the top, most important fields are Machine Learning or ML, Neural Network, Computer Vision, and Natural Language Processing or NLP.',\n",
       " 'Machine Learning is the idea of machines being able to prove themselves similar to how a human being learns a new skill. Machine Learning also allows for the optimization of an existing skill. Machine Learning is used in many different fields and one such application is entertainment. Netflix uses Machine Learning to recommend more shows that you can watch based on the shows that you have already seen.',\n",
       " 'Neural Networks are algorithms that are modeled after the human brain. These algorithms think just like we do which can thereby give similar results to what a human being can give. Artificial Neural Networks are used in medical fields to diagnose cancers like lung cancer and prostate cancer.',\n",
       " 'Computer Vision is the idea that computers have visions. This allows them to see things the way human beings do or potentially better than human beings do, depending on the programming, camera used, etc. Computer Vision is used in autonomous vehicles for navigation from one place to another.',\n",
       " 'Natural Language Processing is the idea that computers can listen to what we say. An example of this is Siri. Siri is able to listen to our demands, process what it means, and provide you an answer based on what is researched.',\n",
       " 'Now that we know what an AI is and what it can do, Let’s talk about the issue.',\n",
       " 'AIs allow for the automation of jobs, thereby replacing what humans already do. This means more job loss and the concentration of wealth to the selected few people. This could mean a destabilization of society and social unrest. In addition to social unrest, AI improves over time. This means it becomes smarter, faster, and cheaper to implement and it will be better at doing repetitive things that humans currently do, such as preparing fast food. It is predicted that AI will improve so much over 50 to 100 years that AI will become super intelligent. This means that it will become even smarter than the most intelligent human on earth. According to many experts such as Elon Musk, this could cause the end of human civilization. AI could potentially start a war against humans, burn crops and do all sorts of tragedies once reserved for human functions. At that point, in theory, we can not stop it because AI would have already thought of all the obstacles that will prevent its goal. This means that we cannot unplug the machine, in effect AI will replace human intelligence.',\n",
       " 'But, will this happen in next 10 to 30 years?',\n",
       " 'NO! The field of Artificial Intelligence is sophisticated enough to do many human tasks that humans currently do. Currently, AI is not smart enough to be empathetic to humans and cannot think strategically enough to solve complex problems. AI solutions can be expensive and have to go through many different tests and standards to implement. It also takes time for AI to improve. For example, Boston Dynamics, one of the world’s top robotics company had a robot in 2009 that needed assistance to walk. Fast forward to 2019, not only the robot could walk by itself but it could jump over objects, do backflips and so much more. In addition to the timing, it takes time for the price of any new technological solution to drop to a point where it is affordable. For example, a desktop computer costs around $1000 in 1999 but now you can get a significantly more powerful laptop for the exact same price. AI will go through the same curve.',\n",
       " 'But what happens after those 10 to 30 years? Will AI make human intelligence obsolete? Maybe. As we have proven earlier AI will become faster better and cheaper. As this happens, more and more companies will use AI technology to automate more and more jobs to save money, increase productivity, and most importantly, stay competitive. As we have demonstrated, AI will become better through repetition via the use of machine learning. The only difference is that AI will be able to learn faster as time progresses due to the amount of data that is available today. It will also be able to learn from other machines or similar machines to learn how to optimize its tasks or new important skills. However, AI also just not do repetitive and routine tasks better, it will also be able to understand emotional intelligence, ethics, and creativity. This seen in three distinct example- IBM',\n",
       " 'IBM uses its IBM Watson to program the AI to create a movie trailer. Fox approached IBM and said they have a movie coming out on AI #Scifi horror. They asked IBM if their platform IBM Watson could a trailer by reviewing and watching the footage and searching for scary,',\n",
       " 'Sad or happy or other moments in the movie that provoked quality emotions based on how the machine was programmed to identify such emotions in a quantifiable manner. IBM Watson was able to generate a trailer for the movie Morgan. The result, a movie trailer created by machines example – Google',\n",
       " 'IN 2018 google demonstrated an AI assistance that could take calls and do simple stuff. The AI was able to set up an appointment! What was more fascinating was that it was able to understand the nuances of the conversation. The receptionist thought it was a human being that was calling her. That is a very primitive version of what is possible with this technology. Eventually, it will be able to have conversations just as human beings do, making many sales jobs obsolete. example – AI generated art',\n",
       " 'In 2018, a Paris art collective consisting of three students used artificial intelligence to generate a portrait. It generated the portrait painting by studying a set of fifteen thousand art images on wiki art. It was estimated to be worth between seven thousand to ten thousand dollars. The painting sold at an auction for four thirty-five thousand US dollars.',\n",
       " 'However, we cannot for sure say that AI will replace human intelligence. This is because we as a society have started asking hard questions and questioning ethics. Elon Musk founded Open AI, a research lab whose whole purpose is to promote and discover artificial intelligence in a way to benefits humanity. In addition to this, there are many factors that affect the long-term outcome of AI replacing human intelligence. Like, to what degree will other humans allow for AI to take over? Depending on the field, do people even want Artificial Intelligence to help them? Or will they prefer a human counterpart? While we may not be able to control what happens in the long run, we can definitely secure our short-term future.',\n",
       " 'Strategic and creative thinking',\n",
       " 'The ability to think outside the box is very human. There are thousands upon thousands of slightly different possible outcomes that may result from every distinguishable action that the human mind with its ability to judge from experience is programmed for these purposes in a far more sophisticated manner than AI can currently achieve. As the billionaire founder of Alibaba, Jack Ma famously said – “AI has logic, human beings have wisdom”.',\n",
       " 'Conflict resolution and negotiations',\n",
       " 'With our understanding of the complexities of human-related processes and our ability to improvise and judge, we are far better equipped to deal with conflicts than robots are ever likely to be.',\n",
       " 'AI may be able to recognize faces and images but it can rarely successfully read the feelings of those faces. Humans, to lesser or greater degrees, are capable of an accurate analysis of emotional subtext. With the application of intuition and the use of delicately worded or elusive languages, through these methods, we are able to properly judge how a person feels.',\n",
       " 'Interpretation of Gray Areas',\n",
       " 'Robots and computers function well when presented with quantifiable data. However, once the situation enters a gray area, whether this term refers to morals, processes, or definitions robots are more likely to falter.',\n",
       " 'Critical thinking',\n",
       " 'Humans are capable of responding to more indicators of quality than computers are. While an AI system may be able to analyze documents according to the true or false statements made within the text, we can judge whether or not it is well written and analyze the implication of the use of certain words and the overall meaning of the content.']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2c883b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "661f0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:44]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ee372bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ID_40 = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2e6f1fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 sentences in the string.\n",
      "The number of words in the string is: 1588\n",
      "The number of characters in the string is: 7802\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_40.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_40.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_40.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "539978b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_40 = re.sub(re_punt, \"\",URL_ID_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "bb663d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anything that could give rise to smarterthanhuman intelligence  in the form of Artificial Intelligence braincomputer interfaces or neurosciencebased human intelligence enhancement  wins hands down beyond contest as doing the most to change the world Nothing else is even in the same league  Eliezer Yudkowsky AI Researcher Theres no denying robots and automation are increasingly part of our daily lives Just look around the grocery store or the highway they are everywhere This makes us wonder what if AI can replace human intelligence? What can we do to make ourselves relevant tomorrow? Let us try to find the answers to all these questions and more Lets first understand what is Artificial Intelligence  Artificial Intelligence or AI basically machines displaying intelligence This can be seen from a machine playing chess or a robot answering questions on Facebook Artificial Intelligence can be further broken down into many different types There are AIs designed to do specific tasks such as detecting a specific type of cancer However there are also AIs that can do multiple tasks such as driving a car There are many types of AIs Among the top most important fields are Machine Learning or ML Neural Network Computer Vision and Natural Language Processing or NLP Machine Learning is the idea of machines being able to prove themselves similar to how a human being learns a new skill Machine Learning also allows for the optimization of an existing skill Machine Learning is used in many different fields and one such application is entertainment Netflix uses Machine Learning to recommend more shows that you can watch based on the shows that you have already seen Neural Networks are algorithms that are modeled after the human brain These algorithms think just like we do which can thereby give similar results to what a human being can give Artificial Neural Networks are used in medical fields to diagnose cancers like lung cancer and prostate cancer Computer Vision is the idea that computers have visions This allows them to see things the way human beings do or potentially better than human beings do depending on the programming camera used etc Computer Vision is used in autonomous vehicles for navigation from one place to another Natural Language Processing is the idea that computers can listen to what we say An example of this is Siri Siri is able to listen to our demands process what it means and provide you an answer based on what is researched Now that we know what an AI is and what it can do Lets talk about the issue AIs allow for the automation of jobs thereby replacing what humans already do This means more job loss and the concentration of wealth to the selected few people This could mean a destabilization of society and social unrest In addition to social unrest AI improves over time This means it becomes smarter faster and cheaper to implement and it will be better at doing repetitive things that humans currently do such as preparing fast food It is predicted that AI will improve so much over 50 to 100 years that AI will become super intelligent This means that it will become even smarter than the most intelligent human on earth According to many experts such as Elon Musk this could cause the end of human civilization AI could potentially start a war against humans burn crops and do all sorts of tragedies once reserved for human functions At that point in theory we can not stop it because AI would have already thought of all the obstacles that will prevent its goal This means that we cannot unplug the machine in effect AI will replace human intelligence But will this happen in next 10 to 30 years? NO! The field of Artificial Intelligence is sophisticated enough to do many human tasks that humans currently do Currently AI is not smart enough to be empathetic to humans and cannot think strategically enough to solve complex problems AI solutions can be expensive and have to go through many different tests and standards to implement It also takes time for AI to improve For example Boston Dynamics one of the worlds top robotics company had a robot in 2009 that needed assistance to walk Fast forward to 2019 not only the robot could walk by itself but it could jump over objects do backflips and so much more In addition to the timing it takes time for the price of any new technological solution to drop to a point where it is affordable For example a desktop computer costs around 1000 in 1999 but now you can get a significantly more powerful laptop for the exact same price AI will go through the same curve But what happens after those 10 to 30 years? Will AI make human intelligence obsolete? Maybe As we have proven earlier AI will become faster better and cheaper As this happens more and more companies will use AI technology to automate more and more jobs to save money increase productivity and most importantly stay competitive As we have demonstrated AI will become better through repetition via the use of machine learning The only difference is that AI will be able to learn faster as time progresses due to the amount of data that is available today It will also be able to learn from other machines or similar machines to learn how to optimize its tasks or new important skills However AI also just not do repetitive and routine tasks better it will also be able to understand emotional intelligence ethics and creativity This seen in three distinct example IBM IBM uses its IBM Watson to program the AI to create a movie trailer Fox approached IBM and said they have a movie coming out on AI Scifi horror They asked IBM if their platform IBM Watson could a trailer by reviewing and watching the footage and searching for scary Sad or happy or other moments in the movie that provoked quality emotions based on how the machine was programmed to identify such emotions in a quantifiable manner IBM Watson was able to generate a trailer for the movie Morgan The result a movie trailer created by machines example  Google IN 2018 google demonstrated an AI assistance that could take calls and do simple stuff The AI was able to set up an appointment! What was more fascinating was that it was able to understand the nuances of the conversation The receptionist thought it was a human being that was calling her That is a very primitive version of what is possible with this technology Eventually it will be able to have conversations just as human beings do making many sales jobs obsolete example  AI generated art In 2018 a Paris art collective consisting of three students used artificial intelligence to generate a portrait It generated the portrait painting by studying a set of fifteen thousand art images on wiki art It was estimated to be worth between seven thousand to ten thousand dollars The painting sold at an auction for four thirtyfive thousand US dollars However we cannot for sure say that AI will replace human intelligence This is because we as a society have started asking hard questions and questioning ethics Elon Musk founded Open AI a research lab whose whole purpose is to promote and discover artificial intelligence in a way to benefits humanity In addition to this there are many factors that affect the longterm outcome of AI replacing human intelligence Like to what degree will other humans allow for AI to take over? Depending on the field do people even want Artificial Intelligence to help them? Or will they prefer a human counterpart? While we may not be able to control what happens in the long run we can definitely secure our shortterm future Strategic and creative thinking The ability to think outside the box is very human There are thousands upon thousands of slightly different possible outcomes that may result from every distinguishable action that the human mind with its ability to judge from experience is programmed for these purposes in a far more sophisticated manner than AI can currently achieve As the billionaire founder of Alibaba Jack Ma famously said  AI has logic human beings have wisdom Conflict resolution and negotiations With our understanding of the complexities of humanrelated processes and our ability to improvise and judge we are far better equipped to deal with conflicts than robots are ever likely to be AI may be able to recognize faces and images but it can rarely successfully read the feelings of those faces Humans to lesser or greater degrees are capable of an accurate analysis of emotional subtext With the application of intuition and the use of delicately worded or elusive languages through these methods we are able to properly judge how a person feels Interpretation of Gray Areas Robots and computers function well when presented with quantifiable data However once the situation enters a gray area whether this term refers to morals processes or definitions robots are more likely to falter Critical thinking Humans are capable of responding to more indicators of quality than computers are While an AI system may be able to analyze documents according to the true or false statements made within the text we can judge whether or not it is well written and analyze the implication of the use of certain words and the overall meaning of the content'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_ID_40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c1a34b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 16:03:18] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 16:03:33] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "file = open(\"40.txt\", \"w\")\n",
    "file.write(URL_ID_40)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"40.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "007ad05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['anything',\n",
       "  'that',\n",
       "  'could',\n",
       "  'give',\n",
       "  'rise',\n",
       "  'to',\n",
       "  'smarterthanhuman',\n",
       "  'intelligence',\n",
       "  'in',\n",
       "  'the',\n",
       "  'form',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'braincomputer',\n",
       "  'interfaces',\n",
       "  'or',\n",
       "  'neurosciencebased',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'enhancement',\n",
       "  'wins',\n",
       "  'hands',\n",
       "  'down',\n",
       "  'beyond',\n",
       "  'contest',\n",
       "  'as',\n",
       "  'doing',\n",
       "  'the',\n",
       "  'most',\n",
       "  'to',\n",
       "  'change',\n",
       "  'the',\n",
       "  'world',\n",
       "  'nothing',\n",
       "  'else',\n",
       "  'is',\n",
       "  'even',\n",
       "  'in',\n",
       "  'the',\n",
       "  'same',\n",
       "  'league',\n",
       "  'eliezer',\n",
       "  'yudkowsky',\n",
       "  'ai',\n",
       "  'researcher',\n",
       "  'theres',\n",
       "  'no',\n",
       "  'denying',\n",
       "  'robots',\n",
       "  'and',\n",
       "  'automation',\n",
       "  'are',\n",
       "  'increasingly',\n",
       "  'part',\n",
       "  'of',\n",
       "  'our',\n",
       "  'daily',\n",
       "  'lives',\n",
       "  'just',\n",
       "  'look',\n",
       "  'around',\n",
       "  'the',\n",
       "  'grocery',\n",
       "  'store',\n",
       "  'or',\n",
       "  'the',\n",
       "  'highway',\n",
       "  'they',\n",
       "  'are',\n",
       "  'everywhere',\n",
       "  'this',\n",
       "  'makes',\n",
       "  'us',\n",
       "  'wonder',\n",
       "  'what',\n",
       "  'if',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'replace',\n",
       "  'human',\n",
       "  'intelligence?',\n",
       "  'what',\n",
       "  'can',\n",
       "  'we',\n",
       "  'do',\n",
       "  'to',\n",
       "  'make',\n",
       "  'ourselves',\n",
       "  'relevant',\n",
       "  'tomorrow?',\n",
       "  'let',\n",
       "  'us',\n",
       "  'try',\n",
       "  'to',\n",
       "  'find',\n",
       "  'the',\n",
       "  'answers',\n",
       "  'to',\n",
       "  'all',\n",
       "  'these',\n",
       "  'questions',\n",
       "  'and',\n",
       "  'more',\n",
       "  'lets',\n",
       "  'first',\n",
       "  'understand',\n",
       "  'what',\n",
       "  'is',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'or',\n",
       "  'ai',\n",
       "  'basically',\n",
       "  'machines',\n",
       "  'displaying',\n",
       "  'intelligence',\n",
       "  'this',\n",
       "  'can',\n",
       "  'be',\n",
       "  'seen',\n",
       "  'from',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'playing',\n",
       "  'chess',\n",
       "  'or',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'answering',\n",
       "  'questions',\n",
       "  'on',\n",
       "  'facebook',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'can',\n",
       "  'be',\n",
       "  'further',\n",
       "  'broken',\n",
       "  'down',\n",
       "  'into',\n",
       "  'many',\n",
       "  'different',\n",
       "  'types',\n",
       "  'there',\n",
       "  'are',\n",
       "  'ais',\n",
       "  'designed',\n",
       "  'to',\n",
       "  'do',\n",
       "  'specific',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'detecting',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'type',\n",
       "  'of',\n",
       "  'cancer',\n",
       "  'however',\n",
       "  'there',\n",
       "  'are',\n",
       "  'also',\n",
       "  'ais',\n",
       "  'that',\n",
       "  'can',\n",
       "  'do',\n",
       "  'multiple',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'driving',\n",
       "  'a',\n",
       "  'car',\n",
       "  'there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'types',\n",
       "  'of',\n",
       "  'ais',\n",
       "  'among',\n",
       "  'the',\n",
       "  'top',\n",
       "  'most',\n",
       "  'important',\n",
       "  'fields',\n",
       "  'are',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'or',\n",
       "  'ml',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'and',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'or',\n",
       "  'nlp',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'machines',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'prove',\n",
       "  'themselves',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'how',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'learns',\n",
       "  'a',\n",
       "  'new',\n",
       "  'skill',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'also',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'the',\n",
       "  'optimization',\n",
       "  'of',\n",
       "  'an',\n",
       "  'existing',\n",
       "  'skill',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'used',\n",
       "  'in',\n",
       "  'many',\n",
       "  'different',\n",
       "  'fields',\n",
       "  'and',\n",
       "  'one',\n",
       "  'such',\n",
       "  'application',\n",
       "  'is',\n",
       "  'entertainment',\n",
       "  'netflix',\n",
       "  'uses',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'to',\n",
       "  'recommend',\n",
       "  'more',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'you',\n",
       "  'can',\n",
       "  'watch',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'you',\n",
       "  'have',\n",
       "  'already',\n",
       "  'seen',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'are',\n",
       "  'algorithms',\n",
       "  'that',\n",
       "  'are',\n",
       "  'modeled',\n",
       "  'after',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'these',\n",
       "  'algorithms',\n",
       "  'think',\n",
       "  'just',\n",
       "  'like',\n",
       "  'we',\n",
       "  'do',\n",
       "  'which',\n",
       "  'can',\n",
       "  'thereby',\n",
       "  'give',\n",
       "  'similar',\n",
       "  'results',\n",
       "  'to',\n",
       "  'what',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'can',\n",
       "  'give',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'are',\n",
       "  'used',\n",
       "  'in',\n",
       "  'medical',\n",
       "  'fields',\n",
       "  'to',\n",
       "  'diagnose',\n",
       "  'cancers',\n",
       "  'like',\n",
       "  'lung',\n",
       "  'cancer',\n",
       "  'and',\n",
       "  'prostate',\n",
       "  'cancer',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'that',\n",
       "  'computers',\n",
       "  'have',\n",
       "  'visions',\n",
       "  'this',\n",
       "  'allows',\n",
       "  'them',\n",
       "  'to',\n",
       "  'see',\n",
       "  'things',\n",
       "  'the',\n",
       "  'way',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'do',\n",
       "  'or',\n",
       "  'potentially',\n",
       "  'better',\n",
       "  'than',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'do',\n",
       "  'depending',\n",
       "  'on',\n",
       "  'the',\n",
       "  'programming',\n",
       "  'camera',\n",
       "  'used',\n",
       "  'etc',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'is',\n",
       "  'used',\n",
       "  'in',\n",
       "  'autonomous',\n",
       "  'vehicles',\n",
       "  'for',\n",
       "  'navigation',\n",
       "  'from',\n",
       "  'one',\n",
       "  'place',\n",
       "  'to',\n",
       "  'another',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'that',\n",
       "  'computers',\n",
       "  'can',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'what',\n",
       "  'we',\n",
       "  'say',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'this',\n",
       "  'is',\n",
       "  'siri',\n",
       "  'siri',\n",
       "  'is',\n",
       "  'able',\n",
       "  'to',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'our',\n",
       "  'demands',\n",
       "  'process',\n",
       "  'what',\n",
       "  'it',\n",
       "  'means',\n",
       "  'and',\n",
       "  'provide',\n",
       "  'you',\n",
       "  'an',\n",
       "  'answer',\n",
       "  'based',\n",
       "  'on',\n",
       "  'what',\n",
       "  'is',\n",
       "  'researched',\n",
       "  'now',\n",
       "  'that',\n",
       "  'we',\n",
       "  'know',\n",
       "  'what',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'and',\n",
       "  'what',\n",
       "  'it',\n",
       "  'can',\n",
       "  'do',\n",
       "  'lets',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'ais',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'the',\n",
       "  'automation',\n",
       "  'of',\n",
       "  'jobs',\n",
       "  'thereby',\n",
       "  'replacing',\n",
       "  'what',\n",
       "  'humans',\n",
       "  'already',\n",
       "  'do',\n",
       "  'this',\n",
       "  'means',\n",
       "  'more',\n",
       "  'job',\n",
       "  'loss',\n",
       "  'and',\n",
       "  'the',\n",
       "  'concentration',\n",
       "  'of',\n",
       "  'wealth',\n",
       "  'to',\n",
       "  'the',\n",
       "  'selected',\n",
       "  'few',\n",
       "  'people',\n",
       "  'this',\n",
       "  'could',\n",
       "  'mean',\n",
       "  'a',\n",
       "  'destabilization',\n",
       "  'of',\n",
       "  'society',\n",
       "  'and',\n",
       "  'social',\n",
       "  'unrest',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'social',\n",
       "  'unrest',\n",
       "  'ai',\n",
       "  'improves',\n",
       "  'over',\n",
       "  'time',\n",
       "  'this',\n",
       "  'means',\n",
       "  'it',\n",
       "  'becomes',\n",
       "  'smarter',\n",
       "  'faster',\n",
       "  'and',\n",
       "  'cheaper',\n",
       "  'to',\n",
       "  'implement',\n",
       "  'and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'better',\n",
       "  'at',\n",
       "  'doing',\n",
       "  'repetitive',\n",
       "  'things',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'currently',\n",
       "  'do',\n",
       "  'such',\n",
       "  'as',\n",
       "  'preparing',\n",
       "  'fast',\n",
       "  'food',\n",
       "  'it',\n",
       "  'is',\n",
       "  'predicted',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'improve',\n",
       "  'so',\n",
       "  'much',\n",
       "  'over',\n",
       "  '50',\n",
       "  'to',\n",
       "  '100',\n",
       "  'years',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'super',\n",
       "  'intelligent',\n",
       "  'this',\n",
       "  'means',\n",
       "  'that',\n",
       "  'it',\n",
       "  'will',\n",
       "  'become',\n",
       "  'even',\n",
       "  'smarter',\n",
       "  'than',\n",
       "  'the',\n",
       "  'most',\n",
       "  'intelligent',\n",
       "  'human',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'according',\n",
       "  'to',\n",
       "  'many',\n",
       "  'experts',\n",
       "  'such',\n",
       "  'as',\n",
       "  'elon',\n",
       "  'musk',\n",
       "  'this',\n",
       "  'could',\n",
       "  'cause',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'human',\n",
       "  'civilization',\n",
       "  'ai',\n",
       "  'could',\n",
       "  'potentially',\n",
       "  'start',\n",
       "  'a',\n",
       "  'war',\n",
       "  'against',\n",
       "  'humans',\n",
       "  'burn',\n",
       "  'crops',\n",
       "  'and',\n",
       "  'do',\n",
       "  'all',\n",
       "  'sorts',\n",
       "  'of',\n",
       "  'tragedies',\n",
       "  'once',\n",
       "  'reserved',\n",
       "  'for',\n",
       "  'human',\n",
       "  'functions',\n",
       "  'at',\n",
       "  'that',\n",
       "  'point',\n",
       "  'in',\n",
       "  'theory',\n",
       "  'we',\n",
       "  'can',\n",
       "  'not',\n",
       "  'stop',\n",
       "  'it',\n",
       "  'because',\n",
       "  'ai',\n",
       "  'would',\n",
       "  'have',\n",
       "  'already',\n",
       "  'thought',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'obstacles',\n",
       "  'that',\n",
       "  'will',\n",
       "  'prevent',\n",
       "  'its',\n",
       "  'goal',\n",
       "  'this',\n",
       "  'means',\n",
       "  'that',\n",
       "  'we',\n",
       "  'cannot',\n",
       "  'unplug',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'in',\n",
       "  'effect',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'replace',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'but',\n",
       "  'will',\n",
       "  'this',\n",
       "  'happen',\n",
       "  'in',\n",
       "  'next',\n",
       "  '10',\n",
       "  'to',\n",
       "  '30',\n",
       "  'years?',\n",
       "  'no!',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'sophisticated',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'do',\n",
       "  'many',\n",
       "  'human',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'currently',\n",
       "  'do',\n",
       "  'currently',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'not',\n",
       "  'smart',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'be',\n",
       "  'empathetic',\n",
       "  'to',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'cannot',\n",
       "  'think',\n",
       "  'strategically',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'complex',\n",
       "  'problems',\n",
       "  'ai',\n",
       "  'solutions',\n",
       "  'can',\n",
       "  'be',\n",
       "  'expensive',\n",
       "  'and',\n",
       "  'have',\n",
       "  'to',\n",
       "  'go',\n",
       "  'through',\n",
       "  'many',\n",
       "  'different',\n",
       "  'tests',\n",
       "  'and',\n",
       "  'standards',\n",
       "  'to',\n",
       "  'implement',\n",
       "  'it',\n",
       "  'also',\n",
       "  'takes',\n",
       "  'time',\n",
       "  'for',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'for',\n",
       "  'example',\n",
       "  'boston',\n",
       "  'dynamics',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'worlds',\n",
       "  'top',\n",
       "  'robotics',\n",
       "  'company',\n",
       "  'had',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'in',\n",
       "  '2009',\n",
       "  'that',\n",
       "  'needed',\n",
       "  'assistance',\n",
       "  'to',\n",
       "  'walk',\n",
       "  'fast',\n",
       "  'forward',\n",
       "  'to',\n",
       "  '2019',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'robot',\n",
       "  'could',\n",
       "  'walk',\n",
       "  'by',\n",
       "  'itself',\n",
       "  'but',\n",
       "  'it',\n",
       "  'could',\n",
       "  'jump',\n",
       "  'over',\n",
       "  'objects',\n",
       "  'do',\n",
       "  'backflips',\n",
       "  'and',\n",
       "  'so',\n",
       "  'much',\n",
       "  'more',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'the',\n",
       "  'timing',\n",
       "  'it',\n",
       "  'takes',\n",
       "  'time',\n",
       "  'for',\n",
       "  'the',\n",
       "  'price',\n",
       "  'of',\n",
       "  'any',\n",
       "  'new',\n",
       "  'technological',\n",
       "  'solution',\n",
       "  'to',\n",
       "  'drop',\n",
       "  'to',\n",
       "  'a',\n",
       "  'point',\n",
       "  'where',\n",
       "  'it',\n",
       "  'is',\n",
       "  'affordable',\n",
       "  'for',\n",
       "  'example',\n",
       "  'a',\n",
       "  'desktop',\n",
       "  'computer',\n",
       "  'costs',\n",
       "  'around',\n",
       "  '1000',\n",
       "  'in',\n",
       "  '1999',\n",
       "  'but',\n",
       "  'now',\n",
       "  'you',\n",
       "  'can',\n",
       "  'get',\n",
       "  'a',\n",
       "  'significantly',\n",
       "  'more',\n",
       "  'powerful',\n",
       "  'laptop',\n",
       "  'for',\n",
       "  'the',\n",
       "  'exact',\n",
       "  'same',\n",
       "  'price',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'go',\n",
       "  'through',\n",
       "  'the',\n",
       "  'same',\n",
       "  'curve',\n",
       "  'but',\n",
       "  'what',\n",
       "  'happens',\n",
       "  'after',\n",
       "  'those',\n",
       "  '10',\n",
       "  'to',\n",
       "  '30',\n",
       "  'years?',\n",
       "  'will',\n",
       "  'ai',\n",
       "  'make',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'obsolete?',\n",
       "  'maybe',\n",
       "  'as',\n",
       "  'we',\n",
       "  'have',\n",
       "  'proven',\n",
       "  'earlier',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'faster',\n",
       "  'better',\n",
       "  'and',\n",
       "  'cheaper',\n",
       "  'as',\n",
       "  'this',\n",
       "  'happens',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'companies',\n",
       "  'will',\n",
       "  'use',\n",
       "  'ai',\n",
       "  'technology',\n",
       "  'to',\n",
       "  'automate',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'to',\n",
       "  'save',\n",
       "  'money',\n",
       "  'increase',\n",
       "  'productivity',\n",
       "  'and',\n",
       "  'most',\n",
       "  'importantly',\n",
       "  'stay',\n",
       "  'competitive',\n",
       "  'as',\n",
       "  'we',\n",
       "  'have',\n",
       "  'demonstrated',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'better',\n",
       "  'through',\n",
       "  'repetition',\n",
       "  'via',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'the',\n",
       "  'only',\n",
       "  'difference',\n",
       "  'is',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'faster',\n",
       "  'as',\n",
       "  'time',\n",
       "  'progresses',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'data',\n",
       "  'that',\n",
       "  'is',\n",
       "  'available',\n",
       "  'today',\n",
       "  'it',\n",
       "  'will',\n",
       "  'also',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'from',\n",
       "  'other',\n",
       "  'machines',\n",
       "  'or',\n",
       "  'similar',\n",
       "  'machines',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'how',\n",
       "  'to',\n",
       "  'optimize',\n",
       "  'its',\n",
       "  'tasks',\n",
       "  'or',\n",
       "  'new',\n",
       "  'important',\n",
       "  'skills',\n",
       "  'however',\n",
       "  'ai',\n",
       "  'also',\n",
       "  'just',\n",
       "  'not',\n",
       "  'do',\n",
       "  'repetitive',\n",
       "  'and',\n",
       "  'routine',\n",
       "  'tasks',\n",
       "  'better',\n",
       "  'it',\n",
       "  'will',\n",
       "  'also',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'emotional',\n",
       "  'intelligence',\n",
       "  'ethics',\n",
       "  'and',\n",
       "  'creativity',\n",
       "  'this',\n",
       "  'seen',\n",
       "  'in',\n",
       "  'three',\n",
       "  'distinct',\n",
       "  'example',\n",
       "  'ibm',\n",
       "  'ibm',\n",
       "  'uses',\n",
       "  'its',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'to',\n",
       "  'program',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'create',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'trailer',\n",
       "  'fox',\n",
       "  'approached',\n",
       "  'ibm',\n",
       "  'and',\n",
       "  'said',\n",
       "  'they',\n",
       "  'have',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'coming',\n",
       "  'out',\n",
       "  'on',\n",
       "  'ai',\n",
       "  'scifi',\n",
       "  'horror',\n",
       "  'they',\n",
       "  'asked',\n",
       "  'ibm',\n",
       "  'if',\n",
       "  'their',\n",
       "  'platform',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'could',\n",
       "  'a',\n",
       "  'trailer',\n",
       "  'by',\n",
       "  'reviewing',\n",
       "  'and',\n",
       "  'watching',\n",
       "  'the',\n",
       "  'footage',\n",
       "  'and',\n",
       "  'searching',\n",
       "  'for',\n",
       "  'scary',\n",
       "  'sad',\n",
       "  'or',\n",
       "  'happy',\n",
       "  'or',\n",
       "  'other',\n",
       "  'moments',\n",
       "  'in',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'that',\n",
       "  ...]]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/40.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f4276aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a7c5692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "            \n",
    "            \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\"WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6442a05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "913541e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f1edfc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 19.132530120481928\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3d582bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.30959752321981426\n",
      "FOG INDEX: 7.776851057480697\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 19.132530120481928\n",
      "COMPLEX WORD COUNT: 300\n",
      "WORD COUNT: 969\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "89391ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2895\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b4fa7c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 8\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 6\n",
      "Total count: 14\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_40.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a6688dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 1\n",
      "PERSONAL PRONOUNS: 1\n",
      "AVG WORD LENGTH: 4.913098236775818\n"
     ]
    }
   ],
   "source": [
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27e1a1",
   "metadata": {},
   "source": [
    "# For URL_ID 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "911e2624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\1168314131.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "012fbe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e8b4a0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Machine intelligence is the last invention that humanity will ever need to make”',\n",
       " 'Nick Bostrom',\n",
       " 'To put it frankly, Artificial Intelligence will eventually replace jobs. Workers in a variety of industries, from healthcare to agriculture and manufacturing, should expect to witness hiring disruptions as a result of Artificial Intelligence.',\n",
       " 'If history has taught us anything, it is that disruptive paradigm-shifting business ideas not only make a fortune for the innovators, but they also build the groundwork for new business models, market entrants, and job opportunities which will inevitably follow. It is true that robots today or in future will eventually replace humans for many jobs, but so did innovative farming equipment for humans and horses during the industrial revolution. But that does not mean that our jobs as humans will end here. We, on the other hand, will be required to generate and provide value in whole new ways for entirely new business models as a result of these changes.',\n",
       " 'According to 71% of the businesses worldwide, Artificial Intelligence can help people overcome critical and challenging problems and live better lives. Artificial Intelligence consultants at work will be more or equally fair, according to a whopping 83% of corporate leaders. These results demonstrate that Artificial Intelligence is steadily extending its measures, yielding societal benefits and allowing citizens to live more fulfilling lives.',\n",
       " 'Since the advent of Industry 4.0, businesses are moving at a fast pace towards automation, be it any type of industry. In 2013, researchers at oxford university did a study on the future of work. They concluded that almost one in every two jobs have a high risk of being automated by machines. Machine learning is responsible for this disruption. It is the most powerful branch of artificial intelligence. It allows machines to learn from data and mimic some of the things that humans can do.',\n",
       " 'A research was conducted by the employees of Kaggle wherein an algorithm was to be created to take images of a human eye and diagnose an eye disease known as diabetic retinopathy. Here, the winning algorithm could match the diagnosis given by human ophthalmologists. Another study was conducted wherein an algorithm should be created to grade high school essays. Here too, the winning algorithm could match the grade given by human teachers.',\n",
       " 'Thus, we can safely conclude that given the right data, machines can easily outperform human beings in tasks like these. A teacher might read 10,000 essays over a 40-year career; an ophthalmologist might see 50,000 eyes but a machine can read a million essays and see a million eyes within minutes.',\n",
       " 'Thus, it is convenient to conclude that we have no chance of competing with machines on frequent, high volume tasks. ',\n",
       " 'Tasks where machines don’t work',\n",
       " 'But there are tasks where human beings have an upper hand, and that is, in novel tasks. Machines can’t handle things they haven’t seen many times before. The fundamental rule of machine learning is that it learns from large volumes of past data. But humans don’t; we have the ability of seemingly connecting disparate threads to solve problems we haven’t seen before. ',\n",
       " 'Percy Spencer was a physicist working on radar during world war 2 where he noticed that the magnetron was melting his chocolate bar. Here, he was able to connect his understanding of electromagnetic radiation with his knowledge of cooking in order to invent the microwave oven. Now this sort of cross pollination happens to each one of us several times in a day. Thus, machines cannot compete with us when it comes to tackling novel situations. ',\n",
       " 'Now as we all know that around 92% of talented professionals believe that soft skills such as human interactions and fostering relationships matter much more than hard skills in being successful in managing a workplace. Perhaps, these are the kind of tasks that machines can never compete with humans at. ',\n",
       " 'Also, creative tasks: the copy behind a marketing campaign needs to grab customers’ attention and will have to stand out of the crowd. Business strategy means finding gaps in the market and accordingly working on them. Since machines cannot outperform humans in novel tasks, it will be humans who would be creating these campaigns and strategies. ',\n",
       " 'Human contact would be essential in care-giving and educational-related work responsibilities, and technology would take a backseat. Health screenings and customer service face-to-face communication would advocate for human contact, with Artificial Intelligence playing a supporting role. ',\n",
       " 'So, what does this mean for the future of work? The future state of any single job lies in the answer to one single question: to what extent is the job reducible to tackling frequent high-volume tasks and to what extent does it involve tackling novel situations?',\n",
       " 'Today machines diagnose diseases and grade exam papers, over the coming years they’re going to conduct audits, they’re going to read boilerplate from legal contracts. But does that mean we’re not going to be needing accountants and lawyers? Wrong. We’re still going to need them for complex tax structuring, for path breaking litigation. It will only get tougher to get these jobs as machine learning will shrink their ranks. ',\n",
       " 'Amazon has recruited more than 100,000 robots in its warehouses to help move goods and products around more effectively, and its warehouse workforce has expanded by more than 80,000 people. Humans pick and pack goods (Amazon has over 480,000,000 products on its “shelves”), while robots move orders throughout the enormous warehouses, therefore reducing “the amount of walking required of workers, making Amazon pickers more efficient and less exhausted.” Furthermore, because Amazon no longer requires aisle space for humans, the robots enable Amazon to pack shelves together like cars in rush-hour traffic.” More inventory under one roof offers better selection for customers, and a higher density of shelf space equals more inventory under one roof.',\n",
       " 'Kodak, once an undisputed giant of the photography industry, had a 90% share in the USA market in 1976, and by 1984, they were employing 1,45,000 people. But in the year 2012, they had a net worth of negative $1 billion and they had to declare bankruptcy. Why? Because they failed to predict the importance of exponential trends when it comes to technology. On the other hand, Instagram, a digital photography company started in 2012 with 13 employees and later they were sold to Facebook for $1 billion. This is so ironic because Kodak pioneered digital photography and actually invented the first digital camera but unfortunately thought of it as a mere product and didn’t pay attention towards it and this created the problem.  ',\n",
       " 'We live in an era of artificial intelligence (AI), which has given us tremendous computing power, storage space, and information access. We were given the spinning wheel in the first, electricity in the second, and computers in the third industrial revolution by the exponential growth of technology.',\n",
       " 'Airbnb, which is a giant start-up and is known for enabling homeowners to rent out their homes and couches to travellers, for example, “is now creating a new Artificial Intelligence system that will empower its designers and product engineers to literally take ideas from the drawing board and convert them into actual products almost instantly.” This might be a significant breakthrough whether you’re a designer, engineer, or other type of technologist.',\n",
       " 'Differences that Automation brings onto the table: ',\n",
       " 'There are three key changes that automation can bring about at the macro level: ',\n",
       " 'Artificial Intelligence isn’t just a fad. Tractica, a market research firm, published a report in 2016 that predicted “annual global revenue for artificial intelligence products and services will expand from 643.7 million in 2016 to $36.8 billion by 2025, a 57-fold increase over that time span.” As a result, it is the IT industry’s fastest-growing segment of any size.”',\n",
       " 'The reduction in need for people as a result of Artificial Intelligence and related technologies, which resulted in job layoffs, was a cause of fear. In India alone, job losses in the IT sector have reportedly reached 1,000 in the last year, owing to the integration of new and advanced technologies like artificial intelligence and machine learning. ',\n",
       " 'Most of the IT companies such as Infosys, Wipro, TCS, and Cognizant have reduced their employee base in India and are recruiting less, while engaging more personnel in the United States and investing heavily in “centres of innovation.” Artificial Intelligence and data science, which are currently the trending aspects that require fewer people and are primarily located abroad, aren’t helping the prospects of local employees. Another factor is that the computer industry is continuously growing and would develop to a size of two million workers. Unfortunately, it’s a drop in the bucket compared to what robots are doing to Information Technology’s less-skilled brothers. ',\n",
       " 'Large e-commerce sites that used to be operated by armies of people are now manned by 200 robots produced by GreyOrange, which is an Indian company based out in Gurgaon. These indefatigable robots lift and stack boxes 24 hours a day, with only a 30-minute break for recharging, and have cut employees by up to 80%. For efficiency, this is a victory but a disaster for job prospects. ',\n",
       " 'Internal re-skilling and redeployment of staff is a critical requirement of the hour. Artificial intelligence has presented Indian policymakers with epistemological, scientific, and ethical issues. This requires us to abandon regular, linear, and non-disruptive mental patterns. The tale of artificial intelligence’s influence on individuals and their occupations will only be told over time. It is up to us to upskill ourselves and look for ways to stay current with the industry’s current trends and demands. ',\n",
       " 'So, will machines be able to take over many of our jobs? The answer is a resounding yes. However, for every job that is taken over by robots, there will be an equal number of positions available for people to do. Some of these human vocations will be artistic in nature. Others will necessitate humans honing superhuman cognitive abilities. Humans and machines can form symbiotic relationships, assisting each other in doing what they do best. In the future, people and machines may be able to collaborate and work together towards a common goal for any business they work for. ']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "fac3d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n",
    "texts=(' '.join(str(x) for x in texts[16:45]))\n",
    "URL_ID_41 = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e2a96fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 81 sentences in the string.\n",
      "The number of words in the string is: 1690\n",
      "The number of characters in the string is: 8822\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_41.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_41.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_41.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "0303709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine intelligence is the last invention that humanity will ever need to make Nick Bostrom To put it frankly Artificial Intelligence will eventually replace jobs Workers in a variety of industries from healthcare to agriculture and manufacturing should expect to witness hiring disruptions as a result of Artificial Intelligence If history has taught us anything it is that disruptive paradigmshifting business ideas not only make a fortune for the innovators but they also build the groundwork for new business models market entrants and job opportunities which will inevitably follow It is true that robots today or in future will eventually replace humans for many jobs but so did innovative farming equipment for humans and horses during the industrial revolution But that does not mean that our jobs as humans will end here We on the other hand will be required to generate and provide value in whole new ways for entirely new business models as a result of these changes According to 71 of the businesses worldwide Artificial Intelligence can help people overcome critical and challenging problems and live better lives Artificial Intelligence consultants at work will be more or equally fair according to a whopping 83 of corporate leaders These results demonstrate that Artificial Intelligence is steadily extending its measures yielding societal benefits and allowing citizens to live more fulfilling lives Since the advent of Industry 40 businesses are moving at a fast pace towards automation be it any type of industry In 2013 researchers at oxford university did a study on the future of work They concluded that almost one in every two jobs have a high risk of being automated by machines Machine learning is responsible for this disruption It is the most powerful branch of artificial intelligence It allows machines to learn from data and mimic some of the things that humans can do A research was conducted by the employees of Kaggle wherein an algorithm was to be created to take images of a human eye and diagnose an eye disease known as diabetic retinopathy Here the winning algorithm could match the diagnosis given by human ophthalmologists Another study was conducted wherein an algorithm should be created to grade high school essays Here too the winning algorithm could match the grade given by human teachers Thus we can safely conclude that given the right data machines can easily outperform human beings in tasks like these A teacher might read 10000 essays over a 40year career an ophthalmologist might see 50000 eyes but a machine can read a million essays and see a million eyes within minutes Thus it is convenient to conclude that we have no chance of competing with machines on frequent high volume tasks  Tasks where machines dont work But there are tasks where human beings have an upper hand and that is in novel tasks Machines cant handle things they havent seen many times before The fundamental rule of machine learning is that it learns from large volumes of past data But humans dont we have the ability of seemingly connecting disparate threads to solve problems we havent seen before  Percy Spencer was a physicist working on radar during world war 2 where he noticed that the magnetron was melting his chocolate bar Here he was able to connect his understanding of electromagnetic radiation with his knowledge of cooking in order to invent the microwave oven Now this sort of cross pollination happens to each one of us several times in a day Thus machines cannot compete with us when it comes to tackling novel situations  Now as we all know that around 92 of talented professionals believe that soft skills such as human interactions and fostering relationships matter much more than hard skills in being successful in managing a workplace Perhaps these are the kind of tasks that machines can never compete with humans at  Also creative tasks the copy behind a marketing campaign needs to grab customers attention and will have to stand out of the crowd Business strategy means finding gaps in the market and accordingly working on them Since machines cannot outperform humans in novel tasks it will be humans who would be creating these campaigns and strategies  Human contact would be essential in caregiving and educationalrelated work responsibilities and technology would take a backseat Health screenings and customer service facetoface communication would advocate for human contact with Artificial Intelligence playing a supporting role  So what does this mean for the future of work? The future state of any single job lies in the answer to one single question to what extent is the job reducible to tackling frequent highvolume tasks and to what extent does it involve tackling novel situations? Today machines diagnose diseases and grade exam papers over the coming years theyre going to conduct audits theyre going to read boilerplate from legal contracts But does that mean were not going to be needing accountants and lawyers? Wrong Were still going to need them for complex tax structuring for path breaking litigation It will only get tougher to get these jobs as machine learning will shrink their ranks  Amazon has recruited more than 100000 robots in its warehouses to help move goods and products around more effectively and its warehouse workforce has expanded by more than 80000 people Humans pick and pack goods Amazon has over 480000000 products on its shelves while robots move orders throughout the enormous warehouses therefore reducing the amount of walking required of workers making Amazon pickers more efficient and less exhausted Furthermore because Amazon no longer requires aisle space for humans the robots enable Amazon to pack shelves together like cars in rushhour traffic More inventory under one roof offers better selection for customers and a higher density of shelf space equals more inventory under one roof Kodak once an undisputed giant of the photography industry had a 90 share in the USA market in 1976 and by 1984 they were employing 145000 people But in the year 2012 they had a net worth of negative 1 billion and they had to declare bankruptcy Why? Because they failed to predict the importance of exponential trends when it comes to technology On the other hand Instagram a digital photography company started in 2012 with 13 employees and later they were sold to Facebook for 1 billion This is so ironic because Kodak pioneered digital photography and actually invented the first digital camera but unfortunately thought of it as a mere product and didnt pay attention towards it and this created the problem   We live in an era of artificial intelligence AI which has given us tremendous computing power storage space and information access We were given the spinning wheel in the first electricity in the second and computers in the third industrial revolution by the exponential growth of technology Airbnb which is a giant startup and is known for enabling homeowners to rent out their homes and couches to travellers for example is now creating a new Artificial Intelligence system that will empower its designers and product engineers to literally take ideas from the drawing board and convert them into actual products almost instantly This might be a significant breakthrough whether youre a designer engineer or other type of technologist Differences that Automation brings onto the table  There are three key changes that automation can bring about at the macro level  Artificial Intelligence isnt just a fad Tractica a market research firm published a report in 2016 that predicted annual global revenue for artificial intelligence products and services will expand from 6437 million in 2016 to 368 billion by 2025 a 57fold increase over that time span As a result it is the IT industrys fastestgrowing segment of any size The reduction in need for people as a result of Artificial Intelligence and related technologies which resulted in job layoffs was a cause of fear In India alone job losses in the IT sector have reportedly reached 1000 in the last year owing to the integration of new and advanced technologies like artificial intelligence and machine learning  Most of the IT companies such as Infosys Wipro TCS and Cognizant have reduced their employee base in India and are recruiting less while engaging more personnel in the United States and investing heavily in centres of innovation Artificial Intelligence and data science which are currently the trending aspects that require fewer people and are primarily located abroad arent helping the prospects of local employees Another factor is that the computer industry is continuously growing and would develop to a size of two million workers Unfortunately its a drop in the bucket compared to what robots are doing to Information Technologys lessskilled brothers  Large ecommerce sites that used to be operated by armies of people are now manned by 200 robots produced by GreyOrange which is an Indian company based out in Gurgaon These indefatigable robots lift and stack boxes 24 hours a day with only a 30minute break for recharging and have cut employees by up to 80 For efficiency this is a victory but a disaster for job prospects  Internal reskilling and redeployment of staff is a critical requirement of the hour Artificial intelligence has presented Indian policymakers with epistemological scientific and ethical issues This requires us to abandon regular linear and nondisruptive mental patterns The tale of artificial intelligences influence on individuals and their occupations will only be told over time It is up to us to upskill ourselves and look for ways to stay current with the industrys current trends and demands  So will machines be able to take over many of our jobs? The answer is a resounding yes However for every job that is taken over by robots there will be an equal number of positions available for people to do Some of these human vocations will be artistic in nature Others will necessitate humans honing superhuman cognitive abilities Humans and machines can form symbiotic relationships assisting each other in doing what they do best In the future people and machines may be able to collaborate and work together towards a common goal for any business they work for '"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_41 = re.sub(re_punt, \"\",URL_ID_41)\n",
    "URL_ID_41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "0ac00ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 16:44:45] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 16:44:55] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "file = open(\"41.txt\", \"w\")\n",
    "file.write(URL_ID_41)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"41.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "44e304c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['machine',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'the',\n",
       "  'last',\n",
       "  'invention',\n",
       "  'that',\n",
       "  'humanity',\n",
       "  'will',\n",
       "  'ever',\n",
       "  'need',\n",
       "  'to',\n",
       "  'make',\n",
       "  'nick',\n",
       "  'bostrom',\n",
       "  'to',\n",
       "  'put',\n",
       "  'it',\n",
       "  'frankly',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'will',\n",
       "  'eventually',\n",
       "  'replace',\n",
       "  'jobs',\n",
       "  'workers',\n",
       "  'in',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'industries',\n",
       "  'from',\n",
       "  'healthcare',\n",
       "  'to',\n",
       "  'agriculture',\n",
       "  'and',\n",
       "  'manufacturing',\n",
       "  'should',\n",
       "  'expect',\n",
       "  'to',\n",
       "  'witness',\n",
       "  'hiring',\n",
       "  'disruptions',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'if',\n",
       "  'history',\n",
       "  'has',\n",
       "  'taught',\n",
       "  'us',\n",
       "  'anything',\n",
       "  'it',\n",
       "  'is',\n",
       "  'that',\n",
       "  'disruptive',\n",
       "  'paradigmshifting',\n",
       "  'business',\n",
       "  'ideas',\n",
       "  'not',\n",
       "  'only',\n",
       "  'make',\n",
       "  'a',\n",
       "  'fortune',\n",
       "  'for',\n",
       "  'the',\n",
       "  'innovators',\n",
       "  'but',\n",
       "  'they',\n",
       "  'also',\n",
       "  'build',\n",
       "  'the',\n",
       "  'groundwork',\n",
       "  'for',\n",
       "  'new',\n",
       "  'business',\n",
       "  'models',\n",
       "  'market',\n",
       "  'entrants',\n",
       "  'and',\n",
       "  'job',\n",
       "  'opportunities',\n",
       "  'which',\n",
       "  'will',\n",
       "  'inevitably',\n",
       "  'follow',\n",
       "  'it',\n",
       "  'is',\n",
       "  'true',\n",
       "  'that',\n",
       "  'robots',\n",
       "  'today',\n",
       "  'or',\n",
       "  'in',\n",
       "  'future',\n",
       "  'will',\n",
       "  'eventually',\n",
       "  'replace',\n",
       "  'humans',\n",
       "  'for',\n",
       "  'many',\n",
       "  'jobs',\n",
       "  'but',\n",
       "  'so',\n",
       "  'did',\n",
       "  'innovative',\n",
       "  'farming',\n",
       "  'equipment',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'horses',\n",
       "  'during',\n",
       "  'the',\n",
       "  'industrial',\n",
       "  'revolution',\n",
       "  'but',\n",
       "  'that',\n",
       "  'does',\n",
       "  'not',\n",
       "  'mean',\n",
       "  'that',\n",
       "  'our',\n",
       "  'jobs',\n",
       "  'as',\n",
       "  'humans',\n",
       "  'will',\n",
       "  'end',\n",
       "  'here',\n",
       "  'we',\n",
       "  'on',\n",
       "  'the',\n",
       "  'other',\n",
       "  'hand',\n",
       "  'will',\n",
       "  'be',\n",
       "  'required',\n",
       "  'to',\n",
       "  'generate',\n",
       "  'and',\n",
       "  'provide',\n",
       "  'value',\n",
       "  'in',\n",
       "  'whole',\n",
       "  'new',\n",
       "  'ways',\n",
       "  'for',\n",
       "  'entirely',\n",
       "  'new',\n",
       "  'business',\n",
       "  'models',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'these',\n",
       "  'changes',\n",
       "  'according',\n",
       "  'to',\n",
       "  '71',\n",
       "  'of',\n",
       "  'the',\n",
       "  'businesses',\n",
       "  'worldwide',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'can',\n",
       "  'help',\n",
       "  'people',\n",
       "  'overcome',\n",
       "  'critical',\n",
       "  'and',\n",
       "  'challenging',\n",
       "  'problems',\n",
       "  'and',\n",
       "  'live',\n",
       "  'better',\n",
       "  'lives',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'consultants',\n",
       "  'at',\n",
       "  'work',\n",
       "  'will',\n",
       "  'be',\n",
       "  'more',\n",
       "  'or',\n",
       "  'equally',\n",
       "  'fair',\n",
       "  'according',\n",
       "  'to',\n",
       "  'a',\n",
       "  'whopping',\n",
       "  '83',\n",
       "  'of',\n",
       "  'corporate',\n",
       "  'leaders',\n",
       "  'these',\n",
       "  'results',\n",
       "  'demonstrate',\n",
       "  'that',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'steadily',\n",
       "  'extending',\n",
       "  'its',\n",
       "  'measures',\n",
       "  'yielding',\n",
       "  'societal',\n",
       "  'benefits',\n",
       "  'and',\n",
       "  'allowing',\n",
       "  'citizens',\n",
       "  'to',\n",
       "  'live',\n",
       "  'more',\n",
       "  'fulfilling',\n",
       "  'lives',\n",
       "  'since',\n",
       "  'the',\n",
       "  'advent',\n",
       "  'of',\n",
       "  'industry',\n",
       "  '40',\n",
       "  'businesses',\n",
       "  'are',\n",
       "  'moving',\n",
       "  'at',\n",
       "  'a',\n",
       "  'fast',\n",
       "  'pace',\n",
       "  'towards',\n",
       "  'automation',\n",
       "  'be',\n",
       "  'it',\n",
       "  'any',\n",
       "  'type',\n",
       "  'of',\n",
       "  'industry',\n",
       "  'in',\n",
       "  '2013',\n",
       "  'researchers',\n",
       "  'at',\n",
       "  'oxford',\n",
       "  'university',\n",
       "  'did',\n",
       "  'a',\n",
       "  'study',\n",
       "  'on',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work',\n",
       "  'they',\n",
       "  'concluded',\n",
       "  'that',\n",
       "  'almost',\n",
       "  'one',\n",
       "  'in',\n",
       "  'every',\n",
       "  'two',\n",
       "  'jobs',\n",
       "  'have',\n",
       "  'a',\n",
       "  'high',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'being',\n",
       "  'automated',\n",
       "  'by',\n",
       "  'machines',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'this',\n",
       "  'disruption',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'branch',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'it',\n",
       "  'allows',\n",
       "  'machines',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'from',\n",
       "  'data',\n",
       "  'and',\n",
       "  'mimic',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'things',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'can',\n",
       "  'do',\n",
       "  'a',\n",
       "  'research',\n",
       "  'was',\n",
       "  'conducted',\n",
       "  'by',\n",
       "  'the',\n",
       "  'employees',\n",
       "  'of',\n",
       "  'kaggle',\n",
       "  'wherein',\n",
       "  'an',\n",
       "  'algorithm',\n",
       "  'was',\n",
       "  'to',\n",
       "  'be',\n",
       "  'created',\n",
       "  'to',\n",
       "  'take',\n",
       "  'images',\n",
       "  'of',\n",
       "  'a',\n",
       "  'human',\n",
       "  'eye',\n",
       "  'and',\n",
       "  'diagnose',\n",
       "  'an',\n",
       "  'eye',\n",
       "  'disease',\n",
       "  'known',\n",
       "  'as',\n",
       "  'diabetic',\n",
       "  'retinopathy',\n",
       "  'here',\n",
       "  'the',\n",
       "  'winning',\n",
       "  'algorithm',\n",
       "  'could',\n",
       "  'match',\n",
       "  'the',\n",
       "  'diagnosis',\n",
       "  'given',\n",
       "  'by',\n",
       "  'human',\n",
       "  'ophthalmologists',\n",
       "  'another',\n",
       "  'study',\n",
       "  'was',\n",
       "  'conducted',\n",
       "  'wherein',\n",
       "  'an',\n",
       "  'algorithm',\n",
       "  'should',\n",
       "  'be',\n",
       "  'created',\n",
       "  'to',\n",
       "  'grade',\n",
       "  'high',\n",
       "  'school',\n",
       "  'essays',\n",
       "  'here',\n",
       "  'too',\n",
       "  'the',\n",
       "  'winning',\n",
       "  'algorithm',\n",
       "  'could',\n",
       "  'match',\n",
       "  'the',\n",
       "  'grade',\n",
       "  'given',\n",
       "  'by',\n",
       "  'human',\n",
       "  'teachers',\n",
       "  'thus',\n",
       "  'we',\n",
       "  'can',\n",
       "  'safely',\n",
       "  'conclude',\n",
       "  'that',\n",
       "  'given',\n",
       "  'the',\n",
       "  'right',\n",
       "  'data',\n",
       "  'machines',\n",
       "  'can',\n",
       "  'easily',\n",
       "  'outperform',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'in',\n",
       "  'tasks',\n",
       "  'like',\n",
       "  'these',\n",
       "  'a',\n",
       "  'teacher',\n",
       "  'might',\n",
       "  'read',\n",
       "  '10000',\n",
       "  'essays',\n",
       "  'over',\n",
       "  'a',\n",
       "  '40year',\n",
       "  'career',\n",
       "  'an',\n",
       "  'ophthalmologist',\n",
       "  'might',\n",
       "  'see',\n",
       "  '50000',\n",
       "  'eyes',\n",
       "  'but',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'can',\n",
       "  'read',\n",
       "  'a',\n",
       "  'million',\n",
       "  'essays',\n",
       "  'and',\n",
       "  'see',\n",
       "  'a',\n",
       "  'million',\n",
       "  'eyes',\n",
       "  'within',\n",
       "  'minutes',\n",
       "  'thus',\n",
       "  'it',\n",
       "  'is',\n",
       "  'convenient',\n",
       "  'to',\n",
       "  'conclude',\n",
       "  'that',\n",
       "  'we',\n",
       "  'have',\n",
       "  'no',\n",
       "  'chance',\n",
       "  'of',\n",
       "  'competing',\n",
       "  'with',\n",
       "  'machines',\n",
       "  'on',\n",
       "  'frequent',\n",
       "  'high',\n",
       "  'volume',\n",
       "  'tasks',\n",
       "  'tasks',\n",
       "  'where',\n",
       "  'machines',\n",
       "  'dont',\n",
       "  'work',\n",
       "  'but',\n",
       "  'there',\n",
       "  'are',\n",
       "  'tasks',\n",
       "  'where',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'have',\n",
       "  'an',\n",
       "  'upper',\n",
       "  'hand',\n",
       "  'and',\n",
       "  'that',\n",
       "  'is',\n",
       "  'in',\n",
       "  'novel',\n",
       "  'tasks',\n",
       "  'machines',\n",
       "  'cant',\n",
       "  'handle',\n",
       "  'things',\n",
       "  'they',\n",
       "  'havent',\n",
       "  'seen',\n",
       "  'many',\n",
       "  'times',\n",
       "  'before',\n",
       "  'the',\n",
       "  'fundamental',\n",
       "  'rule',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  'learns',\n",
       "  'from',\n",
       "  'large',\n",
       "  'volumes',\n",
       "  'of',\n",
       "  'past',\n",
       "  'data',\n",
       "  'but',\n",
       "  'humans',\n",
       "  'dont',\n",
       "  'we',\n",
       "  'have',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'of',\n",
       "  'seemingly',\n",
       "  'connecting',\n",
       "  'disparate',\n",
       "  'threads',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'problems',\n",
       "  'we',\n",
       "  'havent',\n",
       "  'seen',\n",
       "  'before',\n",
       "  'percy',\n",
       "  'spencer',\n",
       "  'was',\n",
       "  'a',\n",
       "  'physicist',\n",
       "  'working',\n",
       "  'on',\n",
       "  'radar',\n",
       "  'during',\n",
       "  'world',\n",
       "  'war',\n",
       "  '2',\n",
       "  'where',\n",
       "  'he',\n",
       "  'noticed',\n",
       "  'that',\n",
       "  'the',\n",
       "  'magnetron',\n",
       "  'was',\n",
       "  'melting',\n",
       "  'his',\n",
       "  'chocolate',\n",
       "  'bar',\n",
       "  'here',\n",
       "  'he',\n",
       "  'was',\n",
       "  'able',\n",
       "  'to',\n",
       "  'connect',\n",
       "  'his',\n",
       "  'understanding',\n",
       "  'of',\n",
       "  'electromagnetic',\n",
       "  'radiation',\n",
       "  'with',\n",
       "  'his',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'cooking',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'invent',\n",
       "  'the',\n",
       "  'microwave',\n",
       "  'oven',\n",
       "  'now',\n",
       "  'this',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'cross',\n",
       "  'pollination',\n",
       "  'happens',\n",
       "  'to',\n",
       "  'each',\n",
       "  'one',\n",
       "  'of',\n",
       "  'us',\n",
       "  'several',\n",
       "  'times',\n",
       "  'in',\n",
       "  'a',\n",
       "  'day',\n",
       "  'thus',\n",
       "  'machines',\n",
       "  'cannot',\n",
       "  'compete',\n",
       "  'with',\n",
       "  'us',\n",
       "  'when',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'tackling',\n",
       "  'novel',\n",
       "  'situations',\n",
       "  'now',\n",
       "  'as',\n",
       "  'we',\n",
       "  'all',\n",
       "  'know',\n",
       "  'that',\n",
       "  'around',\n",
       "  '92',\n",
       "  'of',\n",
       "  'talented',\n",
       "  'professionals',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'soft',\n",
       "  'skills',\n",
       "  'such',\n",
       "  'as',\n",
       "  'human',\n",
       "  'interactions',\n",
       "  'and',\n",
       "  'fostering',\n",
       "  'relationships',\n",
       "  'matter',\n",
       "  'much',\n",
       "  'more',\n",
       "  'than',\n",
       "  'hard',\n",
       "  'skills',\n",
       "  'in',\n",
       "  'being',\n",
       "  'successful',\n",
       "  'in',\n",
       "  'managing',\n",
       "  'a',\n",
       "  'workplace',\n",
       "  'perhaps',\n",
       "  'these',\n",
       "  'are',\n",
       "  'the',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'machines',\n",
       "  'can',\n",
       "  'never',\n",
       "  'compete',\n",
       "  'with',\n",
       "  'humans',\n",
       "  'at',\n",
       "  'also',\n",
       "  'creative',\n",
       "  'tasks',\n",
       "  'the',\n",
       "  'copy',\n",
       "  'behind',\n",
       "  'a',\n",
       "  'marketing',\n",
       "  'campaign',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'grab',\n",
       "  'customers',\n",
       "  'attention',\n",
       "  'and',\n",
       "  'will',\n",
       "  'have',\n",
       "  'to',\n",
       "  'stand',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'crowd',\n",
       "  'business',\n",
       "  'strategy',\n",
       "  'means',\n",
       "  'finding',\n",
       "  'gaps',\n",
       "  'in',\n",
       "  'the',\n",
       "  'market',\n",
       "  'and',\n",
       "  'accordingly',\n",
       "  'working',\n",
       "  'on',\n",
       "  'them',\n",
       "  'since',\n",
       "  'machines',\n",
       "  'cannot',\n",
       "  'outperform',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'novel',\n",
       "  'tasks',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'humans',\n",
       "  'who',\n",
       "  'would',\n",
       "  'be',\n",
       "  'creating',\n",
       "  'these',\n",
       "  'campaigns',\n",
       "  'and',\n",
       "  'strategies',\n",
       "  'human',\n",
       "  'contact',\n",
       "  'would',\n",
       "  'be',\n",
       "  'essential',\n",
       "  'in',\n",
       "  'caregiving',\n",
       "  'and',\n",
       "  'educationalrelated',\n",
       "  'work',\n",
       "  'responsibilities',\n",
       "  'and',\n",
       "  'technology',\n",
       "  'would',\n",
       "  'take',\n",
       "  'a',\n",
       "  'backseat',\n",
       "  'health',\n",
       "  'screenings',\n",
       "  'and',\n",
       "  'customer',\n",
       "  'service',\n",
       "  'facetoface',\n",
       "  'communication',\n",
       "  'would',\n",
       "  'advocate',\n",
       "  'for',\n",
       "  'human',\n",
       "  'contact',\n",
       "  'with',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'playing',\n",
       "  'a',\n",
       "  'supporting',\n",
       "  'role',\n",
       "  'so',\n",
       "  'what',\n",
       "  'does',\n",
       "  'this',\n",
       "  'mean',\n",
       "  'for',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work?',\n",
       "  'the',\n",
       "  'future',\n",
       "  'state',\n",
       "  'of',\n",
       "  'any',\n",
       "  'single',\n",
       "  'job',\n",
       "  'lies',\n",
       "  'in',\n",
       "  'the',\n",
       "  'answer',\n",
       "  'to',\n",
       "  'one',\n",
       "  'single',\n",
       "  'question',\n",
       "  'to',\n",
       "  'what',\n",
       "  'extent',\n",
       "  'is',\n",
       "  'the',\n",
       "  'job',\n",
       "  'reducible',\n",
       "  'to',\n",
       "  'tackling',\n",
       "  'frequent',\n",
       "  'highvolume',\n",
       "  'tasks',\n",
       "  'and',\n",
       "  'to',\n",
       "  'what',\n",
       "  'extent',\n",
       "  'does',\n",
       "  'it',\n",
       "  'involve',\n",
       "  'tackling',\n",
       "  'novel',\n",
       "  'situations?',\n",
       "  'today',\n",
       "  'machines',\n",
       "  'diagnose',\n",
       "  'diseases',\n",
       "  'and',\n",
       "  'grade',\n",
       "  'exam',\n",
       "  'papers',\n",
       "  'over',\n",
       "  'the',\n",
       "  'coming',\n",
       "  'years',\n",
       "  'theyre',\n",
       "  'going',\n",
       "  'to',\n",
       "  'conduct',\n",
       "  'audits',\n",
       "  'theyre',\n",
       "  'going',\n",
       "  'to',\n",
       "  'read',\n",
       "  'boilerplate',\n",
       "  'from',\n",
       "  'legal',\n",
       "  'contracts',\n",
       "  'but',\n",
       "  'does',\n",
       "  'that',\n",
       "  'mean',\n",
       "  'were',\n",
       "  'not',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'needing',\n",
       "  'accountants',\n",
       "  'and',\n",
       "  'lawyers?',\n",
       "  'wrong',\n",
       "  'were',\n",
       "  'still',\n",
       "  'going',\n",
       "  'to',\n",
       "  'need',\n",
       "  'them',\n",
       "  'for',\n",
       "  'complex',\n",
       "  'tax',\n",
       "  'structuring',\n",
       "  'for',\n",
       "  'path',\n",
       "  'breaking',\n",
       "  'litigation',\n",
       "  'it',\n",
       "  'will',\n",
       "  'only',\n",
       "  'get',\n",
       "  'tougher',\n",
       "  'to',\n",
       "  'get',\n",
       "  'these',\n",
       "  'jobs',\n",
       "  'as',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'will',\n",
       "  'shrink',\n",
       "  'their',\n",
       "  'ranks',\n",
       "  'amazon',\n",
       "  'has',\n",
       "  'recruited',\n",
       "  'more',\n",
       "  'than',\n",
       "  '100000',\n",
       "  'robots',\n",
       "  'in',\n",
       "  'its',\n",
       "  'warehouses',\n",
       "  'to',\n",
       "  'help',\n",
       "  'move',\n",
       "  'goods',\n",
       "  'and',\n",
       "  'products',\n",
       "  'around',\n",
       "  'more',\n",
       "  'effectively',\n",
       "  'and',\n",
       "  'its',\n",
       "  'warehouse',\n",
       "  'workforce',\n",
       "  'has',\n",
       "  'expanded',\n",
       "  'by',\n",
       "  'more',\n",
       "  'than',\n",
       "  '80000',\n",
       "  'people',\n",
       "  'humans',\n",
       "  'pick',\n",
       "  'and',\n",
       "  'pack',\n",
       "  'goods',\n",
       "  'amazon',\n",
       "  'has',\n",
       "  'over',\n",
       "  '480000000',\n",
       "  'products',\n",
       "  'on',\n",
       "  'its',\n",
       "  'shelves',\n",
       "  'while',\n",
       "  'robots',\n",
       "  'move',\n",
       "  'orders',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'enormous',\n",
       "  'warehouses',\n",
       "  'therefore',\n",
       "  'reducing',\n",
       "  'the',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'walking',\n",
       "  'required',\n",
       "  'of',\n",
       "  'workers',\n",
       "  'making',\n",
       "  'amazon',\n",
       "  'pickers',\n",
       "  'more',\n",
       "  'efficient',\n",
       "  'and',\n",
       "  'less',\n",
       "  'exhausted',\n",
       "  'furthermore',\n",
       "  'because',\n",
       "  'amazon',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'requires',\n",
       "  'aisle',\n",
       "  'space',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'the',\n",
       "  'robots',\n",
       "  'enable',\n",
       "  'amazon',\n",
       "  'to',\n",
       "  'pack',\n",
       "  'shelves',\n",
       "  'together',\n",
       "  'like',\n",
       "  'cars',\n",
       "  'in',\n",
       "  'rushhour',\n",
       "  'traffic',\n",
       "  'more',\n",
       "  'inventory',\n",
       "  'under',\n",
       "  'one',\n",
       "  'roof',\n",
       "  'offers',\n",
       "  'better',\n",
       "  'selection',\n",
       "  'for',\n",
       "  'customers',\n",
       "  'and',\n",
       "  'a',\n",
       "  'higher',\n",
       "  'density',\n",
       "  'of',\n",
       "  'shelf',\n",
       "  'space',\n",
       "  'equals',\n",
       "  'more',\n",
       "  'inventory',\n",
       "  'under',\n",
       "  'one',\n",
       "  'roof',\n",
       "  'kodak',\n",
       "  'once',\n",
       "  'an',\n",
       "  'undisputed',\n",
       "  'giant',\n",
       "  'of',\n",
       "  'the',\n",
       "  'photography',\n",
       "  'industry',\n",
       "  'had',\n",
       "  'a',\n",
       "  '90',\n",
       "  'share',\n",
       "  'in',\n",
       "  'the',\n",
       "  'usa',\n",
       "  'market',\n",
       "  'in',\n",
       "  '1976',\n",
       "  'and',\n",
       "  'by',\n",
       "  '1984',\n",
       "  'they',\n",
       "  'were',\n",
       "  'employing',\n",
       "  '145000',\n",
       "  'people',\n",
       "  'but',\n",
       "  'in',\n",
       "  'the',\n",
       "  'year',\n",
       "  '2012',\n",
       "  'they',\n",
       "  'had',\n",
       "  ...]]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/41.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ad1da2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5b2841bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 1074\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "            \n",
    "            \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "239f7a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "6d5fc33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 20.864197530864196\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "5c71619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3361266294227188\n",
      "FOG INDEX: 8.480129664114767\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 20.864197530864196\n",
      "COMPLEX WORD COUNT: 361\n",
      "WORD COUNT: 1074\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "5b9d0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3159\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "852629a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 8\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 6\n",
      "Total count: 14\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_41.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "41cb1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG WORD LENGTH: 5.220118343195266\n"
     ]
    }
   ],
   "source": [
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b76c8",
   "metadata": {},
   "source": [
    "#  6.For URL_ID 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6f6f856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\3958467769.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "84fa39a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "505e4b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where is this disruptive technology taking us? Take it or leave it, disruptive technology always creates new jobs much more than depleted jobs. You might notice certain jobs disappearing but those jobs are the jobs that transform humans to robots, to machines, and the technology is creating machines to replace them.  Technology creates the data analysis tools to manipulate and create custom scenarios using artificial intelligence (AI), Big Data and Machine Learning (ML) algorithms to predict and drive consumer behavior. Data Analytics tools, such as Google Analytics , and others are available today for free, and, if used correctly, can help organizations save millions, maybe billions of dollars of sales and marketing.',\n",
       " 'Before I go on, I think it’s best to level set on what constitutes machines. In the context of this article , machines describe computers and computerized equipment, like robots, that have been programmed to learn, sometimes like humans. Occasionally we call this Artificial Intelligence (AI), other times we call this machine learning, and still other times we call this robotics. And yes, these are technically different things. These bots are more efficient than humans in some specific domains and are growing smarter with each passing day. They can do some really tough tasks which are considered difficult for any human being.  But, within the broad discussion related to the future of work, these are totally interrelated. Factory floors deploy robots that are increasingly driven by machine learning algorithms such that they can adjust to people working alongside them. A machine can work efficiently only it has abundant data and information about the work which is being imparted daily to them. But with every forward step & advancement in technology, a threat is proliferating, a threat of being replaced on our work front. Every passing day is sealing some jobs for humans all over the globe. Similarly, AI is being used to turn hand-drawn sketches (done by humans) into digital source code.',\n",
       " 'Companies are clearly developing their AI and robotics expertise with the idea that through these technological innovations they’ll be able to',\n",
       " 'Of course, it’s not just machines and creatives working together either. In another example, Amazon has employed more than 100,000 robots in its warehouses to efficiently move things around while it has increased its warehouse workforce by more than 80,000. Humans, in Amazon’s case, do the picking and packing of goods while robots move orders around the giant warehouses, essentially cutting “down on the walking required of workers, making Amazon pickers more efficient and less tired.” Plus, the robots “allow Amazon to pack shelves together like cars in rush-hour traffic because they no longer need aisle space for humans. The greater density of shelf space means more inventory under one roof, which means better selection for customers.”',\n",
       " 'During the next few decades (or maybe sooner), the notion of work and whether it is handled by a human or a virtual being will hinge on predictability. As they are starting to do today, machines will manage the routine while humans take on the unpredictable – tasks that require creativity, problem-solving, and flexibility. In this context, robotics should be seen not only as a means to improve operations efficiency but also to improve the quality of life for workers.',\n",
       " 'Although it is obvious that human factors involved in a work activity impact job automation, it is also true that highly repetitive tasks—and even mechanical ones—are ideal for robots. Besides greater efficiency and speed, automation leads to a lower risk of accidents, greater control and autonomy, and above all, fewer costs for organizations.',\n",
       " 'Although artificial intelligence and machine learning make us believe that robots are endowed with superior intelligence, in fact they don’t yet have the ability to learn from experience and to respond to unknowns. So as things stand, however much processing speed and automatic learning a robot has, it doesn’t beat factors innate to the human brain. Humans are still a very essential part of the process. Think about delivering services to a client. Most customer challenges are routine, but humans play a very important role in addressing new issues, solving them the first time they appear, and then consolidating the process into the system.',\n",
       " 'While machines and humans are placed in proximity,  robots can be expensive, but this doesn’t apply to all types, especially those based on Robotic Process Automation (RPA), where the development process incorporates algorithms that significantly reduce costs.',\n",
       " 'Moreover, think of how domestic robots—be it a vacuum cleaner, a lawn mower or a pool cleaner—are increasingly part of our daily lives. This level of consumption that robotics has attained makes it affordable to automate tasks in modern homes to obtain greater control, security and comfort.',\n",
       " 'The division between humans and machines has been clear – I’m here, the machine is there – but that boundary is getting fuzzier. Smart prosthetics fuse seamlessly with our bodies, making up for lost limbs or providing additional strength, stability, or resilience, as seen in exoskeletons donned by assembly line workers.',\n",
       " 'We use our smartphones symbiotically, but what if they were integrated directly into our bodies? Think a smartphone in the form of a contact lens capable of transparently delivering augmented reality images straight to the brain. Think it sounds like science fiction? Think again. The first prototypes have already been built.',\n",
       " 'Soon, brain-computer interfaces could become seamless as well, creating a new synergistic relationship between the cloud and us. At that point, the question of who knows what would be moot; you ask me a question and I know the answer. Sometimes that answer will be stored in my own neural circuitry, but most of the time it would come from the connection of my neurons to the web. Our brain’s decision process is influenced by the way it has been “educated” by the cultural context. These external factors are influencing our decision processes to the point that in certain situations, we can legitimately claim that influence has been so strong that our brains can’t be held accountable for the choices made. The point I’m trying to make is that we humans are in symbiosis with our cultural environment and the tools – both physical and conceptual – that we have been taught to use. My guess is that the transformation will be subtle.',\n",
       " 'Practically speaking, robots growing to the point that they take over the world and then start creating smarter, better robots are impractical and should not even be a concern. None of this is expected in the near future, not by a long shot. If you’ve been to an ATM, waited for a PC to boot up after a catastrophic failure, or had a game crash on your X box just when you were about to reach a checkpoint, you understand that we are not in a world where machines do everything perfectly right. Before they can take over all of our jobs, they need to be able to do theirs’ flawlessly; until then, we can depend on humans to mess up our lives. ',\n",
       " 'This isn’t a win-or-lose situation. We’re going to wind up as a partner to our smarter machines, and that partnership will be fostered by our augmentation through technology. Machines will play an essential role in this augmentation and, as with any successful technology, they will fall below our level of perception. In the end, the revolution will be silent and invisible.']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "32de48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n",
    "texts=(' '.join(str(x) for x in texts[16:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e3313f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ID_42 = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "f6f3fdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55 sentences in the string.\n",
      "The number of words in the string is: 1232\n",
      "The number of characters in the string is: 6309\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_42.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_42.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_42.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "bd0170d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_42 = re.sub(re_punt, \"\",URL_ID_42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "37a4b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 18:51:55] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 18:52:04] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "file = open(\"42.txt\", \"w\")\n",
    "file.write(URL_ID_42)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"42.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "689a2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['where',\n",
       "  'is',\n",
       "  'this',\n",
       "  'disruptive',\n",
       "  'technology',\n",
       "  'taking',\n",
       "  'us?',\n",
       "  'take',\n",
       "  'it',\n",
       "  'or',\n",
       "  'leave',\n",
       "  'it',\n",
       "  'disruptive',\n",
       "  'technology',\n",
       "  'always',\n",
       "  'creates',\n",
       "  'new',\n",
       "  'jobs',\n",
       "  'much',\n",
       "  'more',\n",
       "  'than',\n",
       "  'depleted',\n",
       "  'jobs',\n",
       "  'you',\n",
       "  'might',\n",
       "  'notice',\n",
       "  'certain',\n",
       "  'jobs',\n",
       "  'disappearing',\n",
       "  'but',\n",
       "  'those',\n",
       "  'jobs',\n",
       "  'are',\n",
       "  'the',\n",
       "  'jobs',\n",
       "  'that',\n",
       "  'transform',\n",
       "  'humans',\n",
       "  'to',\n",
       "  'robots',\n",
       "  'to',\n",
       "  'machines',\n",
       "  'and',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'is',\n",
       "  'creating',\n",
       "  'machines',\n",
       "  'to',\n",
       "  'replace',\n",
       "  'them',\n",
       "  'technology',\n",
       "  'creates',\n",
       "  'the',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'tools',\n",
       "  'to',\n",
       "  'manipulate',\n",
       "  'and',\n",
       "  'create',\n",
       "  'custom',\n",
       "  'scenarios',\n",
       "  'using',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'ai',\n",
       "  'big',\n",
       "  'data',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'ml',\n",
       "  'algorithms',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'and',\n",
       "  'drive',\n",
       "  'consumer',\n",
       "  'behavior',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'tools',\n",
       "  'such',\n",
       "  'as',\n",
       "  'google',\n",
       "  'analytics',\n",
       "  'and',\n",
       "  'others',\n",
       "  'are',\n",
       "  'available',\n",
       "  'today',\n",
       "  'for',\n",
       "  'free',\n",
       "  'and',\n",
       "  'if',\n",
       "  'used',\n",
       "  'correctly',\n",
       "  'can',\n",
       "  'help',\n",
       "  'organizations',\n",
       "  'save',\n",
       "  'millions',\n",
       "  'maybe',\n",
       "  'billions',\n",
       "  'of',\n",
       "  'dollars',\n",
       "  'of',\n",
       "  'sales',\n",
       "  'and',\n",
       "  'marketing',\n",
       "  'before',\n",
       "  'i',\n",
       "  'go',\n",
       "  'on',\n",
       "  'i',\n",
       "  'think',\n",
       "  'its',\n",
       "  'best',\n",
       "  'to',\n",
       "  'level',\n",
       "  'set',\n",
       "  'on',\n",
       "  'what',\n",
       "  'constitutes',\n",
       "  'machines',\n",
       "  'in',\n",
       "  'the',\n",
       "  'context',\n",
       "  'of',\n",
       "  'this',\n",
       "  'article',\n",
       "  'machines',\n",
       "  'describe',\n",
       "  'computers',\n",
       "  'and',\n",
       "  'computerized',\n",
       "  'equipment',\n",
       "  'like',\n",
       "  'robots',\n",
       "  'that',\n",
       "  'have',\n",
       "  'been',\n",
       "  'programmed',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'sometimes',\n",
       "  'like',\n",
       "  'humans',\n",
       "  'occasionally',\n",
       "  'we',\n",
       "  'call',\n",
       "  'this',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'ai',\n",
       "  'other',\n",
       "  'times',\n",
       "  'we',\n",
       "  'call',\n",
       "  'this',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'still',\n",
       "  'other',\n",
       "  'times',\n",
       "  'we',\n",
       "  'call',\n",
       "  'this',\n",
       "  'robotics',\n",
       "  'and',\n",
       "  'yes',\n",
       "  'these',\n",
       "  'are',\n",
       "  'technically',\n",
       "  'different',\n",
       "  'things',\n",
       "  'these',\n",
       "  'bots',\n",
       "  'are',\n",
       "  'more',\n",
       "  'efficient',\n",
       "  'than',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'some',\n",
       "  'specific',\n",
       "  'domains',\n",
       "  'and',\n",
       "  'are',\n",
       "  'growing',\n",
       "  'smarter',\n",
       "  'with',\n",
       "  'each',\n",
       "  'passing',\n",
       "  'day',\n",
       "  'they',\n",
       "  'can',\n",
       "  'do',\n",
       "  'some',\n",
       "  'really',\n",
       "  'tough',\n",
       "  'tasks',\n",
       "  'which',\n",
       "  'are',\n",
       "  'considered',\n",
       "  'difficult',\n",
       "  'for',\n",
       "  'any',\n",
       "  'human',\n",
       "  'being',\n",
       "  'but',\n",
       "  'within',\n",
       "  'the',\n",
       "  'broad',\n",
       "  'discussion',\n",
       "  'related',\n",
       "  'to',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work',\n",
       "  'these',\n",
       "  'are',\n",
       "  'totally',\n",
       "  'interrelated',\n",
       "  'factory',\n",
       "  'floors',\n",
       "  'deploy',\n",
       "  'robots',\n",
       "  'that',\n",
       "  'are',\n",
       "  'increasingly',\n",
       "  'driven',\n",
       "  'by',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'such',\n",
       "  'that',\n",
       "  'they',\n",
       "  'can',\n",
       "  'adjust',\n",
       "  'to',\n",
       "  'people',\n",
       "  'working',\n",
       "  'alongside',\n",
       "  'them',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'can',\n",
       "  'work',\n",
       "  'efficiently',\n",
       "  'only',\n",
       "  'it',\n",
       "  'has',\n",
       "  'abundant',\n",
       "  'data',\n",
       "  'and',\n",
       "  'information',\n",
       "  'about',\n",
       "  'the',\n",
       "  'work',\n",
       "  'which',\n",
       "  'is',\n",
       "  'being',\n",
       "  'imparted',\n",
       "  'daily',\n",
       "  'to',\n",
       "  'them',\n",
       "  'but',\n",
       "  'with',\n",
       "  'every',\n",
       "  'forward',\n",
       "  'step',\n",
       "  'advancement',\n",
       "  'in',\n",
       "  'technology',\n",
       "  'a',\n",
       "  'threat',\n",
       "  'is',\n",
       "  'proliferating',\n",
       "  'a',\n",
       "  'threat',\n",
       "  'of',\n",
       "  'being',\n",
       "  'replaced',\n",
       "  'on',\n",
       "  'our',\n",
       "  'work',\n",
       "  'front',\n",
       "  'every',\n",
       "  'passing',\n",
       "  'day',\n",
       "  'is',\n",
       "  'sealing',\n",
       "  'some',\n",
       "  'jobs',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'all',\n",
       "  'over',\n",
       "  'the',\n",
       "  'globe',\n",
       "  'similarly',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'being',\n",
       "  'used',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'handdrawn',\n",
       "  'sketches',\n",
       "  'done',\n",
       "  'by',\n",
       "  'humans',\n",
       "  'into',\n",
       "  'digital',\n",
       "  'source',\n",
       "  'code',\n",
       "  'companies',\n",
       "  'are',\n",
       "  'clearly',\n",
       "  'developing',\n",
       "  'their',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'robotics',\n",
       "  'expertise',\n",
       "  'with',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'that',\n",
       "  'through',\n",
       "  'these',\n",
       "  'technological',\n",
       "  'innovations',\n",
       "  'theyll',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'of',\n",
       "  'course',\n",
       "  'its',\n",
       "  'not',\n",
       "  'just',\n",
       "  'machines',\n",
       "  'and',\n",
       "  'creatives',\n",
       "  'working',\n",
       "  'together',\n",
       "  'either',\n",
       "  'in',\n",
       "  'another',\n",
       "  'example',\n",
       "  'amazon',\n",
       "  'has',\n",
       "  'employed',\n",
       "  'more',\n",
       "  'than',\n",
       "  '100000',\n",
       "  'robots',\n",
       "  'in',\n",
       "  'its',\n",
       "  'warehouses',\n",
       "  'to',\n",
       "  'efficiently',\n",
       "  'move',\n",
       "  'things',\n",
       "  'around',\n",
       "  'while',\n",
       "  'it',\n",
       "  'has',\n",
       "  'increased',\n",
       "  'its',\n",
       "  'warehouse',\n",
       "  'workforce',\n",
       "  'by',\n",
       "  'more',\n",
       "  'than',\n",
       "  '80000',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'amazons',\n",
       "  'case',\n",
       "  'do',\n",
       "  'the',\n",
       "  'picking',\n",
       "  'and',\n",
       "  'packing',\n",
       "  'of',\n",
       "  'goods',\n",
       "  'while',\n",
       "  'robots',\n",
       "  'move',\n",
       "  'orders',\n",
       "  'around',\n",
       "  'the',\n",
       "  'giant',\n",
       "  'warehouses',\n",
       "  'essentially',\n",
       "  'cutting',\n",
       "  'down',\n",
       "  'on',\n",
       "  'the',\n",
       "  'walking',\n",
       "  'required',\n",
       "  'of',\n",
       "  'workers',\n",
       "  'making',\n",
       "  'amazon',\n",
       "  'pickers',\n",
       "  'more',\n",
       "  'efficient',\n",
       "  'and',\n",
       "  'less',\n",
       "  'tired',\n",
       "  'plus',\n",
       "  'the',\n",
       "  'robots',\n",
       "  'allow',\n",
       "  'amazon',\n",
       "  'to',\n",
       "  'pack',\n",
       "  'shelves',\n",
       "  'together',\n",
       "  'like',\n",
       "  'cars',\n",
       "  'in',\n",
       "  'rushhour',\n",
       "  'traffic',\n",
       "  'because',\n",
       "  'they',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'need',\n",
       "  'aisle',\n",
       "  'space',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'the',\n",
       "  'greater',\n",
       "  'density',\n",
       "  'of',\n",
       "  'shelf',\n",
       "  'space',\n",
       "  'means',\n",
       "  'more',\n",
       "  'inventory',\n",
       "  'under',\n",
       "  'one',\n",
       "  'roof',\n",
       "  'which',\n",
       "  'means',\n",
       "  'better',\n",
       "  'selection',\n",
       "  'for',\n",
       "  'customers',\n",
       "  'during',\n",
       "  'the',\n",
       "  'next',\n",
       "  'few',\n",
       "  'decades',\n",
       "  'or',\n",
       "  'maybe',\n",
       "  'sooner',\n",
       "  'the',\n",
       "  'notion',\n",
       "  'of',\n",
       "  'work',\n",
       "  'and',\n",
       "  'whether',\n",
       "  'it',\n",
       "  'is',\n",
       "  'handled',\n",
       "  'by',\n",
       "  'a',\n",
       "  'human',\n",
       "  'or',\n",
       "  'a',\n",
       "  'virtual',\n",
       "  'being',\n",
       "  'will',\n",
       "  'hinge',\n",
       "  'on',\n",
       "  'predictability',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'starting',\n",
       "  'to',\n",
       "  'do',\n",
       "  'today',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'manage',\n",
       "  'the',\n",
       "  'routine',\n",
       "  'while',\n",
       "  'humans',\n",
       "  'take',\n",
       "  'on',\n",
       "  'the',\n",
       "  'unpredictable',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'require',\n",
       "  'creativity',\n",
       "  'problemsolving',\n",
       "  'and',\n",
       "  'flexibility',\n",
       "  'in',\n",
       "  'this',\n",
       "  'context',\n",
       "  'robotics',\n",
       "  'should',\n",
       "  'be',\n",
       "  'seen',\n",
       "  'not',\n",
       "  'only',\n",
       "  'as',\n",
       "  'a',\n",
       "  'means',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'operations',\n",
       "  'efficiency',\n",
       "  'but',\n",
       "  'also',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'the',\n",
       "  'quality',\n",
       "  'of',\n",
       "  'life',\n",
       "  'for',\n",
       "  'workers',\n",
       "  'although',\n",
       "  'it',\n",
       "  'is',\n",
       "  'obvious',\n",
       "  'that',\n",
       "  'human',\n",
       "  'factors',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'a',\n",
       "  'work',\n",
       "  'activity',\n",
       "  'impact',\n",
       "  'job',\n",
       "  'automation',\n",
       "  'it',\n",
       "  'is',\n",
       "  'also',\n",
       "  'true',\n",
       "  'that',\n",
       "  'highly',\n",
       "  'repetitive',\n",
       "  'tasksand',\n",
       "  'even',\n",
       "  'mechanical',\n",
       "  'onesare',\n",
       "  'ideal',\n",
       "  'for',\n",
       "  'robots',\n",
       "  'besides',\n",
       "  'greater',\n",
       "  'efficiency',\n",
       "  'and',\n",
       "  'speed',\n",
       "  'automation',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'a',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'accidents',\n",
       "  'greater',\n",
       "  'control',\n",
       "  'and',\n",
       "  'autonomy',\n",
       "  'and',\n",
       "  'above',\n",
       "  'all',\n",
       "  'fewer',\n",
       "  'costs',\n",
       "  'for',\n",
       "  'organizations',\n",
       "  'although',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'make',\n",
       "  'us',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'robots',\n",
       "  'are',\n",
       "  'endowed',\n",
       "  'with',\n",
       "  'superior',\n",
       "  'intelligence',\n",
       "  'in',\n",
       "  'fact',\n",
       "  'they',\n",
       "  'dont',\n",
       "  'yet',\n",
       "  'have',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'from',\n",
       "  'experience',\n",
       "  'and',\n",
       "  'to',\n",
       "  'respond',\n",
       "  'to',\n",
       "  'unknowns',\n",
       "  'so',\n",
       "  'as',\n",
       "  'things',\n",
       "  'stand',\n",
       "  'however',\n",
       "  'much',\n",
       "  'processing',\n",
       "  'speed',\n",
       "  'and',\n",
       "  'automatic',\n",
       "  'learning',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'has',\n",
       "  'it',\n",
       "  'doesnt',\n",
       "  'beat',\n",
       "  'factors',\n",
       "  'innate',\n",
       "  'to',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'still',\n",
       "  'a',\n",
       "  'very',\n",
       "  'essential',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'process',\n",
       "  'think',\n",
       "  'about',\n",
       "  'delivering',\n",
       "  'services',\n",
       "  'to',\n",
       "  'a',\n",
       "  'client',\n",
       "  'most',\n",
       "  'customer',\n",
       "  'challenges',\n",
       "  'are',\n",
       "  'routine',\n",
       "  'but',\n",
       "  'humans',\n",
       "  'play',\n",
       "  'a',\n",
       "  'very',\n",
       "  'important',\n",
       "  'role',\n",
       "  'in',\n",
       "  'addressing',\n",
       "  'new',\n",
       "  'issues',\n",
       "  'solving',\n",
       "  'them',\n",
       "  'the',\n",
       "  'first',\n",
       "  'time',\n",
       "  'they',\n",
       "  'appear',\n",
       "  'and',\n",
       "  'then',\n",
       "  'consolidating',\n",
       "  'the',\n",
       "  'process',\n",
       "  'into',\n",
       "  'the',\n",
       "  'system',\n",
       "  'while',\n",
       "  'machines',\n",
       "  'and',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'placed',\n",
       "  'in',\n",
       "  'proximity',\n",
       "  'robots',\n",
       "  'can',\n",
       "  'be',\n",
       "  'expensive',\n",
       "  'but',\n",
       "  'this',\n",
       "  'doesnt',\n",
       "  'apply',\n",
       "  'to',\n",
       "  'all',\n",
       "  'types',\n",
       "  'especially',\n",
       "  'those',\n",
       "  'based',\n",
       "  'on',\n",
       "  'robotic',\n",
       "  'process',\n",
       "  'automation',\n",
       "  'rpa',\n",
       "  'where',\n",
       "  'the',\n",
       "  'development',\n",
       "  'process',\n",
       "  'incorporates',\n",
       "  'algorithms',\n",
       "  'that',\n",
       "  'significantly',\n",
       "  'reduce',\n",
       "  'costs',\n",
       "  'moreover',\n",
       "  'think',\n",
       "  'of',\n",
       "  'how',\n",
       "  'domestic',\n",
       "  'robotsbe',\n",
       "  'it',\n",
       "  'a',\n",
       "  'vacuum',\n",
       "  'cleaner',\n",
       "  'a',\n",
       "  'lawn',\n",
       "  'mower',\n",
       "  'or',\n",
       "  'a',\n",
       "  'pool',\n",
       "  'cleanerare',\n",
       "  'increasingly',\n",
       "  'part',\n",
       "  'of',\n",
       "  'our',\n",
       "  'daily',\n",
       "  'lives',\n",
       "  'this',\n",
       "  'level',\n",
       "  'of',\n",
       "  'consumption',\n",
       "  'that',\n",
       "  'robotics',\n",
       "  'has',\n",
       "  'attained',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'affordable',\n",
       "  'to',\n",
       "  'automate',\n",
       "  'tasks',\n",
       "  'in',\n",
       "  'modern',\n",
       "  'homes',\n",
       "  'to',\n",
       "  'obtain',\n",
       "  'greater',\n",
       "  'control',\n",
       "  'security',\n",
       "  'and',\n",
       "  'comfort',\n",
       "  'the',\n",
       "  'division',\n",
       "  'between',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'has',\n",
       "  'been',\n",
       "  'clear',\n",
       "  'im',\n",
       "  'here',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'is',\n",
       "  'there',\n",
       "  'but',\n",
       "  'that',\n",
       "  'boundary',\n",
       "  'is',\n",
       "  'getting',\n",
       "  'fuzzier',\n",
       "  'smart',\n",
       "  'prosthetics',\n",
       "  'fuse',\n",
       "  'seamlessly',\n",
       "  'with',\n",
       "  'our',\n",
       "  'bodies',\n",
       "  'making',\n",
       "  'up',\n",
       "  'for',\n",
       "  'lost',\n",
       "  'limbs',\n",
       "  'or',\n",
       "  'providing',\n",
       "  'additional',\n",
       "  'strength',\n",
       "  'stability',\n",
       "  'or',\n",
       "  'resilience',\n",
       "  'as',\n",
       "  'seen',\n",
       "  'in',\n",
       "  'exoskeletons',\n",
       "  'donned',\n",
       "  'by',\n",
       "  'assembly',\n",
       "  'line',\n",
       "  'workers',\n",
       "  'we',\n",
       "  'use',\n",
       "  'our',\n",
       "  'smartphones',\n",
       "  'symbiotically',\n",
       "  'but',\n",
       "  'what',\n",
       "  'if',\n",
       "  'they',\n",
       "  'were',\n",
       "  'integrated',\n",
       "  'directly',\n",
       "  'into',\n",
       "  'our',\n",
       "  'bodies?',\n",
       "  'think',\n",
       "  'a',\n",
       "  'smartphone',\n",
       "  'in',\n",
       "  'the',\n",
       "  'form',\n",
       "  'of',\n",
       "  'a',\n",
       "  'contact',\n",
       "  'lens',\n",
       "  'capable',\n",
       "  'of',\n",
       "  'transparently',\n",
       "  'delivering',\n",
       "  'augmented',\n",
       "  'reality',\n",
       "  'images',\n",
       "  'straight',\n",
       "  'to',\n",
       "  'the',\n",
       "  'brain',\n",
       "  'think',\n",
       "  'it',\n",
       "  'sounds',\n",
       "  'like',\n",
       "  'science',\n",
       "  'fiction?',\n",
       "  'think',\n",
       "  'again',\n",
       "  'the',\n",
       "  'first',\n",
       "  'prototypes',\n",
       "  'have',\n",
       "  'already',\n",
       "  'been',\n",
       "  'built',\n",
       "  'soon',\n",
       "  'braincomputer',\n",
       "  'interfaces',\n",
       "  'could',\n",
       "  'become',\n",
       "  'seamless',\n",
       "  'as',\n",
       "  'well',\n",
       "  'creating',\n",
       "  'a',\n",
       "  'new',\n",
       "  'synergistic',\n",
       "  'relationship',\n",
       "  'between',\n",
       "  'the',\n",
       "  'cloud',\n",
       "  'and',\n",
       "  'us',\n",
       "  'at',\n",
       "  'that',\n",
       "  'point',\n",
       "  'the',\n",
       "  'question',\n",
       "  'of',\n",
       "  'who',\n",
       "  'knows',\n",
       "  'what',\n",
       "  'would',\n",
       "  'be',\n",
       "  'moot',\n",
       "  'you',\n",
       "  'ask',\n",
       "  'me',\n",
       "  'a',\n",
       "  'question',\n",
       "  'and',\n",
       "  'i',\n",
       "  'know',\n",
       "  'the',\n",
       "  'answer',\n",
       "  'sometimes',\n",
       "  'that',\n",
       "  'answer',\n",
       "  'will',\n",
       "  'be',\n",
       "  'stored',\n",
       "  'in',\n",
       "  'my',\n",
       "  'own',\n",
       "  'neural',\n",
       "  'circuitry',\n",
       "  'but',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'time',\n",
       "  'it',\n",
       "  'would',\n",
       "  'come',\n",
       "  'from',\n",
       "  'the',\n",
       "  'connection',\n",
       "  'of',\n",
       "  'my',\n",
       "  'neurons',\n",
       "  'to',\n",
       "  'the',\n",
       "  'web',\n",
       "  'our',\n",
       "  'brains',\n",
       "  'decision',\n",
       "  'process',\n",
       "  'is',\n",
       "  'influenced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'way',\n",
       "  'it',\n",
       "  'has',\n",
       "  'been',\n",
       "  'educated',\n",
       "  'by',\n",
       "  'the',\n",
       "  'cultural',\n",
       "  'context',\n",
       "  'these',\n",
       "  'external',\n",
       "  'factors',\n",
       "  'are',\n",
       "  'influencing',\n",
       "  'our',\n",
       "  'decision',\n",
       "  'processes',\n",
       "  'to',\n",
       "  'the',\n",
       "  'point',\n",
       "  'that',\n",
       "  'in',\n",
       "  'certain',\n",
       "  'situations',\n",
       "  'we',\n",
       "  'can',\n",
       "  'legitimately',\n",
       "  'claim',\n",
       "  'that',\n",
       "  'influence',\n",
       "  'has',\n",
       "  'been',\n",
       "  'so',\n",
       "  'strong',\n",
       "  'that',\n",
       "  'our',\n",
       "  'brains',\n",
       "  'cant',\n",
       "  'be',\n",
       "  'held',\n",
       "  'accountable',\n",
       "  'for',\n",
       "  'the',\n",
       "  'choices',\n",
       "  'made',\n",
       "  ...]]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/42.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "4e1eb840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9eeb7a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 772\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "            \n",
    "            \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "5ebe790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "be1f5183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 22.4\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "ac712a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.32124352331606215\n",
      "FOG INDEX: 9.088497409326425\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 22.4\n",
      "COMPLEX WORD COUNT: 248\n",
      "WORD COUNT: 772\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a547bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2292\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6a0b8d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 3\n",
      "we: 9\n",
      "my: 3\n",
      "ours: 0\n",
      "us: 3\n",
      "Total count: 18\n",
      "PERSONAL PRONOUNS: 18\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_42.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\"?\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "2aaea982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG WORD LENGTH: 5.120941558441558\n"
     ]
    }
   ],
   "source": [
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afb679",
   "metadata": {},
   "source": [
    "# 7.For URL_ID 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "a7a703b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\60225179.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "079b3ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "ab4b4b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In future or in upcoming years humans and machines are going to work together in every field of work. In upcoming days machines will be the need for every human being. Machines [AI technology] will do the work which humans are incapable of doing. Machines will partner and co-operate with humans.',\n",
       " 'According to the professor at the university of Washington, he explained that, as a result of AI, there will be more demand for existing jobs and new jobs will be created that are unimaginable today. Human workers and machines will work together flawlessly, complementing each other. Machines will learn to carry out easier tasks such as following processes or crunching data. They will also help the humans while difficult. Machines or AI will create a great job opportunities for humans in future. John Kelly ll, executive vice president of IBM once said that “Man and Machines working together always beat or make a better decision than a man or a machine independently.”',\n",
       " ' In future, the three sectors of our country like agriculture sector, industrial sector and service sector are going to utilize the machines. So, that their work becomes not difficult. As of now, we can only see that for agriculture purposes various kinds of machines are used which we called as a modern farming method. Some major technologies [machines] that are harvest automation, autonomous tractors, seeding, and weeing and drones. As a result, farms can do agriculture peacefully. In the industrial sector also humans and machines are working together to increase production. Various types of machines are used in industries such as packing machines, loading machine etc. humans provide instructions to the machines and maintain the management in the company. Soon robots [machines] will assist doctors with surgeries. For instance, a doctor at remote location could direct a surgical robot to perform an open heart surgery. But the approaches option and decision will be left to experience and wisdom of the doctor not the robot.',\n",
       " 'What do you think of machines if they will make humans less or more in the field? Machines will push human professionals up the skillset ladder into uniquely human skills such as creativity, social abilities, empathy, and sense-making, which machines cannot automate. As a result, machines will make the workplace more, not less for humans. However, humans have to learn new skills throughout their lives. It is said that in the future 80% of process-oriented tasks will be done by machines. Quantitative reasoning tasks will be done approximately 50% by humans and 50% by machines, while humans will continue to do more than 80% of cross-functional reasoning tasks. According to Harvard research machines, algorithms can read diagnostic scans with 92% accuracy. Humans can do it with 96% accuracy. Together, it will be 99% accurate.',\n",
       " 'Human-machine collaboration enables companies to interact with employees and customers in the novel, more effective ways. Smart machines are helping humans to expand their abilities in three ways. They can amplify our cognitive strengths; interact with customers and employees to free us from higher-level tasks, and embody human skills to extend our physical capabilities. In the research, it was found that 1,500 companies achieve the most significant performance improvement when humans and machines work together. New machine systems have beyond-human cognitive abilities, which many of us fear could potentially dehumanize the future of work. Machines will indeed automate most repetitive and physical tasks, and part of quantitative tasks such as programming and even data science. According to D.E Shaw Group and professor at the University of Washington, explained that, as a result of machines, there will be more demand for existing jobs, and new jobs will be created that are unimaginable today. This is similar to how we couldn’t imagine a web app developer decades ago, and now millions make a living doing that today.',\n",
       " 'Machines are good at doing tasks with speed, precision, and accuracy. But machines are not very good at responding to unknown situations or making judgments. That part will be left to humans. Hence, the need for both humans and machines will be there in the future. Humans and machines have divergent skill sets that, when combined can transform the way we work. Machines have already infiltrated every aspect of our lives, and we must learn to live with them. In the future, human workers will interact more closely with humans.         ']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "148cfb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n",
    "texts=(' '.join(str(x) for x in texts[16:22]))\n",
    "URL_ID_43 = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "63dbaee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 46 sentences in the string.\n",
      "The number of words in the string is: 726\n",
      "The number of characters in the string is: 3779\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_43.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_43.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_43.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "2daf87fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_43 = re.sub(re_punt, \"\",URL_ID_43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "287011ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 19:21:51] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 19:22:00] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "file = open(\"43.txt\", \"w\")\n",
    "file.write(URL_ID_43)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"43.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "b629d073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in',\n",
       "  'future',\n",
       "  'or',\n",
       "  'in',\n",
       "  'upcoming',\n",
       "  'years',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'work',\n",
       "  'together',\n",
       "  'in',\n",
       "  'every',\n",
       "  'field',\n",
       "  'of',\n",
       "  'work',\n",
       "  'in',\n",
       "  'upcoming',\n",
       "  'days',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'need',\n",
       "  'for',\n",
       "  'every',\n",
       "  'human',\n",
       "  'being',\n",
       "  'machines',\n",
       "  'ai',\n",
       "  'technology',\n",
       "  'will',\n",
       "  'do',\n",
       "  'the',\n",
       "  'work',\n",
       "  'which',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'incapable',\n",
       "  'of',\n",
       "  'doing',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'partner',\n",
       "  'and',\n",
       "  'cooperate',\n",
       "  'with',\n",
       "  'humans',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'professor',\n",
       "  'at',\n",
       "  'the',\n",
       "  'university',\n",
       "  'of',\n",
       "  'washington',\n",
       "  'he',\n",
       "  'explained',\n",
       "  'that',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'there',\n",
       "  'will',\n",
       "  'be',\n",
       "  'more',\n",
       "  'demand',\n",
       "  'for',\n",
       "  'existing',\n",
       "  'jobs',\n",
       "  'and',\n",
       "  'new',\n",
       "  'jobs',\n",
       "  'will',\n",
       "  'be',\n",
       "  'created',\n",
       "  'that',\n",
       "  'are',\n",
       "  'unimaginable',\n",
       "  'today',\n",
       "  'human',\n",
       "  'workers',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'work',\n",
       "  'together',\n",
       "  'flawlessly',\n",
       "  'complementing',\n",
       "  'each',\n",
       "  'other',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'learn',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'out',\n",
       "  'easier',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'following',\n",
       "  'processes',\n",
       "  'or',\n",
       "  'crunching',\n",
       "  'data',\n",
       "  'they',\n",
       "  'will',\n",
       "  'also',\n",
       "  'help',\n",
       "  'the',\n",
       "  'humans',\n",
       "  'while',\n",
       "  'difficult',\n",
       "  'machines',\n",
       "  'or',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'create',\n",
       "  'a',\n",
       "  'great',\n",
       "  'job',\n",
       "  'opportunities',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'future',\n",
       "  'john',\n",
       "  'kelly',\n",
       "  'll',\n",
       "  'executive',\n",
       "  'vice',\n",
       "  'president',\n",
       "  'of',\n",
       "  'ibm',\n",
       "  'once',\n",
       "  'said',\n",
       "  'that',\n",
       "  'man',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'working',\n",
       "  'together',\n",
       "  'always',\n",
       "  'beat',\n",
       "  'or',\n",
       "  'make',\n",
       "  'a',\n",
       "  'better',\n",
       "  'decision',\n",
       "  'than',\n",
       "  'a',\n",
       "  'man',\n",
       "  'or',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'independently',\n",
       "  'in',\n",
       "  'future',\n",
       "  'the',\n",
       "  'three',\n",
       "  'sectors',\n",
       "  'of',\n",
       "  'our',\n",
       "  'country',\n",
       "  'like',\n",
       "  'agriculture',\n",
       "  'sector',\n",
       "  'industrial',\n",
       "  'sector',\n",
       "  'and',\n",
       "  'service',\n",
       "  'sector',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'utilize',\n",
       "  'the',\n",
       "  'machines',\n",
       "  'so',\n",
       "  'that',\n",
       "  'their',\n",
       "  'work',\n",
       "  'becomes',\n",
       "  'not',\n",
       "  'difficult',\n",
       "  'as',\n",
       "  'of',\n",
       "  'now',\n",
       "  'we',\n",
       "  'can',\n",
       "  'only',\n",
       "  'see',\n",
       "  'that',\n",
       "  'for',\n",
       "  'agriculture',\n",
       "  'purposes',\n",
       "  'various',\n",
       "  'kinds',\n",
       "  'of',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'used',\n",
       "  'which',\n",
       "  'we',\n",
       "  'called',\n",
       "  'as',\n",
       "  'a',\n",
       "  'modern',\n",
       "  'farming',\n",
       "  'method',\n",
       "  'some',\n",
       "  'major',\n",
       "  'technologies',\n",
       "  'machines',\n",
       "  'that',\n",
       "  'are',\n",
       "  'harvest',\n",
       "  'automation',\n",
       "  'autonomous',\n",
       "  'tractors',\n",
       "  'seeding',\n",
       "  'and',\n",
       "  'weeing',\n",
       "  'and',\n",
       "  'drones',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'farms',\n",
       "  'can',\n",
       "  'do',\n",
       "  'agriculture',\n",
       "  'peacefully',\n",
       "  'in',\n",
       "  'the',\n",
       "  'industrial',\n",
       "  'sector',\n",
       "  'also',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'working',\n",
       "  'together',\n",
       "  'to',\n",
       "  'increase',\n",
       "  'production',\n",
       "  'various',\n",
       "  'types',\n",
       "  'of',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'used',\n",
       "  'in',\n",
       "  'industries',\n",
       "  'such',\n",
       "  'as',\n",
       "  'packing',\n",
       "  'machines',\n",
       "  'loading',\n",
       "  'machine',\n",
       "  'etc',\n",
       "  'humans',\n",
       "  'provide',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'the',\n",
       "  'machines',\n",
       "  'and',\n",
       "  'maintain',\n",
       "  'the',\n",
       "  'management',\n",
       "  'in',\n",
       "  'the',\n",
       "  'company',\n",
       "  'soon',\n",
       "  'robots',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'assist',\n",
       "  'doctors',\n",
       "  'with',\n",
       "  'surgeries',\n",
       "  'for',\n",
       "  'instance',\n",
       "  'a',\n",
       "  'doctor',\n",
       "  'at',\n",
       "  'remote',\n",
       "  'location',\n",
       "  'could',\n",
       "  'direct',\n",
       "  'a',\n",
       "  'surgical',\n",
       "  'robot',\n",
       "  'to',\n",
       "  'perform',\n",
       "  'an',\n",
       "  'open',\n",
       "  'heart',\n",
       "  'surgery',\n",
       "  'but',\n",
       "  'the',\n",
       "  'approaches',\n",
       "  'option',\n",
       "  'and',\n",
       "  'decision',\n",
       "  'will',\n",
       "  'be',\n",
       "  'left',\n",
       "  'to',\n",
       "  'experience',\n",
       "  'and',\n",
       "  'wisdom',\n",
       "  'of',\n",
       "  'the',\n",
       "  'doctor',\n",
       "  'not',\n",
       "  'the',\n",
       "  'robot',\n",
       "  'what',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'of',\n",
       "  'machines',\n",
       "  'if',\n",
       "  'they',\n",
       "  'will',\n",
       "  'make',\n",
       "  'humans',\n",
       "  'less',\n",
       "  'or',\n",
       "  'more',\n",
       "  'in',\n",
       "  'the',\n",
       "  'field?',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'push',\n",
       "  'human',\n",
       "  'professionals',\n",
       "  'up',\n",
       "  'the',\n",
       "  'skillset',\n",
       "  'ladder',\n",
       "  'into',\n",
       "  'uniquely',\n",
       "  'human',\n",
       "  'skills',\n",
       "  'such',\n",
       "  'as',\n",
       "  'creativity',\n",
       "  'social',\n",
       "  'abilities',\n",
       "  'empathy',\n",
       "  'and',\n",
       "  'sensemaking',\n",
       "  'which',\n",
       "  'machines',\n",
       "  'cannot',\n",
       "  'automate',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'make',\n",
       "  'the',\n",
       "  'workplace',\n",
       "  'more',\n",
       "  'not',\n",
       "  'less',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'however',\n",
       "  'humans',\n",
       "  'have',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'new',\n",
       "  'skills',\n",
       "  'throughout',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'it',\n",
       "  'is',\n",
       "  'said',\n",
       "  'that',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  '80',\n",
       "  'of',\n",
       "  'processoriented',\n",
       "  'tasks',\n",
       "  'will',\n",
       "  'be',\n",
       "  'done',\n",
       "  'by',\n",
       "  'machines',\n",
       "  'quantitative',\n",
       "  'reasoning',\n",
       "  'tasks',\n",
       "  'will',\n",
       "  'be',\n",
       "  'done',\n",
       "  'approximately',\n",
       "  '50',\n",
       "  'by',\n",
       "  'humans',\n",
       "  'and',\n",
       "  '50',\n",
       "  'by',\n",
       "  'machines',\n",
       "  'while',\n",
       "  'humans',\n",
       "  'will',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'do',\n",
       "  'more',\n",
       "  'than',\n",
       "  '80',\n",
       "  'of',\n",
       "  'crossfunctional',\n",
       "  'reasoning',\n",
       "  'tasks',\n",
       "  'according',\n",
       "  'to',\n",
       "  'harvard',\n",
       "  'research',\n",
       "  'machines',\n",
       "  'algorithms',\n",
       "  'can',\n",
       "  'read',\n",
       "  'diagnostic',\n",
       "  'scans',\n",
       "  'with',\n",
       "  '92',\n",
       "  'accuracy',\n",
       "  'humans',\n",
       "  'can',\n",
       "  'do',\n",
       "  'it',\n",
       "  'with',\n",
       "  '96',\n",
       "  'accuracy',\n",
       "  'together',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  '99',\n",
       "  'accurate',\n",
       "  'humanmachine',\n",
       "  'collaboration',\n",
       "  'enables',\n",
       "  'companies',\n",
       "  'to',\n",
       "  'interact',\n",
       "  'with',\n",
       "  'employees',\n",
       "  'and',\n",
       "  'customers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'novel',\n",
       "  'more',\n",
       "  'effective',\n",
       "  'ways',\n",
       "  'smart',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'helping',\n",
       "  'humans',\n",
       "  'to',\n",
       "  'expand',\n",
       "  'their',\n",
       "  'abilities',\n",
       "  'in',\n",
       "  'three',\n",
       "  'ways',\n",
       "  'they',\n",
       "  'can',\n",
       "  'amplify',\n",
       "  'our',\n",
       "  'cognitive',\n",
       "  'strengths',\n",
       "  'interact',\n",
       "  'with',\n",
       "  'customers',\n",
       "  'and',\n",
       "  'employees',\n",
       "  'to',\n",
       "  'free',\n",
       "  'us',\n",
       "  'from',\n",
       "  'higherlevel',\n",
       "  'tasks',\n",
       "  'and',\n",
       "  'embody',\n",
       "  'human',\n",
       "  'skills',\n",
       "  'to',\n",
       "  'extend',\n",
       "  'our',\n",
       "  'physical',\n",
       "  'capabilities',\n",
       "  'in',\n",
       "  'the',\n",
       "  'research',\n",
       "  'it',\n",
       "  'was',\n",
       "  'found',\n",
       "  'that',\n",
       "  '1500',\n",
       "  'companies',\n",
       "  'achieve',\n",
       "  'the',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'performance',\n",
       "  'improvement',\n",
       "  'when',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'work',\n",
       "  'together',\n",
       "  'new',\n",
       "  'machine',\n",
       "  'systems',\n",
       "  'have',\n",
       "  'beyondhuman',\n",
       "  'cognitive',\n",
       "  'abilities',\n",
       "  'which',\n",
       "  'many',\n",
       "  'of',\n",
       "  'us',\n",
       "  'fear',\n",
       "  'could',\n",
       "  'potentially',\n",
       "  'dehumanize',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'indeed',\n",
       "  'automate',\n",
       "  'most',\n",
       "  'repetitive',\n",
       "  'and',\n",
       "  'physical',\n",
       "  'tasks',\n",
       "  'and',\n",
       "  'part',\n",
       "  'of',\n",
       "  'quantitative',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'programming',\n",
       "  'and',\n",
       "  'even',\n",
       "  'data',\n",
       "  'science',\n",
       "  'according',\n",
       "  'to',\n",
       "  'de',\n",
       "  'shaw',\n",
       "  'group',\n",
       "  'and',\n",
       "  'professor',\n",
       "  'at',\n",
       "  'the',\n",
       "  'university',\n",
       "  'of',\n",
       "  'washington',\n",
       "  'explained',\n",
       "  'that',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'machines',\n",
       "  'there',\n",
       "  'will',\n",
       "  'be',\n",
       "  'more',\n",
       "  'demand',\n",
       "  'for',\n",
       "  'existing',\n",
       "  'jobs',\n",
       "  'and',\n",
       "  'new',\n",
       "  'jobs',\n",
       "  'will',\n",
       "  'be',\n",
       "  'created',\n",
       "  'that',\n",
       "  'are',\n",
       "  'unimaginable',\n",
       "  'today',\n",
       "  'this',\n",
       "  'is',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'how',\n",
       "  'we',\n",
       "  'couldnt',\n",
       "  'imagine',\n",
       "  'a',\n",
       "  'web',\n",
       "  'app',\n",
       "  'developer',\n",
       "  'decades',\n",
       "  'ago',\n",
       "  'and',\n",
       "  'now',\n",
       "  'millions',\n",
       "  'make',\n",
       "  'a',\n",
       "  'living',\n",
       "  'doing',\n",
       "  'that',\n",
       "  'today',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'good',\n",
       "  'at',\n",
       "  'doing',\n",
       "  'tasks',\n",
       "  'with',\n",
       "  'speed',\n",
       "  'precision',\n",
       "  'and',\n",
       "  'accuracy',\n",
       "  'but',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'not',\n",
       "  'very',\n",
       "  'good',\n",
       "  'at',\n",
       "  'responding',\n",
       "  'to',\n",
       "  'unknown',\n",
       "  'situations',\n",
       "  'or',\n",
       "  'making',\n",
       "  'judgments',\n",
       "  'that',\n",
       "  'part',\n",
       "  'will',\n",
       "  'be',\n",
       "  'left',\n",
       "  'to',\n",
       "  'humans',\n",
       "  'hence',\n",
       "  'the',\n",
       "  'need',\n",
       "  'for',\n",
       "  'both',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'be',\n",
       "  'there',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'have',\n",
       "  'divergent',\n",
       "  'skill',\n",
       "  'sets',\n",
       "  'that',\n",
       "  'when',\n",
       "  'combined',\n",
       "  'can',\n",
       "  'transform',\n",
       "  'the',\n",
       "  'way',\n",
       "  'we',\n",
       "  'work',\n",
       "  'machines',\n",
       "  'have',\n",
       "  'already',\n",
       "  'infiltrated',\n",
       "  'every',\n",
       "  'aspect',\n",
       "  'of',\n",
       "  'our',\n",
       "  'lives',\n",
       "  'and',\n",
       "  'we',\n",
       "  'must',\n",
       "  'learn',\n",
       "  'to',\n",
       "  'live',\n",
       "  'with',\n",
       "  'them',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'human',\n",
       "  'workers',\n",
       "  'will',\n",
       "  'interact',\n",
       "  'more',\n",
       "  'closely',\n",
       "  'with',\n",
       "  'humans']]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/43.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "5c8bef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "716774e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 455\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "            \n",
    "            \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "69794dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "b462904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 15.782608695652174\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "40f8121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3824175824175824\n",
      "FOG INDEX: 6.466010511227903\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 15.782608695652174\n",
      "COMPLEX WORD COUNT: 174\n",
      "WORD COUNT: 455\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "cd8386bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1351\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "93dd81a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 5\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 2\n",
      "Total count: 7\n",
      "PERSONAL PRONOUNS: 7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_43.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "99a4c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG WORD LENGTH: 5.205234159779614\n"
     ]
    }
   ],
   "source": [
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aedd614",
   "metadata": {},
   "source": [
    "# 8.For URL_ID 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "93ae7edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\689717935.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "80d8e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "3daac415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sorry, but the page you are looking for doesn't exist.\",\n",
       " 'We provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.',\n",
       " 'Contact us: hello@blackcoffer.com',\n",
       " '© All Right Reserved, Blackcoffer(OPC) Pvt. Ltd']"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f53e952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa4035",
   "metadata": {},
   "source": [
    "# 9.For URL_ID 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "47e56727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\2443352449.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "ca445f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e4cd6834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine learning techniques may have been used for years, but recently there has been an explosion in their applications. In fact, in a recent Q3 earnings call, Google CEO Sundar Pichai said “Machine learning is a core, transformative way by which we’re re-thinking how we’re doing everything.” And they’re far from the only business making that claim.',\n",
       " 'In the past, successful use of machine learning algorithms required bespoke algorithms and huge R&D budgets, but all that is changing. IBM Watson, Microsoft Azure, Amazon, and Alibaba all launched turnkey cloud-based machine-learning SaaS solutions in 2015. At the same time startups like Idibon, MetaMind, Dato, and MonkeyLearn have built machine learning products that companies can take advantage of.',\n",
       " 'Gartner already puts machine learning at the top of its hype curve, and no: machine learning won’t replace all of your employees with computers or suddenly double your revenue. But that doesn’t mean that it can’t give every business a competitive advantage. There are plenty of business processes that can significantly benefit from machine learning. So how does machine learning change the way businesses operate?',\n",
       " 'First thing’s first: Machine learning needs training data and training data costs money. Especially training data labeled by humans. Let me explain. To make machine learning work for business, the algorithm needs to see lots and lots of examples of what it’s supposed to be doing. If you want an algorithm to tell you if a sales lead is good, you need to show it lots and lots of examples of good sales leads and bad sales leads. If you want an algorithm to tag the support tickets you need to show it many examples of support tickets. If you localize your algorithm to a new language you probably need to collect lots of examples in that language. In some instances, a company may have those training sets in-house. For example, a bunch of disqualified or qualified leads. But say you haven’t labeled each of your support tickets as they’ve come in over the year. You’d need to have people either in-house or en masse via a data enrichment platform -label those tickets. The machine will then look at those judgments and start finding connections and patterns it can learn from.',\n",
       " 'Machine learning is much cheaper and more efficient than people when it works well. The downside is that it often works well in 80 percent of the cases and badly in 20 percent of the cases, and lowering the 20 percent error rate is hard, if not impossible. But even an 80 percent accurate algorithm can save you a lot of money because good machine learning algorithms know where they are accurate and where they are more likely to have errors. Smart companies take the cases where the algorithm has high confidence and uses those directly while sending low confidence cases to humans. Banks have been doing this for years. When you put a check in an ATM, an algorithm tries to decipher the numbers on the check. If you have really sloppy handwriting or the ink is smudged the algorithm passes the task to a human. This design pattern saves banks lots of money while preserving a very high level of accuracy.',\n",
       " 'A huge benefit of machine learning is that it can turn part of your variable cost into more of a fixed cost. If you use humans to handle cases where that algorithm is struggling, you are creating the perfect training data to feed into your algorithm. This is a well-studied technique called active learning it turns out that training data labels collected on cases where the algorithm has low confidence help the algorithm learn much, much more efficiently.',\n",
       " 'As the algorithm becomes increasingly more accurate, the unit economics of your business process become better and as machine learning becomes able to handle more cases, the expensive humans are only called in on the toughest, rarest situations. That means you use the best of both human and machine intelligence in tandem: leveraging the speed and reliability of computers for the easy judgments and the fluency and expertise of humans for the difficult ones. And if that sounds like smart business, it’s because it is.']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "d8ca102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n",
    "texts=(' '.join(str(x) for x in texts[16:23]))\n",
    "URL_ID_45 = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "97c87d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36 sentences in the string.\n",
      "The number of words in the string is: 698\n",
      "The number of characters in the string is: 3441\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_45.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_45.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_45.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "9cf60138",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_45 = re.sub(re_punt, \"\",URL_ID_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ac28b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 19:44:34] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 19:44:41] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "file = open(\"45.txt\", \"w\")\n",
    "file.write(URL_ID_45)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"45.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "819d49a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['machine',\n",
       "  'learning',\n",
       "  'techniques',\n",
       "  'may',\n",
       "  'have',\n",
       "  'been',\n",
       "  'used',\n",
       "  'for',\n",
       "  'years',\n",
       "  'but',\n",
       "  'recently',\n",
       "  'there',\n",
       "  'has',\n",
       "  'been',\n",
       "  'an',\n",
       "  'explosion',\n",
       "  'in',\n",
       "  'their',\n",
       "  'applications',\n",
       "  'in',\n",
       "  'fact',\n",
       "  'in',\n",
       "  'a',\n",
       "  'recent',\n",
       "  'q3',\n",
       "  'earnings',\n",
       "  'call',\n",
       "  'google',\n",
       "  'ceo',\n",
       "  'sundar',\n",
       "  'pichai',\n",
       "  'said',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'a',\n",
       "  'core',\n",
       "  'transformative',\n",
       "  'way',\n",
       "  'by',\n",
       "  'which',\n",
       "  'were',\n",
       "  'rethinking',\n",
       "  'how',\n",
       "  'were',\n",
       "  'doing',\n",
       "  'everything',\n",
       "  'and',\n",
       "  'theyre',\n",
       "  'far',\n",
       "  'from',\n",
       "  'the',\n",
       "  'only',\n",
       "  'business',\n",
       "  'making',\n",
       "  'that',\n",
       "  'claim',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  'successful',\n",
       "  'use',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'required',\n",
       "  'bespoke',\n",
       "  'algorithms',\n",
       "  'and',\n",
       "  'huge',\n",
       "  'rd',\n",
       "  'budgets',\n",
       "  'but',\n",
       "  'all',\n",
       "  'that',\n",
       "  'is',\n",
       "  'changing',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'microsoft',\n",
       "  'azure',\n",
       "  'amazon',\n",
       "  'and',\n",
       "  'alibaba',\n",
       "  'all',\n",
       "  'launched',\n",
       "  'turnkey',\n",
       "  'cloudbased',\n",
       "  'machinelearning',\n",
       "  'saas',\n",
       "  'solutions',\n",
       "  'in',\n",
       "  '2015',\n",
       "  'at',\n",
       "  'the',\n",
       "  'same',\n",
       "  'time',\n",
       "  'startups',\n",
       "  'like',\n",
       "  'idibon',\n",
       "  'metamind',\n",
       "  'dato',\n",
       "  'and',\n",
       "  'monkeylearn',\n",
       "  'have',\n",
       "  'built',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'products',\n",
       "  'that',\n",
       "  'companies',\n",
       "  'can',\n",
       "  'take',\n",
       "  'advantage',\n",
       "  'of',\n",
       "  'gartner',\n",
       "  'already',\n",
       "  'puts',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'at',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'its',\n",
       "  'hype',\n",
       "  'curve',\n",
       "  'and',\n",
       "  'no',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'wont',\n",
       "  'replace',\n",
       "  'all',\n",
       "  'of',\n",
       "  'your',\n",
       "  'employees',\n",
       "  'with',\n",
       "  'computers',\n",
       "  'or',\n",
       "  'suddenly',\n",
       "  'double',\n",
       "  'your',\n",
       "  'revenue',\n",
       "  'but',\n",
       "  'that',\n",
       "  'doesnt',\n",
       "  'mean',\n",
       "  'that',\n",
       "  'it',\n",
       "  'cant',\n",
       "  'give',\n",
       "  'every',\n",
       "  'business',\n",
       "  'a',\n",
       "  'competitive',\n",
       "  'advantage',\n",
       "  'there',\n",
       "  'are',\n",
       "  'plenty',\n",
       "  'of',\n",
       "  'business',\n",
       "  'processes',\n",
       "  'that',\n",
       "  'can',\n",
       "  'significantly',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'so',\n",
       "  'how',\n",
       "  'does',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'change',\n",
       "  'the',\n",
       "  'way',\n",
       "  'businesses',\n",
       "  'operate?',\n",
       "  'first',\n",
       "  'things',\n",
       "  'first',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'needs',\n",
       "  'training',\n",
       "  'data',\n",
       "  'and',\n",
       "  'training',\n",
       "  'data',\n",
       "  'costs',\n",
       "  'money',\n",
       "  'especially',\n",
       "  'training',\n",
       "  'data',\n",
       "  'labeled',\n",
       "  'by',\n",
       "  'humans',\n",
       "  'let',\n",
       "  'me',\n",
       "  'explain',\n",
       "  'to',\n",
       "  'make',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'work',\n",
       "  'for',\n",
       "  'business',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'see',\n",
       "  'lots',\n",
       "  'and',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'what',\n",
       "  'its',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'doing',\n",
       "  'if',\n",
       "  'you',\n",
       "  'want',\n",
       "  'an',\n",
       "  'algorithm',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'you',\n",
       "  'if',\n",
       "  'a',\n",
       "  'sales',\n",
       "  'lead',\n",
       "  'is',\n",
       "  'good',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'show',\n",
       "  'it',\n",
       "  'lots',\n",
       "  'and',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'good',\n",
       "  'sales',\n",
       "  'leads',\n",
       "  'and',\n",
       "  'bad',\n",
       "  'sales',\n",
       "  'leads',\n",
       "  'if',\n",
       "  'you',\n",
       "  'want',\n",
       "  'an',\n",
       "  'algorithm',\n",
       "  'to',\n",
       "  'tag',\n",
       "  'the',\n",
       "  'support',\n",
       "  'tickets',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'show',\n",
       "  'it',\n",
       "  'many',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'support',\n",
       "  'tickets',\n",
       "  'if',\n",
       "  'you',\n",
       "  'localize',\n",
       "  'your',\n",
       "  'algorithm',\n",
       "  'to',\n",
       "  'a',\n",
       "  'new',\n",
       "  'language',\n",
       "  'you',\n",
       "  'probably',\n",
       "  'need',\n",
       "  'to',\n",
       "  'collect',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'examples',\n",
       "  'in',\n",
       "  'that',\n",
       "  'language',\n",
       "  'in',\n",
       "  'some',\n",
       "  'instances',\n",
       "  'a',\n",
       "  'company',\n",
       "  'may',\n",
       "  'have',\n",
       "  'those',\n",
       "  'training',\n",
       "  'sets',\n",
       "  'inhouse',\n",
       "  'for',\n",
       "  'example',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'disqualified',\n",
       "  'or',\n",
       "  'qualified',\n",
       "  'leads',\n",
       "  'but',\n",
       "  'say',\n",
       "  'you',\n",
       "  'havent',\n",
       "  'labeled',\n",
       "  'each',\n",
       "  'of',\n",
       "  'your',\n",
       "  'support',\n",
       "  'tickets',\n",
       "  'as',\n",
       "  'theyve',\n",
       "  'come',\n",
       "  'in',\n",
       "  'over',\n",
       "  'the',\n",
       "  'year',\n",
       "  'youd',\n",
       "  'need',\n",
       "  'to',\n",
       "  'have',\n",
       "  'people',\n",
       "  'either',\n",
       "  'inhouse',\n",
       "  'or',\n",
       "  'en',\n",
       "  'masse',\n",
       "  'via',\n",
       "  'a',\n",
       "  'data',\n",
       "  'enrichment',\n",
       "  'platform',\n",
       "  'label',\n",
       "  'those',\n",
       "  'tickets',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'will',\n",
       "  'then',\n",
       "  'look',\n",
       "  'at',\n",
       "  'those',\n",
       "  'judgments',\n",
       "  'and',\n",
       "  'start',\n",
       "  'finding',\n",
       "  'connections',\n",
       "  'and',\n",
       "  'patterns',\n",
       "  'it',\n",
       "  'can',\n",
       "  'learn',\n",
       "  'from',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'much',\n",
       "  'cheaper',\n",
       "  'and',\n",
       "  'more',\n",
       "  'efficient',\n",
       "  'than',\n",
       "  'people',\n",
       "  'when',\n",
       "  'it',\n",
       "  'works',\n",
       "  'well',\n",
       "  'the',\n",
       "  'downside',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  'often',\n",
       "  'works',\n",
       "  'well',\n",
       "  'in',\n",
       "  '80',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cases',\n",
       "  'and',\n",
       "  'badly',\n",
       "  'in',\n",
       "  '20',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cases',\n",
       "  'and',\n",
       "  'lowering',\n",
       "  'the',\n",
       "  '20',\n",
       "  'percent',\n",
       "  'error',\n",
       "  'rate',\n",
       "  'is',\n",
       "  'hard',\n",
       "  'if',\n",
       "  'not',\n",
       "  'impossible',\n",
       "  'but',\n",
       "  'even',\n",
       "  'an',\n",
       "  '80',\n",
       "  'percent',\n",
       "  'accurate',\n",
       "  'algorithm',\n",
       "  'can',\n",
       "  'save',\n",
       "  'you',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'money',\n",
       "  'because',\n",
       "  'good',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'know',\n",
       "  'where',\n",
       "  'they',\n",
       "  'are',\n",
       "  'accurate',\n",
       "  'and',\n",
       "  'where',\n",
       "  'they',\n",
       "  'are',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'have',\n",
       "  'errors',\n",
       "  'smart',\n",
       "  'companies',\n",
       "  'take',\n",
       "  'the',\n",
       "  'cases',\n",
       "  'where',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'has',\n",
       "  'high',\n",
       "  'confidence',\n",
       "  'and',\n",
       "  'uses',\n",
       "  'those',\n",
       "  'directly',\n",
       "  'while',\n",
       "  'sending',\n",
       "  'low',\n",
       "  'confidence',\n",
       "  'cases',\n",
       "  'to',\n",
       "  'humans',\n",
       "  'banks',\n",
       "  'have',\n",
       "  'been',\n",
       "  'doing',\n",
       "  'this',\n",
       "  'for',\n",
       "  'years',\n",
       "  'when',\n",
       "  'you',\n",
       "  'put',\n",
       "  'a',\n",
       "  'check',\n",
       "  'in',\n",
       "  'an',\n",
       "  'atm',\n",
       "  'an',\n",
       "  'algorithm',\n",
       "  'tries',\n",
       "  'to',\n",
       "  'decipher',\n",
       "  'the',\n",
       "  'numbers',\n",
       "  'on',\n",
       "  'the',\n",
       "  'check',\n",
       "  'if',\n",
       "  'you',\n",
       "  'have',\n",
       "  'really',\n",
       "  'sloppy',\n",
       "  'handwriting',\n",
       "  'or',\n",
       "  'the',\n",
       "  'ink',\n",
       "  'is',\n",
       "  'smudged',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'passes',\n",
       "  'the',\n",
       "  'task',\n",
       "  'to',\n",
       "  'a',\n",
       "  'human',\n",
       "  'this',\n",
       "  'design',\n",
       "  'pattern',\n",
       "  'saves',\n",
       "  'banks',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'money',\n",
       "  'while',\n",
       "  'preserving',\n",
       "  'a',\n",
       "  'very',\n",
       "  'high',\n",
       "  'level',\n",
       "  'of',\n",
       "  'accuracy',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'benefit',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  'can',\n",
       "  'turn',\n",
       "  'part',\n",
       "  'of',\n",
       "  'your',\n",
       "  'variable',\n",
       "  'cost',\n",
       "  'into',\n",
       "  'more',\n",
       "  'of',\n",
       "  'a',\n",
       "  'fixed',\n",
       "  'cost',\n",
       "  'if',\n",
       "  'you',\n",
       "  'use',\n",
       "  'humans',\n",
       "  'to',\n",
       "  'handle',\n",
       "  'cases',\n",
       "  'where',\n",
       "  'that',\n",
       "  'algorithm',\n",
       "  'is',\n",
       "  'struggling',\n",
       "  'you',\n",
       "  'are',\n",
       "  'creating',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  'training',\n",
       "  'data',\n",
       "  'to',\n",
       "  'feed',\n",
       "  'into',\n",
       "  'your',\n",
       "  'algorithm',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'wellstudied',\n",
       "  'technique',\n",
       "  'called',\n",
       "  'active',\n",
       "  'learning',\n",
       "  'it',\n",
       "  'turns',\n",
       "  'out',\n",
       "  'that',\n",
       "  'training',\n",
       "  'data',\n",
       "  'labels',\n",
       "  'collected',\n",
       "  'on',\n",
       "  'cases',\n",
       "  'where',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'has',\n",
       "  'low',\n",
       "  'confidence',\n",
       "  'help',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'learn',\n",
       "  'much',\n",
       "  'much',\n",
       "  'more',\n",
       "  'efficiently',\n",
       "  'as',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'becomes',\n",
       "  'increasingly',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'the',\n",
       "  'unit',\n",
       "  'economics',\n",
       "  'of',\n",
       "  'your',\n",
       "  'business',\n",
       "  'process',\n",
       "  'become',\n",
       "  'better',\n",
       "  'and',\n",
       "  'as',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'becomes',\n",
       "  'able',\n",
       "  'to',\n",
       "  'handle',\n",
       "  'more',\n",
       "  'cases',\n",
       "  'the',\n",
       "  'expensive',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'only',\n",
       "  'called',\n",
       "  'in',\n",
       "  'on',\n",
       "  'the',\n",
       "  'toughest',\n",
       "  'rarest',\n",
       "  'situations',\n",
       "  'that',\n",
       "  'means',\n",
       "  'you',\n",
       "  'use',\n",
       "  'the',\n",
       "  'best',\n",
       "  'of',\n",
       "  'both',\n",
       "  'human',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'intelligence',\n",
       "  'in',\n",
       "  'tandem',\n",
       "  'leveraging',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'and',\n",
       "  'reliability',\n",
       "  'of',\n",
       "  'computers',\n",
       "  'for',\n",
       "  'the',\n",
       "  'easy',\n",
       "  'judgments',\n",
       "  'and',\n",
       "  'the',\n",
       "  'fluency',\n",
       "  'and',\n",
       "  'expertise',\n",
       "  'of',\n",
       "  'humans',\n",
       "  'for',\n",
       "  'the',\n",
       "  'difficult',\n",
       "  'ones',\n",
       "  'and',\n",
       "  'if',\n",
       "  'that',\n",
       "  'sounds',\n",
       "  'like',\n",
       "  'smart',\n",
       "  'business',\n",
       "  'its',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is']]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/45.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a4972d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "2ff9057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 439\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "            \n",
    "            \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "35243056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "c877dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 19.38888888888889\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "36b854bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.296127562642369\n",
      "FOG INDEX: 7.8740065806125035\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 19.38888888888889\n",
      "COMPLEX WORD COUNT: 130\n",
      "WORD COUNT: 439\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f4ade48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1247\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "a47a3b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_45.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "2aa7e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG WORD LENGTH: 4.929799426934097\n"
     ]
    }
   ],
   "source": [
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057e1e9",
   "metadata": {},
   "source": [
    "# 10. For URL_ID 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3934716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\2537057523.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.CLASS_NAME,'tdb-title-text')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "03f0aa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eLearning as technology becomes more affordable in higher education but having a big barrier in the cost of developing its resources. Deep learning using artificial intelligence continues to become more and more popular and having impacts on many areas of eLearning. It offers online learners of the future intuitive algorithms and automated delivery of eLearning content through modern LMS platforms. This paper aims to survey various applications of deep learning approaches for developing the resources of the eLearning platform, in which predictions, algorithms, and analytics come together to create more personalized future eLearning experiences. In addition, deep learning models for developing the contents of the eLearning platform, deep learning framework that enable deep learning systems into eLearning and its development, benefits & future trends of deep learning in eLearning, the relevant deep learning-based artificial intelligence tools, and a platform enabling the developer and learners to quickly reuse resources are clearly summarized. Thus, deep learning has evolved into developing ways to re-purpose existing resources that can mitigate the expense of content development of future eLearning.',\n",
       " 'It is natural to wonder where you might get AI tools to avoid the time and expense of developing your own. Don’t worry about the advert of AIaaS or “AI as a Service” even small education or learning & development professionals can purchase the license of AI tools and components. However, such types of tools cannot be useful for every e-learning ecosystem but may offer some enticing benefits such as adding standard AI tasks (logic, decision making) to your toolbox. Here are some of the AIaaS tools and platforms offered by famous tech giants most of which are cloud-based.',\n",
       " 'Microsoft Azure',\n",
       " 'Cloud-based AI services that can be used to build and manage AI applications like image recognition or bot-based apps',\n",
       " 'IBM’s Watson',\n",
       " 'Cloud-based AI services that can be integrated into your applications; to store and manage your own data',\n",
       " 'Google’s Tensor Flow',\n",
       " ' An end-to-end open-source machine learning platform',\n",
       " 'Amazon Web Services',\n",
       " 'Offers a wide range of products and services on Amazon’s cloud',\n",
       " 'There are other AIaaS platforms such as DataRobot, Petuum, and H2O which shows that the field is expanding.AI will probably not make human workers obsolete, at least not for a long time To put some of your fears to bed: the robots are probably not coming for your jobs, at least not yet. Given how artificial intelligence has been portrayed in the media, in particular in some of our favorite sci-fi movies, it’s clear that the advent of this technology has created fear that AI will one day make human beings obsolete in the workforce. After all, as technology has advanced, many tasks that were once executed by human hands have become automated. It’s only natural to fear that the leap toward creating intelligent computers could herald the beginning of the end of work as we know it. But, I don’t think there is any reason to be so fatalistic. A recent paper published by the MIT Task Force on the Work of the Future entitled “Artificial Intelligence And The Future of Work,” looked closely at developments in AI and their relation to the world of work. The paper paints a more optimistic picture.',\n",
       " 'Rather than promoting the obsolescence of human labor, the paper predicts that AI will continue to drive massive innovation that will fuel many existing industries and could have the potential to create many new sectors for growth, ultimately leading to the creation of more jobs. While AI has made major strides toward replicating the efficacy of human intelligence in executing certain tasks, there are still major limitations. In particular, AI programs are typically only capable of “specialized” intelligence, meaning they can solve only one problem, and execute only one task at a time. Often, they can be rigid, and unable to respond to any changes in input, or perform any “thinking” outside of their prescribed programming. Humans, however, possess “generalized intelligence,” with the kind of problem-solving, abstract thinking, and critical judgment that will continue to be important in business. Human judgment will be relevant, if not in every task, then certainly throughout every level across all sectors. There are many other factors that could limit runaway advancement in AI. AI often requires “learning” which can involve massive amounts of data, calling into question the availability of the right kind of data, and highlighting the need for categorization and issues of privacy and security around such data. There is also the limitation of computation and processing power. The cost of electricity alone to power one supercharged language model AI was estimated at $4.6 million. Another important limitation of note is that data can itself carry bias, and be reflective of societal inequities or the implicit biases of the designers who create and input the data. If there is bias in the data that is inputted into an AI, this bias is likely to carry over to the results generated by the AI.',\n",
       " 'There has even been a bill introduced into Congress entitled the Algorithmic Accountability Act with the goal of forcing the Federal Trade Commission to investigate the use of any new AI technology for the potential to perpetuate bias. Based on these factors and many others, the MIT CCI paper argues that we are a long way from reaching a point in which AI is comparable to human intelligence, and could theoretically replace human workers entirely.  Provided there is an investment at all levels, from education to the private sector and governmental organizations—anywhere that focuses on training and upskilling workers—AI has the potential to ultimately create more jobs, not less. The question should then become not “humans or computers” but “humans and computers” involved in complex systems that advance industry and prosperity. This paper is a fascinating read for anyone hoping to dive deeper into AI and the many potential directions in which it may lead.AI Is becoming standard in all businesses, not just in the world of tech A couple of times recently, AI has come up in conversation with a client or an associate, and I’m noticing a fallacy in how people are thinking about it. There seems to be a sense for many that it is a phenomenon that is only likely to have big impacts in the tech world. In case you hadn’t noticed, the tech world is the world these days. Don’t ever forget when economist Paul Krugman said in 1998 that “By 2005 or so, it will become clear that the Internet’s impact on the economy has been no greater than the fax machine’s.” You definitely don’t want to be behind the curve when it comes to AI.  In fact, 90% of leading businesses already have ongoing investments in AI technologies. More than half of businesses that have implemented some manner of AI-driven technology report experiencing greater productivity. AI is likely to have a strong impact on certain sectors in particular:',\n",
       " 'Medical:',\n",
       " 'The potential benefits of utilizing AI in the field of medicine are already being explored. The medical industry has a robust amount of data, which can be utilized to create predictive models related to healthcare. Additionally, AI has shown to be more effective than physicians in certain diagnostic contexts.',\n",
       " 'Automotive:',\n",
       " 'We’re already seeing how AI is impacting the world of transportation and automobiles with the advent of autonomous vehicles and autonomous navigation. AI will also have a major impact on manufacturing, including within the automotive sector.',\n",
       " 'Cybersecurity:',\n",
       " 'Cybersecurity is front of mind for many business leaders, especially considering the spike in cybersecurity breaches throughout 2020. Attacks rose 600% during the pandemic as hackers capitalized on people working from home, on less secure technological systems, and Wi-Fi networks. AI and machine learning will be critical tools in identifying and predicting threats in cybersecurity. AI will also be a crucial asset for security in the world of finance, given that it can process large amounts of data to predict and catch instances of fraud.',\n",
       " 'E-Commerce:',\n",
       " 'AI will play a pivotal role in e-commerce in the future, in every sector of the industry from user experience to marketing to fulfillment and distribution. We can expect that moving forward, AI will continue to drive e-commerce, including through the use of chat-bots, shopper personalization, image-based targeting advertising, and warehouse and inventory automation.',\n",
       " 'AI can have a big impact on the job search',\n",
       " 'If you are moving forward with the hope that a hiring manager may give you the benefit of the doubt on a small misstep within the application, you might be in for a rude awakening. AI already plays a major role in the hiring process, so much so that up to 75% of resumes are rejected by an automated applicant tracking system, or ATS before they even reach a human being.  In the past, recruiters have had to devote considerable time to poring over resumes to look for relevant candidates. Data from LinkedIn shows that recruiters can spend up to 23 hours looking over resumes for one successful hire.',\n",
       " 'Increasingly, however, resume scanning is being done by AI-powered programs. In 2018, 67% of hiring managers stated that AI was making their jobs easier. Despite the increasing prevalence of automation and algorithms in the hiring process, many have been critical of the use of certain types of AI by hiring managers, based on the charge that it can perpetuate and ever create more bias in hiring. One particular example is illustrated by HireVue, a startup whose initial services included technology that aimed to use facial recognition software and psychology to determine the potential effectiveness of a candidate in a certain role. The Electronic Privacy Information Center filed a lawsuit with the Federal Trade Commission alleging that this software had the potential to perpetuate bias and prejudice. HireVue discontinued the use of facial recognition software in early 2021, and now uses audio analysis and natural language processing. It’s clear that the use of certain types of AI in the hiring process will likely be controversial as new technology develops. However, if potential employers are using AI to process your application, there is no reason that you cannot be utilizing similar technology to your advantage.',\n",
       " 'Jobscan is an excellent resource that provides similar resume scanning to what would be used by a hiring manager. By comparing your resume to a job description, Jobscan will give you information on how to tweak your resume so that it is a good match for a certain position, with the goal of “beating” an applicant tracking system (ATS).',\n",
       " 'Jobseer is a browser add-on, and another great AI-based tool for those on the job market. Based on a scan of your resume, as well as keywords and skills related to your desired jobs, Jobseer will help match you with the job listings that best fit your experience. For each listing, you get a rating based on how well you are aligned with the particular posting, as well as recommendations of skills to add to better position your resume and experience.',\n",
       " 'Rezi: Now, as a disclaimer, I would never encourage you to turn your resume writing over to a bot. But Rezi is an awesome AI-based resume builder that includes templates to help you design a resume that is sure to check the boxes when it comes to applicant tracking systems. This is a great jumping-off point to kickstart a new resume.  Another great way to use this type of tool is to generate a new resume and compare it to your current resume to see how it stacks up, and identify some areas for improvement. AI is also a great place to focus your energy if you are looking to upskill in your career, or make your professional profile more competitive in the job market, especially when you consider that AI will have such far-reaching impacts across many industries.AI and machine learning are at the top of many lists of the most important skills in today’s job market. Jobs requesting AI or machine-learning skills are expected to increase by 71% in the next five years. If you’d like to expand your knowledge base in this arena, consider some of the great free online course offerings that focus on AI skills. If you are tech-savvy, it would be wise to dive deep and learn as much as you can about interacting in the AI space. If your skills lie elsewhere, it is important to recognize that AI will have a big impact, and to the extent of your abilities, you should try to understand the fundamentals of how it functions in different sectors. AI is definitely here to stay, whether we like it or not. Personally, I don’t think we have anything to be afraid of. The best way to move forward is to be aware of and adapt to the new technology around us, AI included. This article was updated on April 16, 2021, to reflect changes in HireVue’s assessment tools.']"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "79fa8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n",
    "texts=(' '.join(str(x) for x in texts[16:43]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "ef18d368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 sentences in the string.\n",
      "The number of words in the string is: 2148\n",
      "The number of characters in the string is: 10840\n"
     ]
    }
   ],
   "source": [
    "URL_ID_46 = texts\n",
    "\n",
    "sentences = URL_ID_40.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_40.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_40.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "841684c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 20:01:57] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 20:02:15] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_46 = re.sub(re_punt, \"\",URL_ID_46)\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"46.txt\", \"w\")\n",
    "file.write(URL_ID_46)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"46.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "f6aa6fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elearning',\n",
       "  'as',\n",
       "  'technology',\n",
       "  'becomes',\n",
       "  'more',\n",
       "  'affordable',\n",
       "  'in',\n",
       "  'higher',\n",
       "  'education',\n",
       "  'but',\n",
       "  'having',\n",
       "  'a',\n",
       "  'big',\n",
       "  'barrier',\n",
       "  'in',\n",
       "  'the',\n",
       "  'cost',\n",
       "  'of',\n",
       "  'developing',\n",
       "  'its',\n",
       "  'resources',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'using',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'continues',\n",
       "  'to',\n",
       "  'become',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'popular',\n",
       "  'and',\n",
       "  'having',\n",
       "  'impacts',\n",
       "  'on',\n",
       "  'many',\n",
       "  'areas',\n",
       "  'of',\n",
       "  'elearning',\n",
       "  'it',\n",
       "  'offers',\n",
       "  'online',\n",
       "  'learners',\n",
       "  'of',\n",
       "  'the',\n",
       "  'future',\n",
       "  'intuitive',\n",
       "  'algorithms',\n",
       "  'and',\n",
       "  'automated',\n",
       "  'delivery',\n",
       "  'of',\n",
       "  'elearning',\n",
       "  'content',\n",
       "  'through',\n",
       "  'modern',\n",
       "  'lms',\n",
       "  'platforms',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'aims',\n",
       "  'to',\n",
       "  'survey',\n",
       "  'various',\n",
       "  'applications',\n",
       "  'of',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'approaches',\n",
       "  'for',\n",
       "  'developing',\n",
       "  'the',\n",
       "  'resources',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elearning',\n",
       "  'platform',\n",
       "  'in',\n",
       "  'which',\n",
       "  'predictions',\n",
       "  'algorithms',\n",
       "  'and',\n",
       "  'analytics',\n",
       "  'come',\n",
       "  'together',\n",
       "  'to',\n",
       "  'create',\n",
       "  'more',\n",
       "  'personalized',\n",
       "  'future',\n",
       "  'elearning',\n",
       "  'experiences',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'models',\n",
       "  'for',\n",
       "  'developing',\n",
       "  'the',\n",
       "  'contents',\n",
       "  'of',\n",
       "  'the',\n",
       "  'elearning',\n",
       "  'platform',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'framework',\n",
       "  'that',\n",
       "  'enable',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'systems',\n",
       "  'into',\n",
       "  'elearning',\n",
       "  'and',\n",
       "  'its',\n",
       "  'development',\n",
       "  'benefits',\n",
       "  'future',\n",
       "  'trends',\n",
       "  'of',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'in',\n",
       "  'elearning',\n",
       "  'the',\n",
       "  'relevant',\n",
       "  'deep',\n",
       "  'learningbased',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'tools',\n",
       "  'and',\n",
       "  'a',\n",
       "  'platform',\n",
       "  'enabling',\n",
       "  'the',\n",
       "  'developer',\n",
       "  'and',\n",
       "  'learners',\n",
       "  'to',\n",
       "  'quickly',\n",
       "  'reuse',\n",
       "  'resources',\n",
       "  'are',\n",
       "  'clearly',\n",
       "  'summarized',\n",
       "  'thus',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'has',\n",
       "  'evolved',\n",
       "  'into',\n",
       "  'developing',\n",
       "  'ways',\n",
       "  'to',\n",
       "  'repurpose',\n",
       "  'existing',\n",
       "  'resources',\n",
       "  'that',\n",
       "  'can',\n",
       "  'mitigate',\n",
       "  'the',\n",
       "  'expense',\n",
       "  'of',\n",
       "  'content',\n",
       "  'development',\n",
       "  'of',\n",
       "  'future',\n",
       "  'elearning',\n",
       "  'it',\n",
       "  'is',\n",
       "  'natural',\n",
       "  'to',\n",
       "  'wonder',\n",
       "  'where',\n",
       "  'you',\n",
       "  'might',\n",
       "  'get',\n",
       "  'ai',\n",
       "  'tools',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'the',\n",
       "  'time',\n",
       "  'and',\n",
       "  'expense',\n",
       "  'of',\n",
       "  'developing',\n",
       "  'your',\n",
       "  'own',\n",
       "  'dont',\n",
       "  'worry',\n",
       "  'about',\n",
       "  'the',\n",
       "  'advert',\n",
       "  'of',\n",
       "  'aiaas',\n",
       "  'or',\n",
       "  'ai',\n",
       "  'as',\n",
       "  'a',\n",
       "  'service',\n",
       "  'even',\n",
       "  'small',\n",
       "  'education',\n",
       "  'or',\n",
       "  'learning',\n",
       "  'development',\n",
       "  'professionals',\n",
       "  'can',\n",
       "  'purchase',\n",
       "  'the',\n",
       "  'license',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'tools',\n",
       "  'and',\n",
       "  'components',\n",
       "  'however',\n",
       "  'such',\n",
       "  'types',\n",
       "  'of',\n",
       "  'tools',\n",
       "  'cannot',\n",
       "  'be',\n",
       "  'useful',\n",
       "  'for',\n",
       "  'every',\n",
       "  'elearning',\n",
       "  'ecosystem',\n",
       "  'but',\n",
       "  'may',\n",
       "  'offer',\n",
       "  'some',\n",
       "  'enticing',\n",
       "  'benefits',\n",
       "  'such',\n",
       "  'as',\n",
       "  'adding',\n",
       "  'standard',\n",
       "  'ai',\n",
       "  'tasks',\n",
       "  'logic',\n",
       "  'decision',\n",
       "  'making',\n",
       "  'to',\n",
       "  'your',\n",
       "  'toolbox',\n",
       "  'here',\n",
       "  'are',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'aiaas',\n",
       "  'tools',\n",
       "  'and',\n",
       "  'platforms',\n",
       "  'offered',\n",
       "  'by',\n",
       "  'famous',\n",
       "  'tech',\n",
       "  'giants',\n",
       "  'most',\n",
       "  'of',\n",
       "  'which',\n",
       "  'are',\n",
       "  'cloudbased',\n",
       "  'microsoft',\n",
       "  'azure',\n",
       "  'cloudbased',\n",
       "  'ai',\n",
       "  'services',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'to',\n",
       "  'build',\n",
       "  'and',\n",
       "  'manage',\n",
       "  'ai',\n",
       "  'applications',\n",
       "  'like',\n",
       "  'image',\n",
       "  'recognition',\n",
       "  'or',\n",
       "  'botbased',\n",
       "  'apps',\n",
       "  'ibms',\n",
       "  'watson',\n",
       "  'cloudbased',\n",
       "  'ai',\n",
       "  'services',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'integrated',\n",
       "  'into',\n",
       "  'your',\n",
       "  'applications',\n",
       "  'to',\n",
       "  'store',\n",
       "  'and',\n",
       "  'manage',\n",
       "  'your',\n",
       "  'own',\n",
       "  'data',\n",
       "  'googles',\n",
       "  'tensor',\n",
       "  'flow',\n",
       "  'an',\n",
       "  'endtoend',\n",
       "  'opensource',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'platform',\n",
       "  'amazon',\n",
       "  'web',\n",
       "  'services',\n",
       "  'offers',\n",
       "  'a',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'of',\n",
       "  'products',\n",
       "  'and',\n",
       "  'services',\n",
       "  'on',\n",
       "  'amazons',\n",
       "  'cloud',\n",
       "  'there',\n",
       "  'are',\n",
       "  'other',\n",
       "  'aiaas',\n",
       "  'platforms',\n",
       "  'such',\n",
       "  'as',\n",
       "  'datarobot',\n",
       "  'petuum',\n",
       "  'and',\n",
       "  'h2o',\n",
       "  'which',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'the',\n",
       "  'field',\n",
       "  'is',\n",
       "  'expandingai',\n",
       "  'will',\n",
       "  'probably',\n",
       "  'not',\n",
       "  'make',\n",
       "  'human',\n",
       "  'workers',\n",
       "  'obsolete',\n",
       "  'at',\n",
       "  'least',\n",
       "  'not',\n",
       "  'for',\n",
       "  'a',\n",
       "  'long',\n",
       "  'time',\n",
       "  'to',\n",
       "  'put',\n",
       "  'some',\n",
       "  'of',\n",
       "  'your',\n",
       "  'fears',\n",
       "  'to',\n",
       "  'bed',\n",
       "  'the',\n",
       "  'robots',\n",
       "  'are',\n",
       "  'probably',\n",
       "  'not',\n",
       "  'coming',\n",
       "  'for',\n",
       "  'your',\n",
       "  'jobs',\n",
       "  'at',\n",
       "  'least',\n",
       "  'not',\n",
       "  'yet',\n",
       "  'given',\n",
       "  'how',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'has',\n",
       "  'been',\n",
       "  'portrayed',\n",
       "  'in',\n",
       "  'the',\n",
       "  'media',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'in',\n",
       "  'some',\n",
       "  'of',\n",
       "  'our',\n",
       "  'favorite',\n",
       "  'scifi',\n",
       "  'movies',\n",
       "  'its',\n",
       "  'clear',\n",
       "  'that',\n",
       "  'the',\n",
       "  'advent',\n",
       "  'of',\n",
       "  'this',\n",
       "  'technology',\n",
       "  'has',\n",
       "  'created',\n",
       "  'fear',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'one',\n",
       "  'day',\n",
       "  'make',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'obsolete',\n",
       "  'in',\n",
       "  'the',\n",
       "  'workforce',\n",
       "  'after',\n",
       "  'all',\n",
       "  'as',\n",
       "  'technology',\n",
       "  'has',\n",
       "  'advanced',\n",
       "  'many',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'were',\n",
       "  'once',\n",
       "  'executed',\n",
       "  'by',\n",
       "  'human',\n",
       "  'hands',\n",
       "  'have',\n",
       "  'become',\n",
       "  'automated',\n",
       "  'its',\n",
       "  'only',\n",
       "  'natural',\n",
       "  'to',\n",
       "  'fear',\n",
       "  'that',\n",
       "  'the',\n",
       "  'leap',\n",
       "  'toward',\n",
       "  'creating',\n",
       "  'intelligent',\n",
       "  'computers',\n",
       "  'could',\n",
       "  'herald',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  'of',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'work',\n",
       "  'as',\n",
       "  'we',\n",
       "  'know',\n",
       "  'it',\n",
       "  'but',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'there',\n",
       "  'is',\n",
       "  'any',\n",
       "  'reason',\n",
       "  'to',\n",
       "  'be',\n",
       "  'so',\n",
       "  'fatalistic',\n",
       "  'a',\n",
       "  'recent',\n",
       "  'paper',\n",
       "  'published',\n",
       "  'by',\n",
       "  'the',\n",
       "  'mit',\n",
       "  'task',\n",
       "  'force',\n",
       "  'on',\n",
       "  'the',\n",
       "  'work',\n",
       "  'of',\n",
       "  'the',\n",
       "  'future',\n",
       "  'entitled',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work',\n",
       "  'looked',\n",
       "  'closely',\n",
       "  'at',\n",
       "  'developments',\n",
       "  'in',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'their',\n",
       "  'relation',\n",
       "  'to',\n",
       "  'the',\n",
       "  'world',\n",
       "  'of',\n",
       "  'work',\n",
       "  'the',\n",
       "  'paper',\n",
       "  'paints',\n",
       "  'a',\n",
       "  'more',\n",
       "  'optimistic',\n",
       "  'picture',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'promoting',\n",
       "  'the',\n",
       "  'obsolescence',\n",
       "  'of',\n",
       "  'human',\n",
       "  'labor',\n",
       "  'the',\n",
       "  'paper',\n",
       "  'predicts',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'drive',\n",
       "  'massive',\n",
       "  'innovation',\n",
       "  'that',\n",
       "  'will',\n",
       "  'fuel',\n",
       "  'many',\n",
       "  'existing',\n",
       "  'industries',\n",
       "  'and',\n",
       "  'could',\n",
       "  'have',\n",
       "  'the',\n",
       "  'potential',\n",
       "  'to',\n",
       "  'create',\n",
       "  'many',\n",
       "  'new',\n",
       "  'sectors',\n",
       "  'for',\n",
       "  'growth',\n",
       "  'ultimately',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'the',\n",
       "  'creation',\n",
       "  'of',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'while',\n",
       "  'ai',\n",
       "  'has',\n",
       "  'made',\n",
       "  'major',\n",
       "  'strides',\n",
       "  'toward',\n",
       "  'replicating',\n",
       "  'the',\n",
       "  'efficacy',\n",
       "  'of',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'in',\n",
       "  'executing',\n",
       "  'certain',\n",
       "  'tasks',\n",
       "  'there',\n",
       "  'are',\n",
       "  'still',\n",
       "  'major',\n",
       "  'limitations',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'ai',\n",
       "  'programs',\n",
       "  'are',\n",
       "  'typically',\n",
       "  'only',\n",
       "  'capable',\n",
       "  'of',\n",
       "  'specialized',\n",
       "  'intelligence',\n",
       "  'meaning',\n",
       "  'they',\n",
       "  'can',\n",
       "  'solve',\n",
       "  'only',\n",
       "  'one',\n",
       "  'problem',\n",
       "  'and',\n",
       "  'execute',\n",
       "  'only',\n",
       "  'one',\n",
       "  'task',\n",
       "  'at',\n",
       "  'a',\n",
       "  'time',\n",
       "  'often',\n",
       "  'they',\n",
       "  'can',\n",
       "  'be',\n",
       "  'rigid',\n",
       "  'and',\n",
       "  'unable',\n",
       "  'to',\n",
       "  'respond',\n",
       "  'to',\n",
       "  'any',\n",
       "  'changes',\n",
       "  'in',\n",
       "  'input',\n",
       "  'or',\n",
       "  'perform',\n",
       "  'any',\n",
       "  'thinking',\n",
       "  'outside',\n",
       "  'of',\n",
       "  'their',\n",
       "  'prescribed',\n",
       "  'programming',\n",
       "  'humans',\n",
       "  'however',\n",
       "  'possess',\n",
       "  'generalized',\n",
       "  'intelligence',\n",
       "  'with',\n",
       "  'the',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'problemsolving',\n",
       "  'abstract',\n",
       "  'thinking',\n",
       "  'and',\n",
       "  'critical',\n",
       "  'judgment',\n",
       "  'that',\n",
       "  'will',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'be',\n",
       "  'important',\n",
       "  'in',\n",
       "  'business',\n",
       "  'human',\n",
       "  'judgment',\n",
       "  'will',\n",
       "  'be',\n",
       "  'relevant',\n",
       "  'if',\n",
       "  'not',\n",
       "  'in',\n",
       "  'every',\n",
       "  'task',\n",
       "  'then',\n",
       "  'certainly',\n",
       "  'throughout',\n",
       "  'every',\n",
       "  'level',\n",
       "  'across',\n",
       "  'all',\n",
       "  'sectors',\n",
       "  'there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'other',\n",
       "  'factors',\n",
       "  'that',\n",
       "  'could',\n",
       "  'limit',\n",
       "  'runaway',\n",
       "  'advancement',\n",
       "  'in',\n",
       "  'ai',\n",
       "  'ai',\n",
       "  'often',\n",
       "  'requires',\n",
       "  'learning',\n",
       "  'which',\n",
       "  'can',\n",
       "  'involve',\n",
       "  'massive',\n",
       "  'amounts',\n",
       "  'of',\n",
       "  'data',\n",
       "  'calling',\n",
       "  'into',\n",
       "  'question',\n",
       "  'the',\n",
       "  'availability',\n",
       "  'of',\n",
       "  'the',\n",
       "  'right',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'data',\n",
       "  'and',\n",
       "  'highlighting',\n",
       "  'the',\n",
       "  'need',\n",
       "  'for',\n",
       "  'categorization',\n",
       "  'and',\n",
       "  'issues',\n",
       "  'of',\n",
       "  'privacy',\n",
       "  'and',\n",
       "  'security',\n",
       "  'around',\n",
       "  'such',\n",
       "  'data',\n",
       "  'there',\n",
       "  'is',\n",
       "  'also',\n",
       "  'the',\n",
       "  'limitation',\n",
       "  'of',\n",
       "  'computation',\n",
       "  'and',\n",
       "  'processing',\n",
       "  'power',\n",
       "  'the',\n",
       "  'cost',\n",
       "  'of',\n",
       "  'electricity',\n",
       "  'alone',\n",
       "  'to',\n",
       "  'power',\n",
       "  'one',\n",
       "  'supercharged',\n",
       "  'language',\n",
       "  'model',\n",
       "  'ai',\n",
       "  'was',\n",
       "  'estimated',\n",
       "  'at',\n",
       "  '46',\n",
       "  'million',\n",
       "  'another',\n",
       "  'important',\n",
       "  'limitation',\n",
       "  'of',\n",
       "  'note',\n",
       "  'is',\n",
       "  'that',\n",
       "  'data',\n",
       "  'can',\n",
       "  'itself',\n",
       "  'carry',\n",
       "  'bias',\n",
       "  'and',\n",
       "  'be',\n",
       "  'reflective',\n",
       "  'of',\n",
       "  'societal',\n",
       "  'inequities',\n",
       "  'or',\n",
       "  'the',\n",
       "  'implicit',\n",
       "  'biases',\n",
       "  'of',\n",
       "  'the',\n",
       "  'designers',\n",
       "  'who',\n",
       "  'create',\n",
       "  'and',\n",
       "  'input',\n",
       "  'the',\n",
       "  'data',\n",
       "  'if',\n",
       "  'there',\n",
       "  'is',\n",
       "  'bias',\n",
       "  'in',\n",
       "  'the',\n",
       "  'data',\n",
       "  'that',\n",
       "  'is',\n",
       "  'inputted',\n",
       "  'into',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'this',\n",
       "  'bias',\n",
       "  'is',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'over',\n",
       "  'to',\n",
       "  'the',\n",
       "  'results',\n",
       "  'generated',\n",
       "  'by',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'there',\n",
       "  'has',\n",
       "  'even',\n",
       "  'been',\n",
       "  'a',\n",
       "  'bill',\n",
       "  'introduced',\n",
       "  'into',\n",
       "  'congress',\n",
       "  'entitled',\n",
       "  'the',\n",
       "  'algorithmic',\n",
       "  'accountability',\n",
       "  'act',\n",
       "  'with',\n",
       "  'the',\n",
       "  'goal',\n",
       "  'of',\n",
       "  'forcing',\n",
       "  'the',\n",
       "  'federal',\n",
       "  'trade',\n",
       "  'commission',\n",
       "  'to',\n",
       "  'investigate',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'any',\n",
       "  'new',\n",
       "  'ai',\n",
       "  'technology',\n",
       "  'for',\n",
       "  'the',\n",
       "  'potential',\n",
       "  'to',\n",
       "  'perpetuate',\n",
       "  'bias',\n",
       "  'based',\n",
       "  'on',\n",
       "  'these',\n",
       "  'factors',\n",
       "  'and',\n",
       "  'many',\n",
       "  'others',\n",
       "  'the',\n",
       "  'mit',\n",
       "  'cci',\n",
       "  'paper',\n",
       "  'argues',\n",
       "  'that',\n",
       "  'we',\n",
       "  'are',\n",
       "  'a',\n",
       "  'long',\n",
       "  'way',\n",
       "  'from',\n",
       "  'reaching',\n",
       "  'a',\n",
       "  'point',\n",
       "  'in',\n",
       "  'which',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'comparable',\n",
       "  'to',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'could',\n",
       "  'theoretically',\n",
       "  'replace',\n",
       "  'human',\n",
       "  'workers',\n",
       "  'entirely',\n",
       "  'provided',\n",
       "  'there',\n",
       "  'is',\n",
       "  'an',\n",
       "  'investment',\n",
       "  'at',\n",
       "  'all',\n",
       "  'levels',\n",
       "  'from',\n",
       "  'education',\n",
       "  'to',\n",
       "  'the',\n",
       "  'private',\n",
       "  'sector',\n",
       "  'and',\n",
       "  'governmental',\n",
       "  'organizationsanywhere',\n",
       "  'that',\n",
       "  'focuses',\n",
       "  'on',\n",
       "  'training',\n",
       "  'and',\n",
       "  'upskilling',\n",
       "  'workersai',\n",
       "  'has',\n",
       "  'the',\n",
       "  'potential',\n",
       "  'to',\n",
       "  'ultimately',\n",
       "  'create',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'not',\n",
       "  'less',\n",
       "  'the',\n",
       "  'question',\n",
       "  'should',\n",
       "  'then',\n",
       "  'become',\n",
       "  'not',\n",
       "  'humans',\n",
       "  'or',\n",
       "  'computers',\n",
       "  'but',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'computers',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'complex',\n",
       "  'systems',\n",
       "  'that',\n",
       "  'advance',\n",
       "  'industry',\n",
       "  'and',\n",
       "  'prosperity',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'is',\n",
       "  'a',\n",
       "  'fascinating',\n",
       "  'read',\n",
       "  'for',\n",
       "  'anyone',\n",
       "  'hoping',\n",
       "  'to',\n",
       "  'dive',\n",
       "  'deeper',\n",
       "  'into',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'the',\n",
       "  'many',\n",
       "  'potential',\n",
       "  'directions',\n",
       "  'in',\n",
       "  'which',\n",
       "  'it',\n",
       "  'may',\n",
       "  'leadai',\n",
       "  'is',\n",
       "  'becoming',\n",
       "  'standard',\n",
       "  'in',\n",
       "  'all',\n",
       "  'businesses',\n",
       "  'not',\n",
       "  'just',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'of',\n",
       "  'tech',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'times',\n",
       "  'recently',\n",
       "  'ai',\n",
       "  'has',\n",
       "  'come',\n",
       "  'up',\n",
       "  'in',\n",
       "  'conversation',\n",
       "  'with',\n",
       "  'a',\n",
       "  ...]]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/46.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "b24f2ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2146\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "c586574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 1343\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "38dd42e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 24.976744186046513\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "37783716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3574087862993299\n",
      "FOG INDEX: 10.133661188938339\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 24.976744186046513\n",
      "COMPLEX WORD COUNT: 480\n",
      "WORD COUNT: 1343\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "a9423cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 4054\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "90f70321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 8\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 6\n",
      "Total count: 14\n",
      "PERSONAL PRONOUNS: 14\n",
      "AVG WORD LENGTH: 5.046554934823091\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_41.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50559ce",
   "metadata": {},
   "source": [
    "# 11. URL 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "e59c29bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\2393847097.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "a1202904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before the internet, information was in some ways restricted and more centralized. The only mediums of information were books, newspapers, and word of mouth, etc. But now with the advent of the internet and improvements to computer technology (Moore’s Law), information and data skyrocketed, and it has become this open-system, where information can be distributed to people without any kind of limits.',\n",
       " 'Various publicly available tools have taken the rocket science out of encrypting (and decrypting) email and files. Data encryption isn’t just for technology geeks; modern tools make it possible for anyone to encrypt emails and other information. “Encryption used to be the sole province of geeks and mathematicians, but a lot has changed in recent years. In particular, various publicly available tools have taken the rocket science out of encrypting (and decrypting) email and files. GPG for Mail, for example, is an open-source plug-in for the Apple Mail program that makes it easy to encrypt, decrypt, sign and verify emails using the OpenPGP standard. And for protecting files, newer versions of Apple’s OS X operating system come with FileVault, a program that encrypts the hard drive of a computer. Those running Microsoft Windows have a similar program. This software will scramble your data, but won’t protect you from government authorities demanding your encryption key under the Regulation of Investigatory Powers Act (2000), which is why some aficionados recommend TrueCrypt, a program with some very interesting facilities, which might have been useful to David Miranda,” explains John Naughton in an article for The Guardian.',\n",
       " 'One of the most basic, yet often overlooked, data protection tips is backing up your data. Basically, this creates a duplicate copy of your data so that if a device is lost, stolen, or compromised, you don’t also lose your important information. As the U.S. Chamber of Commerce and insurance company Nationwide points out, “According to Nationwide, 68% of small businesses don’t have a disaster recovery plan. The problem with this is the longer it takes you to restore your data, the more money you’ll lose. Gartner found that this downtime can cost companies as much as $300,000 an hour.”',\n",
       " 'While you should use sound security practices when you’re making use of the cloud, it can provide an ideal solution for backing up your data. Since data is not stored on a local device, it’s easily accessible even when your hardware becomes compromised. “Cloud storage, where data is kept offsite by a provider, is a guarantee of adequate disaster recovery,” according to this post on TechRadar. Twitter: @techradar',\n",
       " 'Scammers are sneaky: sometimes malware is cleverly disguised as an email from a friend or a useful website. Malware is a serious issue plaguing many computer users, and it’s known for cropping up in inconspicuous places, unbeknownst to users. Anti-malware protection is essential for laying a foundation of security for your devices. “Malware (short for malicious software) is software designed to infiltrate or damage a computer without your consent. Malware includes computer viruses, worms, trojan horses, spyware, scareware, and more. It can be present on websites and emails or hidden in downloadable files, photos, videos, freeware, or shareware. (However, it should be noted that most websites, shareware, or freeware applications do not come with malware.) The best way to avoid getting infected is to run a good anti-virus protection program, do periodic scans for spyware, avoid clicking on suspicious email links or websites. But scammers are sneaky: sometimes malware is cleverly disguised as an email from a friend or a useful website. Even the most cautious of web-surfers will likely pick up an infection at some point.,” explains Clark Howard. Twitter: @ClarkHoward',\n",
       " 'Much information can be gleaned through old computing devices, but you can protect your personal data by making hard drives unreadable before disposing of them. “Make old computers’ hard drives unreadable. After you back up your data and transfer the files elsewhere, you should sanitize by disk shredding, magnetically cleaning the disk, or using software to wipe the disk clean. Destroy old computer disks and backup tapes,” according to the Florida Office of the Attorney General. Twitter: @AGPamBondi',\n",
       " 'Operating system updates are a gigantic pain for users; it’s the honest truth. But they’re a necessary evil, as these updates contain critical security patches that will protect your computer from recently discovered threats. Failing to install these updates means your computer is at risk. “No matter which operating system you use, it’s important that you update it regularly. Windows operating systems are typically updated at least monthly, typically on so-called ‘Patch Tuesday.’ Other operating systems may not be updated quite as frequently or on a regular schedule. It’s best to set your operating system to update automatically. The method for doing so will vary depending upon your particular operating system,” says PrivacyRights.org. Twitter: @PrivacyToday',\n",
       " 'Many software programs will automatically connect and update to defend against known risks.',\n",
       " 'In order to ensure that you’re downloading the latest security updates from operating systems and other software, enable automatic updates. “Many software programs will automatically connect and update to defend against known risks. Turn on automatic updates if that’s an available option,” suggests StaySafeOnline.org. Twitter: @StaySafeOnline',\n",
       " 'A valuable tip for both small business owners and individuals or families, it’s always recommended to secure your wireless network with a password. This prevents unauthorized individuals within proximity to hijack your wireless network. Even if they’re merely attempting to get free Wi-Fi access, you don’t want to inadvertently share private information with other people who are using your network without permission. “If you have a Wi-Fi network for your workplace, make sure it is secure, encrypted, and hidden. To hide your Wi-Fi network, set up your wireless access point or router so it does not broadcast the network name, known as the Service Set Identifier (SSID). Password protect access to the router,” says FCC.gov in an article offering data protection tips for small businesses. Twitter: @FCC',\n",
       " 'When you’re finished using your computer or laptop, power it off. Leaving computing devices on, and most often, connected to the Internet, opens the door for rogue attacks. “Leaving your computer connected to the Internet when it’s not in use gives scammers 24/7 access to install malware and commit cybercrimes. To be safe, turn off your computer when it’s not in use,” suggests CSID, a division of Experian. Twitter: @ExperianPS_NA',\n",
       " '',\n",
       " 'Firewalls assist in blocking dangerous programs, viruses, or spyware before they infiltrate your system.”Firewalls assist in blocking dangerous programs, viruses, or spyware before they infiltrate your system. Various software companies offer firewall protection, but hardware-based firewalls, like those frequently built into network routers, provide a better level of security,” says Geek Squad. Twitter: @GeekSquad',\n",
       " 'Indiana University Information Technology recommends following the Principle of Least Privilege (PoLP): “Do not log into a computer with administrator rights unless you must do so to perform specific tasks. Running your computer as an administrator (or as a Power User in Windows) leaves your computer vulnerable to security risks and exploits. Simply visiting an unfamiliar Internet site with these high-privilege accounts can cause extreme damage to your computer, such as reformatting your hard drive, deleting all your files, and creating a new user account with administrative access. When you do need to perform tasks as an administrator, always follow security procedures.” Twitter: @IndianaUniv',\n",
       " 'What’s the difference? “…we recommend you use passphrases–a series of random words or a sentence. The more characters your passphrase has, the stronger it is.  The advantage is these are much easier to remember and type, but still hard for cyber attackers to hack.” explains SANS. Twitter: @SANSAwareness',\n",
       " 'Encrypt your SIM card in case your phone is ever stolen, or take it out if you are selling your old cell phone. Encrypting your data on your removable storage devices can make it more difficult (albeit not impossible) for criminals to interpret your personal data should your device become lost or stolen. USB drives and SIM cards are excellent examples of removable storage devices that can simply be plugged into another device, enabling the user to access all the data stored on it. Unless, of course, it’s encrypted. “Your USB drive could easily be stolen and put into another computer, where they can steal all of your files and even install malware or viruses onto your flash drive that will infect any computer it is plugged in to. Encrypt your SIM card in case your phone is ever stolen, or take it out if you are selling your old cell phone,” according to Mike Juba in an article on Business2Community. Twitter: @EZSolutionCorp',\n",
       " 'A Post-It note stuck to the outside of your laptop or tablet is “akin to leaving your keys in your car,” says The Ohio State University’s Office of the Chief Information Officer. Likewise, you shouldn’t leave your laptop in your car. It’s a magnet for identity thieves. Twitter: @OhioState',\n",
       " '',\n",
       " 'If you don’t really need your files to be visible to other machines, disable file and media sharing completely. If you have a home wireless network with multiple devices connected, you might find it convenient to share files between machines. However, there’s no reason to make files publicly available if it’s not necessary. “Make sure that you share some of your folders only on the home network. If you don’t really need your files to be visible to other machines, disable file and media sharing completely,” says Kaspersky. Twitter: @kaspersky',\n",
       " 'HowToGeek offers a series of articles with tips, tricks, and tools for encrypting files or sets of files using various programs and tools. This article covers a method for creating an encrypted volume to easily transport private, sensitive data for access on multiple computers. Twitter: @howtogeeksite',\n",
       " 'Deleting your information on a computing device rarely means it’s truly deleted permanently. Often, this data still exists on disk and can be recovered by someone who knows what they’re doing (such as, say, a savvy criminal determined to find your personal information). The only way to really ensure that your old data is gone forever is to overwrite it. Luckily, there are tools to streamline this process. PCWorld covers a tool and process for overwriting old data on Windows operating systems. Twitter: @pcworld',\n",
       " 'If you back up your files to the cloud, remember that even though you delete them on your computer or mobile device, they’re still stored in your cloud account. If you’re diligent about backing up your data and use a secure cloud storage service to do so, you’re headed in the right direction. That said, cloud backups, and any data backups really, create an added step when it comes to deleting old information. Don’t forget to delete files from your backup services in addition to those you remove (or overwrite) on your local devices. “If you back up your files to the cloud, remember that even though you delete them on your computer or mobile device, they’re still stored in your cloud account. To completely delete the file, you’ll also need to remove it from your backup cloud account,” says re/code. Twitter: @Recode']"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "604bdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:38]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "5ec14abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ID_47 = \" \".join((titles, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "372528bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "3fd010be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 115 sentences in the string.\n",
      "The number of words in the string is: 1949\n",
      "The number of characters in the string is: 10424\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_47.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_47.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_47.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "7877861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 21:23:31] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 21:23:39] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_47 = re.sub(re_punt, \"\",URL_ID_47)\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"47.txt\", \"w\")\n",
    "file.write(URL_ID_47)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"47.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "77babce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['securing',\n",
       "  'your',\n",
       "  'devices',\n",
       "  'and',\n",
       "  'networks',\n",
       "  'encrypt',\n",
       "  'your',\n",
       "  'data',\n",
       "  'backup',\n",
       "  'your',\n",
       "  'data',\n",
       "  'the',\n",
       "  'cloud',\n",
       "  'provides',\n",
       "  'a',\n",
       "  'viable',\n",
       "  'backup',\n",
       "  'option',\n",
       "  'antimalware',\n",
       "  'protection',\n",
       "  'is',\n",
       "  'a',\n",
       "  'must',\n",
       "  'make',\n",
       "  'your',\n",
       "  'old',\n",
       "  'computers',\n",
       "  'hard',\n",
       "  'drives',\n",
       "  'unreadable',\n",
       "  'install',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'updates',\n",
       "  'automate',\n",
       "  'your',\n",
       "  'software',\n",
       "  'updates',\n",
       "  'secure',\n",
       "  'your',\n",
       "  'wireless',\n",
       "  'network',\n",
       "  'at',\n",
       "  'your',\n",
       "  'home',\n",
       "  'or',\n",
       "  'business',\n",
       "  'turn',\n",
       "  'off',\n",
       "  'your',\n",
       "  'computer',\n",
       "  'use',\n",
       "  'a',\n",
       "  'firewall',\n",
       "  'practice',\n",
       "  'the',\n",
       "  'principle',\n",
       "  'of',\n",
       "  'least',\n",
       "  'privilege',\n",
       "  'polp',\n",
       "  'use',\n",
       "  'passphrases',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'passwords',\n",
       "  'encrypt',\n",
       "  'data',\n",
       "  'on',\n",
       "  'your',\n",
       "  'usb',\n",
       "  'drives',\n",
       "  'and',\n",
       "  'sim',\n",
       "  'cards',\n",
       "  'dont',\n",
       "  'store',\n",
       "  'passwords',\n",
       "  'with',\n",
       "  'your',\n",
       "  'laptop',\n",
       "  'or',\n",
       "  'mobile',\n",
       "  'device',\n",
       "  'disable',\n",
       "  'file',\n",
       "  'and',\n",
       "  'media',\n",
       "  'sharing',\n",
       "  'if',\n",
       "  'you',\n",
       "  'dont',\n",
       "  'need',\n",
       "  'it',\n",
       "  'create',\n",
       "  'encrypted',\n",
       "  'volumes',\n",
       "  'for',\n",
       "  'portable',\n",
       "  'private',\n",
       "  'data',\n",
       "  'files',\n",
       "  'overwrite',\n",
       "  'deleted',\n",
       "  'files',\n",
       "  'dont',\n",
       "  'forget',\n",
       "  'to',\n",
       "  'delete',\n",
       "  'old',\n",
       "  'files',\n",
       "  'from',\n",
       "  'cloud',\n",
       "  'backups',\n",
       "  'before',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'information',\n",
       "  'was',\n",
       "  'in',\n",
       "  'some',\n",
       "  'ways',\n",
       "  'restricted',\n",
       "  'and',\n",
       "  'more',\n",
       "  'centralized',\n",
       "  'the',\n",
       "  'only',\n",
       "  'mediums',\n",
       "  'of',\n",
       "  'information',\n",
       "  'were',\n",
       "  'books',\n",
       "  'newspapers',\n",
       "  'and',\n",
       "  'word',\n",
       "  'of',\n",
       "  'mouth',\n",
       "  'etc',\n",
       "  'but',\n",
       "  'now',\n",
       "  'with',\n",
       "  'the',\n",
       "  'advent',\n",
       "  'of',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'and',\n",
       "  'improvements',\n",
       "  'to',\n",
       "  'computer',\n",
       "  'technology',\n",
       "  'moores',\n",
       "  'law',\n",
       "  'information',\n",
       "  'and',\n",
       "  'data',\n",
       "  'skyrocketed',\n",
       "  'and',\n",
       "  'it',\n",
       "  'has',\n",
       "  'become',\n",
       "  'this',\n",
       "  'opensystem',\n",
       "  'where',\n",
       "  'information',\n",
       "  'can',\n",
       "  'be',\n",
       "  'distributed',\n",
       "  'to',\n",
       "  'people',\n",
       "  'without',\n",
       "  'any',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'limits',\n",
       "  'various',\n",
       "  'publicly',\n",
       "  'available',\n",
       "  'tools',\n",
       "  'have',\n",
       "  'taken',\n",
       "  'the',\n",
       "  'rocket',\n",
       "  'science',\n",
       "  'out',\n",
       "  'of',\n",
       "  'encrypting',\n",
       "  'and',\n",
       "  'decrypting',\n",
       "  'email',\n",
       "  'and',\n",
       "  'files',\n",
       "  'data',\n",
       "  'encryption',\n",
       "  'isnt',\n",
       "  'just',\n",
       "  'for',\n",
       "  'technology',\n",
       "  'geeks',\n",
       "  'modern',\n",
       "  'tools',\n",
       "  'make',\n",
       "  'it',\n",
       "  'possible',\n",
       "  'for',\n",
       "  'anyone',\n",
       "  'to',\n",
       "  'encrypt',\n",
       "  'emails',\n",
       "  'and',\n",
       "  'other',\n",
       "  'information',\n",
       "  'encryption',\n",
       "  'used',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'sole',\n",
       "  'province',\n",
       "  'of',\n",
       "  'geeks',\n",
       "  'and',\n",
       "  'mathematicians',\n",
       "  'but',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'has',\n",
       "  'changed',\n",
       "  'in',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'various',\n",
       "  'publicly',\n",
       "  'available',\n",
       "  'tools',\n",
       "  'have',\n",
       "  'taken',\n",
       "  'the',\n",
       "  'rocket',\n",
       "  'science',\n",
       "  'out',\n",
       "  'of',\n",
       "  'encrypting',\n",
       "  'and',\n",
       "  'decrypting',\n",
       "  'email',\n",
       "  'and',\n",
       "  'files',\n",
       "  'gpg',\n",
       "  'for',\n",
       "  'mail',\n",
       "  'for',\n",
       "  'example',\n",
       "  'is',\n",
       "  'an',\n",
       "  'opensource',\n",
       "  'plugin',\n",
       "  'for',\n",
       "  'the',\n",
       "  'apple',\n",
       "  'mail',\n",
       "  'program',\n",
       "  'that',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'encrypt',\n",
       "  'decrypt',\n",
       "  'sign',\n",
       "  'and',\n",
       "  'verify',\n",
       "  'emails',\n",
       "  'using',\n",
       "  'the',\n",
       "  'openpgp',\n",
       "  'standard',\n",
       "  'and',\n",
       "  'for',\n",
       "  'protecting',\n",
       "  'files',\n",
       "  'newer',\n",
       "  'versions',\n",
       "  'of',\n",
       "  'apples',\n",
       "  'os',\n",
       "  'x',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'come',\n",
       "  'with',\n",
       "  'filevault',\n",
       "  'a',\n",
       "  'program',\n",
       "  'that',\n",
       "  'encrypts',\n",
       "  'the',\n",
       "  'hard',\n",
       "  'drive',\n",
       "  'of',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'those',\n",
       "  'running',\n",
       "  'microsoft',\n",
       "  'windows',\n",
       "  'have',\n",
       "  'a',\n",
       "  'similar',\n",
       "  'program',\n",
       "  'this',\n",
       "  'software',\n",
       "  'will',\n",
       "  'scramble',\n",
       "  'your',\n",
       "  'data',\n",
       "  'but',\n",
       "  'wont',\n",
       "  'protect',\n",
       "  'you',\n",
       "  'from',\n",
       "  'government',\n",
       "  'authorities',\n",
       "  'demanding',\n",
       "  'your',\n",
       "  'encryption',\n",
       "  'key',\n",
       "  'under',\n",
       "  'the',\n",
       "  'regulation',\n",
       "  'of',\n",
       "  'investigatory',\n",
       "  'powers',\n",
       "  'act',\n",
       "  '2000',\n",
       "  'which',\n",
       "  'is',\n",
       "  'why',\n",
       "  'some',\n",
       "  'aficionados',\n",
       "  'recommend',\n",
       "  'truecrypt',\n",
       "  'a',\n",
       "  'program',\n",
       "  'with',\n",
       "  'some',\n",
       "  'very',\n",
       "  'interesting',\n",
       "  'facilities',\n",
       "  'which',\n",
       "  'might',\n",
       "  'have',\n",
       "  'been',\n",
       "  'useful',\n",
       "  'to',\n",
       "  'david',\n",
       "  'miranda',\n",
       "  'explains',\n",
       "  'john',\n",
       "  'naughton',\n",
       "  'in',\n",
       "  'an',\n",
       "  'article',\n",
       "  'for',\n",
       "  'the',\n",
       "  'guardian',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'basic',\n",
       "  'yet',\n",
       "  'often',\n",
       "  'overlooked',\n",
       "  'data',\n",
       "  'protection',\n",
       "  'tips',\n",
       "  'is',\n",
       "  'backing',\n",
       "  'up',\n",
       "  'your',\n",
       "  'data',\n",
       "  'basically',\n",
       "  'this',\n",
       "  'creates',\n",
       "  'a',\n",
       "  'duplicate',\n",
       "  'copy',\n",
       "  'of',\n",
       "  'your',\n",
       "  'data',\n",
       "  'so',\n",
       "  'that',\n",
       "  'if',\n",
       "  'a',\n",
       "  'device',\n",
       "  'is',\n",
       "  'lost',\n",
       "  'stolen',\n",
       "  'or',\n",
       "  'compromised',\n",
       "  'you',\n",
       "  'dont',\n",
       "  'also',\n",
       "  'lose',\n",
       "  'your',\n",
       "  'important',\n",
       "  'information',\n",
       "  'as',\n",
       "  'the',\n",
       "  'us',\n",
       "  'chamber',\n",
       "  'of',\n",
       "  'commerce',\n",
       "  'and',\n",
       "  'insurance',\n",
       "  'company',\n",
       "  'nationwide',\n",
       "  'points',\n",
       "  'out',\n",
       "  'according',\n",
       "  'to',\n",
       "  'nationwide',\n",
       "  '68',\n",
       "  'of',\n",
       "  'small',\n",
       "  'businesses',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'a',\n",
       "  'disaster',\n",
       "  'recovery',\n",
       "  'plan',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'with',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'longer',\n",
       "  'it',\n",
       "  'takes',\n",
       "  'you',\n",
       "  'to',\n",
       "  'restore',\n",
       "  'your',\n",
       "  'data',\n",
       "  'the',\n",
       "  'more',\n",
       "  'money',\n",
       "  'youll',\n",
       "  'lose',\n",
       "  'gartner',\n",
       "  'found',\n",
       "  'that',\n",
       "  'this',\n",
       "  'downtime',\n",
       "  'can',\n",
       "  'cost',\n",
       "  'companies',\n",
       "  'as',\n",
       "  'much',\n",
       "  'as',\n",
       "  '300000',\n",
       "  'an',\n",
       "  'hour',\n",
       "  'while',\n",
       "  'you',\n",
       "  'should',\n",
       "  'use',\n",
       "  'sound',\n",
       "  'security',\n",
       "  'practices',\n",
       "  'when',\n",
       "  'youre',\n",
       "  'making',\n",
       "  'use',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cloud',\n",
       "  'it',\n",
       "  'can',\n",
       "  'provide',\n",
       "  'an',\n",
       "  'ideal',\n",
       "  'solution',\n",
       "  'for',\n",
       "  'backing',\n",
       "  'up',\n",
       "  'your',\n",
       "  'data',\n",
       "  'since',\n",
       "  'data',\n",
       "  'is',\n",
       "  'not',\n",
       "  'stored',\n",
       "  'on',\n",
       "  'a',\n",
       "  'local',\n",
       "  'device',\n",
       "  'its',\n",
       "  'easily',\n",
       "  'accessible',\n",
       "  'even',\n",
       "  'when',\n",
       "  'your',\n",
       "  'hardware',\n",
       "  'becomes',\n",
       "  'compromised',\n",
       "  'cloud',\n",
       "  'storage',\n",
       "  'where',\n",
       "  'data',\n",
       "  'is',\n",
       "  'kept',\n",
       "  'offsite',\n",
       "  'by',\n",
       "  'a',\n",
       "  'provider',\n",
       "  'is',\n",
       "  'a',\n",
       "  'guarantee',\n",
       "  'of',\n",
       "  'adequate',\n",
       "  'disaster',\n",
       "  'recovery',\n",
       "  'according',\n",
       "  'to',\n",
       "  'this',\n",
       "  'post',\n",
       "  'on',\n",
       "  'techradar',\n",
       "  'twitter',\n",
       "  'techradar',\n",
       "  'scammers',\n",
       "  'are',\n",
       "  'sneaky',\n",
       "  'sometimes',\n",
       "  'malware',\n",
       "  'is',\n",
       "  'cleverly',\n",
       "  'disguised',\n",
       "  'as',\n",
       "  'an',\n",
       "  'email',\n",
       "  'from',\n",
       "  'a',\n",
       "  'friend',\n",
       "  'or',\n",
       "  'a',\n",
       "  'useful',\n",
       "  'website',\n",
       "  'malware',\n",
       "  'is',\n",
       "  'a',\n",
       "  'serious',\n",
       "  'issue',\n",
       "  'plaguing',\n",
       "  'many',\n",
       "  'computer',\n",
       "  'users',\n",
       "  'and',\n",
       "  'its',\n",
       "  'known',\n",
       "  'for',\n",
       "  'cropping',\n",
       "  'up',\n",
       "  'in',\n",
       "  'inconspicuous',\n",
       "  'places',\n",
       "  'unbeknownst',\n",
       "  'to',\n",
       "  'users',\n",
       "  'antimalware',\n",
       "  'protection',\n",
       "  'is',\n",
       "  'essential',\n",
       "  'for',\n",
       "  'laying',\n",
       "  'a',\n",
       "  'foundation',\n",
       "  'of',\n",
       "  'security',\n",
       "  'for',\n",
       "  'your',\n",
       "  'devices',\n",
       "  'malware',\n",
       "  'short',\n",
       "  'for',\n",
       "  'malicious',\n",
       "  'software',\n",
       "  'is',\n",
       "  'software',\n",
       "  'designed',\n",
       "  'to',\n",
       "  'infiltrate',\n",
       "  'or',\n",
       "  'damage',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'without',\n",
       "  'your',\n",
       "  'consent',\n",
       "  'malware',\n",
       "  'includes',\n",
       "  'computer',\n",
       "  'viruses',\n",
       "  'worms',\n",
       "  'trojan',\n",
       "  'horses',\n",
       "  'spyware',\n",
       "  'scareware',\n",
       "  'and',\n",
       "  'more',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'present',\n",
       "  'on',\n",
       "  'websites',\n",
       "  'and',\n",
       "  'emails',\n",
       "  'or',\n",
       "  'hidden',\n",
       "  'in',\n",
       "  'downloadable',\n",
       "  'files',\n",
       "  'photos',\n",
       "  'videos',\n",
       "  'freeware',\n",
       "  'or',\n",
       "  'shareware',\n",
       "  'however',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'noted',\n",
       "  'that',\n",
       "  'most',\n",
       "  'websites',\n",
       "  'shareware',\n",
       "  'or',\n",
       "  'freeware',\n",
       "  'applications',\n",
       "  'do',\n",
       "  'not',\n",
       "  'come',\n",
       "  'with',\n",
       "  'malware',\n",
       "  'the',\n",
       "  'best',\n",
       "  'way',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'getting',\n",
       "  'infected',\n",
       "  'is',\n",
       "  'to',\n",
       "  'run',\n",
       "  'a',\n",
       "  'good',\n",
       "  'antivirus',\n",
       "  'protection',\n",
       "  'program',\n",
       "  'do',\n",
       "  'periodic',\n",
       "  'scans',\n",
       "  'for',\n",
       "  'spyware',\n",
       "  'avoid',\n",
       "  'clicking',\n",
       "  'on',\n",
       "  'suspicious',\n",
       "  'email',\n",
       "  'links',\n",
       "  'or',\n",
       "  'websites',\n",
       "  'but',\n",
       "  'scammers',\n",
       "  'are',\n",
       "  'sneaky',\n",
       "  'sometimes',\n",
       "  'malware',\n",
       "  'is',\n",
       "  'cleverly',\n",
       "  'disguised',\n",
       "  'as',\n",
       "  'an',\n",
       "  'email',\n",
       "  'from',\n",
       "  'a',\n",
       "  'friend',\n",
       "  'or',\n",
       "  'a',\n",
       "  'useful',\n",
       "  'website',\n",
       "  'even',\n",
       "  'the',\n",
       "  'most',\n",
       "  'cautious',\n",
       "  'of',\n",
       "  'websurfers',\n",
       "  'will',\n",
       "  'likely',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'an',\n",
       "  'infection',\n",
       "  'at',\n",
       "  'some',\n",
       "  'point',\n",
       "  'explains',\n",
       "  'clark',\n",
       "  'howard',\n",
       "  'twitter',\n",
       "  'clarkhoward',\n",
       "  'much',\n",
       "  'information',\n",
       "  'can',\n",
       "  'be',\n",
       "  'gleaned',\n",
       "  'through',\n",
       "  'old',\n",
       "  'computing',\n",
       "  'devices',\n",
       "  'but',\n",
       "  'you',\n",
       "  'can',\n",
       "  'protect',\n",
       "  'your',\n",
       "  'personal',\n",
       "  'data',\n",
       "  'by',\n",
       "  'making',\n",
       "  'hard',\n",
       "  'drives',\n",
       "  'unreadable',\n",
       "  'before',\n",
       "  'disposing',\n",
       "  'of',\n",
       "  'them',\n",
       "  'make',\n",
       "  'old',\n",
       "  'computers',\n",
       "  'hard',\n",
       "  'drives',\n",
       "  'unreadable',\n",
       "  'after',\n",
       "  'you',\n",
       "  'back',\n",
       "  'up',\n",
       "  'your',\n",
       "  'data',\n",
       "  'and',\n",
       "  'transfer',\n",
       "  'the',\n",
       "  'files',\n",
       "  'elsewhere',\n",
       "  'you',\n",
       "  'should',\n",
       "  'sanitize',\n",
       "  'by',\n",
       "  'disk',\n",
       "  'shredding',\n",
       "  'magnetically',\n",
       "  'cleaning',\n",
       "  'the',\n",
       "  'disk',\n",
       "  'or',\n",
       "  'using',\n",
       "  'software',\n",
       "  'to',\n",
       "  'wipe',\n",
       "  'the',\n",
       "  'disk',\n",
       "  'clean',\n",
       "  'destroy',\n",
       "  'old',\n",
       "  'computer',\n",
       "  'disks',\n",
       "  'and',\n",
       "  'backup',\n",
       "  'tapes',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'florida',\n",
       "  'office',\n",
       "  'of',\n",
       "  'the',\n",
       "  'attorney',\n",
       "  'general',\n",
       "  'twitter',\n",
       "  'agpambondi',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'updates',\n",
       "  'are',\n",
       "  'a',\n",
       "  'gigantic',\n",
       "  'pain',\n",
       "  'for',\n",
       "  'users',\n",
       "  'its',\n",
       "  'the',\n",
       "  'honest',\n",
       "  'truth',\n",
       "  'but',\n",
       "  'theyre',\n",
       "  'a',\n",
       "  'necessary',\n",
       "  'evil',\n",
       "  'as',\n",
       "  'these',\n",
       "  'updates',\n",
       "  'contain',\n",
       "  'critical',\n",
       "  'security',\n",
       "  'patches',\n",
       "  'that',\n",
       "  'will',\n",
       "  'protect',\n",
       "  'your',\n",
       "  'computer',\n",
       "  'from',\n",
       "  'recently',\n",
       "  'discovered',\n",
       "  'threats',\n",
       "  'failing',\n",
       "  'to',\n",
       "  'install',\n",
       "  'these',\n",
       "  'updates',\n",
       "  'means',\n",
       "  'your',\n",
       "  'computer',\n",
       "  'is',\n",
       "  'at',\n",
       "  'risk',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'which',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'you',\n",
       "  'use',\n",
       "  'its',\n",
       "  'important',\n",
       "  'that',\n",
       "  'you',\n",
       "  'update',\n",
       "  'it',\n",
       "  'regularly',\n",
       "  'windows',\n",
       "  'operating',\n",
       "  'systems',\n",
       "  'are',\n",
       "  'typically',\n",
       "  'updated',\n",
       "  'at',\n",
       "  'least',\n",
       "  'monthly',\n",
       "  'typically',\n",
       "  'on',\n",
       "  'socalled',\n",
       "  'patch',\n",
       "  'tuesday',\n",
       "  'other',\n",
       "  'operating',\n",
       "  'systems',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'updated',\n",
       "  'quite',\n",
       "  'as',\n",
       "  'frequently',\n",
       "  'or',\n",
       "  'on',\n",
       "  'a',\n",
       "  'regular',\n",
       "  'schedule',\n",
       "  'its',\n",
       "  'best',\n",
       "  'to',\n",
       "  'set',\n",
       "  'your',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'to',\n",
       "  'update',\n",
       "  'automatically',\n",
       "  'the',\n",
       "  'method',\n",
       "  'for',\n",
       "  'doing',\n",
       "  'so',\n",
       "  'will',\n",
       "  'vary',\n",
       "  'depending',\n",
       "  'upon',\n",
       "  'your',\n",
       "  'particular',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'says',\n",
       "  'privacyrightsorg',\n",
       "  'twitter',\n",
       "  'privacytoday',\n",
       "  'many',\n",
       "  'software',\n",
       "  'programs',\n",
       "  'will',\n",
       "  'automatically',\n",
       "  'connect',\n",
       "  'and',\n",
       "  'update',\n",
       "  'to',\n",
       "  'defend',\n",
       "  'against',\n",
       "  'known',\n",
       "  'risks',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'that',\n",
       "  'youre',\n",
       "  'downloading',\n",
       "  'the',\n",
       "  'latest',\n",
       "  'security',\n",
       "  'updates',\n",
       "  'from',\n",
       "  'operating',\n",
       "  'systems',\n",
       "  'and',\n",
       "  'other',\n",
       "  'software',\n",
       "  'enable',\n",
       "  'automatic',\n",
       "  'updates',\n",
       "  'many',\n",
       "  'software',\n",
       "  'programs',\n",
       "  'will',\n",
       "  'automatically',\n",
       "  'connect',\n",
       "  'and',\n",
       "  'update',\n",
       "  'to',\n",
       "  'defend',\n",
       "  'against',\n",
       "  'known',\n",
       "  'risks',\n",
       "  'turn',\n",
       "  'on',\n",
       "  'automatic',\n",
       "  'updates',\n",
       "  'if',\n",
       "  'thats',\n",
       "  'an',\n",
       "  'available',\n",
       "  'option',\n",
       "  'suggests',\n",
       "  'staysafeonlineorg',\n",
       "  'twitter',\n",
       "  'staysafeonline',\n",
       "  'a',\n",
       "  'valuable',\n",
       "  'tip',\n",
       "  'for',\n",
       "  'both',\n",
       "  'small',\n",
       "  'business',\n",
       "  'owners',\n",
       "  'and',\n",
       "  'individuals',\n",
       "  'or',\n",
       "  'families',\n",
       "  'its',\n",
       "  'always',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'secure',\n",
       "  'your',\n",
       "  'wireless',\n",
       "  'network',\n",
       "  'with',\n",
       "  'a',\n",
       "  'password',\n",
       "  'this',\n",
       "  'prevents',\n",
       "  'unauthorized',\n",
       "  'individuals',\n",
       "  'within',\n",
       "  'proximity',\n",
       "  ...]]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/47.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "695a68b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "06465f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 1265\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "66a20e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 16.94782608695652\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "2b60e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3675889328063241\n",
      "FOG INDEX: 6.926166007905138\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 16.94782608695652\n",
      "COMPLEX WORD COUNT: 465\n",
      "WORD COUNT: 1265\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e1fca222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3749\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "c5929787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 1\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 2\n",
      "PERSONAL PRONOUNS: 2\n",
      "AVG WORD LENGTH: 5.348383786557209\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_47.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e54864",
   "metadata": {},
   "source": [
    "# 12.URL 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "15fc4f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_2440\\673972968.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "00062a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We all hear day in and day out that we amidst a technological revolution. But do we know what this really means?',\n",
       " 'Before we understand how its going to impact us, let us first discuss what these terms really mean.',\n",
       " 'A technological revolution simply means that we are in a period where better and newer technologies replace the others to get the job done faster and better. We are in an era with rapid innovations where machines are being compared to humans.',\n",
       " '',\n",
       " 'So, then what is Machine Learning?',\n",
       " 'Machine Learning is basically the application of artificial intelligence into electronic systems to enable them to learn and enhance themselves without being programmed by humans. It is the evolution and development of computer programs that can access data and then use it to advance themselves. Whether you know it or not, you use machine learning-powered applications daily.',\n",
       " 'Now, what is Artificial intelligence?',\n",
       " 'At its simplest form, artificial intelligence is a field, which combines computer science and robust datasets, to enable problem-solving. ',\n",
       " 'In simple words, Artificial Intelligence is the technology that facilitates these machines to perform human like behaviour.',\n",
       " 'Just like every other industry, machine learning is playing its role in the finance and banking industry too. In most cases where a human would perform the same task by performing the same calculations or following the same process can be taught to the machine which can now perform it by itself.',\n",
       " 'Let us discuss a few examples of the applications that we might have come in our day to day running which are a result of machine learning in this industry:',\n",
       " 'Portfolio Management',\n",
       " 'In earlier days, an investor would need to consult a financial advisor to understand his/her risk appetite and advise accordingly. Today, using machine learning algorithms there exists the concept of a “Robo-Advisor” that requires any user to give certain inputs about their financial status and goals and calculates their risk tolerance and constructs and idle portfolio allocation for them. Young users today find this extremely useful rather than physically visiting an advisor and paying a fee for doing so.',\n",
       " 'Risk Underwriting',\n",
       " 'Underwriting is one of the core functions for most financial institutions especially banks and insurance companies where they are required to underwrite the risk of the customers before loaning out money or insurance policies. These underwriting activities are based on trends and thumb rules industrywide. The same has been introduced through machine learning which is able to underwrite risks today on a larger and more accurate scale.',\n",
       " 'Algorithmic Trading',\n",
       " 'Machine learning is a mathematical model that tracks market information, analyses massive data sources and study market conditions simultaneously to detect patterns which can be used for trading. This is humanly impossible to do in a fraction of time. Algorithmic systems can make millions of trades daily, often known as “high-frequency trading”. It is highly believed that deep learning is playing its role in calibrating real-time trading decisions.',\n",
       " 'Fraud Detection',\n",
       " 'With the increase in use and dependency on computers for financial transactions came the data security risk. There is an ample amount of valuable data stored online available to create potential risk. Machine learning thus helped in fraud detection by detecting anomalies in transactions and flagging them for scrutiny based on the risk factors defined by the institutions. Fraud identification in insurance claims, credit card payments, identity theft, account theft, are all areas in fraud detection that machine learning can help in.',\n",
       " 'Process Automation',\n",
       " 'Process automation is one of the most common applications of machine learning in finance. The technology has helped in replacing manual work, automate repetitive tasks to avoid redundancy, and as a result, increase productivity. Machine learning has benefitted these organizations to optimize costs, improve customer experiences, and scale up their services. Some examples of financial and banking firms using process automation are the use of chatbots, automated calls, paperwork automation, and gamified employee training.',\n",
       " 'Customer onboarding',\n",
       " 'In this highly competitive industry, customer acquisition and the customer onboarding process is highly relevant in building a good customer relationship. At any stage, during the onboarding, a slight inconvenience or delay can act as a barrier. Machine learning-enabled complete automation in this process for these financial and banking institutions. Today, from opening an account, filing for any application can be completed within a few minutes with utmost ease. With AI, customers’ behavioral patterns have been studied to improvise and make the whole process efficient and user-friendly.',\n",
       " 'Customer churn',\n",
       " 'With the multitude of offerings and availability of a plethora of options, customer stickiness is a big problem faced by financial firms. Customer churn forecasting is one of the best big data use cases. It helps in detecting customers who cancel their subscription and analyses the same to tailor products as per customer needs. Video streaming application, Netflix’s subscribers worldwide has continued to grow to reach 167 million through using machine learning analytics on their customer database.',\n",
       " 'Decision Making',\n",
       " 'Financial and banking institutions function on facilitating investments made by their customers. Organizations are constantly in search of customers from whom they can get more revenue. This is now possible through performing machine learning analysis on both structured and unstructured data which helps them make more informed decisions. It also analyses data from the website and mobile application to construct effective marketing campaigns for the targeted customers.',\n",
       " 'Future of Machine Learning in Finance',\n",
       " 'Financial monitoring, security analysis, prevention of money laundering, network security, investment predictions, personalization of customer service everything comes under the realm of the applications of machine learning in the financial and banking industry. Yet, this is just the tip of the iceberg, there is a lot more that is going to change in the future. It is now visibly imperative that while AI is beginning to create a wave of transformation across these industries and adapting to these changes s important for one’s survival. With smart technology applied everywhere, all financial firms are bound to turn into FinTech’s to stay relevant to the “silver tech generation” consisting of millennials and the GenZs.',\n",
       " 'Final thoughts',\n",
       " 'The financial services industry has entered the space of artificial intelligence and machine learning, and the pace is not surprising knowing the positive changes it has brought. Machine learning has the most use cases in finance than any other industry because of the available computer power and new machine learning tools. The greatest applications include simplifying customer engagement and accurate sales forecasting. It is only making this industry better and more efficient with each new adaptation. Machine learning algorithms have the capability to deal with a lot more than human capacity along with eliminating human error. As even the algorithms are constantly learning and innovating, they can serve as a bridge to a completely flawless automated financial system in the future. Nonetheless, the challenges of high cost and lack of resources that come along play a significant role in how early these firms can adopt these technologies. But even then, the future seems bright as the industry has enough adopters and prospects ready to explore.']"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "a70524c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:47]))\n",
    "URL_ID_48 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "1a9a1df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55 sentences in the string.\n",
      "The number of words in the string is: 1170\n",
      "The number of characters in the string is: 6471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "URL_ID_48 = texts\n",
    "\n",
    "sentences = URL_ID_48.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_48.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_48.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "5b60135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_48 = re.sub(re_punt, \"\",URL_ID_48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "eb84a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [18/Apr/2023 21:49:15] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 21:49:37] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Apr/2023 21:49:44] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "file = open(\"48.txt\", \"w\")\n",
    "file.write(URL_ID_48)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"48.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "dc7cc623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['we',\n",
       "  'all',\n",
       "  'hear',\n",
       "  'day',\n",
       "  'in',\n",
       "  'and',\n",
       "  'day',\n",
       "  'out',\n",
       "  'that',\n",
       "  'we',\n",
       "  'amidst',\n",
       "  'a',\n",
       "  'technological',\n",
       "  'revolution',\n",
       "  'but',\n",
       "  'do',\n",
       "  'we',\n",
       "  'know',\n",
       "  'what',\n",
       "  'this',\n",
       "  'really',\n",
       "  'means?',\n",
       "  'before',\n",
       "  'we',\n",
       "  'understand',\n",
       "  'how',\n",
       "  'its',\n",
       "  'going',\n",
       "  'to',\n",
       "  'impact',\n",
       "  'us',\n",
       "  'let',\n",
       "  'us',\n",
       "  'first',\n",
       "  'discuss',\n",
       "  'what',\n",
       "  'these',\n",
       "  'terms',\n",
       "  'really',\n",
       "  'mean',\n",
       "  'a',\n",
       "  'technological',\n",
       "  'revolution',\n",
       "  'simply',\n",
       "  'means',\n",
       "  'that',\n",
       "  'we',\n",
       "  'are',\n",
       "  'in',\n",
       "  'a',\n",
       "  'period',\n",
       "  'where',\n",
       "  'better',\n",
       "  'and',\n",
       "  'newer',\n",
       "  'technologies',\n",
       "  'replace',\n",
       "  'the',\n",
       "  'others',\n",
       "  'to',\n",
       "  'get',\n",
       "  'the',\n",
       "  'job',\n",
       "  'done',\n",
       "  'faster',\n",
       "  'and',\n",
       "  'better',\n",
       "  'we',\n",
       "  'are',\n",
       "  'in',\n",
       "  'an',\n",
       "  'era',\n",
       "  'with',\n",
       "  'rapid',\n",
       "  'innovations',\n",
       "  'where',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'being',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'humans',\n",
       "  'so',\n",
       "  'then',\n",
       "  'what',\n",
       "  'is',\n",
       "  'machine',\n",
       "  'learning?',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'basically',\n",
       "  'the',\n",
       "  'application',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'into',\n",
       "  'electronic',\n",
       "  'systems',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'them',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'and',\n",
       "  'enhance',\n",
       "  'themselves',\n",
       "  'without',\n",
       "  'being',\n",
       "  'programmed',\n",
       "  'by',\n",
       "  'humans',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'evolution',\n",
       "  'and',\n",
       "  'development',\n",
       "  'of',\n",
       "  'computer',\n",
       "  'programs',\n",
       "  'that',\n",
       "  'can',\n",
       "  'access',\n",
       "  'data',\n",
       "  'and',\n",
       "  'then',\n",
       "  'use',\n",
       "  'it',\n",
       "  'to',\n",
       "  'advance',\n",
       "  'themselves',\n",
       "  'whether',\n",
       "  'you',\n",
       "  'know',\n",
       "  'it',\n",
       "  'or',\n",
       "  'not',\n",
       "  'you',\n",
       "  'use',\n",
       "  'machine',\n",
       "  'learningpowered',\n",
       "  'applications',\n",
       "  'daily',\n",
       "  'now',\n",
       "  'what',\n",
       "  'is',\n",
       "  'artificial',\n",
       "  'intelligence?',\n",
       "  'at',\n",
       "  'its',\n",
       "  'simplest',\n",
       "  'form',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'a',\n",
       "  'field',\n",
       "  'which',\n",
       "  'combines',\n",
       "  'computer',\n",
       "  'science',\n",
       "  'and',\n",
       "  'robust',\n",
       "  'datasets',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'problemsolving',\n",
       "  'in',\n",
       "  'simple',\n",
       "  'words',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'that',\n",
       "  'facilitates',\n",
       "  'these',\n",
       "  'machines',\n",
       "  'to',\n",
       "  'perform',\n",
       "  'human',\n",
       "  'like',\n",
       "  'behaviour',\n",
       "  'just',\n",
       "  'like',\n",
       "  'every',\n",
       "  'other',\n",
       "  'industry',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'playing',\n",
       "  'its',\n",
       "  'role',\n",
       "  'in',\n",
       "  'the',\n",
       "  'finance',\n",
       "  'and',\n",
       "  'banking',\n",
       "  'industry',\n",
       "  'too',\n",
       "  'in',\n",
       "  'most',\n",
       "  'cases',\n",
       "  'where',\n",
       "  'a',\n",
       "  'human',\n",
       "  'would',\n",
       "  'perform',\n",
       "  'the',\n",
       "  'same',\n",
       "  'task',\n",
       "  'by',\n",
       "  'performing',\n",
       "  'the',\n",
       "  'same',\n",
       "  'calculations',\n",
       "  'or',\n",
       "  'following',\n",
       "  'the',\n",
       "  'same',\n",
       "  'process',\n",
       "  'can',\n",
       "  'be',\n",
       "  'taught',\n",
       "  'to',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'which',\n",
       "  'can',\n",
       "  'now',\n",
       "  'perform',\n",
       "  'it',\n",
       "  'by',\n",
       "  'itself',\n",
       "  'let',\n",
       "  'us',\n",
       "  'discuss',\n",
       "  'a',\n",
       "  'few',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'the',\n",
       "  'applications',\n",
       "  'that',\n",
       "  'we',\n",
       "  'might',\n",
       "  'have',\n",
       "  'come',\n",
       "  'in',\n",
       "  'our',\n",
       "  'day',\n",
       "  'to',\n",
       "  'day',\n",
       "  'running',\n",
       "  'which',\n",
       "  'are',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'in',\n",
       "  'this',\n",
       "  'industry',\n",
       "  'portfolio',\n",
       "  'management',\n",
       "  'in',\n",
       "  'earlier',\n",
       "  'days',\n",
       "  'an',\n",
       "  'investor',\n",
       "  'would',\n",
       "  'need',\n",
       "  'to',\n",
       "  'consult',\n",
       "  'a',\n",
       "  'financial',\n",
       "  'advisor',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'hisher',\n",
       "  'risk',\n",
       "  'appetite',\n",
       "  'and',\n",
       "  'advise',\n",
       "  'accordingly',\n",
       "  'today',\n",
       "  'using',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'there',\n",
       "  'exists',\n",
       "  'the',\n",
       "  'concept',\n",
       "  'of',\n",
       "  'a',\n",
       "  'roboadvisor',\n",
       "  'that',\n",
       "  'requires',\n",
       "  'any',\n",
       "  'user',\n",
       "  'to',\n",
       "  'give',\n",
       "  'certain',\n",
       "  'inputs',\n",
       "  'about',\n",
       "  'their',\n",
       "  'financial',\n",
       "  'status',\n",
       "  'and',\n",
       "  'goals',\n",
       "  'and',\n",
       "  'calculates',\n",
       "  'their',\n",
       "  'risk',\n",
       "  'tolerance',\n",
       "  'and',\n",
       "  'constructs',\n",
       "  'and',\n",
       "  'idle',\n",
       "  'portfolio',\n",
       "  'allocation',\n",
       "  'for',\n",
       "  'them',\n",
       "  'young',\n",
       "  'users',\n",
       "  'today',\n",
       "  'find',\n",
       "  'this',\n",
       "  'extremely',\n",
       "  'useful',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'physically',\n",
       "  'visiting',\n",
       "  'an',\n",
       "  'advisor',\n",
       "  'and',\n",
       "  'paying',\n",
       "  'a',\n",
       "  'fee',\n",
       "  'for',\n",
       "  'doing',\n",
       "  'so',\n",
       "  'risk',\n",
       "  'underwriting',\n",
       "  'underwriting',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'core',\n",
       "  'functions',\n",
       "  'for',\n",
       "  'most',\n",
       "  'financial',\n",
       "  'institutions',\n",
       "  'especially',\n",
       "  'banks',\n",
       "  'and',\n",
       "  'insurance',\n",
       "  'companies',\n",
       "  'where',\n",
       "  'they',\n",
       "  'are',\n",
       "  'required',\n",
       "  'to',\n",
       "  'underwrite',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'the',\n",
       "  'customers',\n",
       "  'before',\n",
       "  'loaning',\n",
       "  'out',\n",
       "  'money',\n",
       "  'or',\n",
       "  'insurance',\n",
       "  'policies',\n",
       "  'these',\n",
       "  'underwriting',\n",
       "  'activities',\n",
       "  'are',\n",
       "  'based',\n",
       "  'on',\n",
       "  'trends',\n",
       "  'and',\n",
       "  'thumb',\n",
       "  'rules',\n",
       "  'industrywide',\n",
       "  'the',\n",
       "  'same',\n",
       "  'has',\n",
       "  'been',\n",
       "  'introduced',\n",
       "  'through',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'which',\n",
       "  'is',\n",
       "  'able',\n",
       "  'to',\n",
       "  'underwrite',\n",
       "  'risks',\n",
       "  'today',\n",
       "  'on',\n",
       "  'a',\n",
       "  'larger',\n",
       "  'and',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'scale',\n",
       "  'algorithmic',\n",
       "  'trading',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'a',\n",
       "  'mathematical',\n",
       "  'model',\n",
       "  'that',\n",
       "  'tracks',\n",
       "  'market',\n",
       "  'information',\n",
       "  'analyses',\n",
       "  'massive',\n",
       "  'data',\n",
       "  'sources',\n",
       "  'and',\n",
       "  'study',\n",
       "  'market',\n",
       "  'conditions',\n",
       "  'simultaneously',\n",
       "  'to',\n",
       "  'detect',\n",
       "  'patterns',\n",
       "  'which',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'for',\n",
       "  'trading',\n",
       "  'this',\n",
       "  'is',\n",
       "  'humanly',\n",
       "  'impossible',\n",
       "  'to',\n",
       "  'do',\n",
       "  'in',\n",
       "  'a',\n",
       "  'fraction',\n",
       "  'of',\n",
       "  'time',\n",
       "  'algorithmic',\n",
       "  'systems',\n",
       "  'can',\n",
       "  'make',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'trades',\n",
       "  'daily',\n",
       "  'often',\n",
       "  'known',\n",
       "  'as',\n",
       "  'highfrequency',\n",
       "  'trading',\n",
       "  'it',\n",
       "  'is',\n",
       "  'highly',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'playing',\n",
       "  'its',\n",
       "  'role',\n",
       "  'in',\n",
       "  'calibrating',\n",
       "  'realtime',\n",
       "  'trading',\n",
       "  'decisions',\n",
       "  'fraud',\n",
       "  'detection',\n",
       "  'with',\n",
       "  'the',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'use',\n",
       "  'and',\n",
       "  'dependency',\n",
       "  'on',\n",
       "  'computers',\n",
       "  'for',\n",
       "  'financial',\n",
       "  'transactions',\n",
       "  'came',\n",
       "  'the',\n",
       "  'data',\n",
       "  'security',\n",
       "  'risk',\n",
       "  'there',\n",
       "  'is',\n",
       "  'an',\n",
       "  'ample',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'valuable',\n",
       "  'data',\n",
       "  'stored',\n",
       "  'online',\n",
       "  'available',\n",
       "  'to',\n",
       "  'create',\n",
       "  'potential',\n",
       "  'risk',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'thus',\n",
       "  'helped',\n",
       "  'in',\n",
       "  'fraud',\n",
       "  'detection',\n",
       "  'by',\n",
       "  'detecting',\n",
       "  'anomalies',\n",
       "  'in',\n",
       "  'transactions',\n",
       "  'and',\n",
       "  'flagging',\n",
       "  'them',\n",
       "  'for',\n",
       "  'scrutiny',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'factors',\n",
       "  'defined',\n",
       "  'by',\n",
       "  'the',\n",
       "  'institutions',\n",
       "  'fraud',\n",
       "  'identification',\n",
       "  'in',\n",
       "  'insurance',\n",
       "  'claims',\n",
       "  'credit',\n",
       "  'card',\n",
       "  'payments',\n",
       "  'identity',\n",
       "  'theft',\n",
       "  'account',\n",
       "  'theft',\n",
       "  'are',\n",
       "  'all',\n",
       "  'areas',\n",
       "  'in',\n",
       "  'fraud',\n",
       "  'detection',\n",
       "  'that',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'can',\n",
       "  'help',\n",
       "  'in',\n",
       "  'process',\n",
       "  'automation',\n",
       "  'process',\n",
       "  'automation',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'common',\n",
       "  'applications',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'in',\n",
       "  'finance',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'in',\n",
       "  'replacing',\n",
       "  'manual',\n",
       "  'work',\n",
       "  'automate',\n",
       "  'repetitive',\n",
       "  'tasks',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'redundancy',\n",
       "  'and',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'increase',\n",
       "  'productivity',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'has',\n",
       "  'benefitted',\n",
       "  'these',\n",
       "  'organizations',\n",
       "  'to',\n",
       "  'optimize',\n",
       "  'costs',\n",
       "  'improve',\n",
       "  'customer',\n",
       "  'experiences',\n",
       "  'and',\n",
       "  'scale',\n",
       "  'up',\n",
       "  'their',\n",
       "  'services',\n",
       "  'some',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'financial',\n",
       "  'and',\n",
       "  'banking',\n",
       "  'firms',\n",
       "  'using',\n",
       "  'process',\n",
       "  'automation',\n",
       "  'are',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'chatbots',\n",
       "  'automated',\n",
       "  'calls',\n",
       "  'paperwork',\n",
       "  'automation',\n",
       "  'and',\n",
       "  'gamified',\n",
       "  'employee',\n",
       "  'training',\n",
       "  'customer',\n",
       "  'onboarding',\n",
       "  'in',\n",
       "  'this',\n",
       "  'highly',\n",
       "  'competitive',\n",
       "  'industry',\n",
       "  'customer',\n",
       "  'acquisition',\n",
       "  'and',\n",
       "  'the',\n",
       "  'customer',\n",
       "  'onboarding',\n",
       "  'process',\n",
       "  'is',\n",
       "  'highly',\n",
       "  'relevant',\n",
       "  'in',\n",
       "  'building',\n",
       "  'a',\n",
       "  'good',\n",
       "  'customer',\n",
       "  'relationship',\n",
       "  'at',\n",
       "  'any',\n",
       "  'stage',\n",
       "  'during',\n",
       "  'the',\n",
       "  'onboarding',\n",
       "  'a',\n",
       "  'slight',\n",
       "  'inconvenience',\n",
       "  'or',\n",
       "  'delay',\n",
       "  'can',\n",
       "  'act',\n",
       "  'as',\n",
       "  'a',\n",
       "  'barrier',\n",
       "  'machine',\n",
       "  'learningenabled',\n",
       "  'complete',\n",
       "  'automation',\n",
       "  'in',\n",
       "  'this',\n",
       "  'process',\n",
       "  'for',\n",
       "  'these',\n",
       "  'financial',\n",
       "  'and',\n",
       "  'banking',\n",
       "  'institutions',\n",
       "  'today',\n",
       "  'from',\n",
       "  'opening',\n",
       "  'an',\n",
       "  'account',\n",
       "  'filing',\n",
       "  'for',\n",
       "  'any',\n",
       "  'application',\n",
       "  'can',\n",
       "  'be',\n",
       "  'completed',\n",
       "  'within',\n",
       "  'a',\n",
       "  'few',\n",
       "  'minutes',\n",
       "  'with',\n",
       "  'utmost',\n",
       "  'ease',\n",
       "  'with',\n",
       "  'ai',\n",
       "  'customers',\n",
       "  'behavioral',\n",
       "  'patterns',\n",
       "  'have',\n",
       "  'been',\n",
       "  'studied',\n",
       "  'to',\n",
       "  'improvise',\n",
       "  'and',\n",
       "  'make',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'process',\n",
       "  'efficient',\n",
       "  'and',\n",
       "  'userfriendly',\n",
       "  'customer',\n",
       "  'churn',\n",
       "  'with',\n",
       "  'the',\n",
       "  'multitude',\n",
       "  'of',\n",
       "  'offerings',\n",
       "  'and',\n",
       "  'availability',\n",
       "  'of',\n",
       "  'a',\n",
       "  'plethora',\n",
       "  'of',\n",
       "  'options',\n",
       "  'customer',\n",
       "  'stickiness',\n",
       "  'is',\n",
       "  'a',\n",
       "  'big',\n",
       "  'problem',\n",
       "  'faced',\n",
       "  'by',\n",
       "  'financial',\n",
       "  'firms',\n",
       "  'customer',\n",
       "  'churn',\n",
       "  'forecasting',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'best',\n",
       "  'big',\n",
       "  'data',\n",
       "  'use',\n",
       "  'cases',\n",
       "  'it',\n",
       "  'helps',\n",
       "  'in',\n",
       "  'detecting',\n",
       "  'customers',\n",
       "  'who',\n",
       "  'cancel',\n",
       "  'their',\n",
       "  'subscription',\n",
       "  'and',\n",
       "  'analyses',\n",
       "  'the',\n",
       "  'same',\n",
       "  'to',\n",
       "  'tailor',\n",
       "  'products',\n",
       "  'as',\n",
       "  'per',\n",
       "  'customer',\n",
       "  'needs',\n",
       "  'video',\n",
       "  'streaming',\n",
       "  'application',\n",
       "  'netflixs',\n",
       "  'subscribers',\n",
       "  'worldwide',\n",
       "  'has',\n",
       "  'continued',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'to',\n",
       "  'reach',\n",
       "  '167',\n",
       "  'million',\n",
       "  'through',\n",
       "  'using',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'analytics',\n",
       "  'on',\n",
       "  'their',\n",
       "  'customer',\n",
       "  'database',\n",
       "  'decision',\n",
       "  'making',\n",
       "  'financial',\n",
       "  'and',\n",
       "  'banking',\n",
       "  'institutions',\n",
       "  'function',\n",
       "  'on',\n",
       "  'facilitating',\n",
       "  'investments',\n",
       "  'made',\n",
       "  'by',\n",
       "  'their',\n",
       "  'customers',\n",
       "  'organizations',\n",
       "  'are',\n",
       "  'constantly',\n",
       "  'in',\n",
       "  'search',\n",
       "  'of',\n",
       "  'customers',\n",
       "  'from',\n",
       "  'whom',\n",
       "  'they',\n",
       "  'can',\n",
       "  'get',\n",
       "  'more',\n",
       "  'revenue',\n",
       "  'this',\n",
       "  'is',\n",
       "  'now',\n",
       "  'possible',\n",
       "  'through',\n",
       "  'performing',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'analysis',\n",
       "  'on',\n",
       "  'both',\n",
       "  'structured',\n",
       "  'and',\n",
       "  'unstructured',\n",
       "  'data',\n",
       "  'which',\n",
       "  'helps',\n",
       "  'them',\n",
       "  'make',\n",
       "  'more',\n",
       "  'informed',\n",
       "  'decisions',\n",
       "  'it',\n",
       "  'also',\n",
       "  'analyses',\n",
       "  'data',\n",
       "  'from',\n",
       "  'the',\n",
       "  'website',\n",
       "  'and',\n",
       "  'mobile',\n",
       "  'application',\n",
       "  'to',\n",
       "  'construct',\n",
       "  'effective',\n",
       "  'marketing',\n",
       "  'campaigns',\n",
       "  'for',\n",
       "  'the',\n",
       "  'targeted',\n",
       "  'customers',\n",
       "  'future',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'in',\n",
       "  'finance',\n",
       "  'financial',\n",
       "  'monitoring',\n",
       "  'security',\n",
       "  'analysis',\n",
       "  'prevention',\n",
       "  'of',\n",
       "  'money',\n",
       "  'laundering',\n",
       "  'network',\n",
       "  'security',\n",
       "  'investment',\n",
       "  'predictions',\n",
       "  'personalization',\n",
       "  'of',\n",
       "  'customer',\n",
       "  'service',\n",
       "  'everything',\n",
       "  'comes',\n",
       "  'under',\n",
       "  'the',\n",
       "  'realm',\n",
       "  'of',\n",
       "  'the',\n",
       "  'applications',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'in',\n",
       "  'the',\n",
       "  'financial',\n",
       "  'and',\n",
       "  'banking',\n",
       "  'industry',\n",
       "  'yet',\n",
       "  'this',\n",
       "  'is',\n",
       "  'just',\n",
       "  'the',\n",
       "  'tip',\n",
       "  'of',\n",
       "  'the',\n",
       "  'iceberg',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'more',\n",
       "  'that',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'change',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'it',\n",
       "  'is',\n",
       "  'now',\n",
       "  'visibly',\n",
       "  'imperative',\n",
       "  'that',\n",
       "  'while',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'beginning',\n",
       "  'to',\n",
       "  'create',\n",
       "  'a',\n",
       "  'wave',\n",
       "  'of',\n",
       "  'transformation',\n",
       "  'across',\n",
       "  'these',\n",
       "  'industries',\n",
       "  'and',\n",
       "  'adapting',\n",
       "  'to',\n",
       "  'these',\n",
       "  'changes',\n",
       "  's',\n",
       "  'important',\n",
       "  'for',\n",
       "  'ones',\n",
       "  'survival',\n",
       "  'with',\n",
       "  'smart',\n",
       "  'technology',\n",
       "  'applied',\n",
       "  'everywhere',\n",
       "  'all',\n",
       "  'financial',\n",
       "  'firms',\n",
       "  'are',\n",
       "  'bound',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'into',\n",
       "  'fintechs',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'relevant',\n",
       "  'to',\n",
       "  'the',\n",
       "  'silver',\n",
       "  'tech',\n",
       "  'generation',\n",
       "  'consisting',\n",
       "  'of',\n",
       "  'millennials',\n",
       "  ...]]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/48.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "9d67db3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "76d7dd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 759\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a2c5c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 21.272727272727273\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "f4303848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.43346508563899866\n",
      "FOG INDEX: 8.68247694334651\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 21.272727272727273\n",
      "COMPLEX WORD COUNT: 329\n",
      "WORD COUNT: 759\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "c6b03831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2390\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "a16bac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 7\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 3\n",
      "Total count: 10\n",
      "PERSONAL PRONOUNS: 10\n",
      "AVG WORD LENGTH: 5.530769230769231\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_48.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f565a1e",
   "metadata": {},
   "source": [
    "# For URL 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9627db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4366bc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\84489834.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3228bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text = driver.find_elements(By.TAG_NAME,'p')\n",
    "titles = []\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029b31fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It’s the year 2060. An automaton in a Research Laboratory says to a Scientist, “Warning! Error Occurred Reformatting Hard Disk Now!” The scientist panics. Automaton says again,” Ha! Ha! Just Kidding! “.',\n",
       " 'Funny Right. Before some of you say that this joke isn’t realistic, “How can an Automaton tell you a joke?” But what if I tell you in 2017, “Sofia” the robot made a joke on the show Good Morning Britain! Who thought computers could tell us a joke? Hard to believe? Well, the idea of giving computers human-enjoy thinking has now become a reality. Thanks to the technological advancement in AI in the last decade.',\n",
       " 'Before diving deep into how AI can impact the future of work, let’s begin with the simple question: what’s AI? Artificial Intelligence provides machines the power to think from data. The machine uses the patterns and trends found in data and makes its decision, but cannot create thought beyond these patterns and trends.',\n",
       " 'With the rise of AI, humans are divided into one question. Are machines human’s friend or foe? Tech executives and politicians on conference stages, campaign rallies, and even science fiction Hollywood movies like Carbon Black, Westworld, Minority Report, and Ex Machina have given their take on this question. Some believe AI will help us solve problems while others believe that the rise of AI will result in destruction and maybe the end of the world, we all know.',\n",
       " 'Stephen Hawking made it no secret of his concern about the rise of superhuman AI that eventually would escape earth to a new planet. No, this isn’t a plot of Black Mirror. Right now, Superhumans may not be a reality, but AI is.',\n",
       " '“Homo Deus”, the emergence of the new Digital God using AI. God must also worry, as AI might take his job.',\n",
       " 'Here’s some Career Advice, have you thought about being a Robot? The fear that AI would automate all jobs in the future eventually leaving all humans jobless has been daunting for many workers today. Statistics show that nearly 37% of workers worry about losing their jobs to robots. While another thought that many people believe is that though the rise of AI with result in automating most of the jobs in the future, however, it also will create millions of new job opportunities.',\n",
       " 'AI is already replacing most manual and repetitive tasks. For example, buying a metro ticket or a movie ticket is now almost a human-less interaction. Each year the number of industrial robot jobs increases by 14 %. At this rate, it’s predicted that the 20 million jobs in the manufacturing industry will be replaced by robots due to automation.',\n",
       " 'The coronavirus pandemic and recession have boosted the demand for automation. The Robotic Process Automation (RPA) Software industry has experienced an increase of 19.53% in the year 2021. Coronavirus pandemic has increased interest in technology that reduces human contact as minimal for making workplaces safe.',\n",
       " 'Our workplaces will look much different in the next five to ten years. AI will help humans in simplifying repetitive processes. The two most important catalysts for the future of work are the two D’s- Digitization and Datafication. Digitalization is converting data to digital formats (computer-readable). For example, text to Html, analog video to YouTube video. Digitization helps in increasing data exponentially. Datafication is quantifying human life to data and improving the data-driven business model. By 2025, it is forecasted that the digital transformation space will build in a $3,294 billion industry!',\n",
       " 'One thing is clear, no data, no future of work. What we find is that the future of data and the future of work will go hand in hand. The total volume of data in the datasphere that is created, captured, copied, and consumed in the world is predicted to reach 175 zettabytes by 2025. To give you a much better picture for understanding, if we represent the digital universe as stacks of tablets, there would be 27.25 stacks from earth to the moon.',\n",
       " 'It’s time to prepare for the data-dominated future as Industry 4.0/Fourth Industrial Revolution has begun. So, let’s see how artificial intelligence will affect the following fields:',\n",
       " 'Human Resource: Nowadays, recruiters use AI-powered tools for hiring workers. Using these tools, recruiters get insights into a candidate’s skills, personality and even check whether the candidate is fit for the organization. For example, the company AllyO first identifies high-potential candidates through assessment and smart screening, and then automatically schedules interviews using AI. HR departments at large companies receive hundreds of resumes for a job opening. Entry-level roles focusing on screening and scheduling will be automated. AI will automate specific HR jobs, not HR roles. A Deloitte study found that AI has already eliminated 800,000 low-skilled jobs in the UK, but 3.5 million new jobs were also created. Roles that focus on complex decisions like resolving disputes within a department will continue to be a very human endeavor.',\n",
       " 'Finance and Accounting: In 2015, a report from Accenture named “Finance 2020: death by digital” predicted that 40 percent of transactional accounting work would be automated by 2020. Has technology replaced the human factor? Well, AI has created new jobs involving managing the AI system and using the information to create insights. For example, accounting software has already automated bookkeeping tasks that used to be done by humans, but that’s only opened the door for former bookkeepers to learn skills needed to run and manage the software for employers and clients. Advisors are another crucial role of the accounting and finance team. Using the information gained from transactions in books, the team creates insights to improve business strategy. Owing to automation, the team spends more time analyzing numbers.',\n",
       " 'Marketing and Sales: Marketing automation has helped companies strategize the proper utilization of the company’s resources, managing time, and achieving budget targets. Marketing automation has helped to draw conclusions at a scale no marketer ever would. In this process, marketers and machines both excel in different parts. Marketers using AI tools drive more conversions in less time. Human Intelligence with technology can help identify the right customers to talk to and at the right time. Modern Marketers understand the insights from any marketing campaign and create it into effective messaging.',\n",
       " 'Engineering: Technology is changing in a blink of an eye. The technologies used five years ago in the industry have become obsolete today. Engineers will have to keep up with the technological advancements and keep upgrading their skills to stay relevant in the industry. Learning to work alongside machines and designing work such that interaction better humans and machines are better are going to be important skills for engineers in the future.',\n",
       " '',\n",
       " 'In the 18th and 19th centuries, the rise of the industrial revolution centuries led to millions of people losing their jobs because of scientific advancements. But that also ended in creating millions of other jobs. Statisticians have said, when automation destroys jobs, people find new ones. Thus, AI holds a more optimistic picture for the future.',\n",
       " 'In the future, AI is not going to replace humans, rather make jobs more humane. AI will disrupt millions of middle and entry-level jobs in the next few years but will also create millions of additional jobs and help to boost economies.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ba54ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It’s the year 2060. An automaton in a Research Laboratory says to a Scientist, “Warning! Error Occurred Reformatting Hard Disk Now!” The scientist panics. Automaton says again,” Ha! Ha! Just Kidding! “. Funny Right. Before some of you say that this joke isn’t realistic, “How can an Automaton tell you a joke?” But what if I tell you in 2017, “Sofia” the robot made a joke on the show Good Morning Britain! Who thought computers could tell us a joke? Hard to believe? Well, the idea of giving computers human-enjoy thinking has now become a reality. Thanks to the technological advancement in AI in the last decade. Before diving deep into how AI can impact the future of work, let’s begin with the simple question: what’s AI? Artificial Intelligence provides machines the power to think from data. The machine uses the patterns and trends found in data and makes its decision, but cannot create thought beyond these patterns and trends. With the rise of AI, humans are divided into one question. Are machines human’s friend or foe? Tech executives and politicians on conference stages, campaign rallies, and even science fiction Hollywood movies like Carbon Black, Westworld, Minority Report, and Ex Machina have given their take on this question. Some believe AI will help us solve problems while others believe that the rise of AI will result in destruction and maybe the end of the world, we all know. Stephen Hawking made it no secret of his concern about the rise of superhuman AI that eventually would escape earth to a new planet. No, this isn’t a plot of Black Mirror. Right now, Superhumans may not be a reality, but AI is. “Homo Deus”, the emergence of the new Digital God using AI. God must also worry, as AI might take his job. Here’s some Career Advice, have you thought about being a Robot? The fear that AI would automate all jobs in the future eventually leaving all humans jobless has been daunting for many workers today. Statistics show that nearly 37% of workers worry about losing their jobs to robots. While another thought that many people believe is that though the rise of AI with result in automating most of the jobs in the future, however, it also will create millions of new job opportunities. AI is already replacing most manual and repetitive tasks. For example, buying a metro ticket or a movie ticket is now almost a human-less interaction. Each year the number of industrial robot jobs increases by 14 %. At this rate, it’s predicted that the 20 million jobs in the manufacturing industry will be replaced by robots due to automation. The coronavirus pandemic and recession have boosted the demand for automation. The Robotic Process Automation (RPA) Software industry has experienced an increase of 19.53% in the year 2021. Coronavirus pandemic has increased interest in technology that reduces human contact as minimal for making workplaces safe. Our workplaces will look much different in the next five to ten years. AI will help humans in simplifying repetitive processes. The two most important catalysts for the future of work are the two D’s- Digitization and Datafication. Digitalization is converting data to digital formats (computer-readable). For example, text to Html, analog video to YouTube video. Digitization helps in increasing data exponentially. Datafication is quantifying human life to data and improving the data-driven business model. By 2025, it is forecasted that the digital transformation space will build in a $3,294 billion industry! One thing is clear, no data, no future of work. What we find is that the future of data and the future of work will go hand in hand. The total volume of data in the datasphere that is created, captured, copied, and consumed in the world is predicted to reach 175 zettabytes by 2025. To give you a much better picture for understanding, if we represent the digital universe as stacks of tablets, there would be 27.25 stacks from earth to the moon. It’s time to prepare for the data-dominated future as Industry 4.0/Fourth Industrial Revolution has begun. So, let’s see how artificial intelligence will affect the following fields: Human Resource: Nowadays, recruiters use AI-powered tools for hiring workers. Using these tools, recruiters get insights into a candidate’s skills, personality and even check whether the candidate is fit for the organization. For example, the company AllyO first identifies high-potential candidates through assessment and smart screening, and then automatically schedules interviews using AI. HR departments at large companies receive hundreds of resumes for a job opening. Entry-level roles focusing on screening and scheduling will be automated. AI will automate specific HR jobs, not HR roles. A Deloitte study found that AI has already eliminated 800,000 low-skilled jobs in the UK, but 3.5 million new jobs were also created. Roles that focus on complex decisions like resolving disputes within a department will continue to be a very human endeavor. Finance and Accounting: In 2015, a report from Accenture named “Finance 2020: death by digital” predicted that 40 percent of transactional accounting work would be automated by 2020. Has technology replaced the human factor? Well, AI has created new jobs involving managing the AI system and using the information to create insights. For example, accounting software has already automated bookkeeping tasks that used to be done by humans, but that’s only opened the door for former bookkeepers to learn skills needed to run and manage the software for employers and clients. Advisors are another crucial role of the accounting and finance team. Using the information gained from transactions in books, the team creates insights to improve business strategy. Owing to automation, the team spends more time analyzing numbers. Marketing and Sales: Marketing automation has helped companies strategize the proper utilization of the company’s resources, managing time, and achieving budget targets. Marketing automation has helped to draw conclusions at a scale no marketer ever would. In this process, marketers and machines both excel in different parts. Marketers using AI tools drive more conversions in less time. Human Intelligence with technology can help identify the right customers to talk to and at the right time. Modern Marketers understand the insights from any marketing campaign and create it into effective messaging. Engineering: Technology is changing in a blink of an eye. The technologies used five years ago in the industry have become obsolete today. Engineers will have to keep up with the technological advancements and keep upgrading their skills to stay relevant in the industry. Learning to work alongside machines and designing work such that interaction better humans and machines are better are going to be important skills for engineers in the future.  In the 18th and 19th centuries, the rise of the industrial revolution centuries led to millions of people losing their jobs because of scientific advancements. But that also ended in creating millions of other jobs. Statisticians have said, when automation destroys jobs, people find new ones. Thus, AI holds a more optimistic picture for the future. In the future, AI is not going to replace humans, rather make jobs more humane. AI will disrupt millions of middle and entry-level jobs in the next few years but will also create millions of additional jobs and help to boost economies.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:35]))\n",
    "URL_ID_49 = texts\n",
    "driver.quit()\n",
    "URL_ID_49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2712fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73 sentences in the string.\n",
      "The number of words in the string is: 1207\n",
      "The number of characters in the string is: 6245\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_49.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_49.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_49.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39138188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 12:40:27] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 12:40:28] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 12:40:35] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_49 = re.sub(re_punt, \"\",URL_ID_49)\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"49.txt\", \"w\")\n",
    "file.write(URL_ID_49)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"49.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cbf1893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['its',\n",
       "  'the',\n",
       "  'year',\n",
       "  '2060',\n",
       "  'an',\n",
       "  'automaton',\n",
       "  'in',\n",
       "  'a',\n",
       "  'research',\n",
       "  'laboratory',\n",
       "  'says',\n",
       "  'to',\n",
       "  'a',\n",
       "  'scientist',\n",
       "  'warning!',\n",
       "  'error',\n",
       "  'occurred',\n",
       "  'reformatting',\n",
       "  'hard',\n",
       "  'disk',\n",
       "  'now!',\n",
       "  'the',\n",
       "  'scientist',\n",
       "  'panics',\n",
       "  'automaton',\n",
       "  'says',\n",
       "  'again',\n",
       "  'ha!',\n",
       "  'ha!',\n",
       "  'just',\n",
       "  'kidding!',\n",
       "  'funny',\n",
       "  'right',\n",
       "  'before',\n",
       "  'some',\n",
       "  'of',\n",
       "  'you',\n",
       "  'say',\n",
       "  'that',\n",
       "  'this',\n",
       "  'joke',\n",
       "  'isnt',\n",
       "  'realistic',\n",
       "  'how',\n",
       "  'can',\n",
       "  'an',\n",
       "  'automaton',\n",
       "  'tell',\n",
       "  'you',\n",
       "  'a',\n",
       "  'joke?',\n",
       "  'but',\n",
       "  'what',\n",
       "  'if',\n",
       "  'i',\n",
       "  'tell',\n",
       "  'you',\n",
       "  'in',\n",
       "  '2017',\n",
       "  'sofia',\n",
       "  'the',\n",
       "  'robot',\n",
       "  'made',\n",
       "  'a',\n",
       "  'joke',\n",
       "  'on',\n",
       "  'the',\n",
       "  'show',\n",
       "  'good',\n",
       "  'morning',\n",
       "  'britain!',\n",
       "  'who',\n",
       "  'thought',\n",
       "  'computers',\n",
       "  'could',\n",
       "  'tell',\n",
       "  'us',\n",
       "  'a',\n",
       "  'joke?',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'believe?',\n",
       "  'well',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'giving',\n",
       "  'computers',\n",
       "  'humanenjoy',\n",
       "  'thinking',\n",
       "  'has',\n",
       "  'now',\n",
       "  'become',\n",
       "  'a',\n",
       "  'reality',\n",
       "  'thanks',\n",
       "  'to',\n",
       "  'the',\n",
       "  'technological',\n",
       "  'advancement',\n",
       "  'in',\n",
       "  'ai',\n",
       "  'in',\n",
       "  'the',\n",
       "  'last',\n",
       "  'decade',\n",
       "  'before',\n",
       "  'diving',\n",
       "  'deep',\n",
       "  'into',\n",
       "  'how',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'impact',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work',\n",
       "  'lets',\n",
       "  'begin',\n",
       "  'with',\n",
       "  'the',\n",
       "  'simple',\n",
       "  'question',\n",
       "  'whats',\n",
       "  'ai?',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'provides',\n",
       "  'machines',\n",
       "  'the',\n",
       "  'power',\n",
       "  'to',\n",
       "  'think',\n",
       "  'from',\n",
       "  'data',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'uses',\n",
       "  'the',\n",
       "  'patterns',\n",
       "  'and',\n",
       "  'trends',\n",
       "  'found',\n",
       "  'in',\n",
       "  'data',\n",
       "  'and',\n",
       "  'makes',\n",
       "  'its',\n",
       "  'decision',\n",
       "  'but',\n",
       "  'cannot',\n",
       "  'create',\n",
       "  'thought',\n",
       "  'beyond',\n",
       "  'these',\n",
       "  'patterns',\n",
       "  'and',\n",
       "  'trends',\n",
       "  'with',\n",
       "  'the',\n",
       "  'rise',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'divided',\n",
       "  'into',\n",
       "  'one',\n",
       "  'question',\n",
       "  'are',\n",
       "  'machines',\n",
       "  'humans',\n",
       "  'friend',\n",
       "  'or',\n",
       "  'foe?',\n",
       "  'tech',\n",
       "  'executives',\n",
       "  'and',\n",
       "  'politicians',\n",
       "  'on',\n",
       "  'conference',\n",
       "  'stages',\n",
       "  'campaign',\n",
       "  'rallies',\n",
       "  'and',\n",
       "  'even',\n",
       "  'science',\n",
       "  'fiction',\n",
       "  'hollywood',\n",
       "  'movies',\n",
       "  'like',\n",
       "  'carbon',\n",
       "  'black',\n",
       "  'westworld',\n",
       "  'minority',\n",
       "  'report',\n",
       "  'and',\n",
       "  'ex',\n",
       "  'machina',\n",
       "  'have',\n",
       "  'given',\n",
       "  'their',\n",
       "  'take',\n",
       "  'on',\n",
       "  'this',\n",
       "  'question',\n",
       "  'some',\n",
       "  'believe',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'help',\n",
       "  'us',\n",
       "  'solve',\n",
       "  'problems',\n",
       "  'while',\n",
       "  'others',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'the',\n",
       "  'rise',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'result',\n",
       "  'in',\n",
       "  'destruction',\n",
       "  'and',\n",
       "  'maybe',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  'we',\n",
       "  'all',\n",
       "  'know',\n",
       "  'stephen',\n",
       "  'hawking',\n",
       "  'made',\n",
       "  'it',\n",
       "  'no',\n",
       "  'secret',\n",
       "  'of',\n",
       "  'his',\n",
       "  'concern',\n",
       "  'about',\n",
       "  'the',\n",
       "  'rise',\n",
       "  'of',\n",
       "  'superhuman',\n",
       "  'ai',\n",
       "  'that',\n",
       "  'eventually',\n",
       "  'would',\n",
       "  'escape',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'a',\n",
       "  'new',\n",
       "  'planet',\n",
       "  'no',\n",
       "  'this',\n",
       "  'isnt',\n",
       "  'a',\n",
       "  'plot',\n",
       "  'of',\n",
       "  'black',\n",
       "  'mirror',\n",
       "  'right',\n",
       "  'now',\n",
       "  'superhumans',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'a',\n",
       "  'reality',\n",
       "  'but',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'homo',\n",
       "  'deus',\n",
       "  'the',\n",
       "  'emergence',\n",
       "  'of',\n",
       "  'the',\n",
       "  'new',\n",
       "  'digital',\n",
       "  'god',\n",
       "  'using',\n",
       "  'ai',\n",
       "  'god',\n",
       "  'must',\n",
       "  'also',\n",
       "  'worry',\n",
       "  'as',\n",
       "  'ai',\n",
       "  'might',\n",
       "  'take',\n",
       "  'his',\n",
       "  'job',\n",
       "  'heres',\n",
       "  'some',\n",
       "  'career',\n",
       "  'advice',\n",
       "  'have',\n",
       "  'you',\n",
       "  'thought',\n",
       "  'about',\n",
       "  'being',\n",
       "  'a',\n",
       "  'robot?',\n",
       "  'the',\n",
       "  'fear',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'would',\n",
       "  'automate',\n",
       "  'all',\n",
       "  'jobs',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'eventually',\n",
       "  'leaving',\n",
       "  'all',\n",
       "  'humans',\n",
       "  'jobless',\n",
       "  'has',\n",
       "  'been',\n",
       "  'daunting',\n",
       "  'for',\n",
       "  'many',\n",
       "  'workers',\n",
       "  'today',\n",
       "  'statistics',\n",
       "  'show',\n",
       "  'that',\n",
       "  'nearly',\n",
       "  '37',\n",
       "  'of',\n",
       "  'workers',\n",
       "  'worry',\n",
       "  'about',\n",
       "  'losing',\n",
       "  'their',\n",
       "  'jobs',\n",
       "  'to',\n",
       "  'robots',\n",
       "  'while',\n",
       "  'another',\n",
       "  'thought',\n",
       "  'that',\n",
       "  'many',\n",
       "  'people',\n",
       "  'believe',\n",
       "  'is',\n",
       "  'that',\n",
       "  'though',\n",
       "  'the',\n",
       "  'rise',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'with',\n",
       "  'result',\n",
       "  'in',\n",
       "  'automating',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'jobs',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'however',\n",
       "  'it',\n",
       "  'also',\n",
       "  'will',\n",
       "  'create',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'new',\n",
       "  'job',\n",
       "  'opportunities',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'already',\n",
       "  'replacing',\n",
       "  'most',\n",
       "  'manual',\n",
       "  'and',\n",
       "  'repetitive',\n",
       "  'tasks',\n",
       "  'for',\n",
       "  'example',\n",
       "  'buying',\n",
       "  'a',\n",
       "  'metro',\n",
       "  'ticket',\n",
       "  'or',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'ticket',\n",
       "  'is',\n",
       "  'now',\n",
       "  'almost',\n",
       "  'a',\n",
       "  'humanless',\n",
       "  'interaction',\n",
       "  'each',\n",
       "  'year',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'industrial',\n",
       "  'robot',\n",
       "  'jobs',\n",
       "  'increases',\n",
       "  'by',\n",
       "  '14',\n",
       "  'at',\n",
       "  'this',\n",
       "  'rate',\n",
       "  'its',\n",
       "  'predicted',\n",
       "  'that',\n",
       "  'the',\n",
       "  '20',\n",
       "  'million',\n",
       "  'jobs',\n",
       "  'in',\n",
       "  'the',\n",
       "  'manufacturing',\n",
       "  'industry',\n",
       "  'will',\n",
       "  'be',\n",
       "  'replaced',\n",
       "  'by',\n",
       "  'robots',\n",
       "  'due',\n",
       "  'to',\n",
       "  'automation',\n",
       "  'the',\n",
       "  'coronavirus',\n",
       "  'pandemic',\n",
       "  'and',\n",
       "  'recession',\n",
       "  'have',\n",
       "  'boosted',\n",
       "  'the',\n",
       "  'demand',\n",
       "  'for',\n",
       "  'automation',\n",
       "  'the',\n",
       "  'robotic',\n",
       "  'process',\n",
       "  'automation',\n",
       "  'rpa',\n",
       "  'software',\n",
       "  'industry',\n",
       "  'has',\n",
       "  'experienced',\n",
       "  'an',\n",
       "  'increase',\n",
       "  'of',\n",
       "  '1953',\n",
       "  'in',\n",
       "  'the',\n",
       "  'year',\n",
       "  '2021',\n",
       "  'coronavirus',\n",
       "  'pandemic',\n",
       "  'has',\n",
       "  'increased',\n",
       "  'interest',\n",
       "  'in',\n",
       "  'technology',\n",
       "  'that',\n",
       "  'reduces',\n",
       "  'human',\n",
       "  'contact',\n",
       "  'as',\n",
       "  'minimal',\n",
       "  'for',\n",
       "  'making',\n",
       "  'workplaces',\n",
       "  'safe',\n",
       "  'our',\n",
       "  'workplaces',\n",
       "  'will',\n",
       "  'look',\n",
       "  'much',\n",
       "  'different',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  'five',\n",
       "  'to',\n",
       "  'ten',\n",
       "  'years',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'help',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'simplifying',\n",
       "  'repetitive',\n",
       "  'processes',\n",
       "  'the',\n",
       "  'two',\n",
       "  'most',\n",
       "  'important',\n",
       "  'catalysts',\n",
       "  'for',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work',\n",
       "  'are',\n",
       "  'the',\n",
       "  'two',\n",
       "  'ds',\n",
       "  'digitization',\n",
       "  'and',\n",
       "  'datafication',\n",
       "  'digitalization',\n",
       "  'is',\n",
       "  'converting',\n",
       "  'data',\n",
       "  'to',\n",
       "  'digital',\n",
       "  'formats',\n",
       "  'computerreadable',\n",
       "  'for',\n",
       "  'example',\n",
       "  'text',\n",
       "  'to',\n",
       "  'html',\n",
       "  'analog',\n",
       "  'video',\n",
       "  'to',\n",
       "  'youtube',\n",
       "  'video',\n",
       "  'digitization',\n",
       "  'helps',\n",
       "  'in',\n",
       "  'increasing',\n",
       "  'data',\n",
       "  'exponentially',\n",
       "  'datafication',\n",
       "  'is',\n",
       "  'quantifying',\n",
       "  'human',\n",
       "  'life',\n",
       "  'to',\n",
       "  'data',\n",
       "  'and',\n",
       "  'improving',\n",
       "  'the',\n",
       "  'datadriven',\n",
       "  'business',\n",
       "  'model',\n",
       "  'by',\n",
       "  '2025',\n",
       "  'it',\n",
       "  'is',\n",
       "  'forecasted',\n",
       "  'that',\n",
       "  'the',\n",
       "  'digital',\n",
       "  'transformation',\n",
       "  'space',\n",
       "  'will',\n",
       "  'build',\n",
       "  'in',\n",
       "  'a',\n",
       "  '3294',\n",
       "  'billion',\n",
       "  'industry!',\n",
       "  'one',\n",
       "  'thing',\n",
       "  'is',\n",
       "  'clear',\n",
       "  'no',\n",
       "  'data',\n",
       "  'no',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work',\n",
       "  'what',\n",
       "  'we',\n",
       "  'find',\n",
       "  'is',\n",
       "  'that',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'data',\n",
       "  'and',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'work',\n",
       "  'will',\n",
       "  'go',\n",
       "  'hand',\n",
       "  'in',\n",
       "  'hand',\n",
       "  'the',\n",
       "  'total',\n",
       "  'volume',\n",
       "  'of',\n",
       "  'data',\n",
       "  'in',\n",
       "  'the',\n",
       "  'datasphere',\n",
       "  'that',\n",
       "  'is',\n",
       "  'created',\n",
       "  'captured',\n",
       "  'copied',\n",
       "  'and',\n",
       "  'consumed',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'is',\n",
       "  'predicted',\n",
       "  'to',\n",
       "  'reach',\n",
       "  '175',\n",
       "  'zettabytes',\n",
       "  'by',\n",
       "  '2025',\n",
       "  'to',\n",
       "  'give',\n",
       "  'you',\n",
       "  'a',\n",
       "  'much',\n",
       "  'better',\n",
       "  'picture',\n",
       "  'for',\n",
       "  'understanding',\n",
       "  'if',\n",
       "  'we',\n",
       "  'represent',\n",
       "  'the',\n",
       "  'digital',\n",
       "  'universe',\n",
       "  'as',\n",
       "  'stacks',\n",
       "  'of',\n",
       "  'tablets',\n",
       "  'there',\n",
       "  'would',\n",
       "  'be',\n",
       "  '2725',\n",
       "  'stacks',\n",
       "  'from',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'the',\n",
       "  'moon',\n",
       "  'its',\n",
       "  'time',\n",
       "  'to',\n",
       "  'prepare',\n",
       "  'for',\n",
       "  'the',\n",
       "  'datadominated',\n",
       "  'future',\n",
       "  'as',\n",
       "  'industry',\n",
       "  '40fourth',\n",
       "  'industrial',\n",
       "  'revolution',\n",
       "  'has',\n",
       "  'begun',\n",
       "  'so',\n",
       "  'lets',\n",
       "  'see',\n",
       "  'how',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'will',\n",
       "  'affect',\n",
       "  'the',\n",
       "  'following',\n",
       "  'fields',\n",
       "  'human',\n",
       "  'resource',\n",
       "  'nowadays',\n",
       "  'recruiters',\n",
       "  'use',\n",
       "  'aipowered',\n",
       "  'tools',\n",
       "  'for',\n",
       "  'hiring',\n",
       "  'workers',\n",
       "  'using',\n",
       "  'these',\n",
       "  'tools',\n",
       "  'recruiters',\n",
       "  'get',\n",
       "  'insights',\n",
       "  'into',\n",
       "  'a',\n",
       "  'candidates',\n",
       "  'skills',\n",
       "  'personality',\n",
       "  'and',\n",
       "  'even',\n",
       "  'check',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'candidate',\n",
       "  'is',\n",
       "  'fit',\n",
       "  'for',\n",
       "  'the',\n",
       "  'organization',\n",
       "  'for',\n",
       "  'example',\n",
       "  'the',\n",
       "  'company',\n",
       "  'allyo',\n",
       "  'first',\n",
       "  'identifies',\n",
       "  'highpotential',\n",
       "  'candidates',\n",
       "  'through',\n",
       "  'assessment',\n",
       "  'and',\n",
       "  'smart',\n",
       "  'screening',\n",
       "  'and',\n",
       "  'then',\n",
       "  'automatically',\n",
       "  'schedules',\n",
       "  'interviews',\n",
       "  'using',\n",
       "  'ai',\n",
       "  'hr',\n",
       "  'departments',\n",
       "  'at',\n",
       "  'large',\n",
       "  'companies',\n",
       "  'receive',\n",
       "  'hundreds',\n",
       "  'of',\n",
       "  'resumes',\n",
       "  'for',\n",
       "  'a',\n",
       "  'job',\n",
       "  'opening',\n",
       "  'entrylevel',\n",
       "  'roles',\n",
       "  'focusing',\n",
       "  'on',\n",
       "  'screening',\n",
       "  'and',\n",
       "  'scheduling',\n",
       "  'will',\n",
       "  'be',\n",
       "  'automated',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'automate',\n",
       "  'specific',\n",
       "  'hr',\n",
       "  'jobs',\n",
       "  'not',\n",
       "  'hr',\n",
       "  'roles',\n",
       "  'a',\n",
       "  'deloitte',\n",
       "  'study',\n",
       "  'found',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'has',\n",
       "  'already',\n",
       "  'eliminated',\n",
       "  '800000',\n",
       "  'lowskilled',\n",
       "  'jobs',\n",
       "  'in',\n",
       "  'the',\n",
       "  'uk',\n",
       "  'but',\n",
       "  '35',\n",
       "  'million',\n",
       "  'new',\n",
       "  'jobs',\n",
       "  'were',\n",
       "  'also',\n",
       "  'created',\n",
       "  'roles',\n",
       "  'that',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'complex',\n",
       "  'decisions',\n",
       "  'like',\n",
       "  'resolving',\n",
       "  'disputes',\n",
       "  'within',\n",
       "  'a',\n",
       "  'department',\n",
       "  'will',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'very',\n",
       "  'human',\n",
       "  'endeavor',\n",
       "  'finance',\n",
       "  'and',\n",
       "  'accounting',\n",
       "  'in',\n",
       "  '2015',\n",
       "  'a',\n",
       "  'report',\n",
       "  'from',\n",
       "  'accenture',\n",
       "  'named',\n",
       "  'finance',\n",
       "  '2020',\n",
       "  'death',\n",
       "  'by',\n",
       "  'digital',\n",
       "  'predicted',\n",
       "  'that',\n",
       "  '40',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'transactional',\n",
       "  'accounting',\n",
       "  'work',\n",
       "  'would',\n",
       "  'be',\n",
       "  'automated',\n",
       "  'by',\n",
       "  '2020',\n",
       "  'has',\n",
       "  'technology',\n",
       "  'replaced',\n",
       "  'the',\n",
       "  'human',\n",
       "  'factor?',\n",
       "  'well',\n",
       "  'ai',\n",
       "  'has',\n",
       "  'created',\n",
       "  'new',\n",
       "  'jobs',\n",
       "  'involving',\n",
       "  'managing',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'system',\n",
       "  'and',\n",
       "  'using',\n",
       "  'the',\n",
       "  'information',\n",
       "  'to',\n",
       "  'create',\n",
       "  'insights',\n",
       "  'for',\n",
       "  'example',\n",
       "  'accounting',\n",
       "  'software',\n",
       "  'has',\n",
       "  'already',\n",
       "  'automated',\n",
       "  'bookkeeping',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'used',\n",
       "  'to',\n",
       "  'be',\n",
       "  'done',\n",
       "  'by',\n",
       "  'humans',\n",
       "  'but',\n",
       "  'thats',\n",
       "  'only',\n",
       "  'opened',\n",
       "  'the',\n",
       "  'door',\n",
       "  'for',\n",
       "  'former',\n",
       "  'bookkeepers',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'skills',\n",
       "  'needed',\n",
       "  'to',\n",
       "  'run',\n",
       "  'and',\n",
       "  'manage',\n",
       "  'the',\n",
       "  'software',\n",
       "  'for',\n",
       "  'employers',\n",
       "  'and',\n",
       "  'clients',\n",
       "  'advisors',\n",
       "  'are',\n",
       "  'another',\n",
       "  'crucial',\n",
       "  'role',\n",
       "  'of',\n",
       "  'the',\n",
       "  'accounting',\n",
       "  'and',\n",
       "  'finance',\n",
       "  'team',\n",
       "  'using',\n",
       "  'the',\n",
       "  'information',\n",
       "  'gained',\n",
       "  'from',\n",
       "  'transactions',\n",
       "  'in',\n",
       "  'books',\n",
       "  'the',\n",
       "  'team',\n",
       "  'creates',\n",
       "  'insights',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'business',\n",
       "  'strategy',\n",
       "  'owing',\n",
       "  'to',\n",
       "  'automation',\n",
       "  'the',\n",
       "  'team',\n",
       "  'spends',\n",
       "  'more',\n",
       "  'time',\n",
       "  'analyzing',\n",
       "  'numbers',\n",
       "  'marketing',\n",
       "  'and',\n",
       "  'sales',\n",
       "  'marketing',\n",
       "  'automation',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'companies',\n",
       "  'strategize',\n",
       "  'the',\n",
       "  'proper',\n",
       "  'utilization',\n",
       "  'of',\n",
       "  'the',\n",
       "  'companys',\n",
       "  'resources',\n",
       "  'managing',\n",
       "  'time',\n",
       "  'and',\n",
       "  'achieving',\n",
       "  'budget',\n",
       "  'targets',\n",
       "  'marketing',\n",
       "  'automation',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'to',\n",
       "  'draw',\n",
       "  'conclusions',\n",
       "  'at',\n",
       "  'a',\n",
       "  'scale',\n",
       "  'no',\n",
       "  'marketer',\n",
       "  'ever',\n",
       "  'would',\n",
       "  'in',\n",
       "  'this',\n",
       "  'process',\n",
       "  'marketers',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'both',\n",
       "  'excel',\n",
       "  'in',\n",
       "  'different',\n",
       "  'parts',\n",
       "  'marketers',\n",
       "  'using',\n",
       "  'ai',\n",
       "  'tools',\n",
       "  'drive',\n",
       "  'more',\n",
       "  'conversions',\n",
       "  'in',\n",
       "  ...]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/49.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9651b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce9ad438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 616\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee86f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 16.534246575342465\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14eb2bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENTAGE OF COMPLEX WORDS: 0.4383116883116883\n",
      "FOG INDEX: 6.7890233054616616\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 16.534246575342465\n",
      "COMPLEX WORD COUNT: 270\n",
      "WORD COUNT: 616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72f24859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    }
   ],
   "source": [
    "def has_more_than_two_syllables(word):\n",
    "    vowels = 'aeiouy'\n",
    "    syllables = 0\n",
    "    in_vowel_group = False\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            if not in_vowel_group:\n",
    "                syllables += 1\n",
    "                in_vowel_group = True\n",
    "        else:\n",
    "            in_vowel_group = False\n",
    "    return syllables > 2\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list))) # word List is the no of words in text\n",
    "\n",
    "print(more_than_two_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9396eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 1, 1, 5, 1, 1, 3, 4, 1, 1, 1, 3, 2, 1, 1, 4, 1, 1, 1, 1, 3, 2, 4, 1, 3, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1, 4, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 3, 1, 2, 3, 2, 1, 1, 1, 2, 1, 1, 4, 1, 1, 3, 1, 2, 3, 4, 2, 1, 1, 3, 1, 3, 1, 1, 1, 5, 4, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 1, 1, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 2, 4, 1, 1, 4, 4, 2, 2, 1, 2, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 4, 1, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 4, 1, 2, 2, 2, 1, 2, 1, 4, 1, 5, 1, 4, 2, 3, 3, 1, 2, 3, 3, 3, 2, 2, 2, 1, 2, 3, 2, 1, 1, 3, 2, 2, 2, 2, 1, 1, 4, 2, 4, 1, 1, 1, 1, 2, 2, 2, 2, 4, 1, 1, 2, 1, 1, 1, 2, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 3, 1, 2, 1, 4, 1, 1, 4, 2, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 3, 1, 1, 1, 2, 2, 1, 4, 1, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 3, 2, 2, 2, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, 5, 1, 1, 1, 1, 3, 4, 3, 1, 2, 2, 1, 2, 3, 1, 1, 2, 2, 3, 1, 1, 2, 1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 2, 3, 2, 1, 1, 3, 4, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 5, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 3, 3, 1, 1, 1, 6, 1, 1, 3, 3, 1, 3, 1, 5, 1, 1, 3, 2, 1, 2, 2, 1, 1, 3, 2, 1, 1, 2, 1, 3, 5, 1, 2, 1, 2, 1, 4, 2, 1, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 1, 5, 2, 1, 1, 2, 1, 2, 2, 1, 6, 1, 5, 3, 1, 4, 2, 2, 1, 2, 1, 6, 1, 3, 2, 5, 1, 3, 2, 1, 4, 1, 4, 1, 1, 1, 1, 2, 1, 5, 3, 1, 3, 3, 1, 3, 1, 2, 2, 2, 1, 3, 1, 2, 2, 2, 1, 2, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 3, 5, 3, 1, 1, 1, 3, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 6, 1, 6, 7, 1, 3, 2, 1, 3, 2, 7, 1, 3, 1, 1, 1, 3, 3, 1, 4, 3, 6, 1, 1, 4, 2, 5, 6, 1, 4, 2, 2, 1, 2, 1, 3, 1, 4, 3, 2, 1, 1, 1, 1, 3, 1, 1, 3, 5, 2, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 4, 1, 1, 3, 3, 3, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 3, 1, 4, 1, 1, 3, 1, 3, 4, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 1, 5, 3, 1, 1, 2, 3, 5, 1, 2, 1, 1, 2, 1, 5, 5, 1, 2, 1, 3, 2, 2, 4, 3, 4, 2, 2, 2, 1, 2, 2, 1, 2, 2, 4, 1, 2, 2, 1, 4, 1, 4, 1, 2, 1, 2, 1, 4, 1, 1, 1, 1, 6, 1, 3, 1, 2, 1, 1, 4, 5, 3, 2, 3, 1, 1, 3, 1, 1, 6, 2, 4, 2, 1, 1, 3, 1, 2, 3, 4, 2, 1, 2, 1, 1, 1, 3, 2, 1, 3, 1, 3, 1, 3, 1, 1, 5, 1, 1, 5, 3, 1, 1, 1, 1, 2, 1, 4, 1, 2, 1, 1, 1, 3, 4, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 2, 3, 1, 1, 2, 1, 2, 4, 2, 3, 2, 2, 1, 3, 1, 4, 1, 1, 1, 1, 2, 4, 3, 1, 3, 1, 1, 1, 2, 1, 3, 1, 3, 1, 2, 1, 3, 2, 1, 1, 2, 1, 5, 4, 1, 2, 1, 4, 1, 1, 1, 3, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 3, 3, 1, 1, 1, 1, 2, 1, 5, 1, 3, 2, 1, 3, 4, 3, 1, 3, 4, 5, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 5, 1, 2, 1, 2, 1, 1, 1, 3, 1, 3, 1, 3, 1, 2, 2, 2, 3, 3, 2, 1, 1, 4, 1, 3, 2, 1, 1, 5, 2, 1, 4, 1, 2, 1, 2, 2, 2, 1, 3, 3, 2, 1, 1, 6, 1, 2, 1, 2, 2, 3, 2, 3, 1, 2, 3, 6, 1, 1, 3, 4, 1, 2, 6, 1, 1, 2, 4, 3, 2, 1, 4, 2, 2, 3, 6, 1, 1, 1, 1, 4, 1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 3, 1, 3, 2, 1, 2, 2, 2, 4, 1, 1, 2, 2, 4, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 1, 2, 1, 1, 3, 3, 1, 3, 1, 2, 4, 3, 4, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 4, 1, 2, 2, 2, 1, 1, 2, 2, 3, 4, 2, 3, 1, 2, 1, 2, 1, 1, 1, 5, 4, 1, 2, 3, 2, 1, 1, 1, 3, 1, 1, 2, 3, 1, 1, 4, 2, 1, 3, 1, 1, 1, 5, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 3, 1, 1, 4, 1, 1, 3, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 4, 5, 3, 1, 1, 3, 1, 3, 2, 2, 1, 4, 1, 4, 4, 1, 1, 2, 1, 1, 3, 3, 1, 2, 1, 5, 2, 2, 1, 6, 2, 1, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 2, 1, 3, 2, 2, 2, 1, 2, 3, 1, 1, 2, 3, 1, 2, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 3, 1, 5, 1, 1, 1, 1, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = \"aeiou\"\n",
    "    vowel_count = 0\n",
    "    \n",
    "    # Count the number of vowels in the word\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            vowel_count += 1\n",
    "    \n",
    "    # Handle exceptions for words ending with \"es\" or \"ed\"\n",
    "    if word[-2:] in [\"es\", \"ed\"]:\n",
    "        vowel_count -= 1\n",
    "    \n",
    "    # Handle words with no vowels\n",
    "    if vowel_count == 0:\n",
    "        vowel_count = 1\n",
    "    \n",
    "    return vowel_count\n",
    "\n",
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "print(syllable_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b59c4cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2277\n"
     ]
    }
   ],
   "source": [
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe6dca1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 1\n",
      "we: 3\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 2\n",
      "Total count: 6\n",
      "PERSONAL PRONOUNS: 6\n",
      "AVG WORD LENGTH: 5.173985086992544\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_49.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4376384",
   "metadata": {},
   "source": [
    "# 14 url 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc31d3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\1974942031.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f61bf44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The way work is being done now is destined to undergo massive transformational changes which will impact humans and their ways of working dramatically. With the development of the new machine programs, A.I. is all set to take over the humans in their workplace as no other did. Now we are not only in competition with other beings but with robots too. And robots will overcome us in our fields of work.',\n",
       " 'At present we are being surrounded by A.I. from dusk till dawn, from facial recognition present in our mobile application to dating websites/applications which uses decision making as their algorithms and learn from the past data as well. It is believed that A.I. has grown over 270% over the last years.',\n",
       " 'First, let us know what A.I. is and all the fuss going on about it?\\nA.I. as defined by the internet is simply ‘simulation of human intelligence in machines that are programmed to think like humans and mimic their actions’. This translates to, it can work as a human being just at fast speed and with 100% accuracy.\\nIn my definition I would define A.I. as the god form of human beings.',\n",
       " 'Now the question that arises is, what does A.I. entails for the future?',\n",
       " 'A.I. is fancy enough to continue existing in our minds all the time, but it does come with certain limitations and threats which is a cause for a peaceful sleep for most of the workers. With its introduction to different areas of the workplace, it is clear that half of the human jobs would be taken up by A.I. and then there would arise a need for more jobs for humans in new upcoming AI-based ventures in different industries. Thereby giving us our fair share back to us.',\n",
       " 'In a survey, it was found that some believed that AI will be devastating for humans and while some professionals and tech-savvy people believed that inculcating AI technology into business and our daily lives would be a remarkable step as it will lead to the flourishment of business in the future and give them a competitive edge over their rivals.',\n",
       " 'People believed that when these advanced technologies would come together to work with humans, they will produce a smarter strategic decision with productive collaborative practices. More modern technology prevailing in the organization will lead to stress reduction and produce more satisfying results thereby making the organization more efficient.',\n",
       " 'The Organizations who are in use of the AI technology responds by saying that their managers are more comfortable using A.I. and are accustomed to it and the organizations are now looking forward to having integration of higher-end technology systems, as it is believed that new technology will result in more productivity thereby making more profits in the long run.',\n",
       " 'Many jobs today require AI and humans working in collaboration, which creates a positive signal that in the future to humans would be working closely with the technology. Beyond just training and developing these machines, humans would be working in close vicinity with them and making decisions on how to act on the result that is given by the machine.',\n",
       " 'It can be said that both the AI advanced technology and human can’t remain in the workforce without each other, as the technology will produce accurate and top-notch results but it requires someone to make delivery.\\ne.g., in a firm, an AI-based system produces results based on historical data but there is a need for someone to analyze and communicate and present this data to the respective stakeholders whether inside or outside of the organization.',\n",
       " 'Various uses of artificial intelligence technology in day-to-day functions in regards to interactions with humans are:',\n",
       " 'Artificial intelligence as we know works on algorithms, neural networks, and deep learning which all are analytical tools that help AI in taking analytical decisions based on the data provided.',\n",
       " 'Whereas, humans on the other hand take higher-level decisions based on ‘Intuition’ sometimes, which refers to the gut feeling that generates in humans concerning any situation or challenge.',\n",
       " 'AI alone can’t work to handle critical situations on its own as it needs humans for it to reciprocate them and share the information with stakeholders, and humans alone can’t anticipate much on the accurate and fast-paced analytical solutions to the problems persisting in place of the situation.',\n",
       " 'The strength of humans and AI working in synergy can be surprisingly beneficial and advantageous to organizations.',\n",
       " 'It is believed that machines in the future would be eating up our traditional jobs. But the reality seems to be turning otherwise.',\n",
       " 'The future trend shows that in future the AI-powered technology would take up jobs that were being done by humans but in return would produce more jobs that would require human interference with them. As and when the newer technology is approaching more and more countries are now proceeding towards GIG Economies, and so in the future, we can witness an increase in freelance jobs and the permanent labor market norms could reduce drastically.',\n",
       " 'Some of the jobs today will be replaced by AI which is in the transportation or retail commerce sector that can be 100% automated in the future years. There is an ‘Amazon Go’ store that uses this technology which goes by the name ‘Just walk out technology’ wherein there is no need for any human-induced workforce and all the operations are carried out by AI-powered technologies, which is indeed a breakthrough technology in today’s world.',\n",
       " 'Rather than eating up our jobs AI in return will be creating more jobs in the future by creating massive innovations thereby fueling up many new industries and thereby giving us our fair share of jobs back.',\n",
       " 'There will be a lot of demand placed on the upcoming young workforce which is also categorized as ‘Gen Z’. They are expected to know more about technology and would be high in demand.  These young generations are required to learn new skills which are needed to survive in the dynamic changing environment, and as most of the activities that are carried out by workers will be automated, there will be demand for people working in the back office and maintaining and developing the technology to its best versions.  ',\n",
       " 'AI powered technology has its limitations which makes it a rigid system to hold on to and also which makes it a costly affair at the initial stage.  ',\n",
       " 'It was predicted that the cost of electricity to power a supercharged AI model was around $4.6 million. So, this super-powered AI can be purchased only by big fortune firms and thereby creating more value to their net worth.',\n",
       " 'One of the major limitations of AI is that it can contain biased data as the scientists who put in the data can create biasedness and so the resultant output of the same would have a biased report.',\n",
       " 'These machines as do not have neuroscience-based technology in them yet which enables them to carry human emotions to understand complex situations and a creative way out of that, they tend to have a lack of out of box thinking which in the case is rigid in themselves as they are programmed to work on a single task and they cannot perform more than a single task at the same time.',\n",
       " 'It is also believed that there exists no creativity among the computer, no matter it is fast-paced, but they are not intelligent.',\n",
       " 'Businesses and organizations need to understand and anticipate the opportunities that the future holds for them and they need to start training their employees based on today’s dynamic changing technology. While it’s still unclear what does the future holds for us, but the anticipation of it could benefit us in several ways.',\n",
       " 'As we are unclear about what the future looks like, we need to think in probable terms how it could turn out to be and then employ specific training programs for the employees of the organization.\\nThe training the employees are needed to be done on a continuous and lifetime basis which means that education won’t be only limited to PG degrees but will be now a lifetime process of learning.',\n",
       " 'As the Covid-19 changed the scenario of the work patterns around the world, we now need to think strategically about the working dynamics of the future and how does it look like compared to the pre-covid and post-covid scenario.',\n",
       " 'Employees will be playing a major role in transforming the organizations and work practices in the upcoming future, so organizations need to select and recruit the best candidates among the pool and then provide them with best practices of the new machines and make proficient in their area of work. Policies need to be developed to hire the best people and then retaining the talent in the organization.',\n",
       " 'There needs to be a continuous scanning of the environment by the organizations to comprehend any new trends and assess them, not all trends will be beneficial for organizations, they must be aware of the prospects and plan for the future systematically and consistently.',\n",
       " 'There lies a possibility in future certain years from now, we could have machines who will have general human intelligence who would be able to answer deep meaningful questions asking ‘Why are the curtains blue?’, would be able to clean cars, play politics and tell jokes to us, and by using deep and machine learning programs their level of intelligence would be beyond mathematical calculations to us. That’s how good machines will be in the future, but to make ourselves competitive with machines, we would need to train ourselves for the impending ambiguous future ahead of us.',\n",
       " 'Humans and machines need to work in synergy to get beneficial and satisfying results for both parties.',\n",
       " 'Machines are indeed going take away many of our jobs, but let me make you sleep peacefully tonight, the machines aren’t arriving until we’re retired.  ']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df5db236",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:49]))\n",
    "URL_ID_50 = \" \".join((titles, texts))\n",
    "\n",
    "URL_ID_50 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff12c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 76 sentences in the string.\n",
      "The number of words in the string is: 1647\n",
      "The number of characters in the string is: 8065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = URL_ID_50.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_50.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_50.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d771ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 13:39:42] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 13:39:51] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_50 = re.sub(re_punt, \"\",URL_ID_50)\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"50.txt\", \"w\")\n",
    "file.write(URL_ID_50)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"50.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67470033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'way',\n",
       "  'work',\n",
       "  'is',\n",
       "  'being',\n",
       "  'done',\n",
       "  'now',\n",
       "  'is',\n",
       "  'destined',\n",
       "  'to',\n",
       "  'undergo',\n",
       "  'massive',\n",
       "  'transformational',\n",
       "  'changes',\n",
       "  'which',\n",
       "  'will',\n",
       "  'impact',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'their',\n",
       "  'ways',\n",
       "  'of',\n",
       "  'working',\n",
       "  'dramatically',\n",
       "  'with',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'the',\n",
       "  'new',\n",
       "  'machine',\n",
       "  'programs',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'all',\n",
       "  'set',\n",
       "  'to',\n",
       "  'take',\n",
       "  'over',\n",
       "  'the',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'their',\n",
       "  'workplace',\n",
       "  'as',\n",
       "  'no',\n",
       "  'other',\n",
       "  'did',\n",
       "  'now',\n",
       "  'we',\n",
       "  'are',\n",
       "  'not',\n",
       "  'only',\n",
       "  'in',\n",
       "  'competition',\n",
       "  'with',\n",
       "  'other',\n",
       "  'beings',\n",
       "  'but',\n",
       "  'with',\n",
       "  'robots',\n",
       "  'too',\n",
       "  'and',\n",
       "  'robots',\n",
       "  'will',\n",
       "  'overcome',\n",
       "  'us',\n",
       "  'in',\n",
       "  'our',\n",
       "  'fields',\n",
       "  'of',\n",
       "  'work',\n",
       "  'at',\n",
       "  'present',\n",
       "  'we',\n",
       "  'are',\n",
       "  'being',\n",
       "  'surrounded',\n",
       "  'by',\n",
       "  'ai',\n",
       "  'from',\n",
       "  'dusk',\n",
       "  'till',\n",
       "  'dawn',\n",
       "  'from',\n",
       "  'facial',\n",
       "  'recognition',\n",
       "  'present',\n",
       "  'in',\n",
       "  'our',\n",
       "  'mobile',\n",
       "  'application',\n",
       "  'to',\n",
       "  'dating',\n",
       "  'websitesapplications',\n",
       "  'which',\n",
       "  'uses',\n",
       "  'decision',\n",
       "  'making',\n",
       "  'as',\n",
       "  'their',\n",
       "  'algorithms',\n",
       "  'and',\n",
       "  'learn',\n",
       "  'from',\n",
       "  'the',\n",
       "  'past',\n",
       "  'data',\n",
       "  'as',\n",
       "  'well',\n",
       "  'it',\n",
       "  'is',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'has',\n",
       "  'grown',\n",
       "  'over',\n",
       "  '270',\n",
       "  'over',\n",
       "  'the',\n",
       "  'last',\n",
       "  'years',\n",
       "  'first',\n",
       "  'let',\n",
       "  'us',\n",
       "  'know',\n",
       "  'what',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'and',\n",
       "  'all',\n",
       "  'the',\n",
       "  'fuss',\n",
       "  'going',\n",
       "  'on',\n",
       "  'about',\n",
       "  'it?'],\n",
       " ['ai',\n",
       "  'as',\n",
       "  'defined',\n",
       "  'by',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'is',\n",
       "  'simply',\n",
       "  'simulation',\n",
       "  'of',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'in',\n",
       "  'machines',\n",
       "  'that',\n",
       "  'are',\n",
       "  'programmed',\n",
       "  'to',\n",
       "  'think',\n",
       "  'like',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'mimic',\n",
       "  'their',\n",
       "  'actions',\n",
       "  'this',\n",
       "  'translates',\n",
       "  'to',\n",
       "  'it',\n",
       "  'can',\n",
       "  'work',\n",
       "  'as',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'just',\n",
       "  'at',\n",
       "  'fast',\n",
       "  'speed',\n",
       "  'and',\n",
       "  'with',\n",
       "  '100',\n",
       "  'accuracy'],\n",
       " ['in',\n",
       "  'my',\n",
       "  'definition',\n",
       "  'i',\n",
       "  'would',\n",
       "  'define',\n",
       "  'ai',\n",
       "  'as',\n",
       "  'the',\n",
       "  'god',\n",
       "  'form',\n",
       "  'of',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'now',\n",
       "  'the',\n",
       "  'question',\n",
       "  'that',\n",
       "  'arises',\n",
       "  'is',\n",
       "  'what',\n",
       "  'does',\n",
       "  'ai',\n",
       "  'entails',\n",
       "  'for',\n",
       "  'the',\n",
       "  'future?',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'fancy',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'existing',\n",
       "  'in',\n",
       "  'our',\n",
       "  'minds',\n",
       "  'all',\n",
       "  'the',\n",
       "  'time',\n",
       "  'but',\n",
       "  'it',\n",
       "  'does',\n",
       "  'come',\n",
       "  'with',\n",
       "  'certain',\n",
       "  'limitations',\n",
       "  'and',\n",
       "  'threats',\n",
       "  'which',\n",
       "  'is',\n",
       "  'a',\n",
       "  'cause',\n",
       "  'for',\n",
       "  'a',\n",
       "  'peaceful',\n",
       "  'sleep',\n",
       "  'for',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'workers',\n",
       "  'with',\n",
       "  'its',\n",
       "  'introduction',\n",
       "  'to',\n",
       "  'different',\n",
       "  'areas',\n",
       "  'of',\n",
       "  'the',\n",
       "  'workplace',\n",
       "  'it',\n",
       "  'is',\n",
       "  'clear',\n",
       "  'that',\n",
       "  'half',\n",
       "  'of',\n",
       "  'the',\n",
       "  'human',\n",
       "  'jobs',\n",
       "  'would',\n",
       "  'be',\n",
       "  'taken',\n",
       "  'up',\n",
       "  'by',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'then',\n",
       "  'there',\n",
       "  'would',\n",
       "  'arise',\n",
       "  'a',\n",
       "  'need',\n",
       "  'for',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'new',\n",
       "  'upcoming',\n",
       "  'aibased',\n",
       "  'ventures',\n",
       "  'in',\n",
       "  'different',\n",
       "  'industries',\n",
       "  'thereby',\n",
       "  'giving',\n",
       "  'us',\n",
       "  'our',\n",
       "  'fair',\n",
       "  'share',\n",
       "  'back',\n",
       "  'to',\n",
       "  'us',\n",
       "  'in',\n",
       "  'a',\n",
       "  'survey',\n",
       "  'it',\n",
       "  'was',\n",
       "  'found',\n",
       "  'that',\n",
       "  'some',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'be',\n",
       "  'devastating',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'while',\n",
       "  'some',\n",
       "  'professionals',\n",
       "  'and',\n",
       "  'techsavvy',\n",
       "  'people',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'inculcating',\n",
       "  'ai',\n",
       "  'technology',\n",
       "  'into',\n",
       "  'business',\n",
       "  'and',\n",
       "  'our',\n",
       "  'daily',\n",
       "  'lives',\n",
       "  'would',\n",
       "  'be',\n",
       "  'a',\n",
       "  'remarkable',\n",
       "  'step',\n",
       "  'as',\n",
       "  'it',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'the',\n",
       "  'flourishment',\n",
       "  'of',\n",
       "  'business',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'and',\n",
       "  'give',\n",
       "  'them',\n",
       "  'a',\n",
       "  'competitive',\n",
       "  'edge',\n",
       "  'over',\n",
       "  'their',\n",
       "  'rivals',\n",
       "  'people',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'when',\n",
       "  'these',\n",
       "  'advanced',\n",
       "  'technologies',\n",
       "  'would',\n",
       "  'come',\n",
       "  'together',\n",
       "  'to',\n",
       "  'work',\n",
       "  'with',\n",
       "  'humans',\n",
       "  'they',\n",
       "  'will',\n",
       "  'produce',\n",
       "  'a',\n",
       "  'smarter',\n",
       "  'strategic',\n",
       "  'decision',\n",
       "  'with',\n",
       "  'productive',\n",
       "  'collaborative',\n",
       "  'practices',\n",
       "  'more',\n",
       "  'modern',\n",
       "  'technology',\n",
       "  'prevailing',\n",
       "  'in',\n",
       "  'the',\n",
       "  'organization',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'stress',\n",
       "  'reduction',\n",
       "  'and',\n",
       "  'produce',\n",
       "  'more',\n",
       "  'satisfying',\n",
       "  'results',\n",
       "  'thereby',\n",
       "  'making',\n",
       "  'the',\n",
       "  'organization',\n",
       "  'more',\n",
       "  'efficient',\n",
       "  'the',\n",
       "  'organizations',\n",
       "  'who',\n",
       "  'are',\n",
       "  'in',\n",
       "  'use',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'technology',\n",
       "  'responds',\n",
       "  'by',\n",
       "  'saying',\n",
       "  'that',\n",
       "  'their',\n",
       "  'managers',\n",
       "  'are',\n",
       "  'more',\n",
       "  'comfortable',\n",
       "  'using',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'are',\n",
       "  'accustomed',\n",
       "  'to',\n",
       "  'it',\n",
       "  'and',\n",
       "  'the',\n",
       "  'organizations',\n",
       "  'are',\n",
       "  'now',\n",
       "  'looking',\n",
       "  'forward',\n",
       "  'to',\n",
       "  'having',\n",
       "  'integration',\n",
       "  'of',\n",
       "  'higherend',\n",
       "  'technology',\n",
       "  'systems',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'new',\n",
       "  'technology',\n",
       "  'will',\n",
       "  'result',\n",
       "  'in',\n",
       "  'more',\n",
       "  'productivity',\n",
       "  'thereby',\n",
       "  'making',\n",
       "  'more',\n",
       "  'profits',\n",
       "  'in',\n",
       "  'the',\n",
       "  'long',\n",
       "  'run',\n",
       "  'many',\n",
       "  'jobs',\n",
       "  'today',\n",
       "  'require',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'humans',\n",
       "  'working',\n",
       "  'in',\n",
       "  'collaboration',\n",
       "  'which',\n",
       "  'creates',\n",
       "  'a',\n",
       "  'positive',\n",
       "  'signal',\n",
       "  'that',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'to',\n",
       "  'humans',\n",
       "  'would',\n",
       "  'be',\n",
       "  'working',\n",
       "  'closely',\n",
       "  'with',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'beyond',\n",
       "  'just',\n",
       "  'training',\n",
       "  'and',\n",
       "  'developing',\n",
       "  'these',\n",
       "  'machines',\n",
       "  'humans',\n",
       "  'would',\n",
       "  'be',\n",
       "  'working',\n",
       "  'in',\n",
       "  'close',\n",
       "  'vicinity',\n",
       "  'with',\n",
       "  'them',\n",
       "  'and',\n",
       "  'making',\n",
       "  'decisions',\n",
       "  'on',\n",
       "  'how',\n",
       "  'to',\n",
       "  'act',\n",
       "  'on',\n",
       "  'the',\n",
       "  'result',\n",
       "  'that',\n",
       "  'is',\n",
       "  'given',\n",
       "  'by',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'said',\n",
       "  'that',\n",
       "  'both',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'advanced',\n",
       "  'technology',\n",
       "  'and',\n",
       "  'human',\n",
       "  'cant',\n",
       "  'remain',\n",
       "  'in',\n",
       "  'the',\n",
       "  'workforce',\n",
       "  'without',\n",
       "  'each',\n",
       "  'other',\n",
       "  'as',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'will',\n",
       "  'produce',\n",
       "  'accurate',\n",
       "  'and',\n",
       "  'topnotch',\n",
       "  'results',\n",
       "  'but',\n",
       "  'it',\n",
       "  'requires',\n",
       "  'someone',\n",
       "  'to',\n",
       "  'make',\n",
       "  'delivery'],\n",
       " ['eg',\n",
       "  'in',\n",
       "  'a',\n",
       "  'firm',\n",
       "  'an',\n",
       "  'aibased',\n",
       "  'system',\n",
       "  'produces',\n",
       "  'results',\n",
       "  'based',\n",
       "  'on',\n",
       "  'historical',\n",
       "  'data',\n",
       "  'but',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'need',\n",
       "  'for',\n",
       "  'someone',\n",
       "  'to',\n",
       "  'analyze',\n",
       "  'and',\n",
       "  'communicate',\n",
       "  'and',\n",
       "  'present',\n",
       "  'this',\n",
       "  'data',\n",
       "  'to',\n",
       "  'the',\n",
       "  'respective',\n",
       "  'stakeholders',\n",
       "  'whether',\n",
       "  'inside',\n",
       "  'or',\n",
       "  'outside',\n",
       "  'of',\n",
       "  'the',\n",
       "  'organization',\n",
       "  'various',\n",
       "  'uses',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'technology',\n",
       "  'in',\n",
       "  'daytoday',\n",
       "  'functions',\n",
       "  'in',\n",
       "  'regards',\n",
       "  'to',\n",
       "  'interactions',\n",
       "  'with',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'as',\n",
       "  'we',\n",
       "  'know',\n",
       "  'works',\n",
       "  'on',\n",
       "  'algorithms',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'and',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'which',\n",
       "  'all',\n",
       "  'are',\n",
       "  'analytical',\n",
       "  'tools',\n",
       "  'that',\n",
       "  'help',\n",
       "  'ai',\n",
       "  'in',\n",
       "  'taking',\n",
       "  'analytical',\n",
       "  'decisions',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'data',\n",
       "  'provided',\n",
       "  'whereas',\n",
       "  'humans',\n",
       "  'on',\n",
       "  'the',\n",
       "  'other',\n",
       "  'hand',\n",
       "  'take',\n",
       "  'higherlevel',\n",
       "  'decisions',\n",
       "  'based',\n",
       "  'on',\n",
       "  'intuition',\n",
       "  'sometimes',\n",
       "  'which',\n",
       "  'refers',\n",
       "  'to',\n",
       "  'the',\n",
       "  'gut',\n",
       "  'feeling',\n",
       "  'that',\n",
       "  'generates',\n",
       "  'in',\n",
       "  'humans',\n",
       "  'concerning',\n",
       "  'any',\n",
       "  'situation',\n",
       "  'or',\n",
       "  'challenge',\n",
       "  'ai',\n",
       "  'alone',\n",
       "  'cant',\n",
       "  'work',\n",
       "  'to',\n",
       "  'handle',\n",
       "  'critical',\n",
       "  'situations',\n",
       "  'on',\n",
       "  'its',\n",
       "  'own',\n",
       "  'as',\n",
       "  'it',\n",
       "  'needs',\n",
       "  'humans',\n",
       "  'for',\n",
       "  'it',\n",
       "  'to',\n",
       "  'reciprocate',\n",
       "  'them',\n",
       "  'and',\n",
       "  'share',\n",
       "  'the',\n",
       "  'information',\n",
       "  'with',\n",
       "  'stakeholders',\n",
       "  'and',\n",
       "  'humans',\n",
       "  'alone',\n",
       "  'cant',\n",
       "  'anticipate',\n",
       "  'much',\n",
       "  'on',\n",
       "  'the',\n",
       "  'accurate',\n",
       "  'and',\n",
       "  'fastpaced',\n",
       "  'analytical',\n",
       "  'solutions',\n",
       "  'to',\n",
       "  'the',\n",
       "  'problems',\n",
       "  'persisting',\n",
       "  'in',\n",
       "  'place',\n",
       "  'of',\n",
       "  'the',\n",
       "  'situation',\n",
       "  'the',\n",
       "  'strength',\n",
       "  'of',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'ai',\n",
       "  'working',\n",
       "  'in',\n",
       "  'synergy',\n",
       "  'can',\n",
       "  'be',\n",
       "  'surprisingly',\n",
       "  'beneficial',\n",
       "  'and',\n",
       "  'advantageous',\n",
       "  'to',\n",
       "  'organizations',\n",
       "  'it',\n",
       "  'is',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'machines',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'would',\n",
       "  'be',\n",
       "  'eating',\n",
       "  'up',\n",
       "  'our',\n",
       "  'traditional',\n",
       "  'jobs',\n",
       "  'but',\n",
       "  'the',\n",
       "  'reality',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'be',\n",
       "  'turning',\n",
       "  'otherwise',\n",
       "  'the',\n",
       "  'future',\n",
       "  'trend',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'in',\n",
       "  'future',\n",
       "  'the',\n",
       "  'aipowered',\n",
       "  'technology',\n",
       "  'would',\n",
       "  'take',\n",
       "  'up',\n",
       "  'jobs',\n",
       "  'that',\n",
       "  'were',\n",
       "  'being',\n",
       "  'done',\n",
       "  'by',\n",
       "  'humans',\n",
       "  'but',\n",
       "  'in',\n",
       "  'return',\n",
       "  'would',\n",
       "  'produce',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'that',\n",
       "  'would',\n",
       "  'require',\n",
       "  'human',\n",
       "  'interference',\n",
       "  'with',\n",
       "  'them',\n",
       "  'as',\n",
       "  'and',\n",
       "  'when',\n",
       "  'the',\n",
       "  'newer',\n",
       "  'technology',\n",
       "  'is',\n",
       "  'approaching',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'countries',\n",
       "  'are',\n",
       "  'now',\n",
       "  'proceeding',\n",
       "  'towards',\n",
       "  'gig',\n",
       "  'economies',\n",
       "  'and',\n",
       "  'so',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'we',\n",
       "  'can',\n",
       "  'witness',\n",
       "  'an',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'freelance',\n",
       "  'jobs',\n",
       "  'and',\n",
       "  'the',\n",
       "  'permanent',\n",
       "  'labor',\n",
       "  'market',\n",
       "  'norms',\n",
       "  'could',\n",
       "  'reduce',\n",
       "  'drastically',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'jobs',\n",
       "  'today',\n",
       "  'will',\n",
       "  'be',\n",
       "  'replaced',\n",
       "  'by',\n",
       "  'ai',\n",
       "  'which',\n",
       "  'is',\n",
       "  'in',\n",
       "  'the',\n",
       "  'transportation',\n",
       "  'or',\n",
       "  'retail',\n",
       "  'commerce',\n",
       "  'sector',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  '100',\n",
       "  'automated',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'years',\n",
       "  'there',\n",
       "  'is',\n",
       "  'an',\n",
       "  'amazon',\n",
       "  'go',\n",
       "  'store',\n",
       "  'that',\n",
       "  'uses',\n",
       "  'this',\n",
       "  'technology',\n",
       "  'which',\n",
       "  'goes',\n",
       "  'by',\n",
       "  'the',\n",
       "  'name',\n",
       "  'just',\n",
       "  'walk',\n",
       "  'out',\n",
       "  'technology',\n",
       "  'wherein',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'need',\n",
       "  'for',\n",
       "  'any',\n",
       "  'humaninduced',\n",
       "  'workforce',\n",
       "  'and',\n",
       "  'all',\n",
       "  'the',\n",
       "  'operations',\n",
       "  'are',\n",
       "  'carried',\n",
       "  'out',\n",
       "  'by',\n",
       "  'aipowered',\n",
       "  'technologies',\n",
       "  'which',\n",
       "  'is',\n",
       "  'indeed',\n",
       "  'a',\n",
       "  'breakthrough',\n",
       "  'technology',\n",
       "  'in',\n",
       "  'todays',\n",
       "  'world',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'eating',\n",
       "  'up',\n",
       "  'our',\n",
       "  'jobs',\n",
       "  'ai',\n",
       "  'in',\n",
       "  'return',\n",
       "  'will',\n",
       "  'be',\n",
       "  'creating',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'by',\n",
       "  'creating',\n",
       "  'massive',\n",
       "  'innovations',\n",
       "  'thereby',\n",
       "  'fueling',\n",
       "  'up',\n",
       "  'many',\n",
       "  'new',\n",
       "  'industries',\n",
       "  'and',\n",
       "  'thereby',\n",
       "  'giving',\n",
       "  'us',\n",
       "  'our',\n",
       "  'fair',\n",
       "  'share',\n",
       "  'of',\n",
       "  'jobs',\n",
       "  'back',\n",
       "  'there',\n",
       "  'will',\n",
       "  'be',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'demand',\n",
       "  'placed',\n",
       "  'on',\n",
       "  'the',\n",
       "  'upcoming',\n",
       "  'young',\n",
       "  'workforce',\n",
       "  'which',\n",
       "  'is',\n",
       "  'also',\n",
       "  'categorized',\n",
       "  'as',\n",
       "  'gen',\n",
       "  'z',\n",
       "  'they',\n",
       "  'are',\n",
       "  'expected',\n",
       "  'to',\n",
       "  'know',\n",
       "  'more',\n",
       "  'about',\n",
       "  'technology',\n",
       "  'and',\n",
       "  'would',\n",
       "  'be',\n",
       "  'high',\n",
       "  'in',\n",
       "  'demand',\n",
       "  'these',\n",
       "  'young',\n",
       "  'generations',\n",
       "  'are',\n",
       "  'required',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'new',\n",
       "  'skills',\n",
       "  'which',\n",
       "  'are',\n",
       "  'needed',\n",
       "  'to',\n",
       "  'survive',\n",
       "  'in',\n",
       "  'the',\n",
       "  'dynamic',\n",
       "  'changing',\n",
       "  'environment',\n",
       "  'and',\n",
       "  'as',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'activities',\n",
       "  'that',\n",
       "  'are',\n",
       "  'carried',\n",
       "  'out',\n",
       "  'by',\n",
       "  'workers',\n",
       "  'will',\n",
       "  'be',\n",
       "  'automated',\n",
       "  'there',\n",
       "  'will',\n",
       "  'be',\n",
       "  'demand',\n",
       "  'for',\n",
       "  'people',\n",
       "  'working',\n",
       "  'in',\n",
       "  'the',\n",
       "  'back',\n",
       "  'office',\n",
       "  'and',\n",
       "  'maintaining',\n",
       "  'and',\n",
       "  'developing',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'to',\n",
       "  'its',\n",
       "  'best',\n",
       "  'versions',\n",
       "  'ai',\n",
       "  'powered',\n",
       "  'technology',\n",
       "  'has',\n",
       "  'its',\n",
       "  'limitations',\n",
       "  'which',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'a',\n",
       "  'rigid',\n",
       "  'system',\n",
       "  'to',\n",
       "  'hold',\n",
       "  'on',\n",
       "  'to',\n",
       "  'and',\n",
       "  'also',\n",
       "  'which',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'a',\n",
       "  'costly',\n",
       "  'affair',\n",
       "  'at',\n",
       "  'the',\n",
       "  'initial',\n",
       "  'stage',\n",
       "  'it',\n",
       "  'was',\n",
       "  'predicted',\n",
       "  'that',\n",
       "  'the',\n",
       "  'cost',\n",
       "  'of',\n",
       "  'electricity',\n",
       "  'to',\n",
       "  'power',\n",
       "  'a',\n",
       "  'supercharged',\n",
       "  'ai',\n",
       "  'model',\n",
       "  'was',\n",
       "  'around',\n",
       "  '46',\n",
       "  'million',\n",
       "  'so',\n",
       "  'this',\n",
       "  'superpowered',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'be',\n",
       "  'purchased',\n",
       "  'only',\n",
       "  'by',\n",
       "  'big',\n",
       "  'fortune',\n",
       "  'firms',\n",
       "  'and',\n",
       "  'thereby',\n",
       "  'creating',\n",
       "  'more',\n",
       "  'value',\n",
       "  'to',\n",
       "  'their',\n",
       "  'net',\n",
       "  'worth',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'major',\n",
       "  'limitations',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  'can',\n",
       "  'contain',\n",
       "  'biased',\n",
       "  'data',\n",
       "  'as',\n",
       "  'the',\n",
       "  'scientists',\n",
       "  'who',\n",
       "  'put',\n",
       "  'in',\n",
       "  'the',\n",
       "  'data',\n",
       "  'can',\n",
       "  'create',\n",
       "  'biasedness',\n",
       "  'and',\n",
       "  'so',\n",
       "  'the',\n",
       "  'resultant',\n",
       "  'output',\n",
       "  'of',\n",
       "  'the',\n",
       "  'same',\n",
       "  'would',\n",
       "  'have',\n",
       "  'a',\n",
       "  'biased',\n",
       "  'report',\n",
       "  'these',\n",
       "  'machines',\n",
       "  'as',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'neurosciencebased',\n",
       "  'technology',\n",
       "  'in',\n",
       "  'them',\n",
       "  'yet',\n",
       "  'which',\n",
       "  'enables',\n",
       "  'them',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'human',\n",
       "  'emotions',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'complex',\n",
       "  'situations',\n",
       "  'and',\n",
       "  'a',\n",
       "  'creative',\n",
       "  'way',\n",
       "  'out',\n",
       "  'of',\n",
       "  'that',\n",
       "  'they',\n",
       "  'tend',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'lack',\n",
       "  'of',\n",
       "  'out',\n",
       "  'of',\n",
       "  'box',\n",
       "  'thinking',\n",
       "  'which',\n",
       "  'in',\n",
       "  'the',\n",
       "  'case',\n",
       "  'is',\n",
       "  'rigid',\n",
       "  'in',\n",
       "  'themselves',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'programmed',\n",
       "  'to',\n",
       "  'work',\n",
       "  'on',\n",
       "  'a',\n",
       "  'single',\n",
       "  'task',\n",
       "  'and',\n",
       "  'they',\n",
       "  'cannot',\n",
       "  'perform',\n",
       "  'more',\n",
       "  'than',\n",
       "  'a',\n",
       "  'single',\n",
       "  'task',\n",
       "  'at',\n",
       "  'the',\n",
       "  'same',\n",
       "  'time',\n",
       "  'it',\n",
       "  'is',\n",
       "  'also',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'there',\n",
       "  'exists',\n",
       "  'no',\n",
       "  'creativity',\n",
       "  'among',\n",
       "  'the',\n",
       "  'computer',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'it',\n",
       "  'is',\n",
       "  'fastpaced',\n",
       "  'but',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'intelligent',\n",
       "  'businesses',\n",
       "  'and',\n",
       "  'organizations',\n",
       "  'need',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'and',\n",
       "  'anticipate',\n",
       "  'the',\n",
       "  'opportunities',\n",
       "  'that',\n",
       "  'the',\n",
       "  'future',\n",
       "  'holds',\n",
       "  'for',\n",
       "  'them',\n",
       "  'and',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'start',\n",
       "  'training',\n",
       "  'their',\n",
       "  'employees',\n",
       "  'based',\n",
       "  'on',\n",
       "  'todays',\n",
       "  'dynamic',\n",
       "  'changing',\n",
       "  'technology',\n",
       "  'while',\n",
       "  'its',\n",
       "  'still',\n",
       "  'unclear',\n",
       "  'what',\n",
       "  'does',\n",
       "  'the',\n",
       "  'future',\n",
       "  'holds',\n",
       "  'for',\n",
       "  'us',\n",
       "  'but',\n",
       "  'the',\n",
       "  'anticipation',\n",
       "  'of',\n",
       "  'it',\n",
       "  'could',\n",
       "  'benefit',\n",
       "  'us',\n",
       "  'in',\n",
       "  'several',\n",
       "  'ways',\n",
       "  'as',\n",
       "  'we',\n",
       "  'are',\n",
       "  'unclear',\n",
       "  'about',\n",
       "  'what',\n",
       "  'the',\n",
       "  'future',\n",
       "  'looks',\n",
       "  'like',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'think',\n",
       "  'in',\n",
       "  'probable',\n",
       "  'terms',\n",
       "  'how',\n",
       "  'it',\n",
       "  'could',\n",
       "  'turn',\n",
       "  'out',\n",
       "  'to',\n",
       "  'be',\n",
       "  'and',\n",
       "  'then',\n",
       "  'employ',\n",
       "  'specific',\n",
       "  'training',\n",
       "  'programs',\n",
       "  'for',\n",
       "  'the',\n",
       "  'employees',\n",
       "  'of',\n",
       "  'the',\n",
       "  'organization'],\n",
       " ['the',\n",
       "  'training',\n",
       "  'the',\n",
       "  'employees',\n",
       "  'are',\n",
       "  'needed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'done',\n",
       "  'on',\n",
       "  'a',\n",
       "  'continuous',\n",
       "  'and',\n",
       "  'lifetime',\n",
       "  'basis',\n",
       "  'which',\n",
       "  'means',\n",
       "  'that',\n",
       "  'education',\n",
       "  'wont',\n",
       "  'be',\n",
       "  'only',\n",
       "  'limited',\n",
       "  'to',\n",
       "  'pg',\n",
       "  'degrees',\n",
       "  'but',\n",
       "  'will',\n",
       "  'be',\n",
       "  'now',\n",
       "  'a',\n",
       "  'lifetime',\n",
       "  'process',\n",
       "  'of',\n",
       "  'learning',\n",
       "  'as',\n",
       "  'the',\n",
       "  'covid19',\n",
       "  'changed',\n",
       "  'the',\n",
       "  'scenario',\n",
       "  'of',\n",
       "  'the',\n",
       "  'work',\n",
       "  'patterns',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'we',\n",
       "  'now',\n",
       "  'need',\n",
       "  'to',\n",
       "  'think',\n",
       "  'strategically',\n",
       "  'about',\n",
       "  'the',\n",
       "  'working',\n",
       "  'dynamics',\n",
       "  'of',\n",
       "  'the',\n",
       "  'future',\n",
       "  'and',\n",
       "  'how',\n",
       "  'does',\n",
       "  'it',\n",
       "  'look',\n",
       "  'like',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'the',\n",
       "  'precovid',\n",
       "  'and',\n",
       "  'postcovid',\n",
       "  'scenario',\n",
       "  'employees',\n",
       "  'will',\n",
       "  'be',\n",
       "  'playing',\n",
       "  'a',\n",
       "  'major',\n",
       "  'role',\n",
       "  'in',\n",
       "  'transforming',\n",
       "  'the',\n",
       "  'organizations',\n",
       "  'and',\n",
       "  'work',\n",
       "  'practices',\n",
       "  'in',\n",
       "  'the',\n",
       "  'upcoming',\n",
       "  'future',\n",
       "  'so',\n",
       "  'organizations',\n",
       "  'need',\n",
       "  'to',\n",
       "  'select',\n",
       "  'and',\n",
       "  'recruit',\n",
       "  'the',\n",
       "  'best',\n",
       "  'candidates',\n",
       "  'among',\n",
       "  'the',\n",
       "  'pool',\n",
       "  'and',\n",
       "  'then',\n",
       "  'provide',\n",
       "  'them',\n",
       "  'with',\n",
       "  'best',\n",
       "  'practices',\n",
       "  'of',\n",
       "  'the',\n",
       "  'new',\n",
       "  'machines',\n",
       "  'and',\n",
       "  'make',\n",
       "  'proficient',\n",
       "  'in',\n",
       "  'their',\n",
       "  'area',\n",
       "  'of',\n",
       "  'work',\n",
       "  'policies',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'developed',\n",
       "  'to',\n",
       "  'hire',\n",
       "  'the',\n",
       "  'best',\n",
       "  'people',\n",
       "  'and',\n",
       "  'then',\n",
       "  'retaining',\n",
       "  'the',\n",
       "  'talent',\n",
       "  'in',\n",
       "  'the',\n",
       "  'organization',\n",
       "  'there',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'continuous',\n",
       "  'scanning',\n",
       "  'of',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'by',\n",
       "  'the',\n",
       "  'organizations',\n",
       "  'to',\n",
       "  'comprehend',\n",
       "  'any',\n",
       "  'new',\n",
       "  'trends',\n",
       "  'and',\n",
       "  'assess',\n",
       "  'them',\n",
       "  'not',\n",
       "  'all',\n",
       "  'trends',\n",
       "  'will',\n",
       "  'be',\n",
       "  'beneficial',\n",
       "  'for',\n",
       "  'organizations',\n",
       "  'they',\n",
       "  'must',\n",
       "  'be',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'the',\n",
       "  'prospects',\n",
       "  'and',\n",
       "  'plan',\n",
       "  'for',\n",
       "  'the',\n",
       "  'future',\n",
       "  'systematically',\n",
       "  'and',\n",
       "  'consistently',\n",
       "  'there',\n",
       "  'lies',\n",
       "  'a',\n",
       "  'possibility',\n",
       "  'in',\n",
       "  'future',\n",
       "  'certain',\n",
       "  'years',\n",
       "  'from',\n",
       "  'now',\n",
       "  'we',\n",
       "  'could',\n",
       "  'have',\n",
       "  'machines',\n",
       "  'who',\n",
       "  'will',\n",
       "  'have',\n",
       "  'general',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'who',\n",
       "  'would',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'answer',\n",
       "  'deep',\n",
       "  'meaningful',\n",
       "  'questions',\n",
       "  'asking',\n",
       "  'why',\n",
       "  'are',\n",
       "  'the',\n",
       "  'curtains',\n",
       "  'blue?',\n",
       "  'would',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'clean',\n",
       "  'cars',\n",
       "  'play',\n",
       "  'politics',\n",
       "  'and',\n",
       "  'tell',\n",
       "  'jokes',\n",
       "  'to',\n",
       "  'us',\n",
       "  'and',\n",
       "  'by',\n",
       "  'using',\n",
       "  'deep',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'programs',\n",
       "  'their',\n",
       "  'level',\n",
       "  'of',\n",
       "  'intelligence',\n",
       "  'would',\n",
       "  'be',\n",
       "  'beyond',\n",
       "  'mathematical',\n",
       "  'calculations',\n",
       "  'to',\n",
       "  'us',\n",
       "  'thats',\n",
       "  'how',\n",
       "  'good',\n",
       "  'machines',\n",
       "  'will',\n",
       "  'be',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'but',\n",
       "  'to',\n",
       "  'make',\n",
       "  'ourselves',\n",
       "  'competitive',\n",
       "  'with',\n",
       "  'machines',\n",
       "  'we',\n",
       "  'would',\n",
       "  'need',\n",
       "  'to',\n",
       "  'train',\n",
       "  'ourselves',\n",
       "  'for',\n",
       "  'the',\n",
       "  'impending',\n",
       "  'ambiguous',\n",
       "  'future',\n",
       "  'ahead',\n",
       "  'of',\n",
       "  'us',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'machines',\n",
       "  'need',\n",
       "  'to',\n",
       "  'work',\n",
       "  'in',\n",
       "  'synergy',\n",
       "  'to',\n",
       "  'get',\n",
       "  'beneficial',\n",
       "  'and',\n",
       "  'satisfying',\n",
       "  'results',\n",
       "  'for',\n",
       "  'both',\n",
       "  'parties',\n",
       "  'machines',\n",
       "  'are',\n",
       "  'indeed',\n",
       "  'going',\n",
       "  'take',\n",
       "  'away',\n",
       "  'many',\n",
       "  'of',\n",
       "  'our',\n",
       "  'jobs',\n",
       "  'but',\n",
       "  'let',\n",
       "  'me',\n",
       "  'make',\n",
       "  'you',\n",
       "  'sleep',\n",
       "  'peacefully',\n",
       "  'tonight',\n",
       "  'the',\n",
       "  'machines',\n",
       "  'arent',\n",
       "  'arriving',\n",
       "  'until',\n",
       "  'were',\n",
       "  'retired']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/50.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1710e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a953474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 996\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "256540a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 21.67105263157895\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a6afbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3273092369477912\n",
      "FOG INDEX: 8.799344747410696\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 21.67105263157895\n",
      "COMPLEX WORD COUNT: 326\n",
      "WORD COUNT: 996\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5bb7e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2968\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb9b2624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 1\n",
      "we: 9\n",
      "my: 1\n",
      "ours: 0\n",
      "us: 10\n",
      "Total count: 21\n",
      "PERSONAL PRONOUNS: 21\n",
      "AVG WORD LENGTH: 4.896782027929569\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_50.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7dd759",
   "metadata": {},
   "source": [
    "# 15. for url 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "651d33ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\1213786014.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "539f0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial intelligence and employment are the burning issues nowadays workers need clarity on as we head into the longer term. This article focuses on the various impact of AI on our jobs and explains the benefits of AI in our workplace. That right there must have hit a nerve. However, everything is about to change because this article highlights some of the reasons we should not fear AI.',\n",
       " 'AI is the abbreviation of Artificial Intelligence. Artificial intelligence is often defined as a set of various technologies which will be brought together to permit machines to act with what appears to be human-like levels of intelligence. This includes learning rules required to make certain decisions and reasoning to arrive at certain conclusions, learning from past experiences, and self-correction.',\n",
       " 'AI is of two types.',\n",
       " '1940',\n",
       " 'Expectations that machines could match humans in terms of general intelligence. By that, we mean machines could have the capability to find out, Reason, and React.',\n",
       " '1950',\n",
       " 'Alan Turing develops the Turing Test; a test to determine whether a machine is intelligent.However, it wasn’t for another 60 years or so that any program was deemed to have passed.',\n",
       " '1955',\n",
       " 'The first time a computer virus defeats a person’s World Champion during a parlor game.',\n",
       " '1956',\n",
       " 'John McCarthy invents the new term ‘Artificial Intelligence’ when he held the primary Academic Conference on the subject of AI.',\n",
       " '1962',\n",
       " 'Arthur Samuel‘s machine learning checkers (draughts) program, beat a checkers master.',\n",
       " '1980',\n",
       " 'Reinforcement Learning is introduced. This is a kind of programming that uses rewards and punishments to coach a machine to interact with its environment.',\n",
       " '2012',\n",
       " 'A research group led by Geoffrey Hinton wins the Image Net competition – this competition requires AI to categorize about 1.2 million images into any of 10,000 different categories. The level of accuracy was adequate to that of the typical human completing an equivalent task manually.',\n",
       " '2014',\n",
       " 'Eugene Goostman’s chatbot, a bot pretending to be a 13-year-old boy, supposedly passes the Turing Test, a test which nobody has passed before! But controversy arose with this claim as:',\n",
       " '1. Experts claim it only lasted five minutes.',\n",
       " '2. It had been deemed biased as Eugene’s mother tongue (Ukrainian) wasn’t equivalent to the judge’s (English), which is a plus as language is one among the few ways we will tell the difference between a person’s and machine.',\n",
       " '2018',\n",
       " 'Alibaba’s AI Model performs better than humans during a reading and comprehension test at Stanford University, scoring 82.44 against the 82.304 scored by humans!',\n",
       " 'Artificial Intelligence (AI) is here to remain, and lots of people aren’t happy. After all, it’s hard to embrace something that would displace about 40 percent of human jobs within the next 15 years. In an interview for CBS’s hour, Kai-Fu Lee (a Chinese AI expert) also mentioned truck drivers, chauffeurs, waiters, and chefs as a number of the professions that will be disrupted.',\n",
       " 'But if you were to ask the experts, they might unwaveringly confirm that no matter all the noise, AI is here to profit us all. Case in point, an executive briefing by the McKinsey Global Institute revealed that AI and automation are creating opportunities for the economy, society, and business.',\n",
       " 'That said, it’s time to repress the widespread idea of artificial intelligence taking jobs. So, let’s highlight a number of the useful developments you’ll expect from this technological phenomenon.',\n",
       " 'While the relationship between artificial intelligence and jobs is a matter of hot debate, it is still safe to say that AI will indeed offer new opportunities. According to the planet Economic Forum report, robots and AI will create as many AI jobs as they displace. This conclusion is entirely viable as it is easy to identify some of the many careers in artificial intelligence, for example, data scientists, who evaluate the decisions made by AI algorithms to eliminate any biases. Apart from that, some other AI occupations include:',\n",
       " 'Transparency analysts: people tasked with classifying the varied sorts of opacity for algorithms. Smart-system interaction modelers: experts who develop machine behavior based on employee behavior. Machine-relations managers: people that champion the greater use of algorithms that perform well. As far because the competition for jobs between humans and robots goes, worth noting is that there are jobs that AI can’t replace. Roles that need leadership, empathy, and delegation are samples of the various jobs that are safe from automation.',\n",
       " 'Automation will stir positive change in the workplace. When AI is employed during recruitment or maybe performance management, all workers are going to be evaluated in an unbiased, fact-based manner. In turn, Human Resources managers can get to consider other essential strategic undertakings that ensure balance within the workplace.',\n",
       " 'AI can help HR departments to use machine learning (ML) in discovering where issues like bias stem from and assist them to act accordingly faster. ML shines in identifying instances of bias. In turn, this may promote fairness and variety within the work setting.',\n",
       " 'The impact of AI in business is already felt, and this is often expected to continue through to the longer term. A few years from now, AI-oriented architecture is forecasted to require the lead in assisting businesses to hold out operations in additional comprehensive ways, thus shifting them from traditional data science and machine learning models. It will be necessary to maneuver to business outcomes because AI will play an important role in multiple aspects of the business. While there is no way of telling the future of artificial intelligence in business for sure, it makes sense for owners to keep up with the evolution to avoid being left behind.',\n",
       " 'The workforce of the longer term will lean more towards innovation and creativity. Businesses have spent higher a part of the previous couple of years studying AI automation and the way they will leverage it to realize results fast. With statistics showing that workers spend up to 40 percent of their hours at work performing repetitive tasks, every business should consider automating any functions which will be automated. Automation is not new; machines have been replacing human labor in different areas for decades.',\n",
       " 'However, within the coming years, mundane daily tasks will become fully automated. Already, 39 percent of organizations were completely reliant on automation in 2018. With repetitive tasks taken care of, employees can focus their energies on high-value customer-oriented tasks and collaboration. The designs of workplaces and workflows will also change with the implementation of AI technology. More people will begin to figure more closely with machines as companies will strive to become more agile.',\n",
       " 'Companies that implement AI in their business strategy will experience dramatic improvements in their customer experiences, and their employees are going to be more motivated. Encouraging creativity rather than the performance of repetitive tasks gives workers more fulfillment in their jobs as well.',\n",
       " 'With the web of things and AI working hand in hand, identifying trends and solving problems within the business world will become more convenient and also sustainable. AI, alongside other technologies, is predicted to vary the planet by impacting the way businesses run. With time, we’ll be ready to combine both human and artificial brains to seek out solutions to major global problems.',\n",
       " 'It will even be easier to foresee problems with more accuracy and nip them at the bud with the help of AI. But these positive impacts can only be felt if stakeholders are transparent and mindful in their use of the technology for the greater good of everyone else.',\n",
       " 'According to a report by PWC, 54 percent of companies confirm that the implementation of AI-driven solutions in their companies has already improved productivity. AI and automation, even once they are implemented partially, have unlimited potential for any business. Workers’ skills, attitude, training, command chain, and workflows protocols are a number of the leading productivity challenges that companies face.',\n",
       " 'Apart from increasing productivity, AI systems will help businesses to chop down on costs, improve the standard of their products or services, and make better customer profiles. As a result, companies also will get higher profits, which may be shared among stakeholders as dividends, or reinvest it back within the business. Improved productivity also means firms are going to be ready to sell their products at lower prices, thereby creating more demand among customers and more job opportunities for workers. Businesses can, therefore, use human labor to take up those jobs that have been created by AI and cannot be automated.',\n",
       " 'Artificial Intelligence isn’t showing any signs of slowing down. Soon, it’ll become another necessity of life, a bit like the web. But for now, more and more businesses are beginning to realize how invaluable AI automation and data interpretation are. Though machines will take some jobs initially, the roles created by automation will also keep soaring within the next few years.',\n",
       " 'Will, we’ve reached the purpose of accelerating human intelligence by artificial means? Who knows? What we all know, however, is that those that are going to be sought-after in AI and employment are individuals who have the relevant skills. There’s work that not even the machines can do; so, we should make ourselves as valuable as we can be in our field and we will be irreplaceable.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1572be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:56]))\n",
    "URL_ID_51 = \" \".join((titles, texts))\n",
    "\n",
    "URL_ID_51 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72346c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 81 sentences in the string.\n",
      "The number of words in the string is: 1529\n",
      "The number of characters in the string is: 8045\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_51.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_51.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_51.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05ce93c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 13:52:52] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 13:52:59] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_51 = re.sub(re_punt, \"\",URL_ID_51)\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"51.txt\", \"w\")\n",
    "file.write(URL_ID_51)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"51.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c54b363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['artificial',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'employment',\n",
       "  'are',\n",
       "  'the',\n",
       "  'burning',\n",
       "  'issues',\n",
       "  'nowadays',\n",
       "  'workers',\n",
       "  'need',\n",
       "  'clarity',\n",
       "  'on',\n",
       "  'as',\n",
       "  'we',\n",
       "  'head',\n",
       "  'into',\n",
       "  'the',\n",
       "  'longer',\n",
       "  'term',\n",
       "  'this',\n",
       "  'article',\n",
       "  'focuses',\n",
       "  'on',\n",
       "  'the',\n",
       "  'various',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'on',\n",
       "  'our',\n",
       "  'jobs',\n",
       "  'and',\n",
       "  'explains',\n",
       "  'the',\n",
       "  'benefits',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'in',\n",
       "  'our',\n",
       "  'workplace',\n",
       "  'that',\n",
       "  'right',\n",
       "  'there',\n",
       "  'must',\n",
       "  'have',\n",
       "  'hit',\n",
       "  'a',\n",
       "  'nerve',\n",
       "  'however',\n",
       "  'everything',\n",
       "  'is',\n",
       "  'about',\n",
       "  'to',\n",
       "  'change',\n",
       "  'because',\n",
       "  'this',\n",
       "  'article',\n",
       "  'highlights',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'reasons',\n",
       "  'we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'fear',\n",
       "  'ai',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'the',\n",
       "  'abbreviation',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'often',\n",
       "  'defined',\n",
       "  'as',\n",
       "  'a',\n",
       "  'set',\n",
       "  'of',\n",
       "  'various',\n",
       "  'technologies',\n",
       "  'which',\n",
       "  'will',\n",
       "  'be',\n",
       "  'brought',\n",
       "  'together',\n",
       "  'to',\n",
       "  'permit',\n",
       "  'machines',\n",
       "  'to',\n",
       "  'act',\n",
       "  'with',\n",
       "  'what',\n",
       "  'appears',\n",
       "  'to',\n",
       "  'be',\n",
       "  'humanlike',\n",
       "  'levels',\n",
       "  'of',\n",
       "  'intelligence',\n",
       "  'this',\n",
       "  'includes',\n",
       "  'learning',\n",
       "  'rules',\n",
       "  'required',\n",
       "  'to',\n",
       "  'make',\n",
       "  'certain',\n",
       "  'decisions',\n",
       "  'and',\n",
       "  'reasoning',\n",
       "  'to',\n",
       "  'arrive',\n",
       "  'at',\n",
       "  'certain',\n",
       "  'conclusions',\n",
       "  'learning',\n",
       "  'from',\n",
       "  'past',\n",
       "  'experiences',\n",
       "  'and',\n",
       "  'selfcorrection',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'of',\n",
       "  'two',\n",
       "  'types',\n",
       "  '1940',\n",
       "  'expectations',\n",
       "  'that',\n",
       "  'machines',\n",
       "  'could',\n",
       "  'match',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'general',\n",
       "  'intelligence',\n",
       "  'by',\n",
       "  'that',\n",
       "  'we',\n",
       "  'mean',\n",
       "  'machines',\n",
       "  'could',\n",
       "  'have',\n",
       "  'the',\n",
       "  'capability',\n",
       "  'to',\n",
       "  'find',\n",
       "  'out',\n",
       "  'reason',\n",
       "  'and',\n",
       "  'react',\n",
       "  '1950',\n",
       "  'alan',\n",
       "  'turing',\n",
       "  'develops',\n",
       "  'the',\n",
       "  'turing',\n",
       "  'test',\n",
       "  'a',\n",
       "  'test',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'whether',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'is',\n",
       "  'intelligenthowever',\n",
       "  'it',\n",
       "  'wasnt',\n",
       "  'for',\n",
       "  'another',\n",
       "  '60',\n",
       "  'years',\n",
       "  'or',\n",
       "  'so',\n",
       "  'that',\n",
       "  'any',\n",
       "  'program',\n",
       "  'was',\n",
       "  'deemed',\n",
       "  'to',\n",
       "  'have',\n",
       "  'passed',\n",
       "  '1955',\n",
       "  'the',\n",
       "  'first',\n",
       "  'time',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'virus',\n",
       "  'defeats',\n",
       "  'a',\n",
       "  'persons',\n",
       "  'world',\n",
       "  'champion',\n",
       "  'during',\n",
       "  'a',\n",
       "  'parlor',\n",
       "  'game',\n",
       "  '1956',\n",
       "  'john',\n",
       "  'mccarthy',\n",
       "  'invents',\n",
       "  'the',\n",
       "  'new',\n",
       "  'term',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'when',\n",
       "  'he',\n",
       "  'held',\n",
       "  'the',\n",
       "  'primary',\n",
       "  'academic',\n",
       "  'conference',\n",
       "  'on',\n",
       "  'the',\n",
       "  'subject',\n",
       "  'of',\n",
       "  'ai',\n",
       "  '1962',\n",
       "  'arthur',\n",
       "  'samuels',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'checkers',\n",
       "  'draughts',\n",
       "  'program',\n",
       "  'beat',\n",
       "  'a',\n",
       "  'checkers',\n",
       "  'master',\n",
       "  '1980',\n",
       "  'reinforcement',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'introduced',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'programming',\n",
       "  'that',\n",
       "  'uses',\n",
       "  'rewards',\n",
       "  'and',\n",
       "  'punishments',\n",
       "  'to',\n",
       "  'coach',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'to',\n",
       "  'interact',\n",
       "  'with',\n",
       "  'its',\n",
       "  'environment',\n",
       "  '2012',\n",
       "  'a',\n",
       "  'research',\n",
       "  'group',\n",
       "  'led',\n",
       "  'by',\n",
       "  'geoffrey',\n",
       "  'hinton',\n",
       "  'wins',\n",
       "  'the',\n",
       "  'image',\n",
       "  'net',\n",
       "  'competition',\n",
       "  'this',\n",
       "  'competition',\n",
       "  'requires',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'categorize',\n",
       "  'about',\n",
       "  '12',\n",
       "  'million',\n",
       "  'images',\n",
       "  'into',\n",
       "  'any',\n",
       "  'of',\n",
       "  '10000',\n",
       "  'different',\n",
       "  'categories',\n",
       "  'the',\n",
       "  'level',\n",
       "  'of',\n",
       "  'accuracy',\n",
       "  'was',\n",
       "  'adequate',\n",
       "  'to',\n",
       "  'that',\n",
       "  'of',\n",
       "  'the',\n",
       "  'typical',\n",
       "  'human',\n",
       "  'completing',\n",
       "  'an',\n",
       "  'equivalent',\n",
       "  'task',\n",
       "  'manually',\n",
       "  '2014',\n",
       "  'eugene',\n",
       "  'goostmans',\n",
       "  'chatbot',\n",
       "  'a',\n",
       "  'bot',\n",
       "  'pretending',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  '13yearold',\n",
       "  'boy',\n",
       "  'supposedly',\n",
       "  'passes',\n",
       "  'the',\n",
       "  'turing',\n",
       "  'test',\n",
       "  'a',\n",
       "  'test',\n",
       "  'which',\n",
       "  'nobody',\n",
       "  'has',\n",
       "  'passed',\n",
       "  'before!',\n",
       "  'but',\n",
       "  'controversy',\n",
       "  'arose',\n",
       "  'with',\n",
       "  'this',\n",
       "  'claim',\n",
       "  'as',\n",
       "  '1',\n",
       "  'experts',\n",
       "  'claim',\n",
       "  'it',\n",
       "  'only',\n",
       "  'lasted',\n",
       "  'five',\n",
       "  'minutes',\n",
       "  '2',\n",
       "  'it',\n",
       "  'had',\n",
       "  'been',\n",
       "  'deemed',\n",
       "  'biased',\n",
       "  'as',\n",
       "  'eugenes',\n",
       "  'mother',\n",
       "  'tongue',\n",
       "  'ukrainian',\n",
       "  'wasnt',\n",
       "  'equivalent',\n",
       "  'to',\n",
       "  'the',\n",
       "  'judges',\n",
       "  'english',\n",
       "  'which',\n",
       "  'is',\n",
       "  'a',\n",
       "  'plus',\n",
       "  'as',\n",
       "  'language',\n",
       "  'is',\n",
       "  'one',\n",
       "  'among',\n",
       "  'the',\n",
       "  'few',\n",
       "  'ways',\n",
       "  'we',\n",
       "  'will',\n",
       "  'tell',\n",
       "  'the',\n",
       "  'difference',\n",
       "  'between',\n",
       "  'a',\n",
       "  'persons',\n",
       "  'and',\n",
       "  'machine',\n",
       "  '2018',\n",
       "  'alibabas',\n",
       "  'ai',\n",
       "  'model',\n",
       "  'performs',\n",
       "  'better',\n",
       "  'than',\n",
       "  'humans',\n",
       "  'during',\n",
       "  'a',\n",
       "  'reading',\n",
       "  'and',\n",
       "  'comprehension',\n",
       "  'test',\n",
       "  'at',\n",
       "  'stanford',\n",
       "  'university',\n",
       "  'scoring',\n",
       "  '8244',\n",
       "  'against',\n",
       "  'the',\n",
       "  '82304',\n",
       "  'scored',\n",
       "  'by',\n",
       "  'humans!',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'here',\n",
       "  'to',\n",
       "  'remain',\n",
       "  'and',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'people',\n",
       "  'arent',\n",
       "  'happy',\n",
       "  'after',\n",
       "  'all',\n",
       "  'its',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'embrace',\n",
       "  'something',\n",
       "  'that',\n",
       "  'would',\n",
       "  'displace',\n",
       "  'about',\n",
       "  '40',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'human',\n",
       "  'jobs',\n",
       "  'within',\n",
       "  'the',\n",
       "  'next',\n",
       "  '15',\n",
       "  'years',\n",
       "  'in',\n",
       "  'an',\n",
       "  'interview',\n",
       "  'for',\n",
       "  'cbss',\n",
       "  'hour',\n",
       "  'kaifu',\n",
       "  'lee',\n",
       "  'a',\n",
       "  'chinese',\n",
       "  'ai',\n",
       "  'expert',\n",
       "  'also',\n",
       "  'mentioned',\n",
       "  'truck',\n",
       "  'drivers',\n",
       "  'chauffeurs',\n",
       "  'waiters',\n",
       "  'and',\n",
       "  'chefs',\n",
       "  'as',\n",
       "  'a',\n",
       "  'number',\n",
       "  'of',\n",
       "  'the',\n",
       "  'professions',\n",
       "  'that',\n",
       "  'will',\n",
       "  'be',\n",
       "  'disrupted',\n",
       "  'but',\n",
       "  'if',\n",
       "  'you',\n",
       "  'were',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'the',\n",
       "  'experts',\n",
       "  'they',\n",
       "  'might',\n",
       "  'unwaveringly',\n",
       "  'confirm',\n",
       "  'that',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'all',\n",
       "  'the',\n",
       "  'noise',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'here',\n",
       "  'to',\n",
       "  'profit',\n",
       "  'us',\n",
       "  'all',\n",
       "  'case',\n",
       "  'in',\n",
       "  'point',\n",
       "  'an',\n",
       "  'executive',\n",
       "  'briefing',\n",
       "  'by',\n",
       "  'the',\n",
       "  'mckinsey',\n",
       "  'global',\n",
       "  'institute',\n",
       "  'revealed',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'automation',\n",
       "  'are',\n",
       "  'creating',\n",
       "  'opportunities',\n",
       "  'for',\n",
       "  'the',\n",
       "  'economy',\n",
       "  'society',\n",
       "  'and',\n",
       "  'business',\n",
       "  'that',\n",
       "  'said',\n",
       "  'its',\n",
       "  'time',\n",
       "  'to',\n",
       "  'repress',\n",
       "  'the',\n",
       "  'widespread',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'taking',\n",
       "  'jobs',\n",
       "  'so',\n",
       "  'lets',\n",
       "  'highlight',\n",
       "  'a',\n",
       "  'number',\n",
       "  'of',\n",
       "  'the',\n",
       "  'useful',\n",
       "  'developments',\n",
       "  'youll',\n",
       "  'expect',\n",
       "  'from',\n",
       "  'this',\n",
       "  'technological',\n",
       "  'phenomenon',\n",
       "  'while',\n",
       "  'the',\n",
       "  'relationship',\n",
       "  'between',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'jobs',\n",
       "  'is',\n",
       "  'a',\n",
       "  'matter',\n",
       "  'of',\n",
       "  'hot',\n",
       "  'debate',\n",
       "  'it',\n",
       "  'is',\n",
       "  'still',\n",
       "  'safe',\n",
       "  'to',\n",
       "  'say',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'indeed',\n",
       "  'offer',\n",
       "  'new',\n",
       "  'opportunities',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'planet',\n",
       "  'economic',\n",
       "  'forum',\n",
       "  'report',\n",
       "  'robots',\n",
       "  'and',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'create',\n",
       "  'as',\n",
       "  'many',\n",
       "  'ai',\n",
       "  'jobs',\n",
       "  'as',\n",
       "  'they',\n",
       "  'displace',\n",
       "  'this',\n",
       "  'conclusion',\n",
       "  'is',\n",
       "  'entirely',\n",
       "  'viable',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'many',\n",
       "  'careers',\n",
       "  'in',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'for',\n",
       "  'example',\n",
       "  'data',\n",
       "  'scientists',\n",
       "  'who',\n",
       "  'evaluate',\n",
       "  'the',\n",
       "  'decisions',\n",
       "  'made',\n",
       "  'by',\n",
       "  'ai',\n",
       "  'algorithms',\n",
       "  'to',\n",
       "  'eliminate',\n",
       "  'any',\n",
       "  'biases',\n",
       "  'apart',\n",
       "  'from',\n",
       "  'that',\n",
       "  'some',\n",
       "  'other',\n",
       "  'ai',\n",
       "  'occupations',\n",
       "  'include',\n",
       "  'transparency',\n",
       "  'analysts',\n",
       "  'people',\n",
       "  'tasked',\n",
       "  'with',\n",
       "  'classifying',\n",
       "  'the',\n",
       "  'varied',\n",
       "  'sorts',\n",
       "  'of',\n",
       "  'opacity',\n",
       "  'for',\n",
       "  'algorithms',\n",
       "  'smartsystem',\n",
       "  'interaction',\n",
       "  'modelers',\n",
       "  'experts',\n",
       "  'who',\n",
       "  'develop',\n",
       "  'machine',\n",
       "  'behavior',\n",
       "  'based',\n",
       "  'on',\n",
       "  'employee',\n",
       "  'behavior',\n",
       "  'machinerelations',\n",
       "  'managers',\n",
       "  'people',\n",
       "  'that',\n",
       "  'champion',\n",
       "  'the',\n",
       "  'greater',\n",
       "  'use',\n",
       "  'of',\n",
       "  'algorithms',\n",
       "  'that',\n",
       "  'perform',\n",
       "  'well',\n",
       "  'as',\n",
       "  'far',\n",
       "  'because',\n",
       "  'the',\n",
       "  'competition',\n",
       "  'for',\n",
       "  'jobs',\n",
       "  'between',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'robots',\n",
       "  'goes',\n",
       "  'worth',\n",
       "  'noting',\n",
       "  'is',\n",
       "  'that',\n",
       "  'there',\n",
       "  'are',\n",
       "  'jobs',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'cant',\n",
       "  'replace',\n",
       "  'roles',\n",
       "  'that',\n",
       "  'need',\n",
       "  'leadership',\n",
       "  'empathy',\n",
       "  'and',\n",
       "  'delegation',\n",
       "  'are',\n",
       "  'samples',\n",
       "  'of',\n",
       "  'the',\n",
       "  'various',\n",
       "  'jobs',\n",
       "  'that',\n",
       "  'are',\n",
       "  'safe',\n",
       "  'from',\n",
       "  'automation',\n",
       "  'automation',\n",
       "  'will',\n",
       "  'stir',\n",
       "  'positive',\n",
       "  'change',\n",
       "  'in',\n",
       "  'the',\n",
       "  'workplace',\n",
       "  'when',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'employed',\n",
       "  'during',\n",
       "  'recruitment',\n",
       "  'or',\n",
       "  'maybe',\n",
       "  'performance',\n",
       "  'management',\n",
       "  'all',\n",
       "  'workers',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'evaluated',\n",
       "  'in',\n",
       "  'an',\n",
       "  'unbiased',\n",
       "  'factbased',\n",
       "  'manner',\n",
       "  'in',\n",
       "  'turn',\n",
       "  'human',\n",
       "  'resources',\n",
       "  'managers',\n",
       "  'can',\n",
       "  'get',\n",
       "  'to',\n",
       "  'consider',\n",
       "  'other',\n",
       "  'essential',\n",
       "  'strategic',\n",
       "  'undertakings',\n",
       "  'that',\n",
       "  'ensure',\n",
       "  'balance',\n",
       "  'within',\n",
       "  'the',\n",
       "  'workplace',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'help',\n",
       "  'hr',\n",
       "  'departments',\n",
       "  'to',\n",
       "  'use',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'ml',\n",
       "  'in',\n",
       "  'discovering',\n",
       "  'where',\n",
       "  'issues',\n",
       "  'like',\n",
       "  'bias',\n",
       "  'stem',\n",
       "  'from',\n",
       "  'and',\n",
       "  'assist',\n",
       "  'them',\n",
       "  'to',\n",
       "  'act',\n",
       "  'accordingly',\n",
       "  'faster',\n",
       "  'ml',\n",
       "  'shines',\n",
       "  'in',\n",
       "  'identifying',\n",
       "  'instances',\n",
       "  'of',\n",
       "  'bias',\n",
       "  'in',\n",
       "  'turn',\n",
       "  'this',\n",
       "  'may',\n",
       "  'promote',\n",
       "  'fairness',\n",
       "  'and',\n",
       "  'variety',\n",
       "  'within',\n",
       "  'the',\n",
       "  'work',\n",
       "  'setting',\n",
       "  'the',\n",
       "  'impact',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'in',\n",
       "  'business',\n",
       "  'is',\n",
       "  'already',\n",
       "  'felt',\n",
       "  'and',\n",
       "  'this',\n",
       "  'is',\n",
       "  'often',\n",
       "  'expected',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'through',\n",
       "  'to',\n",
       "  'the',\n",
       "  'longer',\n",
       "  'term',\n",
       "  'a',\n",
       "  'few',\n",
       "  'years',\n",
       "  'from',\n",
       "  'now',\n",
       "  'aioriented',\n",
       "  'architecture',\n",
       "  'is',\n",
       "  'forecasted',\n",
       "  'to',\n",
       "  'require',\n",
       "  'the',\n",
       "  'lead',\n",
       "  'in',\n",
       "  'assisting',\n",
       "  'businesses',\n",
       "  'to',\n",
       "  'hold',\n",
       "  'out',\n",
       "  'operations',\n",
       "  'in',\n",
       "  'additional',\n",
       "  'comprehensive',\n",
       "  'ways',\n",
       "  'thus',\n",
       "  'shifting',\n",
       "  'them',\n",
       "  'from',\n",
       "  'traditional',\n",
       "  'data',\n",
       "  'science',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'models',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'necessary',\n",
       "  'to',\n",
       "  'maneuver',\n",
       "  'to',\n",
       "  'business',\n",
       "  'outcomes',\n",
       "  'because',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'play',\n",
       "  'an',\n",
       "  'important',\n",
       "  'role',\n",
       "  'in',\n",
       "  'multiple',\n",
       "  'aspects',\n",
       "  'of',\n",
       "  'the',\n",
       "  'business',\n",
       "  'while',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'way',\n",
       "  'of',\n",
       "  'telling',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'in',\n",
       "  'business',\n",
       "  'for',\n",
       "  'sure',\n",
       "  'it',\n",
       "  'makes',\n",
       "  'sense',\n",
       "  'for',\n",
       "  'owners',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'up',\n",
       "  'with',\n",
       "  'the',\n",
       "  'evolution',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'being',\n",
       "  'left',\n",
       "  'behind',\n",
       "  'the',\n",
       "  'workforce',\n",
       "  'of',\n",
       "  'the',\n",
       "  'longer',\n",
       "  'term',\n",
       "  'will',\n",
       "  'lean',\n",
       "  'more',\n",
       "  'towards',\n",
       "  'innovation',\n",
       "  'and',\n",
       "  'creativity',\n",
       "  'businesses',\n",
       "  'have',\n",
       "  'spent',\n",
       "  'higher',\n",
       "  'a',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'previous',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'years',\n",
       "  'studying',\n",
       "  'ai',\n",
       "  'automation',\n",
       "  'and',\n",
       "  'the',\n",
       "  'way',\n",
       "  'they',\n",
       "  'will',\n",
       "  'leverage',\n",
       "  'it',\n",
       "  'to',\n",
       "  'realize',\n",
       "  'results',\n",
       "  'fast',\n",
       "  'with',\n",
       "  'statistics',\n",
       "  'showing',\n",
       "  'that',\n",
       "  'workers',\n",
       "  'spend',\n",
       "  'up',\n",
       "  'to',\n",
       "  '40',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'their',\n",
       "  'hours',\n",
       "  'at',\n",
       "  'work',\n",
       "  'performing',\n",
       "  'repetitive',\n",
       "  'tasks',\n",
       "  'every',\n",
       "  'business',\n",
       "  'should',\n",
       "  'consider',\n",
       "  'automating',\n",
       "  'any',\n",
       "  'functions',\n",
       "  'which',\n",
       "  'will',\n",
       "  'be',\n",
       "  'automated',\n",
       "  'automation',\n",
       "  'is',\n",
       "  'not',\n",
       "  'new',\n",
       "  ...]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/51.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34e7974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1528\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0db028ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 958\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8b8f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 18.876543209876544\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e58a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.36116910229645094\n",
      "FOG INDEX: 7.695084924869199\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 18.876543209876544\n",
      "COMPLEX WORD COUNT: 346\n",
      "WORD COUNT: 958\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e11a277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2943\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c595587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0\n",
      "we: 8\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 9\n",
      "PERSONAL PRONOUNS: 9\n",
      "AVG WORD LENGTH: 5.2616088947024195\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_51.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b7563",
   "metadata": {},
   "source": [
    "# 16. for url 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17331c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\3747361029.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a13ffa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Through AI tools like natural language processing, Alexa and google assistant has led the retail industry in its rise towards conversational commerce. As if a customer was interacting with a clerk in a retail store, conversational commerce makes it possible for users to engage with software to research, purchase, or get customer assistance with products and services across a wide range of industries. With Alexa, for example, users can ask any Alexa-enabled device to add an item to an Amazon shopping cart, set a purchasing reminder when a product is running low, or carry out a complete purchase without having to access a shopping cart. The result is a seamless conversational experience that enables consumers to carry out transactions as quickly as it takes to speak a sentence.',\n",
       " 'Through AI tools like natural language processing, Alexa has led the retail industry in its rise towards conversational commerce. As if a customer was interacting with a clerk in a retail store, conversational commerce makes it possible for users to engage with software to research, purchase, or get customer assistance with products and services across a wide range of industries.',\n",
       " 'With the advent of personalized products and on-call delivery, customers have come to expect a new standard experience: fast, easy, accurate, and personalized. Accomplishing this without sacrificing your workday can be a challenge, since the data processing required to meet these needs is immense. Luckily, virtual agents (VAs), powered by conversational AI, can utilize this information faster and more accurately than humans, finding insights and automating communication to deliver an enriched customer experience. If you invest based on these improvements, you’ll find that implementing these tools delivers a powerful competitive advantage. AI has helped in automobile, education, retail and commerce, finance and banking and healthcare.',\n",
       " 'Voice AI has powered the wheels of conversational e-commerce, which has impacted the way the customer communicates with the brand in multiple industries. Brands generally build a campaign to emotionally connect with customers, for long-term growth. With Voice, brand campaigns need to be short and ones that can lead to immediate buying. Conversational e-commerce is still in its nascent stage and it is expected to grow manifold in the coming years. The future of shopping is going to Voice AI and marketers have to get on the bandwagon fast to increase their brand value and visibility. Targeting will have to be highly personalized for success.',\n",
       " 'Despite its narrow focus, conversation AI is an extremely lucrative technology for enterprises, helping businesses more profitable. While an AI chatbot is the most popular form of conversational AI, there are still many other use cases across the enterprise. ',\n",
       " 'While an exclusively chat- or voice-based shopping experience for all scenarios may never completely replace the in-person experience, conversational commerce will continue to grow as an added method of convenient and efficient communication. As users continue to become more accustomed to engaging with chatbots and voice-driven interfaces, expect more innovations in the space as brands continue to develop their unique conversation-based solutions.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9076e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:22]))\n",
    "URL_ID_52 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f83832c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22 sentences in the string.\n",
      "The number of words in the string is: 499\n",
      "The number of characters in the string is: 2774\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = URL_ID_52.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_52.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_52.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "071aa395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 14:02:36] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 14:02:45] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_52 = re.sub(re_punt, \"\",URL_ID_52)\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"52.txt\", \"w\")\n",
    "file.write(URL_ID_52)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"52.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2aaa4139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['through',\n",
       "  'ai',\n",
       "  'tools',\n",
       "  'like',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'alexa',\n",
       "  'and',\n",
       "  'google',\n",
       "  'assistant',\n",
       "  'has',\n",
       "  'led',\n",
       "  'the',\n",
       "  'retail',\n",
       "  'industry',\n",
       "  'in',\n",
       "  'its',\n",
       "  'rise',\n",
       "  'towards',\n",
       "  'conversational',\n",
       "  'commerce',\n",
       "  'as',\n",
       "  'if',\n",
       "  'a',\n",
       "  'customer',\n",
       "  'was',\n",
       "  'interacting',\n",
       "  'with',\n",
       "  'a',\n",
       "  'clerk',\n",
       "  'in',\n",
       "  'a',\n",
       "  'retail',\n",
       "  'store',\n",
       "  'conversational',\n",
       "  'commerce',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'possible',\n",
       "  'for',\n",
       "  'users',\n",
       "  'to',\n",
       "  'engage',\n",
       "  'with',\n",
       "  'software',\n",
       "  'to',\n",
       "  'research',\n",
       "  'purchase',\n",
       "  'or',\n",
       "  'get',\n",
       "  'customer',\n",
       "  'assistance',\n",
       "  'with',\n",
       "  'products',\n",
       "  'and',\n",
       "  'services',\n",
       "  'across',\n",
       "  'a',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'of',\n",
       "  'industries',\n",
       "  'with',\n",
       "  'alexa',\n",
       "  'for',\n",
       "  'example',\n",
       "  'users',\n",
       "  'can',\n",
       "  'ask',\n",
       "  'any',\n",
       "  'alexaenabled',\n",
       "  'device',\n",
       "  'to',\n",
       "  'add',\n",
       "  'an',\n",
       "  'item',\n",
       "  'to',\n",
       "  'an',\n",
       "  'amazon',\n",
       "  'shopping',\n",
       "  'cart',\n",
       "  'set',\n",
       "  'a',\n",
       "  'purchasing',\n",
       "  'reminder',\n",
       "  'when',\n",
       "  'a',\n",
       "  'product',\n",
       "  'is',\n",
       "  'running',\n",
       "  'low',\n",
       "  'or',\n",
       "  'carry',\n",
       "  'out',\n",
       "  'a',\n",
       "  'complete',\n",
       "  'purchase',\n",
       "  'without',\n",
       "  'having',\n",
       "  'to',\n",
       "  'access',\n",
       "  'a',\n",
       "  'shopping',\n",
       "  'cart',\n",
       "  'the',\n",
       "  'result',\n",
       "  'is',\n",
       "  'a',\n",
       "  'seamless',\n",
       "  'conversational',\n",
       "  'experience',\n",
       "  'that',\n",
       "  'enables',\n",
       "  'consumers',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'out',\n",
       "  'transactions',\n",
       "  'as',\n",
       "  'quickly',\n",
       "  'as',\n",
       "  'it',\n",
       "  'takes',\n",
       "  'to',\n",
       "  'speak',\n",
       "  'a',\n",
       "  'sentence',\n",
       "  'through',\n",
       "  'ai',\n",
       "  'tools',\n",
       "  'like',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'alexa',\n",
       "  'has',\n",
       "  'led',\n",
       "  'the',\n",
       "  'retail',\n",
       "  'industry',\n",
       "  'in',\n",
       "  'its',\n",
       "  'rise',\n",
       "  'towards',\n",
       "  'conversational',\n",
       "  'commerce',\n",
       "  'as',\n",
       "  'if',\n",
       "  'a',\n",
       "  'customer',\n",
       "  'was',\n",
       "  'interacting',\n",
       "  'with',\n",
       "  'a',\n",
       "  'clerk',\n",
       "  'in',\n",
       "  'a',\n",
       "  'retail',\n",
       "  'store',\n",
       "  'conversational',\n",
       "  'commerce',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'possible',\n",
       "  'for',\n",
       "  'users',\n",
       "  'to',\n",
       "  'engage',\n",
       "  'with',\n",
       "  'software',\n",
       "  'to',\n",
       "  'research',\n",
       "  'purchase',\n",
       "  'or',\n",
       "  'get',\n",
       "  'customer',\n",
       "  'assistance',\n",
       "  'with',\n",
       "  'products',\n",
       "  'and',\n",
       "  'services',\n",
       "  'across',\n",
       "  'a',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'of',\n",
       "  'industries',\n",
       "  'with',\n",
       "  'the',\n",
       "  'advent',\n",
       "  'of',\n",
       "  'personalized',\n",
       "  'products',\n",
       "  'and',\n",
       "  'oncall',\n",
       "  'delivery',\n",
       "  'customers',\n",
       "  'have',\n",
       "  'come',\n",
       "  'to',\n",
       "  'expect',\n",
       "  'a',\n",
       "  'new',\n",
       "  'standard',\n",
       "  'experience',\n",
       "  'fast',\n",
       "  'easy',\n",
       "  'accurate',\n",
       "  'and',\n",
       "  'personalized',\n",
       "  'accomplishing',\n",
       "  'this',\n",
       "  'without',\n",
       "  'sacrificing',\n",
       "  'your',\n",
       "  'workday',\n",
       "  'can',\n",
       "  'be',\n",
       "  'a',\n",
       "  'challenge',\n",
       "  'since',\n",
       "  'the',\n",
       "  'data',\n",
       "  'processing',\n",
       "  'required',\n",
       "  'to',\n",
       "  'meet',\n",
       "  'these',\n",
       "  'needs',\n",
       "  'is',\n",
       "  'immense',\n",
       "  'luckily',\n",
       "  'virtual',\n",
       "  'agents',\n",
       "  'vas',\n",
       "  'powered',\n",
       "  'by',\n",
       "  'conversational',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'utilize',\n",
       "  'this',\n",
       "  'information',\n",
       "  'faster',\n",
       "  'and',\n",
       "  'more',\n",
       "  'accurately',\n",
       "  'than',\n",
       "  'humans',\n",
       "  'finding',\n",
       "  'insights',\n",
       "  'and',\n",
       "  'automating',\n",
       "  'communication',\n",
       "  'to',\n",
       "  'deliver',\n",
       "  'an',\n",
       "  'enriched',\n",
       "  'customer',\n",
       "  'experience',\n",
       "  'if',\n",
       "  'you',\n",
       "  'invest',\n",
       "  'based',\n",
       "  'on',\n",
       "  'these',\n",
       "  'improvements',\n",
       "  'youll',\n",
       "  'find',\n",
       "  'that',\n",
       "  'implementing',\n",
       "  'these',\n",
       "  'tools',\n",
       "  'delivers',\n",
       "  'a',\n",
       "  'powerful',\n",
       "  'competitive',\n",
       "  'advantage',\n",
       "  'ai',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'in',\n",
       "  'automobile',\n",
       "  'education',\n",
       "  'retail',\n",
       "  'and',\n",
       "  'commerce',\n",
       "  'finance',\n",
       "  'and',\n",
       "  'banking',\n",
       "  'and',\n",
       "  'healthcare',\n",
       "  'voice',\n",
       "  'ai',\n",
       "  'has',\n",
       "  'powered',\n",
       "  'the',\n",
       "  'wheels',\n",
       "  'of',\n",
       "  'conversational',\n",
       "  'ecommerce',\n",
       "  'which',\n",
       "  'has',\n",
       "  'impacted',\n",
       "  'the',\n",
       "  'way',\n",
       "  'the',\n",
       "  'customer',\n",
       "  'communicates',\n",
       "  'with',\n",
       "  'the',\n",
       "  'brand',\n",
       "  'in',\n",
       "  'multiple',\n",
       "  'industries',\n",
       "  'brands',\n",
       "  'generally',\n",
       "  'build',\n",
       "  'a',\n",
       "  'campaign',\n",
       "  'to',\n",
       "  'emotionally',\n",
       "  'connect',\n",
       "  'with',\n",
       "  'customers',\n",
       "  'for',\n",
       "  'longterm',\n",
       "  'growth',\n",
       "  'with',\n",
       "  'voice',\n",
       "  'brand',\n",
       "  'campaigns',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'short',\n",
       "  'and',\n",
       "  'ones',\n",
       "  'that',\n",
       "  'can',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'immediate',\n",
       "  'buying',\n",
       "  'conversational',\n",
       "  'ecommerce',\n",
       "  'is',\n",
       "  'still',\n",
       "  'in',\n",
       "  'its',\n",
       "  'nascent',\n",
       "  'stage',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'expected',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'manifold',\n",
       "  'in',\n",
       "  'the',\n",
       "  'coming',\n",
       "  'years',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'shopping',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'voice',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'marketers',\n",
       "  'have',\n",
       "  'to',\n",
       "  'get',\n",
       "  'on',\n",
       "  'the',\n",
       "  'bandwagon',\n",
       "  'fast',\n",
       "  'to',\n",
       "  'increase',\n",
       "  'their',\n",
       "  'brand',\n",
       "  'value',\n",
       "  'and',\n",
       "  'visibility',\n",
       "  'targeting',\n",
       "  'will',\n",
       "  'have',\n",
       "  'to',\n",
       "  'be',\n",
       "  'highly',\n",
       "  'personalized',\n",
       "  'for',\n",
       "  'success',\n",
       "  'despite',\n",
       "  'its',\n",
       "  'narrow',\n",
       "  'focus',\n",
       "  'conversation',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'an',\n",
       "  'extremely',\n",
       "  'lucrative',\n",
       "  'technology',\n",
       "  'for',\n",
       "  'enterprises',\n",
       "  'helping',\n",
       "  'businesses',\n",
       "  'more',\n",
       "  'profitable',\n",
       "  'while',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'chatbot',\n",
       "  'is',\n",
       "  'the',\n",
       "  'most',\n",
       "  'popular',\n",
       "  'form',\n",
       "  'of',\n",
       "  'conversational',\n",
       "  'ai',\n",
       "  'there',\n",
       "  'are',\n",
       "  'still',\n",
       "  'many',\n",
       "  'other',\n",
       "  'use',\n",
       "  'cases',\n",
       "  'across',\n",
       "  'the',\n",
       "  'enterprise',\n",
       "  'while',\n",
       "  'an',\n",
       "  'exclusively',\n",
       "  'chat',\n",
       "  'or',\n",
       "  'voicebased',\n",
       "  'shopping',\n",
       "  'experience',\n",
       "  'for',\n",
       "  'all',\n",
       "  'scenarios',\n",
       "  'may',\n",
       "  'never',\n",
       "  'completely',\n",
       "  'replace',\n",
       "  'the',\n",
       "  'inperson',\n",
       "  'experience',\n",
       "  'conversational',\n",
       "  'commerce',\n",
       "  'will',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'as',\n",
       "  'an',\n",
       "  'added',\n",
       "  'method',\n",
       "  'of',\n",
       "  'convenient',\n",
       "  'and',\n",
       "  'efficient',\n",
       "  'communication',\n",
       "  'as',\n",
       "  'users',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'become',\n",
       "  'more',\n",
       "  'accustomed',\n",
       "  'to',\n",
       "  'engaging',\n",
       "  'with',\n",
       "  'chatbots',\n",
       "  'and',\n",
       "  'voicedriven',\n",
       "  'interfaces',\n",
       "  'expect',\n",
       "  'more',\n",
       "  'innovations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'space',\n",
       "  'as',\n",
       "  'brands',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'develop',\n",
       "  'their',\n",
       "  'unique',\n",
       "  'conversationbased',\n",
       "  'solutions']]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/52.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2831be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9015c788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD COUNT 322\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    " for word in tk_words:\n",
    "        if word in sw_list:\n",
    "            tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4a1eef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 22.681818181818183\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dca16d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.4503105590062112\n",
      "FOG INDEX: 9.25285149632976\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 22.681818181818183\n",
      "COMPLEX WORD COUNT: 145\n",
      "WORD COUNT: 322\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40324e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1032\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 5.559118236472946\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_52.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab34552",
   "metadata": {},
   "source": [
    "# 17 for url 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b48de649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\1014551008.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5abf0154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Anything that could give rise to smarter-than-human intelligence – in the form of Artificial Intelligence, brain-computer interfaces, or neuroscience-based human intelligence enhancement – wins hands down beyond contest as doing the most to change the world. Nothing else is even in the same league.” ',\n",
       " '–Eliezer Yudkowsky, AI Researcher',\n",
       " 'There’s no denying robots and automation are increasingly part of our daily lives. Just look around the grocery store, or the highway, they are everywhere. This makes us wonder what if AI can replace human intelligence? What can we do to make ourselves relevant tomorrow? Let us try to find the answers to all these questions and more.',\n",
       " 'Let’s first understand what is Artificial Intelligence –',\n",
       " 'Artificial Intelligence or AI basically machines displaying intelligence. This can be seen from a machine playing chess or a robot answering questions on Facebook. Artificial Intelligence can be further broken down into many different types. There are AIs designed to do specific tasks, such as detecting a specific type of cancer. However, there are also AIs that can do multiple tasks, such as driving a car. There are many types of AIs. Among the top, most important fields are Machine Learning or ML, Neural Network, Computer Vision, and Natural Language Processing or NLP.',\n",
       " 'Machine Learning is the idea of machines being able to prove themselves similar to how a human being learns a new skill. Machine Learning also allows for the optimization of an existing skill. Machine Learning is used in many different fields and one such application is entertainment. Netflix uses Machine Learning to recommend more shows that you can watch based on the shows that you have already seen.',\n",
       " 'Neural Networks are algorithms that are modeled after the human brain. These algorithms think just like we do which can thereby give similar results to what a human being can give. Artificial Neural Networks are used in medical fields to diagnose cancers like lung cancer and prostate cancer.',\n",
       " 'Computer Vision is the idea that computers have visions. This allows them to see things the way human beings do or potentially better than human beings do, depending on the programming, camera used, etc. Computer Vision is used in autonomous vehicles for navigation from one place to another.',\n",
       " 'Natural Language Processing is the idea that computers can listen to what we say. An example of this is Siri. Siri is able to listen to our demands, process what it means, and provide you an answer based on what is researched.',\n",
       " 'Now that we know what an AI is and what it can do, Let’s talk about the issue.',\n",
       " 'AIs allow for the automation of jobs, thereby replacing what humans already do. This means more job loss and the concentration of wealth to the selected few people. This could mean a destabilization of society and social unrest. In addition to social unrest, AI improves over time. This means it becomes smarter, faster, and cheaper to implement and it will be better at doing repetitive things that humans currently do, such as preparing fast food. It is predicted that AI will improve so much over 50 to 100 years that AI will become super intelligent. This means that it will become even smarter than the most intelligent human on earth. According to many experts such as Elon Musk, this could cause the end of human civilization. AI could potentially start a war against humans, burn crops and do all sorts of tragedies once reserved for human functions. At that point, in theory, we can not stop it because AI would have already thought of all the obstacles that will prevent its goal. This means that we cannot unplug the machine, in effect AI will replace human intelligence.',\n",
       " 'But, will this happen in next 10 to 30 years?',\n",
       " 'NO! The field of Artificial Intelligence is sophisticated enough to do many human tasks that humans currently do. Currently, AI is not smart enough to be empathetic to humans and cannot think strategically enough to solve complex problems. AI solutions can be expensive and have to go through many different tests and standards to implement. It also takes time for AI to improve. For example, Boston Dynamics, one of the world’s top robotics company had a robot in 2009 that needed assistance to walk. Fast forward to 2019, not only the robot could walk by itself but it could jump over objects, do backflips and so much more. In addition to the timing, it takes time for the price of any new technological solution to drop to a point where it is affordable. For example, a desktop computer costs around $1000 in 1999 but now you can get a significantly more powerful laptop for the exact same price. AI will go through the same curve.',\n",
       " 'But what happens after those 10 to 30 years? Will AI make human intelligence obsolete? Maybe. As we have proven earlier AI will become faster better and cheaper. As this happens, more and more companies will use AI technology to automate more and more jobs to save money, increase productivity, and most importantly, stay competitive. As we have demonstrated, AI will become better through repetition via the use of machine learning. The only difference is that AI will be able to learn faster as time progresses due to the amount of data that is available today. It will also be able to learn from other machines or similar machines to learn how to optimize its tasks or new important skills. However, AI also just not do repetitive and routine tasks better, it will also be able to understand emotional intelligence, ethics, and creativity. This seen in three distinct example- IBM',\n",
       " 'IBM uses its IBM Watson to program the AI to create a movie trailer. Fox approached IBM and said they have a movie coming out on AI #Scifi horror. They asked IBM if their platform IBM Watson could a trailer by reviewing and watching the footage and searching for scary,',\n",
       " 'Sad or happy or other moments in the movie that provoked quality emotions based on how the machine was programmed to identify such emotions in a quantifiable manner. IBM Watson was able to generate a trailer for the movie Morgan. The result, a movie trailer created by machines example – Google',\n",
       " 'IN 2018 google demonstrated an AI assistance that could take calls and do simple stuff. The AI was able to set up an appointment! What was more fascinating was that it was able to understand the nuances of the conversation. The receptionist thought it was a human being that was calling her. That is a very primitive version of what is possible with this technology. Eventually, it will be able to have conversations just as human beings do, making many sales jobs obsolete. example – AI generated art',\n",
       " 'In 2018, a Paris art collective consisting of three students used artificial intelligence to generate a portrait. It generated the portrait painting by studying a set of fifteen thousand art images on wiki art. It was estimated to be worth between seven thousand to ten thousand dollars. The painting sold at an auction for four thirty-five thousand US dollars.',\n",
       " 'However, we cannot for sure say that AI will replace human intelligence. This is because we as a society have started asking hard questions and questioning ethics. Elon Musk founded Open AI, a research lab whose whole purpose is to promote and discover artificial intelligence in a way to benefits humanity. In addition to this, there are many factors that affect the long-term outcome of AI replacing human intelligence. Like, to what degree will other humans allow for AI to take over? Depending on the field, do people even want Artificial Intelligence to help them? Or will they prefer a human counterpart? While we may not be able to control what happens in the long run, we can definitely secure our short-term future.',\n",
       " 'Strategic and creative thinking',\n",
       " 'The ability to think outside the box is very human. There are thousands upon thousands of slightly different possible outcomes that may result from every distinguishable action that the human mind with its ability to judge from experience is programmed for these purposes in a far more sophisticated manner than AI can currently achieve. As the billionaire founder of Alibaba, Jack Ma famously said – “AI has logic, human beings have wisdom”.',\n",
       " 'Conflict resolution and negotiations',\n",
       " 'With our understanding of the complexities of human-related processes and our ability to improvise and judge, we are far better equipped to deal with conflicts than robots are ever likely to be.',\n",
       " 'AI may be able to recognize faces and images but it can rarely successfully read the feelings of those faces. Humans, to lesser or greater degrees, are capable of an accurate analysis of emotional subtext. With the application of intuition and the use of delicately worded or elusive languages, through these methods, we are able to properly judge how a person feels.',\n",
       " 'Interpretation of Gray Areas',\n",
       " 'Robots and computers function well when presented with quantifiable data. However, once the situation enters a gray area, whether this term refers to morals, processes, or definitions robots are more likely to falter.',\n",
       " 'Critical thinking',\n",
       " 'Humans are capable of responding to more indicators of quality than computers are. While an AI system may be able to analyze documents according to the true or false statements made within the text, we can judge whether or not it is well written and analyze the implication of the use of certain words and the overall meaning of the content.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8066e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:44]))\n",
    "URL_ID_53 = \" \".join((titles, texts))\n",
    "\n",
    "URL_ID_53 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c9fd5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 sentences in the string.\n",
      "The number of words in the string is: 1634\n",
      "The number of characters in the string is: 8153\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_40.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_40.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_40.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0724f469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 14:11:20] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 14:11:26] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_53 = re.sub(re_punt, \"\",URL_ID_53)\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"53.txt\", \"w\")\n",
    "file.write(URL_ID_53)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"53.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1bb7adea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['anything',\n",
       "  'that',\n",
       "  'could',\n",
       "  'give',\n",
       "  'rise',\n",
       "  'to',\n",
       "  'smarterthanhuman',\n",
       "  'intelligence',\n",
       "  'in',\n",
       "  'the',\n",
       "  'form',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'braincomputer',\n",
       "  'interfaces',\n",
       "  'or',\n",
       "  'neurosciencebased',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'enhancement',\n",
       "  'wins',\n",
       "  'hands',\n",
       "  'down',\n",
       "  'beyond',\n",
       "  'contest',\n",
       "  'as',\n",
       "  'doing',\n",
       "  'the',\n",
       "  'most',\n",
       "  'to',\n",
       "  'change',\n",
       "  'the',\n",
       "  'world',\n",
       "  'nothing',\n",
       "  'else',\n",
       "  'is',\n",
       "  'even',\n",
       "  'in',\n",
       "  'the',\n",
       "  'same',\n",
       "  'league',\n",
       "  'eliezer',\n",
       "  'yudkowsky',\n",
       "  'ai',\n",
       "  'researcher',\n",
       "  'theres',\n",
       "  'no',\n",
       "  'denying',\n",
       "  'robots',\n",
       "  'and',\n",
       "  'automation',\n",
       "  'are',\n",
       "  'increasingly',\n",
       "  'part',\n",
       "  'of',\n",
       "  'our',\n",
       "  'daily',\n",
       "  'lives',\n",
       "  'just',\n",
       "  'look',\n",
       "  'around',\n",
       "  'the',\n",
       "  'grocery',\n",
       "  'store',\n",
       "  'or',\n",
       "  'the',\n",
       "  'highway',\n",
       "  'they',\n",
       "  'are',\n",
       "  'everywhere',\n",
       "  'this',\n",
       "  'makes',\n",
       "  'us',\n",
       "  'wonder',\n",
       "  'what',\n",
       "  'if',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'replace',\n",
       "  'human',\n",
       "  'intelligence?',\n",
       "  'what',\n",
       "  'can',\n",
       "  'we',\n",
       "  'do',\n",
       "  'to',\n",
       "  'make',\n",
       "  'ourselves',\n",
       "  'relevant',\n",
       "  'tomorrow?',\n",
       "  'let',\n",
       "  'us',\n",
       "  'try',\n",
       "  'to',\n",
       "  'find',\n",
       "  'the',\n",
       "  'answers',\n",
       "  'to',\n",
       "  'all',\n",
       "  'these',\n",
       "  'questions',\n",
       "  'and',\n",
       "  'more',\n",
       "  'lets',\n",
       "  'first',\n",
       "  'understand',\n",
       "  'what',\n",
       "  'is',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'or',\n",
       "  'ai',\n",
       "  'basically',\n",
       "  'machines',\n",
       "  'displaying',\n",
       "  'intelligence',\n",
       "  'this',\n",
       "  'can',\n",
       "  'be',\n",
       "  'seen',\n",
       "  'from',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'playing',\n",
       "  'chess',\n",
       "  'or',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'answering',\n",
       "  'questions',\n",
       "  'on',\n",
       "  'facebook',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'can',\n",
       "  'be',\n",
       "  'further',\n",
       "  'broken',\n",
       "  'down',\n",
       "  'into',\n",
       "  'many',\n",
       "  'different',\n",
       "  'types',\n",
       "  'there',\n",
       "  'are',\n",
       "  'ais',\n",
       "  'designed',\n",
       "  'to',\n",
       "  'do',\n",
       "  'specific',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'detecting',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'type',\n",
       "  'of',\n",
       "  'cancer',\n",
       "  'however',\n",
       "  'there',\n",
       "  'are',\n",
       "  'also',\n",
       "  'ais',\n",
       "  'that',\n",
       "  'can',\n",
       "  'do',\n",
       "  'multiple',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'driving',\n",
       "  'a',\n",
       "  'car',\n",
       "  'there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'types',\n",
       "  'of',\n",
       "  'ais',\n",
       "  'among',\n",
       "  'the',\n",
       "  'top',\n",
       "  'most',\n",
       "  'important',\n",
       "  'fields',\n",
       "  'are',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'or',\n",
       "  'ml',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'and',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'or',\n",
       "  'nlp',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'machines',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'prove',\n",
       "  'themselves',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'how',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'learns',\n",
       "  'a',\n",
       "  'new',\n",
       "  'skill',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'also',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'the',\n",
       "  'optimization',\n",
       "  'of',\n",
       "  'an',\n",
       "  'existing',\n",
       "  'skill',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'used',\n",
       "  'in',\n",
       "  'many',\n",
       "  'different',\n",
       "  'fields',\n",
       "  'and',\n",
       "  'one',\n",
       "  'such',\n",
       "  'application',\n",
       "  'is',\n",
       "  'entertainment',\n",
       "  'netflix',\n",
       "  'uses',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'to',\n",
       "  'recommend',\n",
       "  'more',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'you',\n",
       "  'can',\n",
       "  'watch',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'you',\n",
       "  'have',\n",
       "  'already',\n",
       "  'seen',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'are',\n",
       "  'algorithms',\n",
       "  'that',\n",
       "  'are',\n",
       "  'modeled',\n",
       "  'after',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'these',\n",
       "  'algorithms',\n",
       "  'think',\n",
       "  'just',\n",
       "  'like',\n",
       "  'we',\n",
       "  'do',\n",
       "  'which',\n",
       "  'can',\n",
       "  'thereby',\n",
       "  'give',\n",
       "  'similar',\n",
       "  'results',\n",
       "  'to',\n",
       "  'what',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'can',\n",
       "  'give',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'are',\n",
       "  'used',\n",
       "  'in',\n",
       "  'medical',\n",
       "  'fields',\n",
       "  'to',\n",
       "  'diagnose',\n",
       "  'cancers',\n",
       "  'like',\n",
       "  'lung',\n",
       "  'cancer',\n",
       "  'and',\n",
       "  'prostate',\n",
       "  'cancer',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'that',\n",
       "  'computers',\n",
       "  'have',\n",
       "  'visions',\n",
       "  'this',\n",
       "  'allows',\n",
       "  'them',\n",
       "  'to',\n",
       "  'see',\n",
       "  'things',\n",
       "  'the',\n",
       "  'way',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'do',\n",
       "  'or',\n",
       "  'potentially',\n",
       "  'better',\n",
       "  'than',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'do',\n",
       "  'depending',\n",
       "  'on',\n",
       "  'the',\n",
       "  'programming',\n",
       "  'camera',\n",
       "  'used',\n",
       "  'etc',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'is',\n",
       "  'used',\n",
       "  'in',\n",
       "  'autonomous',\n",
       "  'vehicles',\n",
       "  'for',\n",
       "  'navigation',\n",
       "  'from',\n",
       "  'one',\n",
       "  'place',\n",
       "  'to',\n",
       "  'another',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'that',\n",
       "  'computers',\n",
       "  'can',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'what',\n",
       "  'we',\n",
       "  'say',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'this',\n",
       "  'is',\n",
       "  'siri',\n",
       "  'siri',\n",
       "  'is',\n",
       "  'able',\n",
       "  'to',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'our',\n",
       "  'demands',\n",
       "  'process',\n",
       "  'what',\n",
       "  'it',\n",
       "  'means',\n",
       "  'and',\n",
       "  'provide',\n",
       "  'you',\n",
       "  'an',\n",
       "  'answer',\n",
       "  'based',\n",
       "  'on',\n",
       "  'what',\n",
       "  'is',\n",
       "  'researched',\n",
       "  'now',\n",
       "  'that',\n",
       "  'we',\n",
       "  'know',\n",
       "  'what',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'and',\n",
       "  'what',\n",
       "  'it',\n",
       "  'can',\n",
       "  'do',\n",
       "  'lets',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'ais',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'the',\n",
       "  'automation',\n",
       "  'of',\n",
       "  'jobs',\n",
       "  'thereby',\n",
       "  'replacing',\n",
       "  'what',\n",
       "  'humans',\n",
       "  'already',\n",
       "  'do',\n",
       "  'this',\n",
       "  'means',\n",
       "  'more',\n",
       "  'job',\n",
       "  'loss',\n",
       "  'and',\n",
       "  'the',\n",
       "  'concentration',\n",
       "  'of',\n",
       "  'wealth',\n",
       "  'to',\n",
       "  'the',\n",
       "  'selected',\n",
       "  'few',\n",
       "  'people',\n",
       "  'this',\n",
       "  'could',\n",
       "  'mean',\n",
       "  'a',\n",
       "  'destabilization',\n",
       "  'of',\n",
       "  'society',\n",
       "  'and',\n",
       "  'social',\n",
       "  'unrest',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'social',\n",
       "  'unrest',\n",
       "  'ai',\n",
       "  'improves',\n",
       "  'over',\n",
       "  'time',\n",
       "  'this',\n",
       "  'means',\n",
       "  'it',\n",
       "  'becomes',\n",
       "  'smarter',\n",
       "  'faster',\n",
       "  'and',\n",
       "  'cheaper',\n",
       "  'to',\n",
       "  'implement',\n",
       "  'and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'better',\n",
       "  'at',\n",
       "  'doing',\n",
       "  'repetitive',\n",
       "  'things',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'currently',\n",
       "  'do',\n",
       "  'such',\n",
       "  'as',\n",
       "  'preparing',\n",
       "  'fast',\n",
       "  'food',\n",
       "  'it',\n",
       "  'is',\n",
       "  'predicted',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'improve',\n",
       "  'so',\n",
       "  'much',\n",
       "  'over',\n",
       "  '50',\n",
       "  'to',\n",
       "  '100',\n",
       "  'years',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'super',\n",
       "  'intelligent',\n",
       "  'this',\n",
       "  'means',\n",
       "  'that',\n",
       "  'it',\n",
       "  'will',\n",
       "  'become',\n",
       "  'even',\n",
       "  'smarter',\n",
       "  'than',\n",
       "  'the',\n",
       "  'most',\n",
       "  'intelligent',\n",
       "  'human',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'according',\n",
       "  'to',\n",
       "  'many',\n",
       "  'experts',\n",
       "  'such',\n",
       "  'as',\n",
       "  'elon',\n",
       "  'musk',\n",
       "  'this',\n",
       "  'could',\n",
       "  'cause',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'human',\n",
       "  'civilization',\n",
       "  'ai',\n",
       "  'could',\n",
       "  'potentially',\n",
       "  'start',\n",
       "  'a',\n",
       "  'war',\n",
       "  'against',\n",
       "  'humans',\n",
       "  'burn',\n",
       "  'crops',\n",
       "  'and',\n",
       "  'do',\n",
       "  'all',\n",
       "  'sorts',\n",
       "  'of',\n",
       "  'tragedies',\n",
       "  'once',\n",
       "  'reserved',\n",
       "  'for',\n",
       "  'human',\n",
       "  'functions',\n",
       "  'at',\n",
       "  'that',\n",
       "  'point',\n",
       "  'in',\n",
       "  'theory',\n",
       "  'we',\n",
       "  'can',\n",
       "  'not',\n",
       "  'stop',\n",
       "  'it',\n",
       "  'because',\n",
       "  'ai',\n",
       "  'would',\n",
       "  'have',\n",
       "  'already',\n",
       "  'thought',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'obstacles',\n",
       "  'that',\n",
       "  'will',\n",
       "  'prevent',\n",
       "  'its',\n",
       "  'goal',\n",
       "  'this',\n",
       "  'means',\n",
       "  'that',\n",
       "  'we',\n",
       "  'cannot',\n",
       "  'unplug',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'in',\n",
       "  'effect',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'replace',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'but',\n",
       "  'will',\n",
       "  'this',\n",
       "  'happen',\n",
       "  'in',\n",
       "  'next',\n",
       "  '10',\n",
       "  'to',\n",
       "  '30',\n",
       "  'years?',\n",
       "  'no!',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'sophisticated',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'do',\n",
       "  'many',\n",
       "  'human',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'currently',\n",
       "  'do',\n",
       "  'currently',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'not',\n",
       "  'smart',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'be',\n",
       "  'empathetic',\n",
       "  'to',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'cannot',\n",
       "  'think',\n",
       "  'strategically',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'complex',\n",
       "  'problems',\n",
       "  'ai',\n",
       "  'solutions',\n",
       "  'can',\n",
       "  'be',\n",
       "  'expensive',\n",
       "  'and',\n",
       "  'have',\n",
       "  'to',\n",
       "  'go',\n",
       "  'through',\n",
       "  'many',\n",
       "  'different',\n",
       "  'tests',\n",
       "  'and',\n",
       "  'standards',\n",
       "  'to',\n",
       "  'implement',\n",
       "  'it',\n",
       "  'also',\n",
       "  'takes',\n",
       "  'time',\n",
       "  'for',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'for',\n",
       "  'example',\n",
       "  'boston',\n",
       "  'dynamics',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'worlds',\n",
       "  'top',\n",
       "  'robotics',\n",
       "  'company',\n",
       "  'had',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'in',\n",
       "  '2009',\n",
       "  'that',\n",
       "  'needed',\n",
       "  'assistance',\n",
       "  'to',\n",
       "  'walk',\n",
       "  'fast',\n",
       "  'forward',\n",
       "  'to',\n",
       "  '2019',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'robot',\n",
       "  'could',\n",
       "  'walk',\n",
       "  'by',\n",
       "  'itself',\n",
       "  'but',\n",
       "  'it',\n",
       "  'could',\n",
       "  'jump',\n",
       "  'over',\n",
       "  'objects',\n",
       "  'do',\n",
       "  'backflips',\n",
       "  'and',\n",
       "  'so',\n",
       "  'much',\n",
       "  'more',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'the',\n",
       "  'timing',\n",
       "  'it',\n",
       "  'takes',\n",
       "  'time',\n",
       "  'for',\n",
       "  'the',\n",
       "  'price',\n",
       "  'of',\n",
       "  'any',\n",
       "  'new',\n",
       "  'technological',\n",
       "  'solution',\n",
       "  'to',\n",
       "  'drop',\n",
       "  'to',\n",
       "  'a',\n",
       "  'point',\n",
       "  'where',\n",
       "  'it',\n",
       "  'is',\n",
       "  'affordable',\n",
       "  'for',\n",
       "  'example',\n",
       "  'a',\n",
       "  'desktop',\n",
       "  'computer',\n",
       "  'costs',\n",
       "  'around',\n",
       "  '1000',\n",
       "  'in',\n",
       "  '1999',\n",
       "  'but',\n",
       "  'now',\n",
       "  'you',\n",
       "  'can',\n",
       "  'get',\n",
       "  'a',\n",
       "  'significantly',\n",
       "  'more',\n",
       "  'powerful',\n",
       "  'laptop',\n",
       "  'for',\n",
       "  'the',\n",
       "  'exact',\n",
       "  'same',\n",
       "  'price',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'go',\n",
       "  'through',\n",
       "  'the',\n",
       "  'same',\n",
       "  'curve',\n",
       "  'but',\n",
       "  'what',\n",
       "  'happens',\n",
       "  'after',\n",
       "  'those',\n",
       "  '10',\n",
       "  'to',\n",
       "  '30',\n",
       "  'years?',\n",
       "  'will',\n",
       "  'ai',\n",
       "  'make',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'obsolete?',\n",
       "  'maybe',\n",
       "  'as',\n",
       "  'we',\n",
       "  'have',\n",
       "  'proven',\n",
       "  'earlier',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'faster',\n",
       "  'better',\n",
       "  'and',\n",
       "  'cheaper',\n",
       "  'as',\n",
       "  'this',\n",
       "  'happens',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'companies',\n",
       "  'will',\n",
       "  'use',\n",
       "  'ai',\n",
       "  'technology',\n",
       "  'to',\n",
       "  'automate',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'to',\n",
       "  'save',\n",
       "  'money',\n",
       "  'increase',\n",
       "  'productivity',\n",
       "  'and',\n",
       "  'most',\n",
       "  'importantly',\n",
       "  'stay',\n",
       "  'competitive',\n",
       "  'as',\n",
       "  'we',\n",
       "  'have',\n",
       "  'demonstrated',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'better',\n",
       "  'through',\n",
       "  'repetition',\n",
       "  'via',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'the',\n",
       "  'only',\n",
       "  'difference',\n",
       "  'is',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'faster',\n",
       "  'as',\n",
       "  'time',\n",
       "  'progresses',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'data',\n",
       "  'that',\n",
       "  'is',\n",
       "  'available',\n",
       "  'today',\n",
       "  'it',\n",
       "  'will',\n",
       "  'also',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'from',\n",
       "  'other',\n",
       "  'machines',\n",
       "  'or',\n",
       "  'similar',\n",
       "  'machines',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'how',\n",
       "  'to',\n",
       "  'optimize',\n",
       "  'its',\n",
       "  'tasks',\n",
       "  'or',\n",
       "  'new',\n",
       "  'important',\n",
       "  'skills',\n",
       "  'however',\n",
       "  'ai',\n",
       "  'also',\n",
       "  'just',\n",
       "  'not',\n",
       "  'do',\n",
       "  'repetitive',\n",
       "  'and',\n",
       "  'routine',\n",
       "  'tasks',\n",
       "  'better',\n",
       "  'it',\n",
       "  'will',\n",
       "  'also',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'emotional',\n",
       "  'intelligence',\n",
       "  'ethics',\n",
       "  'and',\n",
       "  'creativity',\n",
       "  'this',\n",
       "  'seen',\n",
       "  'in',\n",
       "  'three',\n",
       "  'distinct',\n",
       "  'example',\n",
       "  'ibm',\n",
       "  'ibm',\n",
       "  'uses',\n",
       "  'its',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'to',\n",
       "  'program',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'create',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'trailer',\n",
       "  'fox',\n",
       "  'approached',\n",
       "  'ibm',\n",
       "  'and',\n",
       "  'said',\n",
       "  'they',\n",
       "  'have',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'coming',\n",
       "  'out',\n",
       "  'on',\n",
       "  'ai',\n",
       "  'scifi',\n",
       "  'horror',\n",
       "  'they',\n",
       "  'asked',\n",
       "  'ibm',\n",
       "  'if',\n",
       "  'their',\n",
       "  'platform',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'could',\n",
       "  'a',\n",
       "  'trailer',\n",
       "  'by',\n",
       "  'reviewing',\n",
       "  'and',\n",
       "  'watching',\n",
       "  'the',\n",
       "  'footage',\n",
       "  'and',\n",
       "  'searching',\n",
       "  'for',\n",
       "  'scary',\n",
       "  'sad',\n",
       "  'or',\n",
       "  'happy',\n",
       "  'or',\n",
       "  'other',\n",
       "  'moments',\n",
       "  'in',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'that',\n",
       "  ...]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/53.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d21e6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "WORD COUNT 969\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aa51abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 19.0\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7ede4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.33126934984520123\n",
      "FOG INDEX: 7.732507739938081\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 19.0\n",
      "COMPLEX WORD COUNT: 321\n",
      "WORD COUNT: 969\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2b0f2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3018\n",
      "I: 0\n",
      "we: 15\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 3\n",
      "Total count: 18\n",
      "PERSONAL PRONOUNS: 18\n",
      "AVG WORD LENGTH: 4.989596083231334\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_53.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa7e85",
   "metadata": {},
   "source": [
    "# 18.for url 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5fcea787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\3493306384.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bc477e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ever wondered how you get notified of the products or services you want or you have been looking for for a long time. Now how does this happen? Let me start with the simple and the most known fact- Marketing,',\n",
       " 'Marketing is a common term which everyone knows and is aware of. Marketing is the action of promoting products and services, including market research and advertising.',\n",
       " 'Traditional Marketing was working fine for all these years. So why there was a need for online marketing?',\n",
       " 'The story begins from the internet era, The online presence of customers-',\n",
       " 'There are 4.72 billion people are on internet users in the world today and the number is increasing day by day. So if the companies want to create awareness about their products and services their is a huge audience present online.',\n",
       " 'There are a lot of benefits of online marketing like a large audience, benefits of targeting on the basis of demographics, location, age, gender, and many more. Because of this diversity, almost every type of company can use the Internet to reach any audience. All would find something of their liking.',\n",
       " 'Let’s take a look at what does online marketing involves.',\n",
       " 'These days, almost everybody is on social media. The majority of people use Facebook, Twitter, Instagram, and other social media platforms to communicate with their friends and relatives. Some people have created companies solely based on their social media activity.',\n",
       " 'You can, however, promote your Knowledge Commerce products through social media. Whether or not you advertise on these sites.',\n",
       " 'The best social media networks for advertising-',\n",
       " 'Facebook advertising',\n",
       " 'Instagram advertising',\n",
       " 'Twitter advertising',\n",
       " 'Pinterest advertising',\n",
       " 'LinkedIn advertising',\n",
       " 'Snapchat advertising',\n",
       " 'Content marketing is a strategic marketing strategy that focuses on producing and delivering useful, appropriate, and reliable content in order to attract and maintain a specific audience — and, eventually, to drive profitable consumer action.',\n",
       " 'In simple words, content marketing is a marketing strategy that producers and delivers relevant and reliable content to attract potential clients and to also retain existing clients.',\n",
       " 'About half of all website traffic originates from a search engine. People who use searches are often high-intent buyers. This indicates that they are searching for a particular item. They’re all set to buy the products and services.',\n",
       " 'The majority of online marketing is focused on pay-per-click (PPC). However, when you hear the word “PPC,” it refers to search ads.',\n",
       " 'Pay-per-click (PPC) advertising on search engines, social media sites, and other online venues can be extremely successful.',\n",
       " 'So the next time when you search for a product and services and you find similar ads on the internet this is a kind of internet marketing.',\n",
       " 'Email marketing is the highly successful digital marketing technique of sending emails to prospects and consumers. It allows communicating directly with the present, former, and potential customers. businesses will inform the audience about new products as they become aware of them.',\n",
       " 'Banner ads are rectangular or square advertisements that appear above, in the sidebar, or below the content on websites. Usually, a banner ad leads to a sales or landing page. You will get great results by running banner ads on websites that attract members of the target audience.',\n",
       " 'An affiliate marketer, like a car salesperson, only gets paid when someone buys the stuff. You may not have to pay if there are no purchases.',\n",
       " 'Affiliates are free to sell your goods anywhere they choose (as long as the material follows the terms of service of the website). It’s a fantastic way to reach new markets.',\n",
       " 'Anyone can start their affiliate marketing career by registering on the different affiliate websites.',\n",
       " 'Influencer marketing is a new trend for online marketing. They have a strong following, can inspire people to buy your goods, and are loved by their viewers.',\n",
       " 'The type of online marketing that will work best for the company will be determined by many factors, including the nature of your industry, the tastes and demographics of the target market, and budget. Market analysis will guide to the best strategy or combination of strategies for your offerings, and comprehensive performance metrics will show you which are the most effective.',\n",
       " 'Online marketing is a rapidly expanding industry that benefits companies in a variety of ways. The number of people who purchase goods and services online is on the rise. As a result, an increasing number of businesses around the world are turning to internet marketing to communicate with consumers and advertise their goods and services.']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[19:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9bd31805",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[19:49]))\n",
    "URL_ID_54 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d9005af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 sentences in the string.\n",
      "The number of words in the string is: 745\n",
      "The number of characters in the string is: 3892\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 14:24:33] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 14:24:45] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_54.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_54.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_54.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_54 = re.sub(re_punt, \"\",URL_ID_54)\n",
    "\n",
    "file = open(\"54.txt\", \"w\")\n",
    "file.write(URL_ID_54)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"54.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0e7c54d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ever',\n",
       "  'wondered',\n",
       "  'how',\n",
       "  'you',\n",
       "  'get',\n",
       "  'notified',\n",
       "  'of',\n",
       "  'the',\n",
       "  'products',\n",
       "  'or',\n",
       "  'services',\n",
       "  'you',\n",
       "  'want',\n",
       "  'or',\n",
       "  'you',\n",
       "  'have',\n",
       "  'been',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'for',\n",
       "  'a',\n",
       "  'long',\n",
       "  'time',\n",
       "  'now',\n",
       "  'how',\n",
       "  'does',\n",
       "  'this',\n",
       "  'happen?',\n",
       "  'let',\n",
       "  'me',\n",
       "  'start',\n",
       "  'with',\n",
       "  'the',\n",
       "  'simple',\n",
       "  'and',\n",
       "  'the',\n",
       "  'most',\n",
       "  'known',\n",
       "  'fact',\n",
       "  'marketing',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'a',\n",
       "  'common',\n",
       "  'term',\n",
       "  'which',\n",
       "  'everyone',\n",
       "  'knows',\n",
       "  'and',\n",
       "  'is',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'the',\n",
       "  'action',\n",
       "  'of',\n",
       "  'promoting',\n",
       "  'products',\n",
       "  'and',\n",
       "  'services',\n",
       "  'including',\n",
       "  'market',\n",
       "  'research',\n",
       "  'and',\n",
       "  'advertising',\n",
       "  'traditional',\n",
       "  'marketing',\n",
       "  'was',\n",
       "  'working',\n",
       "  'fine',\n",
       "  'for',\n",
       "  'all',\n",
       "  'these',\n",
       "  'years',\n",
       "  'so',\n",
       "  'why',\n",
       "  'there',\n",
       "  'was',\n",
       "  'a',\n",
       "  'need',\n",
       "  'for',\n",
       "  'online',\n",
       "  'marketing?',\n",
       "  'the',\n",
       "  'story',\n",
       "  'begins',\n",
       "  'from',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'era',\n",
       "  'the',\n",
       "  'online',\n",
       "  'presence',\n",
       "  'of',\n",
       "  'customers',\n",
       "  'there',\n",
       "  'are',\n",
       "  '472',\n",
       "  'billion',\n",
       "  'people',\n",
       "  'are',\n",
       "  'on',\n",
       "  'internet',\n",
       "  'users',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'today',\n",
       "  'and',\n",
       "  'the',\n",
       "  'number',\n",
       "  'is',\n",
       "  'increasing',\n",
       "  'day',\n",
       "  'by',\n",
       "  'day',\n",
       "  'so',\n",
       "  'if',\n",
       "  'the',\n",
       "  'companies',\n",
       "  'want',\n",
       "  'to',\n",
       "  'create',\n",
       "  'awareness',\n",
       "  'about',\n",
       "  'their',\n",
       "  'products',\n",
       "  'and',\n",
       "  'services',\n",
       "  'their',\n",
       "  'is',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'audience',\n",
       "  'present',\n",
       "  'online',\n",
       "  'there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'benefits',\n",
       "  'of',\n",
       "  'online',\n",
       "  'marketing',\n",
       "  'like',\n",
       "  'a',\n",
       "  'large',\n",
       "  'audience',\n",
       "  'benefits',\n",
       "  'of',\n",
       "  'targeting',\n",
       "  'on',\n",
       "  'the',\n",
       "  'basis',\n",
       "  'of',\n",
       "  'demographics',\n",
       "  'location',\n",
       "  'age',\n",
       "  'gender',\n",
       "  'and',\n",
       "  'many',\n",
       "  'more',\n",
       "  'because',\n",
       "  'of',\n",
       "  'this',\n",
       "  'diversity',\n",
       "  'almost',\n",
       "  'every',\n",
       "  'type',\n",
       "  'of',\n",
       "  'company',\n",
       "  'can',\n",
       "  'use',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'any',\n",
       "  'audience',\n",
       "  'all',\n",
       "  'would',\n",
       "  'find',\n",
       "  'something',\n",
       "  'of',\n",
       "  'their',\n",
       "  'liking',\n",
       "  'lets',\n",
       "  'take',\n",
       "  'a',\n",
       "  'look',\n",
       "  'at',\n",
       "  'what',\n",
       "  'does',\n",
       "  'online',\n",
       "  'marketing',\n",
       "  'involves',\n",
       "  'these',\n",
       "  'days',\n",
       "  'almost',\n",
       "  'everybody',\n",
       "  'is',\n",
       "  'on',\n",
       "  'social',\n",
       "  'media',\n",
       "  'the',\n",
       "  'majority',\n",
       "  'of',\n",
       "  'people',\n",
       "  'use',\n",
       "  'facebook',\n",
       "  'twitter',\n",
       "  'instagram',\n",
       "  'and',\n",
       "  'other',\n",
       "  'social',\n",
       "  'media',\n",
       "  'platforms',\n",
       "  'to',\n",
       "  'communicate',\n",
       "  'with',\n",
       "  'their',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'relatives',\n",
       "  'some',\n",
       "  'people',\n",
       "  'have',\n",
       "  'created',\n",
       "  'companies',\n",
       "  'solely',\n",
       "  'based',\n",
       "  'on',\n",
       "  'their',\n",
       "  'social',\n",
       "  'media',\n",
       "  'activity',\n",
       "  'you',\n",
       "  'can',\n",
       "  'however',\n",
       "  'promote',\n",
       "  'your',\n",
       "  'knowledge',\n",
       "  'commerce',\n",
       "  'products',\n",
       "  'through',\n",
       "  'social',\n",
       "  'media',\n",
       "  'whether',\n",
       "  'or',\n",
       "  'not',\n",
       "  'you',\n",
       "  'advertise',\n",
       "  'on',\n",
       "  'these',\n",
       "  'sites',\n",
       "  'the',\n",
       "  'best',\n",
       "  'social',\n",
       "  'media',\n",
       "  'networks',\n",
       "  'for',\n",
       "  'advertising',\n",
       "  'facebook',\n",
       "  'advertising',\n",
       "  'instagram',\n",
       "  'advertising',\n",
       "  'twitter',\n",
       "  'advertising',\n",
       "  'pinterest',\n",
       "  'advertising',\n",
       "  'linkedin',\n",
       "  'advertising',\n",
       "  'snapchat',\n",
       "  'advertising',\n",
       "  'content',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'a',\n",
       "  'strategic',\n",
       "  'marketing',\n",
       "  'strategy',\n",
       "  'that',\n",
       "  'focuses',\n",
       "  'on',\n",
       "  'producing',\n",
       "  'and',\n",
       "  'delivering',\n",
       "  'useful',\n",
       "  'appropriate',\n",
       "  'and',\n",
       "  'reliable',\n",
       "  'content',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'attract',\n",
       "  'and',\n",
       "  'maintain',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'audience',\n",
       "  'and',\n",
       "  'eventually',\n",
       "  'to',\n",
       "  'drive',\n",
       "  'profitable',\n",
       "  'consumer',\n",
       "  'action',\n",
       "  'in',\n",
       "  'simple',\n",
       "  'words',\n",
       "  'content',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'a',\n",
       "  'marketing',\n",
       "  'strategy',\n",
       "  'that',\n",
       "  'producers',\n",
       "  'and',\n",
       "  'delivers',\n",
       "  'relevant',\n",
       "  'and',\n",
       "  'reliable',\n",
       "  'content',\n",
       "  'to',\n",
       "  'attract',\n",
       "  'potential',\n",
       "  'clients',\n",
       "  'and',\n",
       "  'to',\n",
       "  'also',\n",
       "  'retain',\n",
       "  'existing',\n",
       "  'clients',\n",
       "  'about',\n",
       "  'half',\n",
       "  'of',\n",
       "  'all',\n",
       "  'website',\n",
       "  'traffic',\n",
       "  'originates',\n",
       "  'from',\n",
       "  'a',\n",
       "  'search',\n",
       "  'engine',\n",
       "  'people',\n",
       "  'who',\n",
       "  'use',\n",
       "  'searches',\n",
       "  'are',\n",
       "  'often',\n",
       "  'highintent',\n",
       "  'buyers',\n",
       "  'this',\n",
       "  'indicates',\n",
       "  'that',\n",
       "  'they',\n",
       "  'are',\n",
       "  'searching',\n",
       "  'for',\n",
       "  'a',\n",
       "  'particular',\n",
       "  'item',\n",
       "  'theyre',\n",
       "  'all',\n",
       "  'set',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'the',\n",
       "  'products',\n",
       "  'and',\n",
       "  'services',\n",
       "  'the',\n",
       "  'majority',\n",
       "  'of',\n",
       "  'online',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'focused',\n",
       "  'on',\n",
       "  'payperclick',\n",
       "  'ppc',\n",
       "  'however',\n",
       "  'when',\n",
       "  'you',\n",
       "  'hear',\n",
       "  'the',\n",
       "  'word',\n",
       "  'ppc',\n",
       "  'it',\n",
       "  'refers',\n",
       "  'to',\n",
       "  'search',\n",
       "  'ads',\n",
       "  'payperclick',\n",
       "  'ppc',\n",
       "  'advertising',\n",
       "  'on',\n",
       "  'search',\n",
       "  'engines',\n",
       "  'social',\n",
       "  'media',\n",
       "  'sites',\n",
       "  'and',\n",
       "  'other',\n",
       "  'online',\n",
       "  'venues',\n",
       "  'can',\n",
       "  'be',\n",
       "  'extremely',\n",
       "  'successful',\n",
       "  'so',\n",
       "  'the',\n",
       "  'next',\n",
       "  'time',\n",
       "  'when',\n",
       "  'you',\n",
       "  'search',\n",
       "  'for',\n",
       "  'a',\n",
       "  'product',\n",
       "  'and',\n",
       "  'services',\n",
       "  'and',\n",
       "  'you',\n",
       "  'find',\n",
       "  'similar',\n",
       "  'ads',\n",
       "  'on',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'internet',\n",
       "  'marketing',\n",
       "  'email',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'the',\n",
       "  'highly',\n",
       "  'successful',\n",
       "  'digital',\n",
       "  'marketing',\n",
       "  'technique',\n",
       "  'of',\n",
       "  'sending',\n",
       "  'emails',\n",
       "  'to',\n",
       "  'prospects',\n",
       "  'and',\n",
       "  'consumers',\n",
       "  'it',\n",
       "  'allows',\n",
       "  'communicating',\n",
       "  'directly',\n",
       "  'with',\n",
       "  'the',\n",
       "  'present',\n",
       "  'former',\n",
       "  'and',\n",
       "  'potential',\n",
       "  'customers',\n",
       "  'businesses',\n",
       "  'will',\n",
       "  'inform',\n",
       "  'the',\n",
       "  'audience',\n",
       "  'about',\n",
       "  'new',\n",
       "  'products',\n",
       "  'as',\n",
       "  'they',\n",
       "  'become',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'them',\n",
       "  'banner',\n",
       "  'ads',\n",
       "  'are',\n",
       "  'rectangular',\n",
       "  'or',\n",
       "  'square',\n",
       "  'advertisements',\n",
       "  'that',\n",
       "  'appear',\n",
       "  'above',\n",
       "  'in',\n",
       "  'the',\n",
       "  'sidebar',\n",
       "  'or',\n",
       "  'below',\n",
       "  'the',\n",
       "  'content',\n",
       "  'on',\n",
       "  'websites',\n",
       "  'usually',\n",
       "  'a',\n",
       "  'banner',\n",
       "  'ad',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'a',\n",
       "  'sales',\n",
       "  'or',\n",
       "  'landing',\n",
       "  'page',\n",
       "  'you',\n",
       "  'will',\n",
       "  'get',\n",
       "  'great',\n",
       "  'results',\n",
       "  'by',\n",
       "  'running',\n",
       "  'banner',\n",
       "  'ads',\n",
       "  'on',\n",
       "  'websites',\n",
       "  'that',\n",
       "  'attract',\n",
       "  'members',\n",
       "  'of',\n",
       "  'the',\n",
       "  'target',\n",
       "  'audience',\n",
       "  'an',\n",
       "  'affiliate',\n",
       "  'marketer',\n",
       "  'like',\n",
       "  'a',\n",
       "  'car',\n",
       "  'salesperson',\n",
       "  'only',\n",
       "  'gets',\n",
       "  'paid',\n",
       "  'when',\n",
       "  'someone',\n",
       "  'buys',\n",
       "  'the',\n",
       "  'stuff',\n",
       "  'you',\n",
       "  'may',\n",
       "  'not',\n",
       "  'have',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'if',\n",
       "  'there',\n",
       "  'are',\n",
       "  'no',\n",
       "  'purchases',\n",
       "  'affiliates',\n",
       "  'are',\n",
       "  'free',\n",
       "  'to',\n",
       "  'sell',\n",
       "  'your',\n",
       "  'goods',\n",
       "  'anywhere',\n",
       "  'they',\n",
       "  'choose',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'the',\n",
       "  'material',\n",
       "  'follows',\n",
       "  'the',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'service',\n",
       "  'of',\n",
       "  'the',\n",
       "  'website',\n",
       "  'its',\n",
       "  'a',\n",
       "  'fantastic',\n",
       "  'way',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'new',\n",
       "  'markets',\n",
       "  'anyone',\n",
       "  'can',\n",
       "  'start',\n",
       "  'their',\n",
       "  'affiliate',\n",
       "  'marketing',\n",
       "  'career',\n",
       "  'by',\n",
       "  'registering',\n",
       "  'on',\n",
       "  'the',\n",
       "  'different',\n",
       "  'affiliate',\n",
       "  'websites',\n",
       "  'influencer',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'a',\n",
       "  'new',\n",
       "  'trend',\n",
       "  'for',\n",
       "  'online',\n",
       "  'marketing',\n",
       "  'they',\n",
       "  'have',\n",
       "  'a',\n",
       "  'strong',\n",
       "  'following',\n",
       "  'can',\n",
       "  'inspire',\n",
       "  'people',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'your',\n",
       "  'goods',\n",
       "  'and',\n",
       "  'are',\n",
       "  'loved',\n",
       "  'by',\n",
       "  'their',\n",
       "  'viewers',\n",
       "  'the',\n",
       "  'type',\n",
       "  'of',\n",
       "  'online',\n",
       "  'marketing',\n",
       "  'that',\n",
       "  'will',\n",
       "  'work',\n",
       "  'best',\n",
       "  'for',\n",
       "  'the',\n",
       "  'company',\n",
       "  'will',\n",
       "  'be',\n",
       "  'determined',\n",
       "  'by',\n",
       "  'many',\n",
       "  'factors',\n",
       "  'including',\n",
       "  'the',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'your',\n",
       "  'industry',\n",
       "  'the',\n",
       "  'tastes',\n",
       "  'and',\n",
       "  'demographics',\n",
       "  'of',\n",
       "  'the',\n",
       "  'target',\n",
       "  'market',\n",
       "  'and',\n",
       "  'budget',\n",
       "  'market',\n",
       "  'analysis',\n",
       "  'will',\n",
       "  'guide',\n",
       "  'to',\n",
       "  'the',\n",
       "  'best',\n",
       "  'strategy',\n",
       "  'or',\n",
       "  'combination',\n",
       "  'of',\n",
       "  'strategies',\n",
       "  'for',\n",
       "  'your',\n",
       "  'offerings',\n",
       "  'and',\n",
       "  'comprehensive',\n",
       "  'performance',\n",
       "  'metrics',\n",
       "  'will',\n",
       "  'show',\n",
       "  'you',\n",
       "  'which',\n",
       "  'are',\n",
       "  'the',\n",
       "  'most',\n",
       "  'effective',\n",
       "  'online',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'a',\n",
       "  'rapidly',\n",
       "  'expanding',\n",
       "  'industry',\n",
       "  'that',\n",
       "  'benefits',\n",
       "  'companies',\n",
       "  'in',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'ways',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'people',\n",
       "  'who',\n",
       "  'purchase',\n",
       "  'goods',\n",
       "  'and',\n",
       "  'services',\n",
       "  'online',\n",
       "  'is',\n",
       "  'on',\n",
       "  'the',\n",
       "  'rise',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'an',\n",
       "  'increasing',\n",
       "  'number',\n",
       "  'of',\n",
       "  'businesses',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'are',\n",
       "  'turning',\n",
       "  'to',\n",
       "  'internet',\n",
       "  'marketing',\n",
       "  'to',\n",
       "  'communicate',\n",
       "  'with',\n",
       "  'consumers',\n",
       "  'and',\n",
       "  'advertise',\n",
       "  'their',\n",
       "  'goods',\n",
       "  'and',\n",
       "  'services']]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/54.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "98c841be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744\n",
      "WORD COUNT 474\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ad9e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 16.555555555555557\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cade8a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.4029535864978903\n",
      "FOG INDEX: 6.783403656821379\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 16.555555555555557\n",
      "COMPLEX WORD COUNT: 191\n",
      "WORD COUNT: 474\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e66f2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1433\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 5.2241610738255035\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_54.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551175d",
   "metadata": {},
   "source": [
    "# 19. for url 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "029874d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\4145456027.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/evolution-of-advertising-industry/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "efc0d4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Advertising can be described as a type of specific content broadcasting to a larger audience; the form can take several different forms, and the intended message can differ from genre to genre. The target for each medium could be different. Advertised content could be in print, radio, TV, or digital formats.',\n",
       " 'We’ll look at how the advertising market has changed over the last ten decade.',\n",
       " 'Advertising is a form of communication that aims to persuade a target audience. Typical advertising messages endorse programs, goods, concepts, people, and companies. ',\n",
       " 'First, conventional types of advertising were used to carry out advertising. Let’s take a look at the traditional forms of advertising.',\n",
       " 'Advertising can include in-flight advertising, street furniture, passenger displays, billboards, skywriting, posters, wall paintings, banners, taxi cabs, passenger screens, television, and newspaper advertisements.',\n",
       " 'Other types of advertising include press advertisements in magazines and newspapers. Advertising in the classified section of a newspaper is an example of press advertising. A billboard or digital screen placed on a moving vehicle is often referred to as a mobile billboard.',\n",
       " 'When a brand or product is used in a large entertainment venue, it is known as convert ads or guerrilla advertising. ',\n",
       " 'When a soft drink, a watch, or a pair of sneakers is seen or mentioned in a common film, this is an example of this.',\n",
       " 'Ad in supermarket videos, aisles, and on the inside of shopping carts is referred to as in-store advertising.',\n",
       " 'Consumers are influenced by celebrity advertisements because of the power of wealth, fame, and popularity. However, if a celebrity falls out of favor, the use of that celebrity may be detrimental to a company.',\n",
       " 'Religious organizations, political parties, political candidates, and special interest groups are examples of noncommercial ads.',\n",
       " 'These were the conventional forms of advertisement, but as the internet and technology progressed, the advertising industry began to play a role in helping brands establish a digital presence and advertising their products in a new way.',\n",
       " 'The advertising industry is a multibillion-dollar global company that connects producers with customers. According to the research firm eMarkerter, global media advertising spending totaled nearly $629 billion in 2018, with digital advertising accounting for nearly 44% of that amount.',\n",
       " 'For more than a decade, consumers’ perspectives have been shifted in favor of commercials. Advertisements are created based on the preferences of the target audience, and as the population has become more tech-savvy, advertising agencies have shifted their focus from conventional to digital advertising. The internet, as well as the devices, used to access it.',\n",
       " 'Internet advertising has evolved from a risky gamble to the main marketing medium for most businesses. Digital advertising continues to expand by double digits on an annual revenue basis in the United States, with overall spending exceeding $129 billion in 2019.',\n",
       " 'Mobile advertising is a form of advertising that uses wireless devices such as smartphones, tablets, and personal digital assistants to view advertisements. In the consumer goods and retail industries, it is extremely necessary.',\n",
       " 'Mobile advertising contents tailored to particular age groups present an opportunity for the mobile advertising industry. The challenges that the mobile advertising industry faces pose a significant risk of new entrants.',\n",
       " 'Content marketing is an old trend that has resurfaced. Many marketers have struggled to determine how powerful banners and display advertising on other people’s content are.',\n",
       " 'Companies are embedding their marketing pitch within the content itself, rather than serving an ad. This can take the form of publisher-tailored content that the advertiser can support or content that the advertiser publishes directly.',\n",
       " 'There are different kinds of businesses and websites that have used content marketing to grow and flourish in the industry. Content marketing is a trend that has contributed a large amount of income to the advertisement industry.',\n",
       " 'To summarise, the advertising industry has evolved through time and will continue to do so as technology advances, allowing advertisers to reach a wider audience and gain a greater understanding of the people to whom they are delivering material.',\n",
       " 'The advertising industry will continue to develop in tandem with innovation. People are also becoming more jaded when it comes to advertisements, pushing businesses to come up with new ways to convey their messages. However, advertisement has a promising future. ']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4ef51130",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:38]))\n",
    "URL_ID_55 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dcab225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41 sentences in the string.\n",
      "The number of words in the string is: 701\n",
      "The number of characters in the string is: 3912\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 14:33:16] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 14:33:24] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_55.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_55.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_55.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_55 = re.sub(re_punt, \"\",URL_ID_55)\n",
    "\n",
    "file = open(\"55.txt\", \"w\")\n",
    "file.write(URL_ID_55)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"55.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2c06413e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['advertising',\n",
       "  'can',\n",
       "  'be',\n",
       "  'described',\n",
       "  'as',\n",
       "  'a',\n",
       "  'type',\n",
       "  'of',\n",
       "  'specific',\n",
       "  'content',\n",
       "  'broadcasting',\n",
       "  'to',\n",
       "  'a',\n",
       "  'larger',\n",
       "  'audience',\n",
       "  'the',\n",
       "  'form',\n",
       "  'can',\n",
       "  'take',\n",
       "  'several',\n",
       "  'different',\n",
       "  'forms',\n",
       "  'and',\n",
       "  'the',\n",
       "  'intended',\n",
       "  'message',\n",
       "  'can',\n",
       "  'differ',\n",
       "  'from',\n",
       "  'genre',\n",
       "  'to',\n",
       "  'genre',\n",
       "  'the',\n",
       "  'target',\n",
       "  'for',\n",
       "  'each',\n",
       "  'medium',\n",
       "  'could',\n",
       "  'be',\n",
       "  'different',\n",
       "  'advertised',\n",
       "  'content',\n",
       "  'could',\n",
       "  'be',\n",
       "  'in',\n",
       "  'print',\n",
       "  'radio',\n",
       "  'tv',\n",
       "  'or',\n",
       "  'digital',\n",
       "  'formats',\n",
       "  'well',\n",
       "  'look',\n",
       "  'at',\n",
       "  'how',\n",
       "  'the',\n",
       "  'advertising',\n",
       "  'market',\n",
       "  'has',\n",
       "  'changed',\n",
       "  'over',\n",
       "  'the',\n",
       "  'last',\n",
       "  'ten',\n",
       "  'decade',\n",
       "  'advertising',\n",
       "  'is',\n",
       "  'a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'communication',\n",
       "  'that',\n",
       "  'aims',\n",
       "  'to',\n",
       "  'persuade',\n",
       "  'a',\n",
       "  'target',\n",
       "  'audience',\n",
       "  'typical',\n",
       "  'advertising',\n",
       "  'messages',\n",
       "  'endorse',\n",
       "  'programs',\n",
       "  'goods',\n",
       "  'concepts',\n",
       "  'people',\n",
       "  'and',\n",
       "  'companies',\n",
       "  'first',\n",
       "  'conventional',\n",
       "  'types',\n",
       "  'of',\n",
       "  'advertising',\n",
       "  'were',\n",
       "  'used',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'out',\n",
       "  'advertising',\n",
       "  'lets',\n",
       "  'take',\n",
       "  'a',\n",
       "  'look',\n",
       "  'at',\n",
       "  'the',\n",
       "  'traditional',\n",
       "  'forms',\n",
       "  'of',\n",
       "  'advertising',\n",
       "  'advertising',\n",
       "  'can',\n",
       "  'include',\n",
       "  'inflight',\n",
       "  'advertising',\n",
       "  'street',\n",
       "  'furniture',\n",
       "  'passenger',\n",
       "  'displays',\n",
       "  'billboards',\n",
       "  'skywriting',\n",
       "  'posters',\n",
       "  'wall',\n",
       "  'paintings',\n",
       "  'banners',\n",
       "  'taxi',\n",
       "  'cabs',\n",
       "  'passenger',\n",
       "  'screens',\n",
       "  'television',\n",
       "  'and',\n",
       "  'newspaper',\n",
       "  'advertisements',\n",
       "  'other',\n",
       "  'types',\n",
       "  'of',\n",
       "  'advertising',\n",
       "  'include',\n",
       "  'press',\n",
       "  'advertisements',\n",
       "  'in',\n",
       "  'magazines',\n",
       "  'and',\n",
       "  'newspapers',\n",
       "  'advertising',\n",
       "  'in',\n",
       "  'the',\n",
       "  'classified',\n",
       "  'section',\n",
       "  'of',\n",
       "  'a',\n",
       "  'newspaper',\n",
       "  'is',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'press',\n",
       "  'advertising',\n",
       "  'a',\n",
       "  'billboard',\n",
       "  'or',\n",
       "  'digital',\n",
       "  'screen',\n",
       "  'placed',\n",
       "  'on',\n",
       "  'a',\n",
       "  'moving',\n",
       "  'vehicle',\n",
       "  'is',\n",
       "  'often',\n",
       "  'referred',\n",
       "  'to',\n",
       "  'as',\n",
       "  'a',\n",
       "  'mobile',\n",
       "  'billboard',\n",
       "  'when',\n",
       "  'a',\n",
       "  'brand',\n",
       "  'or',\n",
       "  'product',\n",
       "  'is',\n",
       "  'used',\n",
       "  'in',\n",
       "  'a',\n",
       "  'large',\n",
       "  'entertainment',\n",
       "  'venue',\n",
       "  'it',\n",
       "  'is',\n",
       "  'known',\n",
       "  'as',\n",
       "  'convert',\n",
       "  'ads',\n",
       "  'or',\n",
       "  'guerrilla',\n",
       "  'advertising',\n",
       "  'when',\n",
       "  'a',\n",
       "  'soft',\n",
       "  'drink',\n",
       "  'a',\n",
       "  'watch',\n",
       "  'or',\n",
       "  'a',\n",
       "  'pair',\n",
       "  'of',\n",
       "  'sneakers',\n",
       "  'is',\n",
       "  'seen',\n",
       "  'or',\n",
       "  'mentioned',\n",
       "  'in',\n",
       "  'a',\n",
       "  'common',\n",
       "  'film',\n",
       "  'this',\n",
       "  'is',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'this',\n",
       "  'ad',\n",
       "  'in',\n",
       "  'supermarket',\n",
       "  'videos',\n",
       "  'aisles',\n",
       "  'and',\n",
       "  'on',\n",
       "  'the',\n",
       "  'inside',\n",
       "  'of',\n",
       "  'shopping',\n",
       "  'carts',\n",
       "  'is',\n",
       "  'referred',\n",
       "  'to',\n",
       "  'as',\n",
       "  'instore',\n",
       "  'advertising',\n",
       "  'consumers',\n",
       "  'are',\n",
       "  'influenced',\n",
       "  'by',\n",
       "  'celebrity',\n",
       "  'advertisements',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'power',\n",
       "  'of',\n",
       "  'wealth',\n",
       "  'fame',\n",
       "  'and',\n",
       "  'popularity',\n",
       "  'however',\n",
       "  'if',\n",
       "  'a',\n",
       "  'celebrity',\n",
       "  'falls',\n",
       "  'out',\n",
       "  'of',\n",
       "  'favor',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'that',\n",
       "  'celebrity',\n",
       "  'may',\n",
       "  'be',\n",
       "  'detrimental',\n",
       "  'to',\n",
       "  'a',\n",
       "  'company',\n",
       "  'religious',\n",
       "  'organizations',\n",
       "  'political',\n",
       "  'parties',\n",
       "  'political',\n",
       "  'candidates',\n",
       "  'and',\n",
       "  'special',\n",
       "  'interest',\n",
       "  'groups',\n",
       "  'are',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'noncommercial',\n",
       "  'ads',\n",
       "  'these',\n",
       "  'were',\n",
       "  'the',\n",
       "  'conventional',\n",
       "  'forms',\n",
       "  'of',\n",
       "  'advertisement',\n",
       "  'but',\n",
       "  'as',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'and',\n",
       "  'technology',\n",
       "  'progressed',\n",
       "  'the',\n",
       "  'advertising',\n",
       "  'industry',\n",
       "  'began',\n",
       "  'to',\n",
       "  'play',\n",
       "  'a',\n",
       "  'role',\n",
       "  'in',\n",
       "  'helping',\n",
       "  'brands',\n",
       "  'establish',\n",
       "  'a',\n",
       "  'digital',\n",
       "  'presence',\n",
       "  'and',\n",
       "  'advertising',\n",
       "  'their',\n",
       "  'products',\n",
       "  'in',\n",
       "  'a',\n",
       "  'new',\n",
       "  'way',\n",
       "  'the',\n",
       "  'advertising',\n",
       "  'industry',\n",
       "  'is',\n",
       "  'a',\n",
       "  'multibilliondollar',\n",
       "  'global',\n",
       "  'company',\n",
       "  'that',\n",
       "  'connects',\n",
       "  'producers',\n",
       "  'with',\n",
       "  'customers',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'research',\n",
       "  'firm',\n",
       "  'emarkerter',\n",
       "  'global',\n",
       "  'media',\n",
       "  'advertising',\n",
       "  'spending',\n",
       "  'totaled',\n",
       "  'nearly',\n",
       "  '629',\n",
       "  'billion',\n",
       "  'in',\n",
       "  '2018',\n",
       "  'with',\n",
       "  'digital',\n",
       "  'advertising',\n",
       "  'accounting',\n",
       "  'for',\n",
       "  'nearly',\n",
       "  '44',\n",
       "  'of',\n",
       "  'that',\n",
       "  'amount',\n",
       "  'for',\n",
       "  'more',\n",
       "  'than',\n",
       "  'a',\n",
       "  'decade',\n",
       "  'consumers',\n",
       "  'perspectives',\n",
       "  'have',\n",
       "  'been',\n",
       "  'shifted',\n",
       "  'in',\n",
       "  'favor',\n",
       "  'of',\n",
       "  'commercials',\n",
       "  'advertisements',\n",
       "  'are',\n",
       "  'created',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'preferences',\n",
       "  'of',\n",
       "  'the',\n",
       "  'target',\n",
       "  'audience',\n",
       "  'and',\n",
       "  'as',\n",
       "  'the',\n",
       "  'population',\n",
       "  'has',\n",
       "  'become',\n",
       "  'more',\n",
       "  'techsavvy',\n",
       "  'advertising',\n",
       "  'agencies',\n",
       "  'have',\n",
       "  'shifted',\n",
       "  'their',\n",
       "  'focus',\n",
       "  'from',\n",
       "  'conventional',\n",
       "  'to',\n",
       "  'digital',\n",
       "  'advertising',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'the',\n",
       "  'devices',\n",
       "  'used',\n",
       "  'to',\n",
       "  'access',\n",
       "  'it',\n",
       "  'internet',\n",
       "  'advertising',\n",
       "  'has',\n",
       "  'evolved',\n",
       "  'from',\n",
       "  'a',\n",
       "  'risky',\n",
       "  'gamble',\n",
       "  'to',\n",
       "  'the',\n",
       "  'main',\n",
       "  'marketing',\n",
       "  'medium',\n",
       "  'for',\n",
       "  'most',\n",
       "  'businesses',\n",
       "  'digital',\n",
       "  'advertising',\n",
       "  'continues',\n",
       "  'to',\n",
       "  'expand',\n",
       "  'by',\n",
       "  'double',\n",
       "  'digits',\n",
       "  'on',\n",
       "  'an',\n",
       "  'annual',\n",
       "  'revenue',\n",
       "  'basis',\n",
       "  'in',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  'with',\n",
       "  'overall',\n",
       "  'spending',\n",
       "  'exceeding',\n",
       "  '129',\n",
       "  'billion',\n",
       "  'in',\n",
       "  '2019',\n",
       "  'mobile',\n",
       "  'advertising',\n",
       "  'is',\n",
       "  'a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'advertising',\n",
       "  'that',\n",
       "  'uses',\n",
       "  'wireless',\n",
       "  'devices',\n",
       "  'such',\n",
       "  'as',\n",
       "  'smartphones',\n",
       "  'tablets',\n",
       "  'and',\n",
       "  'personal',\n",
       "  'digital',\n",
       "  'assistants',\n",
       "  'to',\n",
       "  'view',\n",
       "  'advertisements',\n",
       "  'in',\n",
       "  'the',\n",
       "  'consumer',\n",
       "  'goods',\n",
       "  'and',\n",
       "  'retail',\n",
       "  'industries',\n",
       "  'it',\n",
       "  'is',\n",
       "  'extremely',\n",
       "  'necessary',\n",
       "  'mobile',\n",
       "  'advertising',\n",
       "  'contents',\n",
       "  'tailored',\n",
       "  'to',\n",
       "  'particular',\n",
       "  'age',\n",
       "  'groups',\n",
       "  'present',\n",
       "  'an',\n",
       "  'opportunity',\n",
       "  'for',\n",
       "  'the',\n",
       "  'mobile',\n",
       "  'advertising',\n",
       "  'industry',\n",
       "  'the',\n",
       "  'challenges',\n",
       "  'that',\n",
       "  'the',\n",
       "  'mobile',\n",
       "  'advertising',\n",
       "  'industry',\n",
       "  'faces',\n",
       "  'pose',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'new',\n",
       "  'entrants',\n",
       "  'content',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'an',\n",
       "  'old',\n",
       "  'trend',\n",
       "  'that',\n",
       "  'has',\n",
       "  'resurfaced',\n",
       "  'many',\n",
       "  'marketers',\n",
       "  'have',\n",
       "  'struggled',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'how',\n",
       "  'powerful',\n",
       "  'banners',\n",
       "  'and',\n",
       "  'display',\n",
       "  'advertising',\n",
       "  'on',\n",
       "  'other',\n",
       "  'peoples',\n",
       "  'content',\n",
       "  'are',\n",
       "  'companies',\n",
       "  'are',\n",
       "  'embedding',\n",
       "  'their',\n",
       "  'marketing',\n",
       "  'pitch',\n",
       "  'within',\n",
       "  'the',\n",
       "  'content',\n",
       "  'itself',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'serving',\n",
       "  'an',\n",
       "  'ad',\n",
       "  'this',\n",
       "  'can',\n",
       "  'take',\n",
       "  'the',\n",
       "  'form',\n",
       "  'of',\n",
       "  'publishertailored',\n",
       "  'content',\n",
       "  'that',\n",
       "  'the',\n",
       "  'advertiser',\n",
       "  'can',\n",
       "  'support',\n",
       "  'or',\n",
       "  'content',\n",
       "  'that',\n",
       "  'the',\n",
       "  'advertiser',\n",
       "  'publishes',\n",
       "  'directly',\n",
       "  'there',\n",
       "  'are',\n",
       "  'different',\n",
       "  'kinds',\n",
       "  'of',\n",
       "  'businesses',\n",
       "  'and',\n",
       "  'websites',\n",
       "  'that',\n",
       "  'have',\n",
       "  'used',\n",
       "  'content',\n",
       "  'marketing',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'and',\n",
       "  'flourish',\n",
       "  'in',\n",
       "  'the',\n",
       "  'industry',\n",
       "  'content',\n",
       "  'marketing',\n",
       "  'is',\n",
       "  'a',\n",
       "  'trend',\n",
       "  'that',\n",
       "  'has',\n",
       "  'contributed',\n",
       "  'a',\n",
       "  'large',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'income',\n",
       "  'to',\n",
       "  'the',\n",
       "  'advertisement',\n",
       "  'industry',\n",
       "  'to',\n",
       "  'summarise',\n",
       "  'the',\n",
       "  'advertising',\n",
       "  'industry',\n",
       "  'has',\n",
       "  'evolved',\n",
       "  'through',\n",
       "  'time',\n",
       "  'and',\n",
       "  'will',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'do',\n",
       "  'so',\n",
       "  'as',\n",
       "  'technology',\n",
       "  'advances',\n",
       "  'allowing',\n",
       "  'advertisers',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'a',\n",
       "  'wider',\n",
       "  'audience',\n",
       "  'and',\n",
       "  'gain',\n",
       "  'a',\n",
       "  'greater',\n",
       "  'understanding',\n",
       "  'of',\n",
       "  'the',\n",
       "  'people',\n",
       "  'to',\n",
       "  'whom',\n",
       "  'they',\n",
       "  'are',\n",
       "  'delivering',\n",
       "  'material',\n",
       "  'the',\n",
       "  'advertising',\n",
       "  'industry',\n",
       "  'will',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'develop',\n",
       "  'in',\n",
       "  'tandem',\n",
       "  'with',\n",
       "  'innovation',\n",
       "  'people',\n",
       "  'are',\n",
       "  'also',\n",
       "  'becoming',\n",
       "  'more',\n",
       "  'jaded',\n",
       "  'when',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'advertisements',\n",
       "  'pushing',\n",
       "  'businesses',\n",
       "  'to',\n",
       "  'come',\n",
       "  'up',\n",
       "  'with',\n",
       "  'new',\n",
       "  'ways',\n",
       "  'to',\n",
       "  'convey',\n",
       "  'their',\n",
       "  'messages',\n",
       "  'however',\n",
       "  'advertisement',\n",
       "  'has',\n",
       "  'a',\n",
       "  'promising',\n",
       "  'future']]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/55.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8500d1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n",
      "WORD COUNT 456\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "01231fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 17.097560975609756\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5abe622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.45614035087719296\n",
      "FOG INDEX: 7.021480530594779\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 17.097560975609756\n",
      "COMPLEX WORD COUNT: 208\n",
      "WORD COUNT: 456\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "03e505a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1396\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 5.580599144079886\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_55.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c101849",
   "metadata": {},
   "source": [
    "# 20.for url 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5d07b320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\375248540.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "65eea55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before we get into the whole discussion, let’s first discuss the basic working of data analysis.',\n",
       " 'Data analysis is defined as a process of cleaning, transforming, and modeling data to discover useful information for business decision-making.',\n",
       " 'Using data analysis, we can extract useful information from the given data and then take corresponding decisions based upon the analyzed data.',\n",
       " 'During the pandemic known as COVID-19, many businesses failed to grow whereas many touched the sky, for example, the transportation of raw materials was drastically low because:',\n",
       " 'On the other hand, new business/startups got a chance to compete in the market by getting early responses from the companies they wanted to tie up with or from the head of the companies that they wanted investments from.',\n",
       " 'The data analysis can help businesses in many ways such as:',\n",
       " 'Data analysis provides different analytical techniques such as:',\n",
       " 'Using these techniques, businesses can analyze everything and predict almost anything.',\n",
       " 'These techniques, tools, and models, can help businesses tackle this horrendous situation that is COVID-19.']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d48225ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:25]))\n",
    "URL_ID_56 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "31153da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 sentences in the string.\n",
      "The number of words in the string is: 171\n",
      "The number of characters in the string is: 945\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 18:50:12] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 18:50:40] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 18:50:50] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_56.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_56.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_56.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_56 = re.sub(re_punt, \"\",URL_ID_56)\n",
    "\n",
    "file = open(\"56.txt\", \"w\")\n",
    "file.write(URL_ID_56)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"56.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "daf3e1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['data',\n",
       "  'analysis',\n",
       "  'before',\n",
       "  'we',\n",
       "  'get',\n",
       "  'into',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'discussion',\n",
       "  'lets',\n",
       "  'first',\n",
       "  'discuss',\n",
       "  'the',\n",
       "  'basic',\n",
       "  'working',\n",
       "  'of',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'is',\n",
       "  'defined',\n",
       "  'as',\n",
       "  'a',\n",
       "  'process',\n",
       "  'of',\n",
       "  'cleaning',\n",
       "  'transforming',\n",
       "  'and',\n",
       "  'modeling',\n",
       "  'data',\n",
       "  'to',\n",
       "  'discover',\n",
       "  'useful',\n",
       "  'information',\n",
       "  'for',\n",
       "  'business',\n",
       "  'decisionmaking',\n",
       "  'using',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'we',\n",
       "  'can',\n",
       "  'extract',\n",
       "  'useful',\n",
       "  'information',\n",
       "  'from',\n",
       "  'the',\n",
       "  'given',\n",
       "  'data',\n",
       "  'and',\n",
       "  'then',\n",
       "  'take',\n",
       "  'corresponding',\n",
       "  'decisions',\n",
       "  'based',\n",
       "  'upon',\n",
       "  'the',\n",
       "  'analyzed',\n",
       "  'data',\n",
       "  'during',\n",
       "  'the',\n",
       "  'pandemic',\n",
       "  'known',\n",
       "  'as',\n",
       "  'covid19',\n",
       "  'many',\n",
       "  'businesses',\n",
       "  'failed',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'whereas',\n",
       "  'many',\n",
       "  'touched',\n",
       "  'the',\n",
       "  'sky',\n",
       "  'for',\n",
       "  'example',\n",
       "  'the',\n",
       "  'transportation',\n",
       "  'of',\n",
       "  'raw',\n",
       "  'materials',\n",
       "  'was',\n",
       "  'drastically',\n",
       "  'low',\n",
       "  'because',\n",
       "  'on',\n",
       "  'the',\n",
       "  'other',\n",
       "  'hand',\n",
       "  'new',\n",
       "  'businessstartups',\n",
       "  'got',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'compete',\n",
       "  'in',\n",
       "  'the',\n",
       "  'market',\n",
       "  'by',\n",
       "  'getting',\n",
       "  'early',\n",
       "  'responses',\n",
       "  'from',\n",
       "  'the',\n",
       "  'companies',\n",
       "  'they',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'tie',\n",
       "  'up',\n",
       "  'with',\n",
       "  'or',\n",
       "  'from',\n",
       "  'the',\n",
       "  'head',\n",
       "  'of',\n",
       "  'the',\n",
       "  'companies',\n",
       "  'that',\n",
       "  'they',\n",
       "  'wanted',\n",
       "  'investments',\n",
       "  'from',\n",
       "  'the',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'can',\n",
       "  'help',\n",
       "  'businesses',\n",
       "  'in',\n",
       "  'many',\n",
       "  'ways',\n",
       "  'such',\n",
       "  'as',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'provides',\n",
       "  'different',\n",
       "  'analytical',\n",
       "  'techniques',\n",
       "  'such',\n",
       "  'as',\n",
       "  'using',\n",
       "  'these',\n",
       "  'techniques',\n",
       "  'businesses',\n",
       "  'can',\n",
       "  'analyze',\n",
       "  'everything',\n",
       "  'and',\n",
       "  'predict',\n",
       "  'almost',\n",
       "  'anything',\n",
       "  'these',\n",
       "  'techniques',\n",
       "  'tools',\n",
       "  'and',\n",
       "  'models',\n",
       "  'can',\n",
       "  'help',\n",
       "  'businesses',\n",
       "  'tackle',\n",
       "  'this',\n",
       "  'horrendous',\n",
       "  'situation',\n",
       "  'that',\n",
       "  'is',\n",
       "  'covid19']]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/56.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1e0c97b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n",
      "WORD COUNT 108\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0f08eb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 24.428571428571427\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "274bce99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.4444444444444444\n",
      "FOG INDEX: 9.94920634920635\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 24.428571428571427\n",
      "COMPLEX WORD COUNT: 48\n",
      "WORD COUNT: 108\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4c45999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 324\n",
      "I: 0\n",
      "we: 2\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 2\n",
      "PERSONAL PRONOUNS: 2\n",
      "AVG WORD LENGTH: 5.526315789473684\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_56.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e9815",
   "metadata": {},
   "source": [
    "# 22. url 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "881d8615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\668883652.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a9ffdf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Covid- 19 pandemics forced factories to shut down, flights getting canceled and a massive decrease in the global economy, with a significant decrease in Green House Gases (GHG) in many developed and developing countries.',\n",
       " 'The SARS- CoV2 came into the spotlight in December 2019 and has impacted most of the countries till then. Nearly 131 million peoples were infected worldwide and resulting in deaths of around 2.9 Million according to World Health Organisation (WHO). Most of the countries dealt with the new virus by imposing strict lockdowns and social distancing to control the spread of the virus. These policies caused adverse effects worldwide. One of the most important impacts of the Covid-19 Pandemic is on the environment.',\n",
       " 'There have been few positive impacts on the environment due to lockdown like, air pollution has decreased dramatically, as people were asked to stay in their houses due to the lockdowns. There has also been a sharp decline in environmental noise. Environmental noise can be well defined as the unwanted or harmful outdoor sounds caused by human activities like noise emitted by road traffics, air traffics, rail traffics, and industrial activities. It is one of the most important challenges in the modern era as noise pollution can cause adverse effects on humans as well as harm many animals too. The imposition of lockdown and quarantine by various nation’s governments has caused people to remain back at their homes. Because of this, the movement of people from one place to a different place has reduced significantly and the use of personal and public transport has also decreased. Due to all these changes, the environmental noise generated in most of the cities has dropped substantially.',\n",
       " '',\n",
       " 'Water Pollution at beaches have reduced significantly and many animals were spotted back in the cities, but the covid-19 virus has also generated many negative and indirect effect on the environment.',\n",
       " 'To begin with, some of the developed countries have halted their sustainability program during the pandemic. In the United States and in many other European nation-States, waste recycling plants have been suspended in many municipalities and cities due to the concern of the virus getting spread at the recycling centers. This has resulted in an increase in the use of single-use plastic bags instead of the re-usable bags by many leading restaurants, firms, and corporations. For instance, Starbucks, a leading coffee company during the month of March 2020, has announced a short-lived ban on the utilization of recyclable and reusable cups.',\n",
       " 'Furthermore, with most of the people staying indoors because of the lockdown majority of the department stores, shops, restaurants, and food outlets are closed, making an online purchase and food delivery are quite high. This has created more consumption and demand for fossil fuels due to the transportation and mobility of these goods to each individual. There has been an enormous upsurge of medical waste- because most of the products employed by healthcare professionals are usually single-use items that can be used only once before they are disposed of. Some of these wastes include used masks, personal protection kits, and gloves. For instance, nearly 200 tons of medical waste were generated during the peak of the pandemic breakout in Wuhan, China. This is 50 tones more than the average waste generated before the outbreak in Wuhan.',\n",
       " '',\n",
       " 'These organic and inorganic wastes generated due to the policies crafted by the government takes a heavy toll on the environment and can cause environmental issues like water pollution, air pollution, soil erosion, and can harm the local flora and fauna.',\n",
       " 'The demand for masks during the pandemic has become skyrocketing but the materials required for the production of these masks are highly dangerous for the environment as they are generally composed of non-woven fabrics. Polyester, Polystyrene, polyethylene, and polycarbonate, are some common materials used for the surgical mask with density lying between 20grams to 25 grams/sq. meter. These materials are mostly resistant to liquids and are plastic-based products with a really high afterlife after being discarded. If not treated properly without discarding, they end up filling the landfills and the oceans making it dangerous to aquatic lifeforms. For example, recently the environment in Hong Kong has started degrading drastically during the pandemic with the accumulation of these clinical wastes.',\n",
       " '',\n",
       " 'With recycling plants on hold, piles of small mountains of wastes and their depositions at open areas are formed due to the increasing number of unrecycled wastes generated every day. This makes the surrounding more vulnerable and also creating a high risk of air pollutions as the dumped open wastes decays into Methane (CH4), a greenhouse gas, hence increasing the risk of global warming too.  Not only the surroundings are getting affected by these careless methods, but the local people are also getting affected. If the excess methane gets accumulated in the Earth’s atmosphere due to piles of unrecycled wastes, this could result in increases in Earth’s average temperature and can be harmful to future generations.',\n",
       " 'Many protected and endangered flora and fauna are facing much greater risks due to the imposition of the lockdown. Many countries under lockdown have made people stay inside their homes. The employees, NGOs, and volunteers working in these protected areas like National Parks, Marine Conservation Zones, and wildlife sanctuaries are made to stay at home making these protected and endangered flora and fauna unattended. This has also led to an increase in many illegal activities like wildlife hunting, illegal deforestation, and fishing activities due to the absence of these people. The prohibition of eco-tourism has also led to a significant financial drop in the economy of these protected areas.',\n",
       " 'Some nations like China have asked the local authorities and native government bodies to increase the amount of disinfection routine, mainly to increase the dosage of chlorine in the wastewater treatment plant to prevent the spread of the COVID-19 virus. However, according to WHO (2020), no solid evidence has been found on the survival of the virus on the lifespan of the virus in wastewater as well as in drinking water. Despite the fact that excessive amounts of chlorine in water can cause harmful problems and issues associated with people’s health like bladder cancer and it also damages its cells.',\n",
       " 'The COVID-19 is a reminder that the health of the planet is also linked to the health of humans. Evidence proves that the virus is zoonotic, meaning it can be transmitted between people and animals. They are accountable for seventy-five percent of all emerging infectious diseases in the World. With the Virus infecting millions of people every day across the globe, Various governments and agencies’ top priority is to regulate the spread of the virus by shifting the spotlight on the management and treatment of wastes (especially the clinical and medical waste).  Likewise, at the same time, we as responsible individuals need to step up and follow the necessary guideline and precautions for the disposal of the waste and medical gears.',\n",
       " '',\n",
       " 'In Spite of various data showing that the pollutions have reduced significantly during the pandemic, History has witnessed a rise in pollution during any “post-financial crisis”.  A similar case was observed during the 2008 financial crash – although there was a temporary decrease in emissions of 1.3% was observed, but as the economy recovered in 2010, emissions were at an all-time high. After all, only through sheer mutual empathy and goodwill that the world will emerge stronger after this global pandemic. To prevent future outbreaks, we must address regularly the threats to the ecosystems and wildlife, including habitat loss, illegal trade, pollution, and climate change as human life depends on Earth’s life.',\n",
       " 'If you live near a spacious outdoor area, like the desert or an empty road lined with trees and you realize it’s the only safe, surface-less space to take a walk in, then you begin to realize the beauty of nature. The point is not to remain indoors, but to avoid being in close contact with others. When you do leave your home, whether it is for a walk in the desert or a run on your street, make sure to wipe down any surfaces you come into contact with, avoid touching your face, and frequently wash your hands.']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a14f7a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:34]))\n",
    "URL_ID_58 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e8f30a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58 sentences in the string.\n",
      "The number of words in the string is: 1366\n",
      "The number of characters in the string is: 7123\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 19:08:59] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 19:09:08] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_58.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_58.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_58.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_58 = re.sub(re_punt, \"\",URL_ID_58)\n",
    "\n",
    "file = open(\"58.txt\", \"w\")\n",
    "file.write(URL_ID_58)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"58.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8f6042c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'covid',\n",
       "  '19',\n",
       "  'pandemics',\n",
       "  'forced',\n",
       "  'factories',\n",
       "  'to',\n",
       "  'shut',\n",
       "  'down',\n",
       "  'flights',\n",
       "  'getting',\n",
       "  'canceled',\n",
       "  'and',\n",
       "  'a',\n",
       "  'massive',\n",
       "  'decrease',\n",
       "  'in',\n",
       "  'the',\n",
       "  'global',\n",
       "  'economy',\n",
       "  'with',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'decrease',\n",
       "  'in',\n",
       "  'green',\n",
       "  'house',\n",
       "  'gases',\n",
       "  'ghg',\n",
       "  'in',\n",
       "  'many',\n",
       "  'developed',\n",
       "  'and',\n",
       "  'developing',\n",
       "  'countries',\n",
       "  'the',\n",
       "  'sars',\n",
       "  'cov2',\n",
       "  'came',\n",
       "  'into',\n",
       "  'the',\n",
       "  'spotlight',\n",
       "  'in',\n",
       "  'december',\n",
       "  '2019',\n",
       "  'and',\n",
       "  'has',\n",
       "  'impacted',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'countries',\n",
       "  'till',\n",
       "  'then',\n",
       "  'nearly',\n",
       "  '131',\n",
       "  'million',\n",
       "  'peoples',\n",
       "  'were',\n",
       "  'infected',\n",
       "  'worldwide',\n",
       "  'and',\n",
       "  'resulting',\n",
       "  'in',\n",
       "  'deaths',\n",
       "  'of',\n",
       "  'around',\n",
       "  '29',\n",
       "  'million',\n",
       "  'according',\n",
       "  'to',\n",
       "  'world',\n",
       "  'health',\n",
       "  'organisation',\n",
       "  'who',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'countries',\n",
       "  'dealt',\n",
       "  'with',\n",
       "  'the',\n",
       "  'new',\n",
       "  'virus',\n",
       "  'by',\n",
       "  'imposing',\n",
       "  'strict',\n",
       "  'lockdowns',\n",
       "  'and',\n",
       "  'social',\n",
       "  'distancing',\n",
       "  'to',\n",
       "  'control',\n",
       "  'the',\n",
       "  'spread',\n",
       "  'of',\n",
       "  'the',\n",
       "  'virus',\n",
       "  'these',\n",
       "  'policies',\n",
       "  'caused',\n",
       "  'adverse',\n",
       "  'effects',\n",
       "  'worldwide',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'important',\n",
       "  'impacts',\n",
       "  'of',\n",
       "  'the',\n",
       "  'covid19',\n",
       "  'pandemic',\n",
       "  'is',\n",
       "  'on',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'there',\n",
       "  'have',\n",
       "  'been',\n",
       "  'few',\n",
       "  'positive',\n",
       "  'impacts',\n",
       "  'on',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'due',\n",
       "  'to',\n",
       "  'lockdown',\n",
       "  'like',\n",
       "  'air',\n",
       "  'pollution',\n",
       "  'has',\n",
       "  'decreased',\n",
       "  'dramatically',\n",
       "  'as',\n",
       "  'people',\n",
       "  'were',\n",
       "  'asked',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'in',\n",
       "  'their',\n",
       "  'houses',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'lockdowns',\n",
       "  'there',\n",
       "  'has',\n",
       "  'also',\n",
       "  'been',\n",
       "  'a',\n",
       "  'sharp',\n",
       "  'decline',\n",
       "  'in',\n",
       "  'environmental',\n",
       "  'noise',\n",
       "  'environmental',\n",
       "  'noise',\n",
       "  'can',\n",
       "  'be',\n",
       "  'well',\n",
       "  'defined',\n",
       "  'as',\n",
       "  'the',\n",
       "  'unwanted',\n",
       "  'or',\n",
       "  'harmful',\n",
       "  'outdoor',\n",
       "  'sounds',\n",
       "  'caused',\n",
       "  'by',\n",
       "  'human',\n",
       "  'activities',\n",
       "  'like',\n",
       "  'noise',\n",
       "  'emitted',\n",
       "  'by',\n",
       "  'road',\n",
       "  'traffics',\n",
       "  'air',\n",
       "  'traffics',\n",
       "  'rail',\n",
       "  'traffics',\n",
       "  'and',\n",
       "  'industrial',\n",
       "  'activities',\n",
       "  'it',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'important',\n",
       "  'challenges',\n",
       "  'in',\n",
       "  'the',\n",
       "  'modern',\n",
       "  'era',\n",
       "  'as',\n",
       "  'noise',\n",
       "  'pollution',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'adverse',\n",
       "  'effects',\n",
       "  'on',\n",
       "  'humans',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'harm',\n",
       "  'many',\n",
       "  'animals',\n",
       "  'too',\n",
       "  'the',\n",
       "  'imposition',\n",
       "  'of',\n",
       "  'lockdown',\n",
       "  'and',\n",
       "  'quarantine',\n",
       "  'by',\n",
       "  'various',\n",
       "  'nations',\n",
       "  'governments',\n",
       "  'has',\n",
       "  'caused',\n",
       "  'people',\n",
       "  'to',\n",
       "  'remain',\n",
       "  'back',\n",
       "  'at',\n",
       "  'their',\n",
       "  'homes',\n",
       "  'because',\n",
       "  'of',\n",
       "  'this',\n",
       "  'the',\n",
       "  'movement',\n",
       "  'of',\n",
       "  'people',\n",
       "  'from',\n",
       "  'one',\n",
       "  'place',\n",
       "  'to',\n",
       "  'a',\n",
       "  'different',\n",
       "  'place',\n",
       "  'has',\n",
       "  'reduced',\n",
       "  'significantly',\n",
       "  'and',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'personal',\n",
       "  'and',\n",
       "  'public',\n",
       "  'transport',\n",
       "  'has',\n",
       "  'also',\n",
       "  'decreased',\n",
       "  'due',\n",
       "  'to',\n",
       "  'all',\n",
       "  'these',\n",
       "  'changes',\n",
       "  'the',\n",
       "  'environmental',\n",
       "  'noise',\n",
       "  'generated',\n",
       "  'in',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cities',\n",
       "  'has',\n",
       "  'dropped',\n",
       "  'substantially',\n",
       "  'water',\n",
       "  'pollution',\n",
       "  'at',\n",
       "  'beaches',\n",
       "  'have',\n",
       "  'reduced',\n",
       "  'significantly',\n",
       "  'and',\n",
       "  'many',\n",
       "  'animals',\n",
       "  'were',\n",
       "  'spotted',\n",
       "  'back',\n",
       "  'in',\n",
       "  'the',\n",
       "  'cities',\n",
       "  'but',\n",
       "  'the',\n",
       "  'covid19',\n",
       "  'virus',\n",
       "  'has',\n",
       "  'also',\n",
       "  'generated',\n",
       "  'many',\n",
       "  'negative',\n",
       "  'and',\n",
       "  'indirect',\n",
       "  'effect',\n",
       "  'on',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'to',\n",
       "  'begin',\n",
       "  'with',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'developed',\n",
       "  'countries',\n",
       "  'have',\n",
       "  'halted',\n",
       "  'their',\n",
       "  'sustainability',\n",
       "  'program',\n",
       "  'during',\n",
       "  'the',\n",
       "  'pandemic',\n",
       "  'in',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  'and',\n",
       "  'in',\n",
       "  'many',\n",
       "  'other',\n",
       "  'european',\n",
       "  'nationstates',\n",
       "  'waste',\n",
       "  'recycling',\n",
       "  'plants',\n",
       "  'have',\n",
       "  'been',\n",
       "  'suspended',\n",
       "  'in',\n",
       "  'many',\n",
       "  'municipalities',\n",
       "  'and',\n",
       "  'cities',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'concern',\n",
       "  'of',\n",
       "  'the',\n",
       "  'virus',\n",
       "  'getting',\n",
       "  'spread',\n",
       "  'at',\n",
       "  'the',\n",
       "  'recycling',\n",
       "  'centers',\n",
       "  'this',\n",
       "  'has',\n",
       "  'resulted',\n",
       "  'in',\n",
       "  'an',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'singleuse',\n",
       "  'plastic',\n",
       "  'bags',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'the',\n",
       "  'reusable',\n",
       "  'bags',\n",
       "  'by',\n",
       "  'many',\n",
       "  'leading',\n",
       "  'restaurants',\n",
       "  'firms',\n",
       "  'and',\n",
       "  'corporations',\n",
       "  'for',\n",
       "  'instance',\n",
       "  'starbucks',\n",
       "  'a',\n",
       "  'leading',\n",
       "  'coffee',\n",
       "  'company',\n",
       "  'during',\n",
       "  'the',\n",
       "  'month',\n",
       "  'of',\n",
       "  'march',\n",
       "  '2020',\n",
       "  'has',\n",
       "  'announced',\n",
       "  'a',\n",
       "  'shortlived',\n",
       "  'ban',\n",
       "  'on',\n",
       "  'the',\n",
       "  'utilization',\n",
       "  'of',\n",
       "  'recyclable',\n",
       "  'and',\n",
       "  'reusable',\n",
       "  'cups',\n",
       "  'furthermore',\n",
       "  'with',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'people',\n",
       "  'staying',\n",
       "  'indoors',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lockdown',\n",
       "  'majority',\n",
       "  'of',\n",
       "  'the',\n",
       "  'department',\n",
       "  'stores',\n",
       "  'shops',\n",
       "  'restaurants',\n",
       "  'and',\n",
       "  'food',\n",
       "  'outlets',\n",
       "  'are',\n",
       "  'closed',\n",
       "  'making',\n",
       "  'an',\n",
       "  'online',\n",
       "  'purchase',\n",
       "  'and',\n",
       "  'food',\n",
       "  'delivery',\n",
       "  'are',\n",
       "  'quite',\n",
       "  'high',\n",
       "  'this',\n",
       "  'has',\n",
       "  'created',\n",
       "  'more',\n",
       "  'consumption',\n",
       "  'and',\n",
       "  'demand',\n",
       "  'for',\n",
       "  'fossil',\n",
       "  'fuels',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'transportation',\n",
       "  'and',\n",
       "  'mobility',\n",
       "  'of',\n",
       "  'these',\n",
       "  'goods',\n",
       "  'to',\n",
       "  'each',\n",
       "  'individual',\n",
       "  'there',\n",
       "  'has',\n",
       "  'been',\n",
       "  'an',\n",
       "  'enormous',\n",
       "  'upsurge',\n",
       "  'of',\n",
       "  'medical',\n",
       "  'waste',\n",
       "  'because',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'products',\n",
       "  'employed',\n",
       "  'by',\n",
       "  'healthcare',\n",
       "  'professionals',\n",
       "  'are',\n",
       "  'usually',\n",
       "  'singleuse',\n",
       "  'items',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'only',\n",
       "  'once',\n",
       "  'before',\n",
       "  'they',\n",
       "  'are',\n",
       "  'disposed',\n",
       "  'of',\n",
       "  'some',\n",
       "  'of',\n",
       "  'these',\n",
       "  'wastes',\n",
       "  'include',\n",
       "  'used',\n",
       "  'masks',\n",
       "  'personal',\n",
       "  'protection',\n",
       "  'kits',\n",
       "  'and',\n",
       "  'gloves',\n",
       "  'for',\n",
       "  'instance',\n",
       "  'nearly',\n",
       "  '200',\n",
       "  'tons',\n",
       "  'of',\n",
       "  'medical',\n",
       "  'waste',\n",
       "  'were',\n",
       "  'generated',\n",
       "  'during',\n",
       "  'the',\n",
       "  'peak',\n",
       "  'of',\n",
       "  'the',\n",
       "  'pandemic',\n",
       "  'breakout',\n",
       "  'in',\n",
       "  'wuhan',\n",
       "  'china',\n",
       "  'this',\n",
       "  'is',\n",
       "  '50',\n",
       "  'tones',\n",
       "  'more',\n",
       "  'than',\n",
       "  'the',\n",
       "  'average',\n",
       "  'waste',\n",
       "  'generated',\n",
       "  'before',\n",
       "  'the',\n",
       "  'outbreak',\n",
       "  'in',\n",
       "  'wuhan',\n",
       "  'these',\n",
       "  'organic',\n",
       "  'and',\n",
       "  'inorganic',\n",
       "  'wastes',\n",
       "  'generated',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'policies',\n",
       "  'crafted',\n",
       "  'by',\n",
       "  'the',\n",
       "  'government',\n",
       "  'takes',\n",
       "  'a',\n",
       "  'heavy',\n",
       "  'toll',\n",
       "  'on',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'and',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'environmental',\n",
       "  'issues',\n",
       "  'like',\n",
       "  'water',\n",
       "  'pollution',\n",
       "  'air',\n",
       "  'pollution',\n",
       "  'soil',\n",
       "  'erosion',\n",
       "  'and',\n",
       "  'can',\n",
       "  'harm',\n",
       "  'the',\n",
       "  'local',\n",
       "  'flora',\n",
       "  'and',\n",
       "  'fauna',\n",
       "  'the',\n",
       "  'demand',\n",
       "  'for',\n",
       "  'masks',\n",
       "  'during',\n",
       "  'the',\n",
       "  'pandemic',\n",
       "  'has',\n",
       "  'become',\n",
       "  'skyrocketing',\n",
       "  'but',\n",
       "  'the',\n",
       "  'materials',\n",
       "  'required',\n",
       "  'for',\n",
       "  'the',\n",
       "  'production',\n",
       "  'of',\n",
       "  'these',\n",
       "  'masks',\n",
       "  'are',\n",
       "  'highly',\n",
       "  'dangerous',\n",
       "  'for',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'generally',\n",
       "  'composed',\n",
       "  'of',\n",
       "  'nonwoven',\n",
       "  'fabrics',\n",
       "  'polyester',\n",
       "  'polystyrene',\n",
       "  'polyethylene',\n",
       "  'and',\n",
       "  'polycarbonate',\n",
       "  'are',\n",
       "  'some',\n",
       "  'common',\n",
       "  'materials',\n",
       "  'used',\n",
       "  'for',\n",
       "  'the',\n",
       "  'surgical',\n",
       "  'mask',\n",
       "  'with',\n",
       "  'density',\n",
       "  'lying',\n",
       "  'between',\n",
       "  '20grams',\n",
       "  'to',\n",
       "  '25',\n",
       "  'gramssq',\n",
       "  'meter',\n",
       "  'these',\n",
       "  'materials',\n",
       "  'are',\n",
       "  'mostly',\n",
       "  'resistant',\n",
       "  'to',\n",
       "  'liquids',\n",
       "  'and',\n",
       "  'are',\n",
       "  'plasticbased',\n",
       "  'products',\n",
       "  'with',\n",
       "  'a',\n",
       "  'really',\n",
       "  'high',\n",
       "  'afterlife',\n",
       "  'after',\n",
       "  'being',\n",
       "  'discarded',\n",
       "  'if',\n",
       "  'not',\n",
       "  'treated',\n",
       "  'properly',\n",
       "  'without',\n",
       "  'discarding',\n",
       "  'they',\n",
       "  'end',\n",
       "  'up',\n",
       "  'filling',\n",
       "  'the',\n",
       "  'landfills',\n",
       "  'and',\n",
       "  'the',\n",
       "  'oceans',\n",
       "  'making',\n",
       "  'it',\n",
       "  'dangerous',\n",
       "  'to',\n",
       "  'aquatic',\n",
       "  'lifeforms',\n",
       "  'for',\n",
       "  'example',\n",
       "  'recently',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'in',\n",
       "  'hong',\n",
       "  'kong',\n",
       "  'has',\n",
       "  'started',\n",
       "  'degrading',\n",
       "  'drastically',\n",
       "  'during',\n",
       "  'the',\n",
       "  'pandemic',\n",
       "  'with',\n",
       "  'the',\n",
       "  'accumulation',\n",
       "  'of',\n",
       "  'these',\n",
       "  'clinical',\n",
       "  'wastes',\n",
       "  'with',\n",
       "  'recycling',\n",
       "  'plants',\n",
       "  'on',\n",
       "  'hold',\n",
       "  'piles',\n",
       "  'of',\n",
       "  'small',\n",
       "  'mountains',\n",
       "  'of',\n",
       "  'wastes',\n",
       "  'and',\n",
       "  'their',\n",
       "  'depositions',\n",
       "  'at',\n",
       "  'open',\n",
       "  'areas',\n",
       "  'are',\n",
       "  'formed',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'increasing',\n",
       "  'number',\n",
       "  'of',\n",
       "  'unrecycled',\n",
       "  'wastes',\n",
       "  'generated',\n",
       "  'every',\n",
       "  'day',\n",
       "  'this',\n",
       "  'makes',\n",
       "  'the',\n",
       "  'surrounding',\n",
       "  'more',\n",
       "  'vulnerable',\n",
       "  'and',\n",
       "  'also',\n",
       "  'creating',\n",
       "  'a',\n",
       "  'high',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'air',\n",
       "  'pollutions',\n",
       "  'as',\n",
       "  'the',\n",
       "  'dumped',\n",
       "  'open',\n",
       "  'wastes',\n",
       "  'decays',\n",
       "  'into',\n",
       "  'methane',\n",
       "  'ch4',\n",
       "  'a',\n",
       "  'greenhouse',\n",
       "  'gas',\n",
       "  'hence',\n",
       "  'increasing',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'global',\n",
       "  'warming',\n",
       "  'too',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'surroundings',\n",
       "  'are',\n",
       "  'getting',\n",
       "  'affected',\n",
       "  'by',\n",
       "  'these',\n",
       "  'careless',\n",
       "  'methods',\n",
       "  'but',\n",
       "  'the',\n",
       "  'local',\n",
       "  'people',\n",
       "  'are',\n",
       "  'also',\n",
       "  'getting',\n",
       "  'affected',\n",
       "  'if',\n",
       "  'the',\n",
       "  'excess',\n",
       "  'methane',\n",
       "  'gets',\n",
       "  'accumulated',\n",
       "  'in',\n",
       "  'the',\n",
       "  'earths',\n",
       "  'atmosphere',\n",
       "  'due',\n",
       "  'to',\n",
       "  'piles',\n",
       "  'of',\n",
       "  'unrecycled',\n",
       "  'wastes',\n",
       "  'this',\n",
       "  'could',\n",
       "  'result',\n",
       "  'in',\n",
       "  'increases',\n",
       "  'in',\n",
       "  'earths',\n",
       "  'average',\n",
       "  'temperature',\n",
       "  'and',\n",
       "  'can',\n",
       "  'be',\n",
       "  'harmful',\n",
       "  'to',\n",
       "  'future',\n",
       "  'generations',\n",
       "  'many',\n",
       "  'protected',\n",
       "  'and',\n",
       "  'endangered',\n",
       "  'flora',\n",
       "  'and',\n",
       "  'fauna',\n",
       "  'are',\n",
       "  'facing',\n",
       "  'much',\n",
       "  'greater',\n",
       "  'risks',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'imposition',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lockdown',\n",
       "  'many',\n",
       "  'countries',\n",
       "  'under',\n",
       "  'lockdown',\n",
       "  'have',\n",
       "  'made',\n",
       "  'people',\n",
       "  'stay',\n",
       "  'inside',\n",
       "  'their',\n",
       "  'homes',\n",
       "  'the',\n",
       "  'employees',\n",
       "  'ngos',\n",
       "  'and',\n",
       "  'volunteers',\n",
       "  'working',\n",
       "  'in',\n",
       "  'these',\n",
       "  'protected',\n",
       "  'areas',\n",
       "  'like',\n",
       "  'national',\n",
       "  'parks',\n",
       "  'marine',\n",
       "  'conservation',\n",
       "  'zones',\n",
       "  'and',\n",
       "  'wildlife',\n",
       "  'sanctuaries',\n",
       "  'are',\n",
       "  'made',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'at',\n",
       "  'home',\n",
       "  'making',\n",
       "  'these',\n",
       "  'protected',\n",
       "  'and',\n",
       "  'endangered',\n",
       "  'flora',\n",
       "  'and',\n",
       "  'fauna',\n",
       "  'unattended',\n",
       "  'this',\n",
       "  'has',\n",
       "  'also',\n",
       "  'led',\n",
       "  'to',\n",
       "  'an',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'many',\n",
       "  'illegal',\n",
       "  'activities',\n",
       "  'like',\n",
       "  'wildlife',\n",
       "  'hunting',\n",
       "  'illegal',\n",
       "  'deforestation',\n",
       "  'and',\n",
       "  'fishing',\n",
       "  'activities',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'absence',\n",
       "  'of',\n",
       "  'these',\n",
       "  'people',\n",
       "  'the',\n",
       "  'prohibition',\n",
       "  'of',\n",
       "  'ecotourism',\n",
       "  'has',\n",
       "  'also',\n",
       "  'led',\n",
       "  'to',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'financial',\n",
       "  'drop',\n",
       "  'in',\n",
       "  'the',\n",
       "  'economy',\n",
       "  'of',\n",
       "  'these',\n",
       "  'protected',\n",
       "  'areas',\n",
       "  'some',\n",
       "  'nations',\n",
       "  'like',\n",
       "  'china',\n",
       "  'have',\n",
       "  'asked',\n",
       "  'the',\n",
       "  'local',\n",
       "  'authorities',\n",
       "  'and',\n",
       "  'native',\n",
       "  'government',\n",
       "  'bodies',\n",
       "  'to',\n",
       "  'increase',\n",
       "  'the',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'disinfection',\n",
       "  'routine',\n",
       "  'mainly',\n",
       "  'to',\n",
       "  'increase',\n",
       "  'the',\n",
       "  'dosage',\n",
       "  'of',\n",
       "  'chlorine',\n",
       "  'in',\n",
       "  'the',\n",
       "  'wastewater',\n",
       "  'treatment',\n",
       "  'plant',\n",
       "  'to',\n",
       "  'prevent',\n",
       "  'the',\n",
       "  'spread',\n",
       "  'of',\n",
       "  'the',\n",
       "  'covid19',\n",
       "  'virus',\n",
       "  'however',\n",
       "  'according',\n",
       "  'to',\n",
       "  'who',\n",
       "  '2020',\n",
       "  'no',\n",
       "  'solid',\n",
       "  'evidence',\n",
       "  'has',\n",
       "  'been',\n",
       "  'found',\n",
       "  'on',\n",
       "  'the',\n",
       "  'survival',\n",
       "  'of',\n",
       "  'the',\n",
       "  'virus',\n",
       "  'on',\n",
       "  'the',\n",
       "  'lifespan',\n",
       "  'of',\n",
       "  'the',\n",
       "  'virus',\n",
       "  'in',\n",
       "  'wastewater',\n",
       "  'as',\n",
       "  ...]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/58.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fe9e0ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365\n",
      "WORD COUNT 879\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "86e004fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 23.551724137931036\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f96a1c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.34584755403868034\n",
      "FOG INDEX: 9.559028676787888\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 23.551724137931036\n",
      "COMPLEX WORD COUNT: 304\n",
      "WORD COUNT: 879\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "31cbb350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2618\n",
      "I: 0\n",
      "we: 2\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 2\n",
      "PERSONAL PRONOUNS: 2\n",
      "AVG WORD LENGTH: 5.214494875549049\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_58.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fe5a11",
   "metadata": {},
   "source": [
    "# 23. url 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3037c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\660182166.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f8cc770e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Even though COVID-19 has not yet halted and we are facing the nth wave of the coronavirus outbreak across several countries, most notably the US, India, and Brazil. It is a fact that Data Analytics and AI are the big guns of our artillery in this fight against the COVID-19 pandemic. It has helped us in several stages of this outbreak, like the detection of its first outbreak, vaccine development and manufacturing contact tracing, and future hotspot detection. Some of these interesting applications are discussed in this article.',\n",
       " 'A lesser-known fact is that the COVID-19 outbreak was first detected in Toronto, Canada, nearly 7,230 miles away from the first outbreak, nine days before the WHO issued its warning. It was with the help of Big Data Analytics and AI, more specifically Deep Learnings (DL, a subset of Machine Learning) application in Natural Language Processing (NLP) to analyze text inputs that traced the surge of pneumonia cases in the Wuhan province of China. The specialty of DL algorithms is that they mimic the brain cells called neurons and can identify patterns in Big Data. This DL-backed software is used as inputs, reports from public health organizations, global airline ticketing data, etc. These were used to flag unusual surges and potential spreads of infectious diseases.',\n",
       " 'The next application of Big Data Analytics and AI was in the Research and Development of drugs to halt COVID-19. AI was used to analyze the protein structure of the virus, findings that were significant in the progress of vaccine development. In preliminary studies, it was found that it does not mutate as fast as other viruses such as HIV, which means that a prophylactic vaccine is a better way to proceed rather than a therapy. But there is also some evidence supporting the fact that when we find any kind of cure for it, there is a chance of the virus mutating, which is what happened and major mutations have been found in the UK, Brazil, and South Africa. AI also assisted scientists in rapidly shortlisting a set of already available vaccines that could be effective against the coronavirus.',\n",
       " 'Another interesting application of AI can be found in the selection of the right candidates, i.e. most likely to test positive for testing coronavirus in case of insufficient testing resources. This method was first exercised on Greek borders and was called project EVA. Whenever a traveler wanted to come into Greece, he had to fill out a form known as Passenger Locator Form (PLF) at least 24 hours prior to arrival, containing information on their origin country, demographics, point, and date of entry, and the intended destination. EVA then allocated testing resources according to the size of the set of passengers to be tested. After the test results, if found positive, they are put in quarantine. The results were sent back to the program for real-time learning.',\n",
       " 'The question remains how EVA made allocations, It was found that, statistically, only the origin country and the city were significant factors for screening. Ultimately, from a variety of countries and city pairs, EVA had to predict how many testing resources were to be allocated at each entry point and to particular passengers from a location is technically called the Multi-Armed Bandit (MAB) problem, and the chosen method to solve this problem was an AI algorithm called optimistic Gittins index. This algorithm identified on average 1.85x as many asymptomatic, infected travelers as random surveillance testing, and up to 2-4x as many during peak travel. After the test results, if found positive, they are put in quarantine. Following the collection of significant data through the aforementioned process, after a certain period, policies were made categorizing them separately and imposing restrictions on travelers from the specific location. This EVA as presented above was in operation from August 6th to November 1st processing around 38,500 PLFs each day and testing on an average 18.5% of households entering the country every day.',\n",
       " 'Above mentioned applications just show the tip of the iceberg and there is more to get into some of the other developments to watch for include the use of Image Recognition to identify covid based on x-ray images, the use of Deep Learning to predict the 3-D protein structure associated with COVID-19 and so on.']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "815c3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:22]))\n",
    "URL_ID_59 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8b31d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 sentences in the string.\n",
      "The number of words in the string is: 713\n",
      "The number of characters in the string is: 3626\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 19:17:33] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 19:17:43] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_59.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_59.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_59.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_59 = re.sub(re_punt, \"\",URL_ID_59)\n",
    "\n",
    "file = open(\"59.txt\", \"w\")\n",
    "file.write(URL_ID_59)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"59.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fc98b669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['even',\n",
       "  'though',\n",
       "  'covid19',\n",
       "  'has',\n",
       "  'not',\n",
       "  'yet',\n",
       "  'halted',\n",
       "  'and',\n",
       "  'we',\n",
       "  'are',\n",
       "  'facing',\n",
       "  'the',\n",
       "  'nth',\n",
       "  'wave',\n",
       "  'of',\n",
       "  'the',\n",
       "  'coronavirus',\n",
       "  'outbreak',\n",
       "  'across',\n",
       "  'several',\n",
       "  'countries',\n",
       "  'most',\n",
       "  'notably',\n",
       "  'the',\n",
       "  'us',\n",
       "  'india',\n",
       "  'and',\n",
       "  'brazil',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'and',\n",
       "  'ai',\n",
       "  'are',\n",
       "  'the',\n",
       "  'big',\n",
       "  'guns',\n",
       "  'of',\n",
       "  'our',\n",
       "  'artillery',\n",
       "  'in',\n",
       "  'this',\n",
       "  'fight',\n",
       "  'against',\n",
       "  'the',\n",
       "  'covid19',\n",
       "  'pandemic',\n",
       "  'it',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'us',\n",
       "  'in',\n",
       "  'several',\n",
       "  'stages',\n",
       "  'of',\n",
       "  'this',\n",
       "  'outbreak',\n",
       "  'like',\n",
       "  'the',\n",
       "  'detection',\n",
       "  'of',\n",
       "  'its',\n",
       "  'first',\n",
       "  'outbreak',\n",
       "  'vaccine',\n",
       "  'development',\n",
       "  'and',\n",
       "  'manufacturing',\n",
       "  'contact',\n",
       "  'tracing',\n",
       "  'and',\n",
       "  'future',\n",
       "  'hotspot',\n",
       "  'detection',\n",
       "  'some',\n",
       "  'of',\n",
       "  'these',\n",
       "  'interesting',\n",
       "  'applications',\n",
       "  'are',\n",
       "  'discussed',\n",
       "  'in',\n",
       "  'this',\n",
       "  'article',\n",
       "  'a',\n",
       "  'lesserknown',\n",
       "  'fact',\n",
       "  'is',\n",
       "  'that',\n",
       "  'the',\n",
       "  'covid19',\n",
       "  'outbreak',\n",
       "  'was',\n",
       "  'first',\n",
       "  'detected',\n",
       "  'in',\n",
       "  'toronto',\n",
       "  'canada',\n",
       "  'nearly',\n",
       "  '7230',\n",
       "  'miles',\n",
       "  'away',\n",
       "  'from',\n",
       "  'the',\n",
       "  'first',\n",
       "  'outbreak',\n",
       "  'nine',\n",
       "  'days',\n",
       "  'before',\n",
       "  'the',\n",
       "  'who',\n",
       "  'issued',\n",
       "  'its',\n",
       "  'warning',\n",
       "  'it',\n",
       "  'was',\n",
       "  'with',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'big',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'and',\n",
       "  'ai',\n",
       "  'more',\n",
       "  'specifically',\n",
       "  'deep',\n",
       "  'learnings',\n",
       "  'dl',\n",
       "  'a',\n",
       "  'subset',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'application',\n",
       "  'in',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'to',\n",
       "  'analyze',\n",
       "  'text',\n",
       "  'inputs',\n",
       "  'that',\n",
       "  'traced',\n",
       "  'the',\n",
       "  'surge',\n",
       "  'of',\n",
       "  'pneumonia',\n",
       "  'cases',\n",
       "  'in',\n",
       "  'the',\n",
       "  'wuhan',\n",
       "  'province',\n",
       "  'of',\n",
       "  'china',\n",
       "  'the',\n",
       "  'specialty',\n",
       "  'of',\n",
       "  'dl',\n",
       "  'algorithms',\n",
       "  'is',\n",
       "  'that',\n",
       "  'they',\n",
       "  'mimic',\n",
       "  'the',\n",
       "  'brain',\n",
       "  'cells',\n",
       "  'called',\n",
       "  'neurons',\n",
       "  'and',\n",
       "  'can',\n",
       "  'identify',\n",
       "  'patterns',\n",
       "  'in',\n",
       "  'big',\n",
       "  'data',\n",
       "  'this',\n",
       "  'dlbacked',\n",
       "  'software',\n",
       "  'is',\n",
       "  'used',\n",
       "  'as',\n",
       "  'inputs',\n",
       "  'reports',\n",
       "  'from',\n",
       "  'public',\n",
       "  'health',\n",
       "  'organizations',\n",
       "  'global',\n",
       "  'airline',\n",
       "  'ticketing',\n",
       "  'data',\n",
       "  'etc',\n",
       "  'these',\n",
       "  'were',\n",
       "  'used',\n",
       "  'to',\n",
       "  'flag',\n",
       "  'unusual',\n",
       "  'surges',\n",
       "  'and',\n",
       "  'potential',\n",
       "  'spreads',\n",
       "  'of',\n",
       "  'infectious',\n",
       "  'diseases',\n",
       "  'the',\n",
       "  'next',\n",
       "  'application',\n",
       "  'of',\n",
       "  'big',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'and',\n",
       "  'ai',\n",
       "  'was',\n",
       "  'in',\n",
       "  'the',\n",
       "  'research',\n",
       "  'and',\n",
       "  'development',\n",
       "  'of',\n",
       "  'drugs',\n",
       "  'to',\n",
       "  'halt',\n",
       "  'covid19',\n",
       "  'ai',\n",
       "  'was',\n",
       "  'used',\n",
       "  'to',\n",
       "  'analyze',\n",
       "  'the',\n",
       "  'protein',\n",
       "  'structure',\n",
       "  'of',\n",
       "  'the',\n",
       "  'virus',\n",
       "  'findings',\n",
       "  'that',\n",
       "  'were',\n",
       "  'significant',\n",
       "  'in',\n",
       "  'the',\n",
       "  'progress',\n",
       "  'of',\n",
       "  'vaccine',\n",
       "  'development',\n",
       "  'in',\n",
       "  'preliminary',\n",
       "  'studies',\n",
       "  'it',\n",
       "  'was',\n",
       "  'found',\n",
       "  'that',\n",
       "  'it',\n",
       "  'does',\n",
       "  'not',\n",
       "  'mutate',\n",
       "  'as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  'other',\n",
       "  'viruses',\n",
       "  'such',\n",
       "  'as',\n",
       "  'hiv',\n",
       "  'which',\n",
       "  'means',\n",
       "  'that',\n",
       "  'a',\n",
       "  'prophylactic',\n",
       "  'vaccine',\n",
       "  'is',\n",
       "  'a',\n",
       "  'better',\n",
       "  'way',\n",
       "  'to',\n",
       "  'proceed',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'a',\n",
       "  'therapy',\n",
       "  'but',\n",
       "  'there',\n",
       "  'is',\n",
       "  'also',\n",
       "  'some',\n",
       "  'evidence',\n",
       "  'supporting',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'when',\n",
       "  'we',\n",
       "  'find',\n",
       "  'any',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'cure',\n",
       "  'for',\n",
       "  'it',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'of',\n",
       "  'the',\n",
       "  'virus',\n",
       "  'mutating',\n",
       "  'which',\n",
       "  'is',\n",
       "  'what',\n",
       "  'happened',\n",
       "  'and',\n",
       "  'major',\n",
       "  'mutations',\n",
       "  'have',\n",
       "  'been',\n",
       "  'found',\n",
       "  'in',\n",
       "  'the',\n",
       "  'uk',\n",
       "  'brazil',\n",
       "  'and',\n",
       "  'south',\n",
       "  'africa',\n",
       "  'ai',\n",
       "  'also',\n",
       "  'assisted',\n",
       "  'scientists',\n",
       "  'in',\n",
       "  'rapidly',\n",
       "  'shortlisting',\n",
       "  'a',\n",
       "  'set',\n",
       "  'of',\n",
       "  'already',\n",
       "  'available',\n",
       "  'vaccines',\n",
       "  'that',\n",
       "  'could',\n",
       "  'be',\n",
       "  'effective',\n",
       "  'against',\n",
       "  'the',\n",
       "  'coronavirus',\n",
       "  'another',\n",
       "  'interesting',\n",
       "  'application',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'be',\n",
       "  'found',\n",
       "  'in',\n",
       "  'the',\n",
       "  'selection',\n",
       "  'of',\n",
       "  'the',\n",
       "  'right',\n",
       "  'candidates',\n",
       "  'ie',\n",
       "  'most',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'test',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'testing',\n",
       "  'coronavirus',\n",
       "  'in',\n",
       "  'case',\n",
       "  'of',\n",
       "  'insufficient',\n",
       "  'testing',\n",
       "  'resources',\n",
       "  'this',\n",
       "  'method',\n",
       "  'was',\n",
       "  'first',\n",
       "  'exercised',\n",
       "  'on',\n",
       "  'greek',\n",
       "  'borders',\n",
       "  'and',\n",
       "  'was',\n",
       "  'called',\n",
       "  'project',\n",
       "  'eva',\n",
       "  'whenever',\n",
       "  'a',\n",
       "  'traveler',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'come',\n",
       "  'into',\n",
       "  'greece',\n",
       "  'he',\n",
       "  'had',\n",
       "  'to',\n",
       "  'fill',\n",
       "  'out',\n",
       "  'a',\n",
       "  'form',\n",
       "  'known',\n",
       "  'as',\n",
       "  'passenger',\n",
       "  'locator',\n",
       "  'form',\n",
       "  'plf',\n",
       "  'at',\n",
       "  'least',\n",
       "  '24',\n",
       "  'hours',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'arrival',\n",
       "  'containing',\n",
       "  'information',\n",
       "  'on',\n",
       "  'their',\n",
       "  'origin',\n",
       "  'country',\n",
       "  'demographics',\n",
       "  'point',\n",
       "  'and',\n",
       "  'date',\n",
       "  'of',\n",
       "  'entry',\n",
       "  'and',\n",
       "  'the',\n",
       "  'intended',\n",
       "  'destination',\n",
       "  'eva',\n",
       "  'then',\n",
       "  'allocated',\n",
       "  'testing',\n",
       "  'resources',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'size',\n",
       "  'of',\n",
       "  'the',\n",
       "  'set',\n",
       "  'of',\n",
       "  'passengers',\n",
       "  'to',\n",
       "  'be',\n",
       "  'tested',\n",
       "  'after',\n",
       "  'the',\n",
       "  'test',\n",
       "  'results',\n",
       "  'if',\n",
       "  'found',\n",
       "  'positive',\n",
       "  'they',\n",
       "  'are',\n",
       "  'put',\n",
       "  'in',\n",
       "  'quarantine',\n",
       "  'the',\n",
       "  'results',\n",
       "  'were',\n",
       "  'sent',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'program',\n",
       "  'for',\n",
       "  'realtime',\n",
       "  'learning',\n",
       "  'the',\n",
       "  'question',\n",
       "  'remains',\n",
       "  'how',\n",
       "  'eva',\n",
       "  'made',\n",
       "  'allocations',\n",
       "  'it',\n",
       "  'was',\n",
       "  'found',\n",
       "  'that',\n",
       "  'statistically',\n",
       "  'only',\n",
       "  'the',\n",
       "  'origin',\n",
       "  'country',\n",
       "  'and',\n",
       "  'the',\n",
       "  'city',\n",
       "  'were',\n",
       "  'significant',\n",
       "  'factors',\n",
       "  'for',\n",
       "  'screening',\n",
       "  'ultimately',\n",
       "  'from',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'countries',\n",
       "  'and',\n",
       "  'city',\n",
       "  'pairs',\n",
       "  'eva',\n",
       "  'had',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'how',\n",
       "  'many',\n",
       "  'testing',\n",
       "  'resources',\n",
       "  'were',\n",
       "  'to',\n",
       "  'be',\n",
       "  'allocated',\n",
       "  'at',\n",
       "  'each',\n",
       "  'entry',\n",
       "  'point',\n",
       "  'and',\n",
       "  'to',\n",
       "  'particular',\n",
       "  'passengers',\n",
       "  'from',\n",
       "  'a',\n",
       "  'location',\n",
       "  'is',\n",
       "  'technically',\n",
       "  'called',\n",
       "  'the',\n",
       "  'multiarmed',\n",
       "  'bandit',\n",
       "  'mab',\n",
       "  'problem',\n",
       "  'and',\n",
       "  'the',\n",
       "  'chosen',\n",
       "  'method',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'this',\n",
       "  'problem',\n",
       "  'was',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'algorithm',\n",
       "  'called',\n",
       "  'optimistic',\n",
       "  'gittins',\n",
       "  'index',\n",
       "  'this',\n",
       "  'algorithm',\n",
       "  'identified',\n",
       "  'on',\n",
       "  'average',\n",
       "  '185x',\n",
       "  'as',\n",
       "  'many',\n",
       "  'asymptomatic',\n",
       "  'infected',\n",
       "  'travelers',\n",
       "  'as',\n",
       "  'random',\n",
       "  'surveillance',\n",
       "  'testing',\n",
       "  'and',\n",
       "  'up',\n",
       "  'to',\n",
       "  '24x',\n",
       "  'as',\n",
       "  'many',\n",
       "  'during',\n",
       "  'peak',\n",
       "  'travel',\n",
       "  'after',\n",
       "  'the',\n",
       "  'test',\n",
       "  'results',\n",
       "  'if',\n",
       "  'found',\n",
       "  'positive',\n",
       "  'they',\n",
       "  'are',\n",
       "  'put',\n",
       "  'in',\n",
       "  'quarantine',\n",
       "  'following',\n",
       "  'the',\n",
       "  'collection',\n",
       "  'of',\n",
       "  'significant',\n",
       "  'data',\n",
       "  'through',\n",
       "  'the',\n",
       "  'aforementioned',\n",
       "  'process',\n",
       "  'after',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'period',\n",
       "  'policies',\n",
       "  'were',\n",
       "  'made',\n",
       "  'categorizing',\n",
       "  'them',\n",
       "  'separately',\n",
       "  'and',\n",
       "  'imposing',\n",
       "  'restrictions',\n",
       "  'on',\n",
       "  'travelers',\n",
       "  'from',\n",
       "  'the',\n",
       "  'specific',\n",
       "  'location',\n",
       "  'this',\n",
       "  'eva',\n",
       "  'as',\n",
       "  'presented',\n",
       "  'above',\n",
       "  'was',\n",
       "  'in',\n",
       "  'operation',\n",
       "  'from',\n",
       "  'august',\n",
       "  '6th',\n",
       "  'to',\n",
       "  'november',\n",
       "  '1st',\n",
       "  'processing',\n",
       "  'around',\n",
       "  '38500',\n",
       "  'plfs',\n",
       "  'each',\n",
       "  'day',\n",
       "  'and',\n",
       "  'testing',\n",
       "  'on',\n",
       "  'an',\n",
       "  'average',\n",
       "  '185',\n",
       "  'of',\n",
       "  'households',\n",
       "  'entering',\n",
       "  'the',\n",
       "  'country',\n",
       "  'every',\n",
       "  'day',\n",
       "  'above',\n",
       "  'mentioned',\n",
       "  'applications',\n",
       "  'just',\n",
       "  'show',\n",
       "  'the',\n",
       "  'tip',\n",
       "  'of',\n",
       "  'the',\n",
       "  'iceberg',\n",
       "  'and',\n",
       "  'there',\n",
       "  'is',\n",
       "  'more',\n",
       "  'to',\n",
       "  'get',\n",
       "  'into',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'other',\n",
       "  'developments',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'for',\n",
       "  'include',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'image',\n",
       "  'recognition',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'covid',\n",
       "  'based',\n",
       "  'on',\n",
       "  'xray',\n",
       "  'images',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'the',\n",
       "  '3d',\n",
       "  'protein',\n",
       "  'structure',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'covid19',\n",
       "  'and',\n",
       "  'so',\n",
       "  'on']]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/59.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "396ca1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713\n",
      "WORD COUNT 449\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d6bee618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 22.28125\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0dd24f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.34075723830734966\n",
      "FOG INDEX: 9.048802895322941\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 22.28125\n",
      "COMPLEX WORD COUNT: 153\n",
      "WORD COUNT: 449\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "08c26ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1302\n",
      "I: 0\n",
      "we: 2\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 2\n",
      "Total count: 4\n",
      "PERSONAL PRONOUNS: 4\n",
      "AVG WORD LENGTH: 5.085553997194951\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_59.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99551ef",
   "metadata": {},
   "source": [
    "# 24 url 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "33f847db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\436239251.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "efbdabfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Data is the new oil” has become the most important trendline of the 21st century. The reason for this is the advancements in the fields related to data analysis. The field of AI Machine Learning Statistics and Data Mining all deal with data and are developing at such a staggering pace, that these fields have become the most popular buzzwords these days.',\n",
       " 'Buzzwords are originated through technical terms but often the underlying essence is ignored through fashionable use and mainly used to impress. This is the main reason for the misconception amongst people. AI, ML, Stats, Data Mining, and many other fields related to the analysis of data are most often mistook for one and the same thing, thus all these words are often used interchangeably to convey one and the same thing. But this is not true at all!',\n",
       " 'The only similarity between these disciplines is that all of these disciplines are related to the analysis of the data and converting this data into “information”.',\n",
       " 'In academics, while learning AI Machine Learning Statistics and Data Mining, the academic approach only wander in the technical definitions and concepts but the underlying essence and the aim of the discipline remain unexplored, same is the case with most of the articles out there which try to explain the difference. Thus, becoming the primary cause of confusion between learners. Hence, this article explains the difference by explaining the philosophy and the aims of each of the disciplines rather than wandering in the technical definitions.',\n",
       " 'The essential difference between these disciplines lies in their “aims” and the approach taken to achieve those aims.',\n",
       " 'The aim of Artificial intelligence is to understand intelligent entities. Then to satisfy this aim, we must first understand what is intelligence and what makes an agent intelligent agent? The answer to all these questions can be found by studying intelligent agents and the best example of an intelligent agent can be found by just standing in front of a mirror! Yes! Humans are the best examples of intelligent entities. Thus, in the 1900s, researchers began exploring the thought process, the reasoning process of humans as human beings were considered as an ideal intelligent agent. Mimicking human behavior became the aim of AI in the initial years of the research. After setting this goal, studies and experiments began and the most famous experiment conducted in the initial years to achieve this aim was the Turing Test! Turing defined intelligent behavior as the ability to achieve human-level performance in all cognitive tasks, sufficient to fool an interrogator. But this test received criticism as only mimicking human behavior is not exactly intelligence. Because intelligence should be related to the working of the human brain as without the human brain, intelligence has no meaning!',\n",
       " '            Thus, mimicking human thought processes and reasoning became the transformed aim. The field of Psychology and philosophy also resonate with this aim that is to understand the human thought process. The difference is that AI not only tries to understand the thought process but to mimic it, build it. The collaboration of these fields resulted in models such as Neural Networks which try to mimic the function of neurons present in the human brain. So, basically, this initial aim was human-centered and humans were considered as the ideal intelligent agent.',\n",
       " 'Concurrently, the field of computer science was developing at a greater pace. With the advances in computer science, the experiments and theories could be easily tested and validated. As programs were being applied to solve real-life problems, it was found that computers performed better than humans at some tasks that are really complex for humans. One of the best examples of this could be the chess-playing program. An AI program defeated the world’s best chess player Garry Kasparov. This incident indicated that human intelligence is not the ultimate intelligence or else a human would have been able to defeat the AI program. This leads to a question, is human intelligence the ideal intelligence?',\n",
       " 'As computers became more advanced, they proved to be better than humans at certain complex tasks. That is why the new definition of intelligence was being related to the ability to solve cognitive tasks or problems. So, rather than considering the nature of agents, researchers began to study the nature of intelligence itself. Then the question comes how to test or validate intelligence? The best way to test intelligence is to solve cognitive problems. An agent can be said intelligent only if it can solve a complex problem. The problem-solving approach can be easily tested and validated on computers. Thus, some researchers began studying the ideal intelligence, and the selected agent to validate the experiments was the computer. So, a computer and problem-solving approach were adopted. So, the human-centered approach and computer, problem-solving approach are the two main aims of AI. Both of these fields have contributed to the field by giving valuable insights.',\n",
       " 'Both the aims are important and both of these collaboratively form the main aim of AI!',\n",
       " 'In the problem-solving approach, there is a big challenge that AI has to overcome in order to achieve its aim. Consider the example of solving a math problem. There are two cases by which intelligence can be tested in this problem-solving approach. Let us say two math problems are given for you to solve. The first problem is familiar to you and the second problem is not.',\n",
       " 'Consider the first problem. The first problem is familiar to you, that means you know how to solve such kind of problems as you have already solved some similar problems in the past. So, there comes a question, how our mind is able to solve that problem? The answer is, that you have solved similar problems in the past, thus you have learned from the past data, how to solve such problems, thus even if you haven’t seen that problem in the past, you will still be able to solve similar problems. This is one form of intelligence.',\n",
       " 'Consider another case where you are given a second problem where you have not solved such kind of problems in the past. Then to solve this problem, you will try to consciously gather and manipulate the given information so that you reach a certain conclusion. This kind of approach does not necessarily rely on the past data but completely on the reasoning process. This is the second kind of intelligence.',\n",
       " 'For AI to build intelligent agents, both of these kinds of intelligence must be developed in the agent. But, the reality is that AI has reached the point where it is able to build agents which can only learn from past data and find some useful information. AI today has not reached a point where it can build agents who can think on their own. That is the second type of intelligence.',\n",
       " 'So, the way AI is able to implement the first type of intelligence is through Machine Learning! So, the domain of AI which focuses solely on implementing the first kind of intelligence is in fact Machine Learning. That is the reason why ML is called the subset of AI! So, this is the main difference between AI and ML.',\n",
       " 'Technically speaking, “It is the field of study that gives computers the ability to learn from past data and find some meaningful conclusions, patterns without being explicitly programmed”. This statement needs some elaboration. The essence of ML is related to the process of “Generalization” and learning from past data. Generalization is an abstraction by which common properties of specific instances are formulated as general concepts or claims. Consider how we humans recognize daily life objects. If we see an animal, then we can easily recognize if it is a “dog” or a “cat”. It is a very trivial task for us but have you ever wondered how our mind is able to do it? The answer is Generalization!',\n",
       " 'If you were given a picture of a dog, you can easily recognize that it is a picture of a dog, because, our minds have abstracted the description of a dog and formulated it into a “concept” of what a dog is and these concepts became better and better as we learned from the past experiences of a dog. So, the way we think is dependent on the fact that things are represented as generalized concepts in our minds.',\n",
       " 'With generalization only, can come real “information”. So, we try to give computers the ability to generalize the “raw data” and convert it into “information” which can be patterns and trends in the data on their own.',\n",
       " 'This is the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data. Statistics tries to deal with data with the only aim that is to explain it. So, it is the study of explaining the data itself! Statistics has two main domains which are Descriptive statistics and Inferential statistics.',\n",
       " 'Descriptive statistics deals with the explanation or description of data thus the name “Descriptive” statistics. It tries to explain as much information as possible, easily about the whole large data which would be a very complex task otherwise.',\n",
       " ' Inferential statistics try to make accurate inferences from the available small data. We use inference in many tasks in our daily lives. Consider a simple case of cooking a soup. After completing the recipe, you will taste a small sample, that is, a spoonful of the soup to check if the soup tastes good or bad. Depending upon the result of the sample, you make an inference about the whole soup that if the soup as a whole, good or bad. Similarly, in statistics, there are cases where you have to apply inference to have meaningful information. For example, consider a case where you cannot gather the whole data because it is very time-consuming and costly. In these cases, applying inference based on the available sample introduces uncertainty. That is where inferential statistics come for help.',\n",
       " 'So, the use of data in the context of uncertainty and decision-making in the face of uncertainty is what statistics deals with. So, however, and whatever the data, statistics tries to explain that data. This aim does not resonate with that of AI and ML, but statistics help these fields to correctly interpret the data!',\n",
       " '“Data”, is not useful at all in its raw form. Consider examples of sensors used in industrial applications. These sensors might be used in a manufacturing plant to sense different properties like temperature, pressure, etc. The raw data generated by these sensors are not useful until and unless it is converted to a suitable form, then processed, analyzed to gather valuable insights, which can be used to solve a problem!',\n",
       " 'Due to its unique aim of capturing the essence of very large datasets, to gather insights, Data Mining is also referred to as “Knowledge Discovery”. That is why, Carly Fiorina, former CEO of Hewlett-Packard once said, “The goal is to turn data into information and information into Insight”. This statement completely explains the aim of Data Mining!',\n",
       " '            So, the difference between AI Machine Learning Statistics and Data Mining lies in their aims. But the approaches taken in all of these fields, help in one way or the other in fulfilling the aims of the other fields. This is the beauty of these fields!']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "683e86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:41]))\n",
    "URL_ID_60 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2f6f538d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 91 sentences in the string.\n",
      "The number of words in the string is: 1887\n",
      "The number of characters in the string is: 9363\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 19:26:02] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 19:26:12] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_60.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_60.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_60.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_60 = re.sub(re_punt, \"\",URL_ID_60)\n",
    "\n",
    "file = open(\"60.txt\", \"w\")\n",
    "file.write(URL_ID_60)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"60.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "912c4cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['data',\n",
       "  'is',\n",
       "  'the',\n",
       "  'new',\n",
       "  'oil',\n",
       "  'has',\n",
       "  'become',\n",
       "  'the',\n",
       "  'most',\n",
       "  'important',\n",
       "  'trendline',\n",
       "  'of',\n",
       "  'the',\n",
       "  '21st',\n",
       "  'century',\n",
       "  'the',\n",
       "  'reason',\n",
       "  'for',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'advancements',\n",
       "  'in',\n",
       "  'the',\n",
       "  'fields',\n",
       "  'related',\n",
       "  'to',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'statistics',\n",
       "  'and',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'all',\n",
       "  'deal',\n",
       "  'with',\n",
       "  'data',\n",
       "  'and',\n",
       "  'are',\n",
       "  'developing',\n",
       "  'at',\n",
       "  'such',\n",
       "  'a',\n",
       "  'staggering',\n",
       "  'pace',\n",
       "  'that',\n",
       "  'these',\n",
       "  'fields',\n",
       "  'have',\n",
       "  'become',\n",
       "  'the',\n",
       "  'most',\n",
       "  'popular',\n",
       "  'buzzwords',\n",
       "  'these',\n",
       "  'days',\n",
       "  'buzzwords',\n",
       "  'are',\n",
       "  'originated',\n",
       "  'through',\n",
       "  'technical',\n",
       "  'terms',\n",
       "  'but',\n",
       "  'often',\n",
       "  'the',\n",
       "  'underlying',\n",
       "  'essence',\n",
       "  'is',\n",
       "  'ignored',\n",
       "  'through',\n",
       "  'fashionable',\n",
       "  'use',\n",
       "  'and',\n",
       "  'mainly',\n",
       "  'used',\n",
       "  'to',\n",
       "  'impress',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'main',\n",
       "  'reason',\n",
       "  'for',\n",
       "  'the',\n",
       "  'misconception',\n",
       "  'amongst',\n",
       "  'people',\n",
       "  'ai',\n",
       "  'ml',\n",
       "  'stats',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'and',\n",
       "  'many',\n",
       "  'other',\n",
       "  'fields',\n",
       "  'related',\n",
       "  'to',\n",
       "  'the',\n",
       "  'analysis',\n",
       "  'of',\n",
       "  'data',\n",
       "  'are',\n",
       "  'most',\n",
       "  'often',\n",
       "  'mistook',\n",
       "  'for',\n",
       "  'one',\n",
       "  'and',\n",
       "  'the',\n",
       "  'same',\n",
       "  'thing',\n",
       "  'thus',\n",
       "  'all',\n",
       "  'these',\n",
       "  'words',\n",
       "  'are',\n",
       "  'often',\n",
       "  'used',\n",
       "  'interchangeably',\n",
       "  'to',\n",
       "  'convey',\n",
       "  'one',\n",
       "  'and',\n",
       "  'the',\n",
       "  'same',\n",
       "  'thing',\n",
       "  'but',\n",
       "  'this',\n",
       "  'is',\n",
       "  'not',\n",
       "  'true',\n",
       "  'at',\n",
       "  'all!',\n",
       "  'the',\n",
       "  'only',\n",
       "  'similarity',\n",
       "  'between',\n",
       "  'these',\n",
       "  'disciplines',\n",
       "  'is',\n",
       "  'that',\n",
       "  'all',\n",
       "  'of',\n",
       "  'these',\n",
       "  'disciplines',\n",
       "  'are',\n",
       "  'related',\n",
       "  'to',\n",
       "  'the',\n",
       "  'analysis',\n",
       "  'of',\n",
       "  'the',\n",
       "  'data',\n",
       "  'and',\n",
       "  'converting',\n",
       "  'this',\n",
       "  'data',\n",
       "  'into',\n",
       "  'information',\n",
       "  'in',\n",
       "  'academics',\n",
       "  'while',\n",
       "  'learning',\n",
       "  'ai',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'statistics',\n",
       "  'and',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'the',\n",
       "  'academic',\n",
       "  'approach',\n",
       "  'only',\n",
       "  'wander',\n",
       "  'in',\n",
       "  'the',\n",
       "  'technical',\n",
       "  'definitions',\n",
       "  'and',\n",
       "  'concepts',\n",
       "  'but',\n",
       "  'the',\n",
       "  'underlying',\n",
       "  'essence',\n",
       "  'and',\n",
       "  'the',\n",
       "  'aim',\n",
       "  'of',\n",
       "  'the',\n",
       "  'discipline',\n",
       "  'remain',\n",
       "  'unexplored',\n",
       "  'same',\n",
       "  'is',\n",
       "  'the',\n",
       "  'case',\n",
       "  'with',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'articles',\n",
       "  'out',\n",
       "  'there',\n",
       "  'which',\n",
       "  'try',\n",
       "  'to',\n",
       "  'explain',\n",
       "  'the',\n",
       "  'difference',\n",
       "  'thus',\n",
       "  'becoming',\n",
       "  'the',\n",
       "  'primary',\n",
       "  'cause',\n",
       "  'of',\n",
       "  'confusion',\n",
       "  'between',\n",
       "  'learners',\n",
       "  'hence',\n",
       "  'this',\n",
       "  'article',\n",
       "  'explains',\n",
       "  'the',\n",
       "  'difference',\n",
       "  'by',\n",
       "  'explaining',\n",
       "  'the',\n",
       "  'philosophy',\n",
       "  'and',\n",
       "  'the',\n",
       "  'aims',\n",
       "  'of',\n",
       "  'each',\n",
       "  'of',\n",
       "  'the',\n",
       "  'disciplines',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'wandering',\n",
       "  'in',\n",
       "  'the',\n",
       "  'technical',\n",
       "  'definitions',\n",
       "  'the',\n",
       "  'essential',\n",
       "  'difference',\n",
       "  'between',\n",
       "  'these',\n",
       "  'disciplines',\n",
       "  'lies',\n",
       "  'in',\n",
       "  'their',\n",
       "  'aims',\n",
       "  'and',\n",
       "  'the',\n",
       "  'approach',\n",
       "  'taken',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'those',\n",
       "  'aims',\n",
       "  'the',\n",
       "  'aim',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'intelligent',\n",
       "  'entities',\n",
       "  'then',\n",
       "  'to',\n",
       "  'satisfy',\n",
       "  'this',\n",
       "  'aim',\n",
       "  'we',\n",
       "  'must',\n",
       "  'first',\n",
       "  'understand',\n",
       "  'what',\n",
       "  'is',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'what',\n",
       "  'makes',\n",
       "  'an',\n",
       "  'agent',\n",
       "  'intelligent',\n",
       "  'agent?',\n",
       "  'the',\n",
       "  'answer',\n",
       "  'to',\n",
       "  'all',\n",
       "  'these',\n",
       "  'questions',\n",
       "  'can',\n",
       "  'be',\n",
       "  'found',\n",
       "  'by',\n",
       "  'studying',\n",
       "  'intelligent',\n",
       "  'agents',\n",
       "  'and',\n",
       "  'the',\n",
       "  'best',\n",
       "  'example',\n",
       "  'of',\n",
       "  'an',\n",
       "  'intelligent',\n",
       "  'agent',\n",
       "  'can',\n",
       "  'be',\n",
       "  'found',\n",
       "  'by',\n",
       "  'just',\n",
       "  'standing',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'a',\n",
       "  'mirror!',\n",
       "  'yes!',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'the',\n",
       "  'best',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'intelligent',\n",
       "  'entities',\n",
       "  'thus',\n",
       "  'in',\n",
       "  'the',\n",
       "  '1900s',\n",
       "  'researchers',\n",
       "  'began',\n",
       "  'exploring',\n",
       "  'the',\n",
       "  'thought',\n",
       "  'process',\n",
       "  'the',\n",
       "  'reasoning',\n",
       "  'process',\n",
       "  'of',\n",
       "  'humans',\n",
       "  'as',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'were',\n",
       "  'considered',\n",
       "  'as',\n",
       "  'an',\n",
       "  'ideal',\n",
       "  'intelligent',\n",
       "  'agent',\n",
       "  'mimicking',\n",
       "  'human',\n",
       "  'behavior',\n",
       "  'became',\n",
       "  'the',\n",
       "  'aim',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'in',\n",
       "  'the',\n",
       "  'initial',\n",
       "  'years',\n",
       "  'of',\n",
       "  'the',\n",
       "  'research',\n",
       "  'after',\n",
       "  'setting',\n",
       "  'this',\n",
       "  'goal',\n",
       "  'studies',\n",
       "  'and',\n",
       "  'experiments',\n",
       "  'began',\n",
       "  'and',\n",
       "  'the',\n",
       "  'most',\n",
       "  'famous',\n",
       "  'experiment',\n",
       "  'conducted',\n",
       "  'in',\n",
       "  'the',\n",
       "  'initial',\n",
       "  'years',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'this',\n",
       "  'aim',\n",
       "  'was',\n",
       "  'the',\n",
       "  'turing',\n",
       "  'test!',\n",
       "  'turing',\n",
       "  'defined',\n",
       "  'intelligent',\n",
       "  'behavior',\n",
       "  'as',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'humanlevel',\n",
       "  'performance',\n",
       "  'in',\n",
       "  'all',\n",
       "  'cognitive',\n",
       "  'tasks',\n",
       "  'sufficient',\n",
       "  'to',\n",
       "  'fool',\n",
       "  'an',\n",
       "  'interrogator',\n",
       "  'but',\n",
       "  'this',\n",
       "  'test',\n",
       "  'received',\n",
       "  'criticism',\n",
       "  'as',\n",
       "  'only',\n",
       "  'mimicking',\n",
       "  'human',\n",
       "  'behavior',\n",
       "  'is',\n",
       "  'not',\n",
       "  'exactly',\n",
       "  'intelligence',\n",
       "  'because',\n",
       "  'intelligence',\n",
       "  'should',\n",
       "  'be',\n",
       "  'related',\n",
       "  'to',\n",
       "  'the',\n",
       "  'working',\n",
       "  'of',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'as',\n",
       "  'without',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'intelligence',\n",
       "  'has',\n",
       "  'no',\n",
       "  'meaning!',\n",
       "  'thus',\n",
       "  'mimicking',\n",
       "  'human',\n",
       "  'thought',\n",
       "  'processes',\n",
       "  'and',\n",
       "  'reasoning',\n",
       "  'became',\n",
       "  'the',\n",
       "  'transformed',\n",
       "  'aim',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'psychology',\n",
       "  'and',\n",
       "  'philosophy',\n",
       "  'also',\n",
       "  'resonate',\n",
       "  'with',\n",
       "  'this',\n",
       "  'aim',\n",
       "  'that',\n",
       "  'is',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'human',\n",
       "  'thought',\n",
       "  'process',\n",
       "  'the',\n",
       "  'difference',\n",
       "  'is',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'not',\n",
       "  'only',\n",
       "  'tries',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'thought',\n",
       "  'process',\n",
       "  'but',\n",
       "  'to',\n",
       "  'mimic',\n",
       "  'it',\n",
       "  'build',\n",
       "  'it',\n",
       "  'the',\n",
       "  'collaboration',\n",
       "  'of',\n",
       "  'these',\n",
       "  'fields',\n",
       "  'resulted',\n",
       "  'in',\n",
       "  'models',\n",
       "  'such',\n",
       "  'as',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'which',\n",
       "  'try',\n",
       "  'to',\n",
       "  'mimic',\n",
       "  'the',\n",
       "  'function',\n",
       "  'of',\n",
       "  'neurons',\n",
       "  'present',\n",
       "  'in',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'so',\n",
       "  'basically',\n",
       "  'this',\n",
       "  'initial',\n",
       "  'aim',\n",
       "  'was',\n",
       "  'humancentered',\n",
       "  'and',\n",
       "  'humans',\n",
       "  'were',\n",
       "  'considered',\n",
       "  'as',\n",
       "  'the',\n",
       "  'ideal',\n",
       "  'intelligent',\n",
       "  'agent',\n",
       "  'concurrently',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'computer',\n",
       "  'science',\n",
       "  'was',\n",
       "  'developing',\n",
       "  'at',\n",
       "  'a',\n",
       "  'greater',\n",
       "  'pace',\n",
       "  'with',\n",
       "  'the',\n",
       "  'advances',\n",
       "  'in',\n",
       "  'computer',\n",
       "  'science',\n",
       "  'the',\n",
       "  'experiments',\n",
       "  'and',\n",
       "  'theories',\n",
       "  'could',\n",
       "  'be',\n",
       "  'easily',\n",
       "  'tested',\n",
       "  'and',\n",
       "  'validated',\n",
       "  'as',\n",
       "  'programs',\n",
       "  'were',\n",
       "  'being',\n",
       "  'applied',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'reallife',\n",
       "  'problems',\n",
       "  'it',\n",
       "  'was',\n",
       "  'found',\n",
       "  'that',\n",
       "  'computers',\n",
       "  'performed',\n",
       "  'better',\n",
       "  'than',\n",
       "  'humans',\n",
       "  'at',\n",
       "  'some',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'are',\n",
       "  'really',\n",
       "  'complex',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'best',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'this',\n",
       "  'could',\n",
       "  'be',\n",
       "  'the',\n",
       "  'chessplaying',\n",
       "  'program',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'program',\n",
       "  'defeated',\n",
       "  'the',\n",
       "  'worlds',\n",
       "  'best',\n",
       "  'chess',\n",
       "  'player',\n",
       "  'garry',\n",
       "  'kasparov',\n",
       "  'this',\n",
       "  'incident',\n",
       "  'indicated',\n",
       "  'that',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'not',\n",
       "  'the',\n",
       "  'ultimate',\n",
       "  'intelligence',\n",
       "  'or',\n",
       "  'else',\n",
       "  'a',\n",
       "  'human',\n",
       "  'would',\n",
       "  'have',\n",
       "  'been',\n",
       "  'able',\n",
       "  'to',\n",
       "  'defeat',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'program',\n",
       "  'this',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'a',\n",
       "  'question',\n",
       "  'is',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'the',\n",
       "  'ideal',\n",
       "  'intelligence?',\n",
       "  'as',\n",
       "  'computers',\n",
       "  'became',\n",
       "  'more',\n",
       "  'advanced',\n",
       "  'they',\n",
       "  'proved',\n",
       "  'to',\n",
       "  'be',\n",
       "  'better',\n",
       "  'than',\n",
       "  'humans',\n",
       "  'at',\n",
       "  'certain',\n",
       "  'complex',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'is',\n",
       "  'why',\n",
       "  'the',\n",
       "  'new',\n",
       "  'definition',\n",
       "  'of',\n",
       "  'intelligence',\n",
       "  'was',\n",
       "  'being',\n",
       "  'related',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'cognitive',\n",
       "  'tasks',\n",
       "  'or',\n",
       "  'problems',\n",
       "  'so',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'considering',\n",
       "  'the',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'agents',\n",
       "  'researchers',\n",
       "  'began',\n",
       "  'to',\n",
       "  'study',\n",
       "  'the',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'intelligence',\n",
       "  'itself',\n",
       "  'then',\n",
       "  'the',\n",
       "  'question',\n",
       "  'comes',\n",
       "  'how',\n",
       "  'to',\n",
       "  'test',\n",
       "  'or',\n",
       "  'validate',\n",
       "  'intelligence?',\n",
       "  'the',\n",
       "  'best',\n",
       "  'way',\n",
       "  'to',\n",
       "  'test',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'cognitive',\n",
       "  'problems',\n",
       "  'an',\n",
       "  'agent',\n",
       "  'can',\n",
       "  'be',\n",
       "  'said',\n",
       "  'intelligent',\n",
       "  'only',\n",
       "  'if',\n",
       "  'it',\n",
       "  'can',\n",
       "  'solve',\n",
       "  'a',\n",
       "  'complex',\n",
       "  'problem',\n",
       "  'the',\n",
       "  'problemsolving',\n",
       "  'approach',\n",
       "  'can',\n",
       "  'be',\n",
       "  'easily',\n",
       "  'tested',\n",
       "  'and',\n",
       "  'validated',\n",
       "  'on',\n",
       "  'computers',\n",
       "  'thus',\n",
       "  'some',\n",
       "  'researchers',\n",
       "  'began',\n",
       "  'studying',\n",
       "  'the',\n",
       "  'ideal',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'the',\n",
       "  'selected',\n",
       "  'agent',\n",
       "  'to',\n",
       "  'validate',\n",
       "  'the',\n",
       "  'experiments',\n",
       "  'was',\n",
       "  'the',\n",
       "  'computer',\n",
       "  'so',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'and',\n",
       "  'problemsolving',\n",
       "  'approach',\n",
       "  'were',\n",
       "  'adopted',\n",
       "  'so',\n",
       "  'the',\n",
       "  'humancentered',\n",
       "  'approach',\n",
       "  'and',\n",
       "  'computer',\n",
       "  'problemsolving',\n",
       "  'approach',\n",
       "  'are',\n",
       "  'the',\n",
       "  'two',\n",
       "  'main',\n",
       "  'aims',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'both',\n",
       "  'of',\n",
       "  'these',\n",
       "  'fields',\n",
       "  'have',\n",
       "  'contributed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'field',\n",
       "  'by',\n",
       "  'giving',\n",
       "  'valuable',\n",
       "  'insights',\n",
       "  'both',\n",
       "  'the',\n",
       "  'aims',\n",
       "  'are',\n",
       "  'important',\n",
       "  'and',\n",
       "  'both',\n",
       "  'of',\n",
       "  'these',\n",
       "  'collaboratively',\n",
       "  'form',\n",
       "  'the',\n",
       "  'main',\n",
       "  'aim',\n",
       "  'of',\n",
       "  'ai!',\n",
       "  'in',\n",
       "  'the',\n",
       "  'problemsolving',\n",
       "  'approach',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'big',\n",
       "  'challenge',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'has',\n",
       "  'to',\n",
       "  'overcome',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'its',\n",
       "  'aim',\n",
       "  'consider',\n",
       "  'the',\n",
       "  'example',\n",
       "  'of',\n",
       "  'solving',\n",
       "  'a',\n",
       "  'math',\n",
       "  'problem',\n",
       "  'there',\n",
       "  'are',\n",
       "  'two',\n",
       "  'cases',\n",
       "  'by',\n",
       "  'which',\n",
       "  'intelligence',\n",
       "  'can',\n",
       "  'be',\n",
       "  'tested',\n",
       "  'in',\n",
       "  'this',\n",
       "  'problemsolving',\n",
       "  'approach',\n",
       "  'let',\n",
       "  'us',\n",
       "  'say',\n",
       "  'two',\n",
       "  'math',\n",
       "  'problems',\n",
       "  'are',\n",
       "  'given',\n",
       "  'for',\n",
       "  'you',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'the',\n",
       "  'first',\n",
       "  'problem',\n",
       "  'is',\n",
       "  'familiar',\n",
       "  'to',\n",
       "  'you',\n",
       "  'and',\n",
       "  'the',\n",
       "  'second',\n",
       "  'problem',\n",
       "  'is',\n",
       "  'not',\n",
       "  'consider',\n",
       "  'the',\n",
       "  'first',\n",
       "  'problem',\n",
       "  'the',\n",
       "  'first',\n",
       "  'problem',\n",
       "  'is',\n",
       "  'familiar',\n",
       "  'to',\n",
       "  'you',\n",
       "  'that',\n",
       "  'means',\n",
       "  'you',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'such',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'problems',\n",
       "  'as',\n",
       "  'you',\n",
       "  'have',\n",
       "  'already',\n",
       "  'solved',\n",
       "  'some',\n",
       "  'similar',\n",
       "  'problems',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  'so',\n",
       "  'there',\n",
       "  'comes',\n",
       "  'a',\n",
       "  'question',\n",
       "  'how',\n",
       "  'our',\n",
       "  'mind',\n",
       "  'is',\n",
       "  'able',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'that',\n",
       "  'problem?',\n",
       "  'the',\n",
       "  'answer',\n",
       "  'is',\n",
       "  'that',\n",
       "  'you',\n",
       "  'have',\n",
       "  'solved',\n",
       "  'similar',\n",
       "  'problems',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  'thus',\n",
       "  'you',\n",
       "  'have',\n",
       "  'learned',\n",
       "  'from',\n",
       "  'the',\n",
       "  'past',\n",
       "  'data',\n",
       "  'how',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'such',\n",
       "  'problems',\n",
       "  'thus',\n",
       "  'even',\n",
       "  'if',\n",
       "  'you',\n",
       "  'havent',\n",
       "  'seen',\n",
       "  'that',\n",
       "  'problem',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  'you',\n",
       "  'will',\n",
       "  'still',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'similar',\n",
       "  'problems',\n",
       "  'this',\n",
       "  'is',\n",
       "  'one',\n",
       "  'form',\n",
       "  'of',\n",
       "  'intelligence',\n",
       "  'consider',\n",
       "  'another',\n",
       "  ...]]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/60.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "64e1fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1887\n",
      "WORD COUNT 1159\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "66e24177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 20.736263736263737\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e806a149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.31492666091458155\n",
      "FOG INDEX: 8.420476158871327\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 20.736263736263737\n",
      "COMPLEX WORD COUNT: 365\n",
      "WORD COUNT: 1159\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "90f8be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3443\n",
      "I: 0\n",
      "we: 8\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 2\n",
      "Total count: 10\n",
      "PERSONAL PRONOUNS: 10\n",
      "AVG WORD LENGTH: 4.961844197138315\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_60.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c898057",
   "metadata": {},
   "source": [
    "# 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0c36e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\629202680.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "44533c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science is gaining popularity exponentially over the past decade, and thanks to that we are now enjoying better products, recommendations, and smoother life. Data science is an interdisciplinary subject that includes statistics, math, IT, etc.',\n",
       " 'Now there is so much to do in Data Science,  so we need an arrangement where all this can be accessible in one place. It will be very hectic to go to hundreds of different resources while doing analysis or building models. But don’t worry, PYTHON is there for you.',\n",
       " 'Yes, you read it right, Python is a general programming language that can provide everything you need for Data Science. Several features that have made Python become the choice of data science in past times are:',\n",
       " '1. Python is a progressively typed language, so the variables are defined automatically.',\n",
       " '2. Python is more readable and uses lesser code to play out a similar task when contrasted with other programming languages.',\n",
       " '3. Python is specifically typed. In this way, developers need to cast types manually.',\n",
       " '4. Python is an interpreted language. This implies the program need not have complied.',\n",
       " '5. Python is flexible, convenient, and can run on any platform effectively. It is adaptable and can be integrated with other third-party software effectively.',\n",
       " 'This library available in python makes it very easier to analyze the data, you can read a variety of data sets like CSV, XML, XLSX, JSON, etc. You can perform several operations like Groupby, sorting with the help of easily accessible objects from pandas.',\n",
       " 'This package helps you with any numerical operation that is needed to be performed in Data science, for example calculating Euclidean distance, finding ranks of the matrix, etc.',\n",
       " 'These are excellent data visualization libraries available in python that produce some excellent visualization like shown here,',\n",
       " 'It provides you state of the art machine learning algorithms for your accurate predictive analysis. Scikit–Learn is characterized by a clean, uniform, and streamlined API, as well as by very useful and complete online documentation. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering, and dimensionality reduction via a consistent interface in Python.',\n",
       " 'Keras is an open-source software library that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library. Keras is an industry-strength framework that can scale to large clusters of GPUs or an entire TPU pod.',\n",
       " 'See, Now that you have a variety of resources available here in python, then why go anywhere else. Python I also becoming the world’s most loved and most wanted programming language and it will surely help to get you the job. Data science consulting organizations are empowering their group of developers and data scientists to utilize Python as a programming language. Python has gotten well-known and the most significant programming language in an extremely brief timeframe. Data Scientists need to manage a large amount of data known as big data. With simple utilization and a huge arrangement of python libraries, Python has become a popular choice to deal with big data.',\n",
       " 'Seeing the stats we can clearly see that Python has taken over other Languages needed for data science. It has also surpassed R which is exclusively built for Data science. Isn’t this exciting.',\n",
       " 'Python in Data science has empowered data scientists to accomplish more in less time. Python is an adaptable programming language that can be effectively understood and is exceptionally amazing as well.',\n",
       " 'Python is highly adaptable and can work in any environment effectively. Additionally, with negligible changes, it can run on any operating system and can be integrated with other programming languages. These qualities have settled on Python as the top choice for developers & data scientists.',\n",
       " 'So next time you do analysis or work on any Data Science project, feel proud cause you are working with the most loved language of the world.']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9364f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:34]))\n",
    "URL_ID_61 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "204d8df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49 sentences in the string.\n",
      "The number of words in the string is: 663\n",
      "The number of characters in the string is: 3476\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 19:34:13] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 19:34:20] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_61.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_61.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_61.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_61 = re.sub(re_punt, \"\",URL_ID_61)\n",
    "\n",
    "file = open(\"61.txt\", \"w\")\n",
    "file.write(URL_ID_61)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"61.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4650b23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  'pandas',\n",
       "  'numpy',\n",
       "  'matplotlib',\n",
       "  'and',\n",
       "  'seaborn',\n",
       "  'sklearn',\n",
       "  'scikit',\n",
       "  'learn',\n",
       "  'keras',\n",
       "  'keras',\n",
       "  'framework',\n",
       "  'data',\n",
       "  'science',\n",
       "  'is',\n",
       "  'gaining',\n",
       "  'popularity',\n",
       "  'exponentially',\n",
       "  'over',\n",
       "  'the',\n",
       "  'past',\n",
       "  'decade',\n",
       "  'and',\n",
       "  'thanks',\n",
       "  'to',\n",
       "  'that',\n",
       "  'we',\n",
       "  'are',\n",
       "  'now',\n",
       "  'enjoying',\n",
       "  'better',\n",
       "  'products',\n",
       "  'recommendations',\n",
       "  'and',\n",
       "  'smoother',\n",
       "  'life',\n",
       "  'data',\n",
       "  'science',\n",
       "  'is',\n",
       "  'an',\n",
       "  'interdisciplinary',\n",
       "  'subject',\n",
       "  'that',\n",
       "  'includes',\n",
       "  'statistics',\n",
       "  'math',\n",
       "  'it',\n",
       "  'etc',\n",
       "  'now',\n",
       "  'there',\n",
       "  'is',\n",
       "  'so',\n",
       "  'much',\n",
       "  'to',\n",
       "  'do',\n",
       "  'in',\n",
       "  'data',\n",
       "  'science',\n",
       "  'so',\n",
       "  'we',\n",
       "  'need',\n",
       "  'an',\n",
       "  'arrangement',\n",
       "  'where',\n",
       "  'all',\n",
       "  'this',\n",
       "  'can',\n",
       "  'be',\n",
       "  'accessible',\n",
       "  'in',\n",
       "  'one',\n",
       "  'place',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'very',\n",
       "  'hectic',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'hundreds',\n",
       "  'of',\n",
       "  'different',\n",
       "  'resources',\n",
       "  'while',\n",
       "  'doing',\n",
       "  'analysis',\n",
       "  'or',\n",
       "  'building',\n",
       "  'models',\n",
       "  'but',\n",
       "  'dont',\n",
       "  'worry',\n",
       "  'python',\n",
       "  'is',\n",
       "  'there',\n",
       "  'for',\n",
       "  'you',\n",
       "  'yes',\n",
       "  'you',\n",
       "  'read',\n",
       "  'it',\n",
       "  'right',\n",
       "  'python',\n",
       "  'is',\n",
       "  'a',\n",
       "  'general',\n",
       "  'programming',\n",
       "  'language',\n",
       "  'that',\n",
       "  'can',\n",
       "  'provide',\n",
       "  'everything',\n",
       "  'you',\n",
       "  'need',\n",
       "  'for',\n",
       "  'data',\n",
       "  'science',\n",
       "  'several',\n",
       "  'features',\n",
       "  'that',\n",
       "  'have',\n",
       "  'made',\n",
       "  'python',\n",
       "  'become',\n",
       "  'the',\n",
       "  'choice',\n",
       "  'of',\n",
       "  'data',\n",
       "  'science',\n",
       "  'in',\n",
       "  'past',\n",
       "  'times',\n",
       "  'are',\n",
       "  '1',\n",
       "  'python',\n",
       "  'is',\n",
       "  'a',\n",
       "  'progressively',\n",
       "  'typed',\n",
       "  'language',\n",
       "  'so',\n",
       "  'the',\n",
       "  'variables',\n",
       "  'are',\n",
       "  'defined',\n",
       "  'automatically',\n",
       "  '2',\n",
       "  'python',\n",
       "  'is',\n",
       "  'more',\n",
       "  'readable',\n",
       "  'and',\n",
       "  'uses',\n",
       "  'lesser',\n",
       "  'code',\n",
       "  'to',\n",
       "  'play',\n",
       "  'out',\n",
       "  'a',\n",
       "  'similar',\n",
       "  'task',\n",
       "  'when',\n",
       "  'contrasted',\n",
       "  'with',\n",
       "  'other',\n",
       "  'programming',\n",
       "  'languages',\n",
       "  '3',\n",
       "  'python',\n",
       "  'is',\n",
       "  'specifically',\n",
       "  'typed',\n",
       "  'in',\n",
       "  'this',\n",
       "  'way',\n",
       "  'developers',\n",
       "  'need',\n",
       "  'to',\n",
       "  'cast',\n",
       "  'types',\n",
       "  'manually',\n",
       "  '4',\n",
       "  'python',\n",
       "  'is',\n",
       "  'an',\n",
       "  'interpreted',\n",
       "  'language',\n",
       "  'this',\n",
       "  'implies',\n",
       "  'the',\n",
       "  'program',\n",
       "  'need',\n",
       "  'not',\n",
       "  'have',\n",
       "  'complied',\n",
       "  '5',\n",
       "  'python',\n",
       "  'is',\n",
       "  'flexible',\n",
       "  'convenient',\n",
       "  'and',\n",
       "  'can',\n",
       "  'run',\n",
       "  'on',\n",
       "  'any',\n",
       "  'platform',\n",
       "  'effectively',\n",
       "  'it',\n",
       "  'is',\n",
       "  'adaptable',\n",
       "  'and',\n",
       "  'can',\n",
       "  'be',\n",
       "  'integrated',\n",
       "  'with',\n",
       "  'other',\n",
       "  'thirdparty',\n",
       "  'software',\n",
       "  'effectively',\n",
       "  'this',\n",
       "  'library',\n",
       "  'available',\n",
       "  'in',\n",
       "  'python',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'very',\n",
       "  'easier',\n",
       "  'to',\n",
       "  'analyze',\n",
       "  'the',\n",
       "  'data',\n",
       "  'you',\n",
       "  'can',\n",
       "  'read',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'data',\n",
       "  'sets',\n",
       "  'like',\n",
       "  'csv',\n",
       "  'xml',\n",
       "  'xlsx',\n",
       "  'json',\n",
       "  'etc',\n",
       "  'you',\n",
       "  'can',\n",
       "  'perform',\n",
       "  'several',\n",
       "  'operations',\n",
       "  'like',\n",
       "  'groupby',\n",
       "  'sorting',\n",
       "  'with',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'easily',\n",
       "  'accessible',\n",
       "  'objects',\n",
       "  'from',\n",
       "  'pandas',\n",
       "  'this',\n",
       "  'package',\n",
       "  'helps',\n",
       "  'you',\n",
       "  'with',\n",
       "  'any',\n",
       "  'numerical',\n",
       "  'operation',\n",
       "  'that',\n",
       "  'is',\n",
       "  'needed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'performed',\n",
       "  'in',\n",
       "  'data',\n",
       "  'science',\n",
       "  'for',\n",
       "  'example',\n",
       "  'calculating',\n",
       "  'euclidean',\n",
       "  'distance',\n",
       "  'finding',\n",
       "  'ranks',\n",
       "  'of',\n",
       "  'the',\n",
       "  'matrix',\n",
       "  'etc',\n",
       "  'these',\n",
       "  'are',\n",
       "  'excellent',\n",
       "  'data',\n",
       "  'visualization',\n",
       "  'libraries',\n",
       "  'available',\n",
       "  'in',\n",
       "  'python',\n",
       "  'that',\n",
       "  'produce',\n",
       "  'some',\n",
       "  'excellent',\n",
       "  'visualization',\n",
       "  'like',\n",
       "  'shown',\n",
       "  'here',\n",
       "  'it',\n",
       "  'provides',\n",
       "  'you',\n",
       "  'state',\n",
       "  'of',\n",
       "  'the',\n",
       "  'art',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'for',\n",
       "  'your',\n",
       "  'accurate',\n",
       "  'predictive',\n",
       "  'analysis',\n",
       "  'scikitlearn',\n",
       "  'is',\n",
       "  'characterized',\n",
       "  'by',\n",
       "  'a',\n",
       "  'clean',\n",
       "  'uniform',\n",
       "  'and',\n",
       "  'streamlined',\n",
       "  'api',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'by',\n",
       "  'very',\n",
       "  'useful',\n",
       "  'and',\n",
       "  'complete',\n",
       "  'online',\n",
       "  'documentation',\n",
       "  'it',\n",
       "  'provides',\n",
       "  'a',\n",
       "  'selection',\n",
       "  'of',\n",
       "  'efficient',\n",
       "  'tools',\n",
       "  'for',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'statistical',\n",
       "  'modeling',\n",
       "  'including',\n",
       "  'classification',\n",
       "  'regression',\n",
       "  'clustering',\n",
       "  'and',\n",
       "  'dimensionality',\n",
       "  'reduction',\n",
       "  'via',\n",
       "  'a',\n",
       "  'consistent',\n",
       "  'interface',\n",
       "  'in',\n",
       "  'python',\n",
       "  'keras',\n",
       "  'is',\n",
       "  'an',\n",
       "  'opensource',\n",
       "  'software',\n",
       "  'library',\n",
       "  'that',\n",
       "  'provides',\n",
       "  'a',\n",
       "  'python',\n",
       "  'interface',\n",
       "  'for',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'keras',\n",
       "  'acts',\n",
       "  'as',\n",
       "  'an',\n",
       "  'interface',\n",
       "  'for',\n",
       "  'the',\n",
       "  'tensorflow',\n",
       "  'library',\n",
       "  'keras',\n",
       "  'is',\n",
       "  'an',\n",
       "  'industrystrength',\n",
       "  'framework',\n",
       "  'that',\n",
       "  'can',\n",
       "  'scale',\n",
       "  'to',\n",
       "  'large',\n",
       "  'clusters',\n",
       "  'of',\n",
       "  'gpus',\n",
       "  'or',\n",
       "  'an',\n",
       "  'entire',\n",
       "  'tpu',\n",
       "  'pod',\n",
       "  'see',\n",
       "  'now',\n",
       "  'that',\n",
       "  'you',\n",
       "  'have',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'resources',\n",
       "  'available',\n",
       "  'here',\n",
       "  'in',\n",
       "  'python',\n",
       "  'then',\n",
       "  'why',\n",
       "  'go',\n",
       "  'anywhere',\n",
       "  'else',\n",
       "  'python',\n",
       "  'i',\n",
       "  'also',\n",
       "  'becoming',\n",
       "  'the',\n",
       "  'worlds',\n",
       "  'most',\n",
       "  'loved',\n",
       "  'and',\n",
       "  'most',\n",
       "  'wanted',\n",
       "  'programming',\n",
       "  'language',\n",
       "  'and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'surely',\n",
       "  'help',\n",
       "  'to',\n",
       "  'get',\n",
       "  'you',\n",
       "  'the',\n",
       "  'job',\n",
       "  'data',\n",
       "  'science',\n",
       "  'consulting',\n",
       "  'organizations',\n",
       "  'are',\n",
       "  'empowering',\n",
       "  'their',\n",
       "  'group',\n",
       "  'of',\n",
       "  'developers',\n",
       "  'and',\n",
       "  'data',\n",
       "  'scientists',\n",
       "  'to',\n",
       "  'utilize',\n",
       "  'python',\n",
       "  'as',\n",
       "  'a',\n",
       "  'programming',\n",
       "  'language',\n",
       "  'python',\n",
       "  'has',\n",
       "  'gotten',\n",
       "  'wellknown',\n",
       "  'and',\n",
       "  'the',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'programming',\n",
       "  'language',\n",
       "  'in',\n",
       "  'an',\n",
       "  'extremely',\n",
       "  'brief',\n",
       "  'timeframe',\n",
       "  'data',\n",
       "  'scientists',\n",
       "  'need',\n",
       "  'to',\n",
       "  'manage',\n",
       "  'a',\n",
       "  'large',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'data',\n",
       "  'known',\n",
       "  'as',\n",
       "  'big',\n",
       "  'data',\n",
       "  'with',\n",
       "  'simple',\n",
       "  'utilization',\n",
       "  'and',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'arrangement',\n",
       "  'of',\n",
       "  'python',\n",
       "  'libraries',\n",
       "  'python',\n",
       "  'has',\n",
       "  'become',\n",
       "  'a',\n",
       "  'popular',\n",
       "  'choice',\n",
       "  'to',\n",
       "  'deal',\n",
       "  'with',\n",
       "  'big',\n",
       "  'data',\n",
       "  'seeing',\n",
       "  'the',\n",
       "  'stats',\n",
       "  'we',\n",
       "  'can',\n",
       "  'clearly',\n",
       "  'see',\n",
       "  'that',\n",
       "  'python',\n",
       "  'has',\n",
       "  'taken',\n",
       "  'over',\n",
       "  'other',\n",
       "  'languages',\n",
       "  'needed',\n",
       "  'for',\n",
       "  'data',\n",
       "  'science',\n",
       "  'it',\n",
       "  'has',\n",
       "  'also',\n",
       "  'surpassed',\n",
       "  'r',\n",
       "  'which',\n",
       "  'is',\n",
       "  'exclusively',\n",
       "  'built',\n",
       "  'for',\n",
       "  'data',\n",
       "  'science',\n",
       "  'isnt',\n",
       "  'this',\n",
       "  'exciting',\n",
       "  'python',\n",
       "  'in',\n",
       "  'data',\n",
       "  'science',\n",
       "  'has',\n",
       "  'empowered',\n",
       "  'data',\n",
       "  'scientists',\n",
       "  'to',\n",
       "  'accomplish',\n",
       "  'more',\n",
       "  'in',\n",
       "  'less',\n",
       "  'time',\n",
       "  'python',\n",
       "  'is',\n",
       "  'an',\n",
       "  'adaptable',\n",
       "  'programming',\n",
       "  'language',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'effectively',\n",
       "  'understood',\n",
       "  'and',\n",
       "  'is',\n",
       "  'exceptionally',\n",
       "  'amazing',\n",
       "  'as',\n",
       "  'well',\n",
       "  'python',\n",
       "  'is',\n",
       "  'highly',\n",
       "  'adaptable',\n",
       "  'and',\n",
       "  'can',\n",
       "  'work',\n",
       "  'in',\n",
       "  'any',\n",
       "  'environment',\n",
       "  'effectively',\n",
       "  'additionally',\n",
       "  'with',\n",
       "  'negligible',\n",
       "  'changes',\n",
       "  'it',\n",
       "  'can',\n",
       "  'run',\n",
       "  'on',\n",
       "  'any',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'and',\n",
       "  'can',\n",
       "  'be',\n",
       "  'integrated',\n",
       "  'with',\n",
       "  'other',\n",
       "  'programming',\n",
       "  'languages',\n",
       "  'these',\n",
       "  'qualities',\n",
       "  'have',\n",
       "  'settled',\n",
       "  'on',\n",
       "  'python',\n",
       "  'as',\n",
       "  'the',\n",
       "  'top',\n",
       "  'choice',\n",
       "  'for',\n",
       "  'developers',\n",
       "  'data',\n",
       "  'scientists',\n",
       "  'so',\n",
       "  'next',\n",
       "  'time',\n",
       "  'you',\n",
       "  'do',\n",
       "  'analysis',\n",
       "  'or',\n",
       "  'work',\n",
       "  'on',\n",
       "  'any',\n",
       "  'data',\n",
       "  'science',\n",
       "  'project',\n",
       "  'feel',\n",
       "  'proud',\n",
       "  'cause',\n",
       "  'you',\n",
       "  'are',\n",
       "  'working',\n",
       "  'with',\n",
       "  'the',\n",
       "  'most',\n",
       "  'loved',\n",
       "  'language',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world']]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/61.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "50add4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n",
      "WORD COUNT 443\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "554f7d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 13.53061224489796\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9369f910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3611738148984199\n",
      "FOG INDEX: 5.556714423918552\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 13.53061224489796\n",
      "COMPLEX WORD COUNT: 160\n",
      "WORD COUNT: 443\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "332abd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1267\n",
      "i: 1\n",
      "we: 3\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 4\n",
      "PERSONAL PRONOUNS: 4\n",
      "AVG WORD LENGTH: 5.242835595776772\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_61.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff4afd6",
   "metadata": {},
   "source": [
    "# 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "26496814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\493526899.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "eba80682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was in March that Tech giant Google came up with a ground-breaking announcement of Google Fit able to measure one’s heart and respiratory rates using their smartphones. This news spread like wildfire. Instantly became the talk of the town. This feature was said to be available to the Google Fit app exclusively to its Pixel phone users. Google also plans to expand to its other Android devices in the future.',\n",
       " 'This was after Google’s newest endeavor of acquiring the Fitbit for a whopping $2.1 billion. This acquisition not only does steps up a stage for a potential Google Smartwatch but also gives Google the ownerships to Fitbit’s health business and wealth of data assets. Users just need to place their head and upper torso in view of the front-facing phone camera for those who wish to measure their respiratory rate. For measuring Heart rate the user just has to place their finger on the rear-facing camera lens. Mind-blowing right!',\n",
       " 'Once the measurements have been taken the users simply have to store and save them in the Google Fit app to monitor and track their day-to-day wellness. On asked how it’s measuring these heart rate and respiratory rate, Google Health director of health technologies Shwethak Patel explained that these features rely on the sensors that have been built into the smartphone, such as its camera, microphone, and accelerometer. Thanks to increasingly power sensors even in affordable smartphones and advancements in computer vision, these features let use one smartphone’s camera to track even tiny physical signals like your chest movement to measure your respiratory rate and subtle changes in the color of your finger for your heart rate.',\n",
       " 'Pixel underwent and completed initial clinical trials to validate the algorithm cloud work in a variety of different world conditions and that too with many people while developing the features. Since our heart rate relies on approximating blood flow from color changes in someone’s fingertip, it has to account for factors such as lighting, skin tone, age. Adding to be able to measure heart and respiratory rate soon Google Fit also displays user daily stats such as daily goals, weekly goals, heart points, workout, and also sleep monitor.']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2bbd5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:20]))\n",
    "URL_ID_62 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "536a106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 sentences in the string.\n",
      "The number of words in the string is: 365\n",
      "The number of characters in the string is: 1860\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 19:45:07] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 19:45:29] \"GET /download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_62.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_62.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_62.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_62 = re.sub(re_punt, \"\",URL_ID_62)\n",
    "\n",
    "file = open(\"62.txt\", \"w\")\n",
    "file.write(URL_ID_62)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def download_file():\n",
    "    path = \"62.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d328460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it',\n",
       "  'was',\n",
       "  'in',\n",
       "  'march',\n",
       "  'that',\n",
       "  'tech',\n",
       "  'giant',\n",
       "  'google',\n",
       "  'came',\n",
       "  'up',\n",
       "  'with',\n",
       "  'a',\n",
       "  'groundbreaking',\n",
       "  'announcement',\n",
       "  'of',\n",
       "  'google',\n",
       "  'fit',\n",
       "  'able',\n",
       "  'to',\n",
       "  'measure',\n",
       "  'ones',\n",
       "  'heart',\n",
       "  'and',\n",
       "  'respiratory',\n",
       "  'rates',\n",
       "  'using',\n",
       "  'their',\n",
       "  'smartphones',\n",
       "  'this',\n",
       "  'news',\n",
       "  'spread',\n",
       "  'like',\n",
       "  'wildfire',\n",
       "  'instantly',\n",
       "  'became',\n",
       "  'the',\n",
       "  'talk',\n",
       "  'of',\n",
       "  'the',\n",
       "  'town',\n",
       "  'this',\n",
       "  'feature',\n",
       "  'was',\n",
       "  'said',\n",
       "  'to',\n",
       "  'be',\n",
       "  'available',\n",
       "  'to',\n",
       "  'the',\n",
       "  'google',\n",
       "  'fit',\n",
       "  'app',\n",
       "  'exclusively',\n",
       "  'to',\n",
       "  'its',\n",
       "  'pixel',\n",
       "  'phone',\n",
       "  'users',\n",
       "  'google',\n",
       "  'also',\n",
       "  'plans',\n",
       "  'to',\n",
       "  'expand',\n",
       "  'to',\n",
       "  'its',\n",
       "  'other',\n",
       "  'android',\n",
       "  'devices',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'this',\n",
       "  'was',\n",
       "  'after',\n",
       "  'googles',\n",
       "  'newest',\n",
       "  'endeavor',\n",
       "  'of',\n",
       "  'acquiring',\n",
       "  'the',\n",
       "  'fitbit',\n",
       "  'for',\n",
       "  'a',\n",
       "  'whopping',\n",
       "  '21',\n",
       "  'billion',\n",
       "  'this',\n",
       "  'acquisition',\n",
       "  'not',\n",
       "  'only',\n",
       "  'does',\n",
       "  'steps',\n",
       "  'up',\n",
       "  'a',\n",
       "  'stage',\n",
       "  'for',\n",
       "  'a',\n",
       "  'potential',\n",
       "  'google',\n",
       "  'smartwatch',\n",
       "  'but',\n",
       "  'also',\n",
       "  'gives',\n",
       "  'google',\n",
       "  'the',\n",
       "  'ownerships',\n",
       "  'to',\n",
       "  'fitbits',\n",
       "  'health',\n",
       "  'business',\n",
       "  'and',\n",
       "  'wealth',\n",
       "  'of',\n",
       "  'data',\n",
       "  'assets',\n",
       "  'users',\n",
       "  'just',\n",
       "  'need',\n",
       "  'to',\n",
       "  'place',\n",
       "  'their',\n",
       "  'head',\n",
       "  'and',\n",
       "  'upper',\n",
       "  'torso',\n",
       "  'in',\n",
       "  'view',\n",
       "  'of',\n",
       "  'the',\n",
       "  'frontfacing',\n",
       "  'phone',\n",
       "  'camera',\n",
       "  'for',\n",
       "  'those',\n",
       "  'who',\n",
       "  'wish',\n",
       "  'to',\n",
       "  'measure',\n",
       "  'their',\n",
       "  'respiratory',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'measuring',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  'the',\n",
       "  'user',\n",
       "  'just',\n",
       "  'has',\n",
       "  'to',\n",
       "  'place',\n",
       "  'their',\n",
       "  'finger',\n",
       "  'on',\n",
       "  'the',\n",
       "  'rearfacing',\n",
       "  'camera',\n",
       "  'lens',\n",
       "  'mindblowing',\n",
       "  'right!',\n",
       "  'once',\n",
       "  'the',\n",
       "  'measurements',\n",
       "  'have',\n",
       "  'been',\n",
       "  'taken',\n",
       "  'the',\n",
       "  'users',\n",
       "  'simply',\n",
       "  'have',\n",
       "  'to',\n",
       "  'store',\n",
       "  'and',\n",
       "  'save',\n",
       "  'them',\n",
       "  'in',\n",
       "  'the',\n",
       "  'google',\n",
       "  'fit',\n",
       "  'app',\n",
       "  'to',\n",
       "  'monitor',\n",
       "  'and',\n",
       "  'track',\n",
       "  'their',\n",
       "  'daytoday',\n",
       "  'wellness',\n",
       "  'on',\n",
       "  'asked',\n",
       "  'how',\n",
       "  'its',\n",
       "  'measuring',\n",
       "  'these',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  'and',\n",
       "  'respiratory',\n",
       "  'rate',\n",
       "  'google',\n",
       "  'health',\n",
       "  'director',\n",
       "  'of',\n",
       "  'health',\n",
       "  'technologies',\n",
       "  'shwethak',\n",
       "  'patel',\n",
       "  'explained',\n",
       "  'that',\n",
       "  'these',\n",
       "  'features',\n",
       "  'rely',\n",
       "  'on',\n",
       "  'the',\n",
       "  'sensors',\n",
       "  'that',\n",
       "  'have',\n",
       "  'been',\n",
       "  'built',\n",
       "  'into',\n",
       "  'the',\n",
       "  'smartphone',\n",
       "  'such',\n",
       "  'as',\n",
       "  'its',\n",
       "  'camera',\n",
       "  'microphone',\n",
       "  'and',\n",
       "  'accelerometer',\n",
       "  'thanks',\n",
       "  'to',\n",
       "  'increasingly',\n",
       "  'power',\n",
       "  'sensors',\n",
       "  'even',\n",
       "  'in',\n",
       "  'affordable',\n",
       "  'smartphones',\n",
       "  'and',\n",
       "  'advancements',\n",
       "  'in',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'these',\n",
       "  'features',\n",
       "  'let',\n",
       "  'use',\n",
       "  'one',\n",
       "  'smartphones',\n",
       "  'camera',\n",
       "  'to',\n",
       "  'track',\n",
       "  'even',\n",
       "  'tiny',\n",
       "  'physical',\n",
       "  'signals',\n",
       "  'like',\n",
       "  'your',\n",
       "  'chest',\n",
       "  'movement',\n",
       "  'to',\n",
       "  'measure',\n",
       "  'your',\n",
       "  'respiratory',\n",
       "  'rate',\n",
       "  'and',\n",
       "  'subtle',\n",
       "  'changes',\n",
       "  'in',\n",
       "  'the',\n",
       "  'color',\n",
       "  'of',\n",
       "  'your',\n",
       "  'finger',\n",
       "  'for',\n",
       "  'your',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  'pixel',\n",
       "  'underwent',\n",
       "  'and',\n",
       "  'completed',\n",
       "  'initial',\n",
       "  'clinical',\n",
       "  'trials',\n",
       "  'to',\n",
       "  'validate',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'cloud',\n",
       "  'work',\n",
       "  'in',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'different',\n",
       "  'world',\n",
       "  'conditions',\n",
       "  'and',\n",
       "  'that',\n",
       "  'too',\n",
       "  'with',\n",
       "  'many',\n",
       "  'people',\n",
       "  'while',\n",
       "  'developing',\n",
       "  'the',\n",
       "  'features',\n",
       "  'since',\n",
       "  'our',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  'relies',\n",
       "  'on',\n",
       "  'approximating',\n",
       "  'blood',\n",
       "  'flow',\n",
       "  'from',\n",
       "  'color',\n",
       "  'changes',\n",
       "  'in',\n",
       "  'someones',\n",
       "  'fingertip',\n",
       "  'it',\n",
       "  'has',\n",
       "  'to',\n",
       "  'account',\n",
       "  'for',\n",
       "  'factors',\n",
       "  'such',\n",
       "  'as',\n",
       "  'lighting',\n",
       "  'skin',\n",
       "  'tone',\n",
       "  'age',\n",
       "  'adding',\n",
       "  'to',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'measure',\n",
       "  'heart',\n",
       "  'and',\n",
       "  'respiratory',\n",
       "  'rate',\n",
       "  'soon',\n",
       "  'google',\n",
       "  'fit',\n",
       "  'also',\n",
       "  'displays',\n",
       "  'user',\n",
       "  'daily',\n",
       "  'stats',\n",
       "  'such',\n",
       "  'as',\n",
       "  'daily',\n",
       "  'goals',\n",
       "  'weekly',\n",
       "  'goals',\n",
       "  'heart',\n",
       "  'points',\n",
       "  'workout',\n",
       "  'and',\n",
       "  'also',\n",
       "  'sleep',\n",
       "  'monitor']]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/62.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "68cb9169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n",
      "WORD COUNT 236\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1b76d193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 21.470588235294116\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "905d6ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.288135593220339\n",
      "FOG INDEX: 8.703489531405783\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 21.470588235294116\n",
      "COMPLEX WORD COUNT: 68\n",
      "WORD COUNT: 236\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9aa37edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 690\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 5.095890410958904\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_62.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653214e",
   "metadata": {},
   "source": [
    "# 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8908a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\4228129017.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "35b9d888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From what I have learned on the mobile apps development market recently, it is becoming harder for an Android or iOS developer to find a suitable and well-paying job in the market.',\n",
       " 'Some major reasons include the increasing supply of mobile engineers, people generally stop downloading apps, and many more.',\n",
       " 'In this article, I will go through a more detailed explanation of the recent trend mentioned above and my two cents on what mobile engineers could do to prepare themself for the upcoming challenge! and the future of mobile apps.',\n",
       " 'Although the demand for mobile developers has not fallen sharply compared with previous years, the growth rate has slowed. On the other hand, owing to a great number of coding boot camps that target to bring up mobile and frontend engineers, a great number of developers are flooding into the developer job market.',\n",
       " 'The supply side for mobile engineers has increased rapidly in recent years, raising the standards for qualified mobile engineers. The days of a mobile engineer easily getting over 10 job offers are over.',\n",
       " 'Recode ran an article in mid-2016, that begins: “The mobile app boom kicked off in July 2008, when Apple introduced the App Store. Now it is over.”',\n",
       " 'According to data gathered and analyzed by the CakeResume team, JavaScript and Python are now the most in-demand programming languages for companies who post product development jobs on CakeResume, both together taking up almost half of the job opportunities, while mobile engineers taking up merely 10% of the job opportunities.',\n",
       " 'While App usage continues to grow and revenue also ascends, the majority of consumers actually download zero apps per month',\n",
       " 'let’s face the truth, born and raised up in the era of the information explosion, individuals don’t have the leisure to check on what’s new on the app store every day. When it comes to choosing an App to download, many people feel overwhelmed by the sheer number of options available.',\n",
       " 'Take the productivity category of the App Store as an example, there are over thousands of Apps in this category, and new Apps popping up almost every week. It is almost impossible for users to dig through and learn all the apps. They just choose what is on top then click Install.',\n",
       " 'And not to mention that if you could build an awesome productivity app, Google and Apple could do it 10 times better and faster than you. In the end, there’s not as much need for individual apps to accomplish similar convenience factors.',\n",
       " 'Although the bull run for mobile development has ended, there are still over 2 billion smartphone users, 27.5 billion mobile apps downloaded, and time spent per day on mobile devices has increased rapidly in recent years. Moreover, apps offer a user experience that even ‘Responsive Websites’ are unable to provide.',\n",
       " 'In order to stay on top of the game, you will have to differentiate yourself from the pack — other mobile engineers. If you are a mobile engineer who only knows how to code and tweak your App’s UI, you aren’t that different from others after all. Below I listed a few ways that you could implement so that you could stay competitive in the job market.',\n",
       " 'If you are an Android developer, you could start choosing a job involving Kotlin or Flutter, which are backed by Google. If you are an iOS developer, try to look for a job to get involved with using Swift.',\n",
       " 'Although older mobile coding languages, such as Java and Objective-C, still have their upsides, the main reason why Kotlin and Swift are created at first is to address the older languages issue. It means that Kotlin and swift provide many safety mechanisms available out-of-the-box while being more concise and expressive than Java and Objective-C at the same time.',\n",
       " ' ',\n",
       " 'This point is especially crucial. Each industry has its specific skills to learn and refine. For example, if you are building a stock, foreign exchange, future, or options market app, you will have to understand the WebSocket protocol, which lets you transfer as much data as you like without incurring the overhead associated with traditional HTTP requests.',\n",
       " 'For the streaming media industry, possessing experience with live streaming protocols such as HLS, RTMP, WebRTC will be a must to deal with streaming-related apps.',\n",
       " 'These industry skills can really make you stand out, and adds another layer of expertise to your already pretty impressive mobile engineer title, making you more valuable in the job market.',\n",
       " 'The future of mobile app development will be shaped by how businesses harness mobile technology to solve people’s everyday problems.',\n",
       " 'Don’t try to fight the irresistible trend, see how you can surf the trend! Exposing yourself or trying to get a job in the field mentioned below will absolutely give you more opportunities as a mobile developer.']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0a046704",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:37]))\n",
    "URL_ID_63 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "333aab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 sentences in the string.\n",
      "The number of words in the string is: 915\n",
      "The number of characters in the string is: 4551\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 19:55:48] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 19:55:53] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_63.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_63.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_63.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_63 = re.sub(re_punt, \"\",URL_ID_63)\n",
    "\n",
    "file = open(\"63.txt\", \"w\")\n",
    "file.write(URL_ID_40)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"63.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "09395445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['anything',\n",
       "  'that',\n",
       "  'could',\n",
       "  'give',\n",
       "  'rise',\n",
       "  'to',\n",
       "  'smarterthanhuman',\n",
       "  'intelligence',\n",
       "  'in',\n",
       "  'the',\n",
       "  'form',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'braincomputer',\n",
       "  'interfaces',\n",
       "  'or',\n",
       "  'neurosciencebased',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'enhancement',\n",
       "  'wins',\n",
       "  'hands',\n",
       "  'down',\n",
       "  'beyond',\n",
       "  'contest',\n",
       "  'as',\n",
       "  'doing',\n",
       "  'the',\n",
       "  'most',\n",
       "  'to',\n",
       "  'change',\n",
       "  'the',\n",
       "  'world',\n",
       "  'nothing',\n",
       "  'else',\n",
       "  'is',\n",
       "  'even',\n",
       "  'in',\n",
       "  'the',\n",
       "  'same',\n",
       "  'league',\n",
       "  'eliezer',\n",
       "  'yudkowsky',\n",
       "  'ai',\n",
       "  'researcher',\n",
       "  'theres',\n",
       "  'no',\n",
       "  'denying',\n",
       "  'robots',\n",
       "  'and',\n",
       "  'automation',\n",
       "  'are',\n",
       "  'increasingly',\n",
       "  'part',\n",
       "  'of',\n",
       "  'our',\n",
       "  'daily',\n",
       "  'lives',\n",
       "  'just',\n",
       "  'look',\n",
       "  'around',\n",
       "  'the',\n",
       "  'grocery',\n",
       "  'store',\n",
       "  'or',\n",
       "  'the',\n",
       "  'highway',\n",
       "  'they',\n",
       "  'are',\n",
       "  'everywhere',\n",
       "  'this',\n",
       "  'makes',\n",
       "  'us',\n",
       "  'wonder',\n",
       "  'what',\n",
       "  'if',\n",
       "  'ai',\n",
       "  'can',\n",
       "  'replace',\n",
       "  'human',\n",
       "  'intelligence?',\n",
       "  'what',\n",
       "  'can',\n",
       "  'we',\n",
       "  'do',\n",
       "  'to',\n",
       "  'make',\n",
       "  'ourselves',\n",
       "  'relevant',\n",
       "  'tomorrow?',\n",
       "  'let',\n",
       "  'us',\n",
       "  'try',\n",
       "  'to',\n",
       "  'find',\n",
       "  'the',\n",
       "  'answers',\n",
       "  'to',\n",
       "  'all',\n",
       "  'these',\n",
       "  'questions',\n",
       "  'and',\n",
       "  'more',\n",
       "  'lets',\n",
       "  'first',\n",
       "  'understand',\n",
       "  'what',\n",
       "  'is',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'or',\n",
       "  'ai',\n",
       "  'basically',\n",
       "  'machines',\n",
       "  'displaying',\n",
       "  'intelligence',\n",
       "  'this',\n",
       "  'can',\n",
       "  'be',\n",
       "  'seen',\n",
       "  'from',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'playing',\n",
       "  'chess',\n",
       "  'or',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'answering',\n",
       "  'questions',\n",
       "  'on',\n",
       "  'facebook',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'can',\n",
       "  'be',\n",
       "  'further',\n",
       "  'broken',\n",
       "  'down',\n",
       "  'into',\n",
       "  'many',\n",
       "  'different',\n",
       "  'types',\n",
       "  'there',\n",
       "  'are',\n",
       "  'ais',\n",
       "  'designed',\n",
       "  'to',\n",
       "  'do',\n",
       "  'specific',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'detecting',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'type',\n",
       "  'of',\n",
       "  'cancer',\n",
       "  'however',\n",
       "  'there',\n",
       "  'are',\n",
       "  'also',\n",
       "  'ais',\n",
       "  'that',\n",
       "  'can',\n",
       "  'do',\n",
       "  'multiple',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'driving',\n",
       "  'a',\n",
       "  'car',\n",
       "  'there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'types',\n",
       "  'of',\n",
       "  'ais',\n",
       "  'among',\n",
       "  'the',\n",
       "  'top',\n",
       "  'most',\n",
       "  'important',\n",
       "  'fields',\n",
       "  'are',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'or',\n",
       "  'ml',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'and',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'or',\n",
       "  'nlp',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'machines',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'prove',\n",
       "  'themselves',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'how',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'learns',\n",
       "  'a',\n",
       "  'new',\n",
       "  'skill',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'also',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'the',\n",
       "  'optimization',\n",
       "  'of',\n",
       "  'an',\n",
       "  'existing',\n",
       "  'skill',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'used',\n",
       "  'in',\n",
       "  'many',\n",
       "  'different',\n",
       "  'fields',\n",
       "  'and',\n",
       "  'one',\n",
       "  'such',\n",
       "  'application',\n",
       "  'is',\n",
       "  'entertainment',\n",
       "  'netflix',\n",
       "  'uses',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'to',\n",
       "  'recommend',\n",
       "  'more',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'you',\n",
       "  'can',\n",
       "  'watch',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'shows',\n",
       "  'that',\n",
       "  'you',\n",
       "  'have',\n",
       "  'already',\n",
       "  'seen',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'are',\n",
       "  'algorithms',\n",
       "  'that',\n",
       "  'are',\n",
       "  'modeled',\n",
       "  'after',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'these',\n",
       "  'algorithms',\n",
       "  'think',\n",
       "  'just',\n",
       "  'like',\n",
       "  'we',\n",
       "  'do',\n",
       "  'which',\n",
       "  'can',\n",
       "  'thereby',\n",
       "  'give',\n",
       "  'similar',\n",
       "  'results',\n",
       "  'to',\n",
       "  'what',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'can',\n",
       "  'give',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'are',\n",
       "  'used',\n",
       "  'in',\n",
       "  'medical',\n",
       "  'fields',\n",
       "  'to',\n",
       "  'diagnose',\n",
       "  'cancers',\n",
       "  'like',\n",
       "  'lung',\n",
       "  'cancer',\n",
       "  'and',\n",
       "  'prostate',\n",
       "  'cancer',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'that',\n",
       "  'computers',\n",
       "  'have',\n",
       "  'visions',\n",
       "  'this',\n",
       "  'allows',\n",
       "  'them',\n",
       "  'to',\n",
       "  'see',\n",
       "  'things',\n",
       "  'the',\n",
       "  'way',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'do',\n",
       "  'or',\n",
       "  'potentially',\n",
       "  'better',\n",
       "  'than',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'do',\n",
       "  'depending',\n",
       "  'on',\n",
       "  'the',\n",
       "  'programming',\n",
       "  'camera',\n",
       "  'used',\n",
       "  'etc',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'is',\n",
       "  'used',\n",
       "  'in',\n",
       "  'autonomous',\n",
       "  'vehicles',\n",
       "  'for',\n",
       "  'navigation',\n",
       "  'from',\n",
       "  'one',\n",
       "  'place',\n",
       "  'to',\n",
       "  'another',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'is',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'that',\n",
       "  'computers',\n",
       "  'can',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'what',\n",
       "  'we',\n",
       "  'say',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'this',\n",
       "  'is',\n",
       "  'siri',\n",
       "  'siri',\n",
       "  'is',\n",
       "  'able',\n",
       "  'to',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'our',\n",
       "  'demands',\n",
       "  'process',\n",
       "  'what',\n",
       "  'it',\n",
       "  'means',\n",
       "  'and',\n",
       "  'provide',\n",
       "  'you',\n",
       "  'an',\n",
       "  'answer',\n",
       "  'based',\n",
       "  'on',\n",
       "  'what',\n",
       "  'is',\n",
       "  'researched',\n",
       "  'now',\n",
       "  'that',\n",
       "  'we',\n",
       "  'know',\n",
       "  'what',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'and',\n",
       "  'what',\n",
       "  'it',\n",
       "  'can',\n",
       "  'do',\n",
       "  'lets',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'ais',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'the',\n",
       "  'automation',\n",
       "  'of',\n",
       "  'jobs',\n",
       "  'thereby',\n",
       "  'replacing',\n",
       "  'what',\n",
       "  'humans',\n",
       "  'already',\n",
       "  'do',\n",
       "  'this',\n",
       "  'means',\n",
       "  'more',\n",
       "  'job',\n",
       "  'loss',\n",
       "  'and',\n",
       "  'the',\n",
       "  'concentration',\n",
       "  'of',\n",
       "  'wealth',\n",
       "  'to',\n",
       "  'the',\n",
       "  'selected',\n",
       "  'few',\n",
       "  'people',\n",
       "  'this',\n",
       "  'could',\n",
       "  'mean',\n",
       "  'a',\n",
       "  'destabilization',\n",
       "  'of',\n",
       "  'society',\n",
       "  'and',\n",
       "  'social',\n",
       "  'unrest',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'social',\n",
       "  'unrest',\n",
       "  'ai',\n",
       "  'improves',\n",
       "  'over',\n",
       "  'time',\n",
       "  'this',\n",
       "  'means',\n",
       "  'it',\n",
       "  'becomes',\n",
       "  'smarter',\n",
       "  'faster',\n",
       "  'and',\n",
       "  'cheaper',\n",
       "  'to',\n",
       "  'implement',\n",
       "  'and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'better',\n",
       "  'at',\n",
       "  'doing',\n",
       "  'repetitive',\n",
       "  'things',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'currently',\n",
       "  'do',\n",
       "  'such',\n",
       "  'as',\n",
       "  'preparing',\n",
       "  'fast',\n",
       "  'food',\n",
       "  'it',\n",
       "  'is',\n",
       "  'predicted',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'improve',\n",
       "  'so',\n",
       "  'much',\n",
       "  'over',\n",
       "  '50',\n",
       "  'to',\n",
       "  '100',\n",
       "  'years',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'super',\n",
       "  'intelligent',\n",
       "  'this',\n",
       "  'means',\n",
       "  'that',\n",
       "  'it',\n",
       "  'will',\n",
       "  'become',\n",
       "  'even',\n",
       "  'smarter',\n",
       "  'than',\n",
       "  'the',\n",
       "  'most',\n",
       "  'intelligent',\n",
       "  'human',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'according',\n",
       "  'to',\n",
       "  'many',\n",
       "  'experts',\n",
       "  'such',\n",
       "  'as',\n",
       "  'elon',\n",
       "  'musk',\n",
       "  'this',\n",
       "  'could',\n",
       "  'cause',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'human',\n",
       "  'civilization',\n",
       "  'ai',\n",
       "  'could',\n",
       "  'potentially',\n",
       "  'start',\n",
       "  'a',\n",
       "  'war',\n",
       "  'against',\n",
       "  'humans',\n",
       "  'burn',\n",
       "  'crops',\n",
       "  'and',\n",
       "  'do',\n",
       "  'all',\n",
       "  'sorts',\n",
       "  'of',\n",
       "  'tragedies',\n",
       "  'once',\n",
       "  'reserved',\n",
       "  'for',\n",
       "  'human',\n",
       "  'functions',\n",
       "  'at',\n",
       "  'that',\n",
       "  'point',\n",
       "  'in',\n",
       "  'theory',\n",
       "  'we',\n",
       "  'can',\n",
       "  'not',\n",
       "  'stop',\n",
       "  'it',\n",
       "  'because',\n",
       "  'ai',\n",
       "  'would',\n",
       "  'have',\n",
       "  'already',\n",
       "  'thought',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'obstacles',\n",
       "  'that',\n",
       "  'will',\n",
       "  'prevent',\n",
       "  'its',\n",
       "  'goal',\n",
       "  'this',\n",
       "  'means',\n",
       "  'that',\n",
       "  'we',\n",
       "  'cannot',\n",
       "  'unplug',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'in',\n",
       "  'effect',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'replace',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'but',\n",
       "  'will',\n",
       "  'this',\n",
       "  'happen',\n",
       "  'in',\n",
       "  'next',\n",
       "  '10',\n",
       "  'to',\n",
       "  '30',\n",
       "  'years?',\n",
       "  'no!',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'sophisticated',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'do',\n",
       "  'many',\n",
       "  'human',\n",
       "  'tasks',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'currently',\n",
       "  'do',\n",
       "  'currently',\n",
       "  'ai',\n",
       "  'is',\n",
       "  'not',\n",
       "  'smart',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'be',\n",
       "  'empathetic',\n",
       "  'to',\n",
       "  'humans',\n",
       "  'and',\n",
       "  'cannot',\n",
       "  'think',\n",
       "  'strategically',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'complex',\n",
       "  'problems',\n",
       "  'ai',\n",
       "  'solutions',\n",
       "  'can',\n",
       "  'be',\n",
       "  'expensive',\n",
       "  'and',\n",
       "  'have',\n",
       "  'to',\n",
       "  'go',\n",
       "  'through',\n",
       "  'many',\n",
       "  'different',\n",
       "  'tests',\n",
       "  'and',\n",
       "  'standards',\n",
       "  'to',\n",
       "  'implement',\n",
       "  'it',\n",
       "  'also',\n",
       "  'takes',\n",
       "  'time',\n",
       "  'for',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'for',\n",
       "  'example',\n",
       "  'boston',\n",
       "  'dynamics',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'worlds',\n",
       "  'top',\n",
       "  'robotics',\n",
       "  'company',\n",
       "  'had',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'in',\n",
       "  '2009',\n",
       "  'that',\n",
       "  'needed',\n",
       "  'assistance',\n",
       "  'to',\n",
       "  'walk',\n",
       "  'fast',\n",
       "  'forward',\n",
       "  'to',\n",
       "  '2019',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'robot',\n",
       "  'could',\n",
       "  'walk',\n",
       "  'by',\n",
       "  'itself',\n",
       "  'but',\n",
       "  'it',\n",
       "  'could',\n",
       "  'jump',\n",
       "  'over',\n",
       "  'objects',\n",
       "  'do',\n",
       "  'backflips',\n",
       "  'and',\n",
       "  'so',\n",
       "  'much',\n",
       "  'more',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'the',\n",
       "  'timing',\n",
       "  'it',\n",
       "  'takes',\n",
       "  'time',\n",
       "  'for',\n",
       "  'the',\n",
       "  'price',\n",
       "  'of',\n",
       "  'any',\n",
       "  'new',\n",
       "  'technological',\n",
       "  'solution',\n",
       "  'to',\n",
       "  'drop',\n",
       "  'to',\n",
       "  'a',\n",
       "  'point',\n",
       "  'where',\n",
       "  'it',\n",
       "  'is',\n",
       "  'affordable',\n",
       "  'for',\n",
       "  'example',\n",
       "  'a',\n",
       "  'desktop',\n",
       "  'computer',\n",
       "  'costs',\n",
       "  'around',\n",
       "  '1000',\n",
       "  'in',\n",
       "  '1999',\n",
       "  'but',\n",
       "  'now',\n",
       "  'you',\n",
       "  'can',\n",
       "  'get',\n",
       "  'a',\n",
       "  'significantly',\n",
       "  'more',\n",
       "  'powerful',\n",
       "  'laptop',\n",
       "  'for',\n",
       "  'the',\n",
       "  'exact',\n",
       "  'same',\n",
       "  'price',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'go',\n",
       "  'through',\n",
       "  'the',\n",
       "  'same',\n",
       "  'curve',\n",
       "  'but',\n",
       "  'what',\n",
       "  'happens',\n",
       "  'after',\n",
       "  'those',\n",
       "  '10',\n",
       "  'to',\n",
       "  '30',\n",
       "  'years?',\n",
       "  'will',\n",
       "  'ai',\n",
       "  'make',\n",
       "  'human',\n",
       "  'intelligence',\n",
       "  'obsolete?',\n",
       "  'maybe',\n",
       "  'as',\n",
       "  'we',\n",
       "  'have',\n",
       "  'proven',\n",
       "  'earlier',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'faster',\n",
       "  'better',\n",
       "  'and',\n",
       "  'cheaper',\n",
       "  'as',\n",
       "  'this',\n",
       "  'happens',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'companies',\n",
       "  'will',\n",
       "  'use',\n",
       "  'ai',\n",
       "  'technology',\n",
       "  'to',\n",
       "  'automate',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'jobs',\n",
       "  'to',\n",
       "  'save',\n",
       "  'money',\n",
       "  'increase',\n",
       "  'productivity',\n",
       "  'and',\n",
       "  'most',\n",
       "  'importantly',\n",
       "  'stay',\n",
       "  'competitive',\n",
       "  'as',\n",
       "  'we',\n",
       "  'have',\n",
       "  'demonstrated',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'become',\n",
       "  'better',\n",
       "  'through',\n",
       "  'repetition',\n",
       "  'via',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'the',\n",
       "  'only',\n",
       "  'difference',\n",
       "  'is',\n",
       "  'that',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'faster',\n",
       "  'as',\n",
       "  'time',\n",
       "  'progresses',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'data',\n",
       "  'that',\n",
       "  'is',\n",
       "  'available',\n",
       "  'today',\n",
       "  'it',\n",
       "  'will',\n",
       "  'also',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'from',\n",
       "  'other',\n",
       "  'machines',\n",
       "  'or',\n",
       "  'similar',\n",
       "  'machines',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'how',\n",
       "  'to',\n",
       "  'optimize',\n",
       "  'its',\n",
       "  'tasks',\n",
       "  'or',\n",
       "  'new',\n",
       "  'important',\n",
       "  'skills',\n",
       "  'however',\n",
       "  'ai',\n",
       "  'also',\n",
       "  'just',\n",
       "  'not',\n",
       "  'do',\n",
       "  'repetitive',\n",
       "  'and',\n",
       "  'routine',\n",
       "  'tasks',\n",
       "  'better',\n",
       "  'it',\n",
       "  'will',\n",
       "  'also',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'emotional',\n",
       "  'intelligence',\n",
       "  'ethics',\n",
       "  'and',\n",
       "  'creativity',\n",
       "  'this',\n",
       "  'seen',\n",
       "  'in',\n",
       "  'three',\n",
       "  'distinct',\n",
       "  'example',\n",
       "  'ibm',\n",
       "  'ibm',\n",
       "  'uses',\n",
       "  'its',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'to',\n",
       "  'program',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'create',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'trailer',\n",
       "  'fox',\n",
       "  'approached',\n",
       "  'ibm',\n",
       "  'and',\n",
       "  'said',\n",
       "  'they',\n",
       "  'have',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'coming',\n",
       "  'out',\n",
       "  'on',\n",
       "  'ai',\n",
       "  'scifi',\n",
       "  'horror',\n",
       "  'they',\n",
       "  'asked',\n",
       "  'ibm',\n",
       "  'if',\n",
       "  'their',\n",
       "  'platform',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'could',\n",
       "  'a',\n",
       "  'trailer',\n",
       "  'by',\n",
       "  'reviewing',\n",
       "  'and',\n",
       "  'watching',\n",
       "  'the',\n",
       "  'footage',\n",
       "  'and',\n",
       "  'searching',\n",
       "  'for',\n",
       "  'scary',\n",
       "  'sad',\n",
       "  'or',\n",
       "  'happy',\n",
       "  'or',\n",
       "  'other',\n",
       "  'moments',\n",
       "  'in',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'that',\n",
       "  ...]]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/63.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9702a5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1627\n",
      "WORD COUNT 1002\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "704900d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 22.875\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "513b3726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.18862275449101795\n",
      "FOG INDEX: 9.225449101796407\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 22.875\n",
      "COMPLEX WORD COUNT: 189\n",
      "WORD COUNT: 1002\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "034ebd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1674\n",
      "i: 3\n",
      "we: 0\n",
      "my: 1\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 4\n",
      "PERSONAL PRONOUNS: 4\n",
      "AVG WORD LENGTH: 4.973770491803279\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_63.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358aa88",
   "metadata": {},
   "source": [
    "# for url 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "741674bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\2177916535.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b842a40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI allows those in training to go through naturalistic simulations in a way that simple computer-driven algorithms cannot. The advent of natural speech and the ability of an AI  computer to draw instantly on a large database of scenarios means the response to questions, decisions, or advice from a trainee can challenge in a way that humans cannot in health and medicine',\n",
       " 'Wearable health trackers-like those from FitBit, Apple, Garmin, and others- monitor health rate and activity levels. They can send alerts to the user to get more exercise and can share this information with doctors.',\n",
       " 'Machine learning algorithms can process unimaginable amounts of information in the blink of an eye and provide more precision than humans in spotting even the smallest detail in medical imaging.  A few of them are Blackford, Zebra, Enlitic, Lunit.',\n",
       " 'The company “Zebra Medical Vision” developed a new platform called profound, which analyzes all types of medical imaging reports that are able to find every sign of potential conditions such as osteoporosis, aortic aneurysms, and many more with a 90% accuracy rate.',\n",
       " 'For eg, the digital health firm #HealthTap developed “Dr. AI”, and apps like Babylon in the UK use AI to give medical consultations based on personal medical history and common medical knowledge. Users report their symptoms into the app, which uses speech recognition to compare against a database of illness and asks patients to specify symptoms to triage whether they should go to the ED, urgent care, or a primary care doctor.',\n",
       " 'AI robot-assisted surgery: Robots have been used in medicine for more than 30 years. Surgical robots can either aid a human surgeon or execute operations by themselves. They’re also used in hospitals and labs for repetitive tasks, in rehabilitation, physical therapy, and in support of those with long-term conditions.     ',\n",
       " ' Health chatbots such as Babylon, Ada, and mostly close-ended communications.',\n",
       " '#MICROSOFT: Predictive analysis in vision care',\n",
       " '#GOOGLE: clinical decision support in breast cancer diagnosis',\n",
       " '#IBM WATSON: precision medicine in population health management',\n",
       " 'Actionable medical insights:  An ever-increasing amount of medical data are being digitized at all public and private healthcare institutions. However, by its very nature, this kind of data is messy and unstructured. Unlike other types of business data, where traditional statistical methods can be used for quick insights, patient data is not particularly amenable to simple modeling and analytics tools.',\n",
       " ' For eg.- Enlitic, a San Francisco-based start-up, has a mission of mixing intelligence with empathy and leverage the power of AI in health and medicine for precisely generating.',\n",
       " 'Therefore, a massive parallel effort to rationalize the legal and policy-making is needed to bring the full benefit of advancement in AI technologies into the healthcare space. As technologies and AI/ML enthusiasts, we can only hope for such a bright future where the power of this intelligence.']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a5fee27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:29]))\n",
    "URL_ID_64 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "53b0eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21 sentences in the string.\n",
      "The number of words in the string is: 512\n",
      "The number of characters in the string is: 2788\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 21:43:39] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 21:43:44] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_64.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_64.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_64.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_64 = re.sub(re_punt, \"\",URL_ID_64)\n",
    "\n",
    "file = open(\"64.txt\", \"w\")\n",
    "file.write(URL_ID_64)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"64.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9e888d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['health',\n",
       "  'monitoring',\n",
       "  'fitbit',\n",
       "  'apple',\n",
       "  'garmin',\n",
       "  'medical',\n",
       "  'imaging',\n",
       "  'blackford',\n",
       "  'zebra',\n",
       "  'enlitic',\n",
       "  'lunit',\n",
       "  'zebra',\n",
       "  'medical',\n",
       "  'vision',\n",
       "  'digital',\n",
       "  'consultation',\n",
       "  'babylon',\n",
       "  'ada',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'a',\n",
       "  'type',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'that',\n",
       "  'allows',\n",
       "  'computers',\n",
       "  'to',\n",
       "  'make',\n",
       "  'predictions',\n",
       "  'without',\n",
       "  'being',\n",
       "  'explicitly',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'in',\n",
       "  'healthcare',\n",
       "  'and',\n",
       "  'medicine',\n",
       "  'for',\n",
       "  'eg',\n",
       "  'enlitic',\n",
       "  'a',\n",
       "  'san',\n",
       "  'franciscobased',\n",
       "  'ai',\n",
       "  'allows',\n",
       "  'those',\n",
       "  'in',\n",
       "  'training',\n",
       "  'to',\n",
       "  'go',\n",
       "  'through',\n",
       "  'naturalistic',\n",
       "  'simulations',\n",
       "  'in',\n",
       "  'a',\n",
       "  'way',\n",
       "  'that',\n",
       "  'simple',\n",
       "  'computerdriven',\n",
       "  'algorithms',\n",
       "  'cannot',\n",
       "  'the',\n",
       "  'advent',\n",
       "  'of',\n",
       "  'natural',\n",
       "  'speech',\n",
       "  'and',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'of',\n",
       "  'an',\n",
       "  'ai',\n",
       "  'computer',\n",
       "  'to',\n",
       "  'draw',\n",
       "  'instantly',\n",
       "  'on',\n",
       "  'a',\n",
       "  'large',\n",
       "  'database',\n",
       "  'of',\n",
       "  'scenarios',\n",
       "  'means',\n",
       "  'the',\n",
       "  'response',\n",
       "  'to',\n",
       "  'questions',\n",
       "  'decisions',\n",
       "  'or',\n",
       "  'advice',\n",
       "  'from',\n",
       "  'a',\n",
       "  'trainee',\n",
       "  'can',\n",
       "  'challenge',\n",
       "  'in',\n",
       "  'a',\n",
       "  'way',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'cannot',\n",
       "  'in',\n",
       "  'health',\n",
       "  'and',\n",
       "  'medicine',\n",
       "  'wearable',\n",
       "  'health',\n",
       "  'trackerslike',\n",
       "  'those',\n",
       "  'from',\n",
       "  'fitbit',\n",
       "  'apple',\n",
       "  'garmin',\n",
       "  'and',\n",
       "  'others',\n",
       "  'monitor',\n",
       "  'health',\n",
       "  'rate',\n",
       "  'and',\n",
       "  'activity',\n",
       "  'levels',\n",
       "  'they',\n",
       "  'can',\n",
       "  'send',\n",
       "  'alerts',\n",
       "  'to',\n",
       "  'the',\n",
       "  'user',\n",
       "  'to',\n",
       "  'get',\n",
       "  'more',\n",
       "  'exercise',\n",
       "  'and',\n",
       "  'can',\n",
       "  'share',\n",
       "  'this',\n",
       "  'information',\n",
       "  'with',\n",
       "  'doctors',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'can',\n",
       "  'process',\n",
       "  'unimaginable',\n",
       "  'amounts',\n",
       "  'of',\n",
       "  'information',\n",
       "  'in',\n",
       "  'the',\n",
       "  'blink',\n",
       "  'of',\n",
       "  'an',\n",
       "  'eye',\n",
       "  'and',\n",
       "  'provide',\n",
       "  'more',\n",
       "  'precision',\n",
       "  'than',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'spotting',\n",
       "  'even',\n",
       "  'the',\n",
       "  'smallest',\n",
       "  'detail',\n",
       "  'in',\n",
       "  'medical',\n",
       "  'imaging',\n",
       "  'a',\n",
       "  'few',\n",
       "  'of',\n",
       "  'them',\n",
       "  'are',\n",
       "  'blackford',\n",
       "  'zebra',\n",
       "  'enlitic',\n",
       "  'lunit',\n",
       "  'the',\n",
       "  'company',\n",
       "  'zebra',\n",
       "  'medical',\n",
       "  'vision',\n",
       "  'developed',\n",
       "  'a',\n",
       "  'new',\n",
       "  'platform',\n",
       "  'called',\n",
       "  'profound',\n",
       "  'which',\n",
       "  'analyzes',\n",
       "  'all',\n",
       "  'types',\n",
       "  'of',\n",
       "  'medical',\n",
       "  'imaging',\n",
       "  'reports',\n",
       "  'that',\n",
       "  'are',\n",
       "  'able',\n",
       "  'to',\n",
       "  'find',\n",
       "  'every',\n",
       "  'sign',\n",
       "  'of',\n",
       "  'potential',\n",
       "  'conditions',\n",
       "  'such',\n",
       "  'as',\n",
       "  'osteoporosis',\n",
       "  'aortic',\n",
       "  'aneurysms',\n",
       "  'and',\n",
       "  'many',\n",
       "  'more',\n",
       "  'with',\n",
       "  'a',\n",
       "  '90',\n",
       "  'accuracy',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'eg',\n",
       "  'the',\n",
       "  'digital',\n",
       "  'health',\n",
       "  'firm',\n",
       "  'healthtap',\n",
       "  'developed',\n",
       "  'dr',\n",
       "  'ai',\n",
       "  'and',\n",
       "  'apps',\n",
       "  'like',\n",
       "  'babylon',\n",
       "  'in',\n",
       "  'the',\n",
       "  'uk',\n",
       "  'use',\n",
       "  'ai',\n",
       "  'to',\n",
       "  'give',\n",
       "  'medical',\n",
       "  'consultations',\n",
       "  'based',\n",
       "  'on',\n",
       "  'personal',\n",
       "  'medical',\n",
       "  'history',\n",
       "  'and',\n",
       "  'common',\n",
       "  'medical',\n",
       "  'knowledge',\n",
       "  'users',\n",
       "  'report',\n",
       "  'their',\n",
       "  'symptoms',\n",
       "  'into',\n",
       "  'the',\n",
       "  'app',\n",
       "  'which',\n",
       "  'uses',\n",
       "  'speech',\n",
       "  'recognition',\n",
       "  'to',\n",
       "  'compare',\n",
       "  'against',\n",
       "  'a',\n",
       "  'database',\n",
       "  'of',\n",
       "  'illness',\n",
       "  'and',\n",
       "  'asks',\n",
       "  'patients',\n",
       "  'to',\n",
       "  'specify',\n",
       "  'symptoms',\n",
       "  'to',\n",
       "  'triage',\n",
       "  'whether',\n",
       "  'they',\n",
       "  'should',\n",
       "  'go',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ed',\n",
       "  'urgent',\n",
       "  'care',\n",
       "  'or',\n",
       "  'a',\n",
       "  'primary',\n",
       "  'care',\n",
       "  'doctor',\n",
       "  'ai',\n",
       "  'robotassisted',\n",
       "  'surgery',\n",
       "  'robots',\n",
       "  'have',\n",
       "  'been',\n",
       "  'used',\n",
       "  'in',\n",
       "  'medicine',\n",
       "  'for',\n",
       "  'more',\n",
       "  'than',\n",
       "  '30',\n",
       "  'years',\n",
       "  'surgical',\n",
       "  'robots',\n",
       "  'can',\n",
       "  'either',\n",
       "  'aid',\n",
       "  'a',\n",
       "  'human',\n",
       "  'surgeon',\n",
       "  'or',\n",
       "  'execute',\n",
       "  'operations',\n",
       "  'by',\n",
       "  'themselves',\n",
       "  'theyre',\n",
       "  'also',\n",
       "  'used',\n",
       "  'in',\n",
       "  'hospitals',\n",
       "  'and',\n",
       "  'labs',\n",
       "  'for',\n",
       "  'repetitive',\n",
       "  'tasks',\n",
       "  'in',\n",
       "  'rehabilitation',\n",
       "  'physical',\n",
       "  'therapy',\n",
       "  'and',\n",
       "  'in',\n",
       "  'support',\n",
       "  'of',\n",
       "  'those',\n",
       "  'with',\n",
       "  'longterm',\n",
       "  'conditions',\n",
       "  'health',\n",
       "  'chatbots',\n",
       "  'such',\n",
       "  'as',\n",
       "  'babylon',\n",
       "  'ada',\n",
       "  'and',\n",
       "  'mostly',\n",
       "  'closeended',\n",
       "  'communications',\n",
       "  'microsoft',\n",
       "  'predictive',\n",
       "  'analysis',\n",
       "  'in',\n",
       "  'vision',\n",
       "  'care',\n",
       "  'google',\n",
       "  'clinical',\n",
       "  'decision',\n",
       "  'support',\n",
       "  'in',\n",
       "  'breast',\n",
       "  'cancer',\n",
       "  'diagnosis',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'precision',\n",
       "  'medicine',\n",
       "  'in',\n",
       "  'population',\n",
       "  'health',\n",
       "  'management',\n",
       "  'actionable',\n",
       "  'medical',\n",
       "  'insights',\n",
       "  'an',\n",
       "  'everincreasing',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'medical',\n",
       "  'data',\n",
       "  'are',\n",
       "  'being',\n",
       "  'digitized',\n",
       "  'at',\n",
       "  'all',\n",
       "  'public',\n",
       "  'and',\n",
       "  'private',\n",
       "  'healthcare',\n",
       "  'institutions',\n",
       "  'however',\n",
       "  'by',\n",
       "  'its',\n",
       "  'very',\n",
       "  'nature',\n",
       "  'this',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'data',\n",
       "  'is',\n",
       "  'messy',\n",
       "  'and',\n",
       "  'unstructured',\n",
       "  'unlike',\n",
       "  'other',\n",
       "  'types',\n",
       "  'of',\n",
       "  'business',\n",
       "  'data',\n",
       "  'where',\n",
       "  'traditional',\n",
       "  'statistical',\n",
       "  'methods',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'for',\n",
       "  'quick',\n",
       "  'insights',\n",
       "  'patient',\n",
       "  'data',\n",
       "  'is',\n",
       "  'not',\n",
       "  'particularly',\n",
       "  'amenable',\n",
       "  'to',\n",
       "  'simple',\n",
       "  'modeling',\n",
       "  'and',\n",
       "  'analytics',\n",
       "  'tools',\n",
       "  'for',\n",
       "  'eg',\n",
       "  'enlitic',\n",
       "  'a',\n",
       "  'san',\n",
       "  'franciscobased',\n",
       "  'startup',\n",
       "  'has',\n",
       "  'a',\n",
       "  'mission',\n",
       "  'of',\n",
       "  'mixing',\n",
       "  'intelligence',\n",
       "  'with',\n",
       "  'empathy',\n",
       "  'and',\n",
       "  'leverage',\n",
       "  'the',\n",
       "  'power',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'in',\n",
       "  'health',\n",
       "  'and',\n",
       "  'medicine',\n",
       "  'for',\n",
       "  'precisely',\n",
       "  'generating',\n",
       "  'therefore',\n",
       "  'a',\n",
       "  'massive',\n",
       "  'parallel',\n",
       "  'effort',\n",
       "  'to',\n",
       "  'rationalize',\n",
       "  'the',\n",
       "  'legal',\n",
       "  'and',\n",
       "  'policymaking',\n",
       "  'is',\n",
       "  'needed',\n",
       "  'to',\n",
       "  'bring',\n",
       "  'the',\n",
       "  'full',\n",
       "  'benefit',\n",
       "  'of',\n",
       "  'advancement',\n",
       "  'in',\n",
       "  'ai',\n",
       "  'technologies',\n",
       "  'into',\n",
       "  'the',\n",
       "  'healthcare',\n",
       "  'space',\n",
       "  'as',\n",
       "  'technologies',\n",
       "  'and',\n",
       "  'aiml',\n",
       "  'enthusiasts',\n",
       "  'we',\n",
       "  'can',\n",
       "  'only',\n",
       "  'hope',\n",
       "  'for',\n",
       "  'such',\n",
       "  'a',\n",
       "  'bright',\n",
       "  'future',\n",
       "  'where',\n",
       "  'the',\n",
       "  'power',\n",
       "  'of',\n",
       "  'this',\n",
       "  'intelligence']]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/64.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b67f913e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "WORD COUNT 340\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "584fc1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 24.38095238095238\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9f70dd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3911764705882353\n",
      "FOG INDEX: 9.908851540616247\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 24.38095238095238\n",
      "COMPLEX WORD COUNT: 133\n",
      "WORD COUNT: 340\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1c8b5746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1023\n",
      "I: 0\n",
      "we: 1\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 1\n",
      "PERSONAL PRONOUNS: 1\n",
      "AVG WORD LENGTH: 5.4453125\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_64.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d62ff",
   "metadata": {},
   "source": [
    "# url 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5a3dd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\694118058.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b91bc76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In today’s world, telemedicine technology is one of those technologies which has brought about a change. Compared to the early days there have been remarkable differences in the methods of consultation with a doctor. In the years that have passed by, consultation for a disease with a doctor was quite hectic. It involved waiting, traveling, etc. But with the advent of telemedicine opportunities, this has completely changed.',\n",
       " 'It is a rural area that has been completely blessed with the invention of telemedicine. Today a considerable amount of people are able to consult doctors remotely. Not just doctors, but specialists in various fields of medicine. This has been of great importance as far as rural people are concerned. There are a lot of telemedicine tools that have been found. There are a lot of areas like ophthalmology, oncology, dermatology, etc where the facility of telemedicine has been practiced.',\n",
       " 'Most of the patients are truly benefitting from telemedicine. Patients are pretty satisfied with the consultation they are getting. They don’t have to travel now. They can consult doctors and other specialists from remote areas. The cost of consultation has become pretty much affordable. Moreover, they get exposed to highly efficient and qualified experts in the field of medicine.',\n",
       " 'On the other hand, there can be patients who do not fully get satisfied through a virtual consultation. Rather they might feel that they need to have a direct talk with the doctor, which can boost up their confidence and also it helps to maintain a better relationship with the doctor and patient. The patients feel trust when they talk to doctors face to face. Moreover, doctors also might be able to console their patients when they have direct interaction with their patients. There could also be patients who doubt if these virtual methodologies are really trusted worthy or not. It is so because, while the patients have direct contact with their patients, the qualifications are visible to the patients. So there shall be no question of distrust.',\n",
       " 'There are major challenges like better connectivity of the internet, without which the patients will not be able to have continuous interaction with the doctors. Technical glitches may hinder the consultation too. Moreover, emergency situations cannot be addressed beyond a limit through telemedicine.']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0e354415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts=(' '.join(str(x) for x in texts[16:21]))\n",
    "URL_ID_65 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b5859c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28 sentences in the string.\n",
      "The number of words in the string is: 377\n",
      "The number of characters in the string is: 1977\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 21:55:51] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 21:55:58] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_65.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_65.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_65.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_65 = re.sub(re_punt, \"\",URL_ID_65)\n",
    "\n",
    "file = open(\"65.txt\", \"w\")\n",
    "file.write(URL_ID_65)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"65.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6db7af1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in',\n",
       "  'todays',\n",
       "  'world',\n",
       "  'telemedicine',\n",
       "  'technology',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'those',\n",
       "  'technologies',\n",
       "  'which',\n",
       "  'has',\n",
       "  'brought',\n",
       "  'about',\n",
       "  'a',\n",
       "  'change',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'the',\n",
       "  'early',\n",
       "  'days',\n",
       "  'there',\n",
       "  'have',\n",
       "  'been',\n",
       "  'remarkable',\n",
       "  'differences',\n",
       "  'in',\n",
       "  'the',\n",
       "  'methods',\n",
       "  'of',\n",
       "  'consultation',\n",
       "  'with',\n",
       "  'a',\n",
       "  'doctor',\n",
       "  'in',\n",
       "  'the',\n",
       "  'years',\n",
       "  'that',\n",
       "  'have',\n",
       "  'passed',\n",
       "  'by',\n",
       "  'consultation',\n",
       "  'for',\n",
       "  'a',\n",
       "  'disease',\n",
       "  'with',\n",
       "  'a',\n",
       "  'doctor',\n",
       "  'was',\n",
       "  'quite',\n",
       "  'hectic',\n",
       "  'it',\n",
       "  'involved',\n",
       "  'waiting',\n",
       "  'traveling',\n",
       "  'etc',\n",
       "  'but',\n",
       "  'with',\n",
       "  'the',\n",
       "  'advent',\n",
       "  'of',\n",
       "  'telemedicine',\n",
       "  'opportunities',\n",
       "  'this',\n",
       "  'has',\n",
       "  'completely',\n",
       "  'changed',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'rural',\n",
       "  'area',\n",
       "  'that',\n",
       "  'has',\n",
       "  'been',\n",
       "  'completely',\n",
       "  'blessed',\n",
       "  'with',\n",
       "  'the',\n",
       "  'invention',\n",
       "  'of',\n",
       "  'telemedicine',\n",
       "  'today',\n",
       "  'a',\n",
       "  'considerable',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'people',\n",
       "  'are',\n",
       "  'able',\n",
       "  'to',\n",
       "  'consult',\n",
       "  'doctors',\n",
       "  'remotely',\n",
       "  'not',\n",
       "  'just',\n",
       "  'doctors',\n",
       "  'but',\n",
       "  'specialists',\n",
       "  'in',\n",
       "  'various',\n",
       "  'fields',\n",
       "  'of',\n",
       "  'medicine',\n",
       "  'this',\n",
       "  'has',\n",
       "  'been',\n",
       "  'of',\n",
       "  'great',\n",
       "  'importance',\n",
       "  'as',\n",
       "  'far',\n",
       "  'as',\n",
       "  'rural',\n",
       "  'people',\n",
       "  'are',\n",
       "  'concerned',\n",
       "  'there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'telemedicine',\n",
       "  'tools',\n",
       "  'that',\n",
       "  'have',\n",
       "  'been',\n",
       "  'found',\n",
       "  'there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'areas',\n",
       "  'like',\n",
       "  'ophthalmology',\n",
       "  'oncology',\n",
       "  'dermatology',\n",
       "  'etc',\n",
       "  'where',\n",
       "  'the',\n",
       "  'facility',\n",
       "  'of',\n",
       "  'telemedicine',\n",
       "  'has',\n",
       "  'been',\n",
       "  'practiced',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'patients',\n",
       "  'are',\n",
       "  'truly',\n",
       "  'benefitting',\n",
       "  'from',\n",
       "  'telemedicine',\n",
       "  'patients',\n",
       "  'are',\n",
       "  'pretty',\n",
       "  'satisfied',\n",
       "  'with',\n",
       "  'the',\n",
       "  'consultation',\n",
       "  'they',\n",
       "  'are',\n",
       "  'getting',\n",
       "  'they',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'to',\n",
       "  'travel',\n",
       "  'now',\n",
       "  'they',\n",
       "  'can',\n",
       "  'consult',\n",
       "  'doctors',\n",
       "  'and',\n",
       "  'other',\n",
       "  'specialists',\n",
       "  'from',\n",
       "  'remote',\n",
       "  'areas',\n",
       "  'the',\n",
       "  'cost',\n",
       "  'of',\n",
       "  'consultation',\n",
       "  'has',\n",
       "  'become',\n",
       "  'pretty',\n",
       "  'much',\n",
       "  'affordable',\n",
       "  'moreover',\n",
       "  'they',\n",
       "  'get',\n",
       "  'exposed',\n",
       "  'to',\n",
       "  'highly',\n",
       "  'efficient',\n",
       "  'and',\n",
       "  'qualified',\n",
       "  'experts',\n",
       "  'in',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'medicine',\n",
       "  'on',\n",
       "  'the',\n",
       "  'other',\n",
       "  'hand',\n",
       "  'there',\n",
       "  'can',\n",
       "  'be',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'do',\n",
       "  'not',\n",
       "  'fully',\n",
       "  'get',\n",
       "  'satisfied',\n",
       "  'through',\n",
       "  'a',\n",
       "  'virtual',\n",
       "  'consultation',\n",
       "  'rather',\n",
       "  'they',\n",
       "  'might',\n",
       "  'feel',\n",
       "  'that',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'direct',\n",
       "  'talk',\n",
       "  'with',\n",
       "  'the',\n",
       "  'doctor',\n",
       "  'which',\n",
       "  'can',\n",
       "  'boost',\n",
       "  'up',\n",
       "  'their',\n",
       "  'confidence',\n",
       "  'and',\n",
       "  'also',\n",
       "  'it',\n",
       "  'helps',\n",
       "  'to',\n",
       "  'maintain',\n",
       "  'a',\n",
       "  'better',\n",
       "  'relationship',\n",
       "  'with',\n",
       "  'the',\n",
       "  'doctor',\n",
       "  'and',\n",
       "  'patient',\n",
       "  'the',\n",
       "  'patients',\n",
       "  'feel',\n",
       "  'trust',\n",
       "  'when',\n",
       "  'they',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'doctors',\n",
       "  'face',\n",
       "  'to',\n",
       "  'face',\n",
       "  'moreover',\n",
       "  'doctors',\n",
       "  'also',\n",
       "  'might',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'console',\n",
       "  'their',\n",
       "  'patients',\n",
       "  'when',\n",
       "  'they',\n",
       "  'have',\n",
       "  'direct',\n",
       "  'interaction',\n",
       "  'with',\n",
       "  'their',\n",
       "  'patients',\n",
       "  'there',\n",
       "  'could',\n",
       "  'also',\n",
       "  'be',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'doubt',\n",
       "  'if',\n",
       "  'these',\n",
       "  'virtual',\n",
       "  'methodologies',\n",
       "  'are',\n",
       "  'really',\n",
       "  'trusted',\n",
       "  'worthy',\n",
       "  'or',\n",
       "  'not',\n",
       "  'it',\n",
       "  'is',\n",
       "  'so',\n",
       "  'because',\n",
       "  'while',\n",
       "  'the',\n",
       "  'patients',\n",
       "  'have',\n",
       "  'direct',\n",
       "  'contact',\n",
       "  'with',\n",
       "  'their',\n",
       "  'patients',\n",
       "  'the',\n",
       "  'qualifications',\n",
       "  'are',\n",
       "  'visible',\n",
       "  'to',\n",
       "  'the',\n",
       "  'patients',\n",
       "  'so',\n",
       "  'there',\n",
       "  'shall',\n",
       "  'be',\n",
       "  'no',\n",
       "  'question',\n",
       "  'of',\n",
       "  'distrust',\n",
       "  'there',\n",
       "  'are',\n",
       "  'major',\n",
       "  'challenges',\n",
       "  'like',\n",
       "  'better',\n",
       "  'connectivity',\n",
       "  'of',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'without',\n",
       "  'which',\n",
       "  'the',\n",
       "  'patients',\n",
       "  'will',\n",
       "  'not',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'have',\n",
       "  'continuous',\n",
       "  'interaction',\n",
       "  'with',\n",
       "  'the',\n",
       "  'doctors',\n",
       "  'technical',\n",
       "  'glitches',\n",
       "  'may',\n",
       "  'hinder',\n",
       "  'the',\n",
       "  'consultation',\n",
       "  'too',\n",
       "  'moreover',\n",
       "  'emergency',\n",
       "  'situations',\n",
       "  'cannot',\n",
       "  'be',\n",
       "  'addressed',\n",
       "  'beyond',\n",
       "  'a',\n",
       "  'limit',\n",
       "  'through',\n",
       "  'telemedicine']]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/65.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7a912bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n",
      "WORD COUNT 227\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a659c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 13.464285714285714\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "76c8c3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.29515418502202645\n",
      "FOG INDEX: 5.503775959723097\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 13.464285714285714\n",
      "COMPLEX WORD COUNT: 67\n",
      "WORD COUNT: 227\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "339fddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 743\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 5.244031830238727\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_65.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fde486",
   "metadata": {},
   "source": [
    "# url 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3f2c1cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\1323511038.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-we-forecast-future-technologies/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0f368670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TECHNOLOGY is playing a dominant role in human life. And as in our daily lifestyle technology is used each and every place where human beings are present. so How we forecast future technologies? ',\n",
       " 'So, the fact is that technology is not a single immutable piece of hardware orbit chemistry. It is simply knowledge of physical relationships and it systematically applied to the useful arts. This knowledge can vary continuously over time. It can range basic phenomenon can be applied to an end product, device, or production machine in a mature operating system. Even as time passes, the performance characteristics of any machine, product, or operating system are normally improved in small continuous increments over time.',\n",
       " 'Advance in technology is usually nothing more than an accumulation of small advances not worth introducing individually to make a significant change in total technology. Forecast future technologies no matter how accurate – unless they eventually influence action.']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5e46e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts=(' '.join(str(x) for x in texts[16:19]))\n",
    "URL_ID_66 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5a10dc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 sentences in the string.\n",
      "The number of words in the string is: 153\n",
      "The number of characters in the string is: 833\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 22:08:04] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 22:08:12] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_66.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_66.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_66.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_66 = re.sub(re_punt, \"\",URL_ID_66)\n",
    "\n",
    "file = open(\"66.txt\", \"w\")\n",
    "file.write(URL_ID_66)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"66.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "725e5ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['technology',\n",
       "  'is',\n",
       "  'playing',\n",
       "  'a',\n",
       "  'dominant',\n",
       "  'role',\n",
       "  'in',\n",
       "  'human',\n",
       "  'life',\n",
       "  'and',\n",
       "  'as',\n",
       "  'in',\n",
       "  'our',\n",
       "  'daily',\n",
       "  'lifestyle',\n",
       "  'technology',\n",
       "  'is',\n",
       "  'used',\n",
       "  'each',\n",
       "  'and',\n",
       "  'every',\n",
       "  'place',\n",
       "  'where',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'are',\n",
       "  'present',\n",
       "  'so',\n",
       "  'how',\n",
       "  'we',\n",
       "  'forecast',\n",
       "  'future',\n",
       "  'technologies?',\n",
       "  'so',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'is',\n",
       "  'that',\n",
       "  'technology',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'single',\n",
       "  'immutable',\n",
       "  'piece',\n",
       "  'of',\n",
       "  'hardware',\n",
       "  'orbit',\n",
       "  'chemistry',\n",
       "  'it',\n",
       "  'is',\n",
       "  'simply',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'physical',\n",
       "  'relationships',\n",
       "  'and',\n",
       "  'it',\n",
       "  'systematically',\n",
       "  'applied',\n",
       "  'to',\n",
       "  'the',\n",
       "  'useful',\n",
       "  'arts',\n",
       "  'this',\n",
       "  'knowledge',\n",
       "  'can',\n",
       "  'vary',\n",
       "  'continuously',\n",
       "  'over',\n",
       "  'time',\n",
       "  'it',\n",
       "  'can',\n",
       "  'range',\n",
       "  'basic',\n",
       "  'phenomenon',\n",
       "  'can',\n",
       "  'be',\n",
       "  'applied',\n",
       "  'to',\n",
       "  'an',\n",
       "  'end',\n",
       "  'product',\n",
       "  'device',\n",
       "  'or',\n",
       "  'production',\n",
       "  'machine',\n",
       "  'in',\n",
       "  'a',\n",
       "  'mature',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'even',\n",
       "  'as',\n",
       "  'time',\n",
       "  'passes',\n",
       "  'the',\n",
       "  'performance',\n",
       "  'characteristics',\n",
       "  'of',\n",
       "  'any',\n",
       "  'machine',\n",
       "  'product',\n",
       "  'or',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'are',\n",
       "  'normally',\n",
       "  'improved',\n",
       "  'in',\n",
       "  'small',\n",
       "  'continuous',\n",
       "  'increments',\n",
       "  'over',\n",
       "  'time',\n",
       "  'advance',\n",
       "  'in',\n",
       "  'technology',\n",
       "  'is',\n",
       "  'usually',\n",
       "  'nothing',\n",
       "  'more',\n",
       "  'than',\n",
       "  'an',\n",
       "  'accumulation',\n",
       "  'of',\n",
       "  'small',\n",
       "  'advances',\n",
       "  'not',\n",
       "  'worth',\n",
       "  'introducing',\n",
       "  'individually',\n",
       "  'to',\n",
       "  'make',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'change',\n",
       "  'in',\n",
       "  'total',\n",
       "  'technology',\n",
       "  'forecast',\n",
       "  'future',\n",
       "  'technologies',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'how',\n",
       "  'accurate',\n",
       "  'unless',\n",
       "  'they',\n",
       "  'eventually',\n",
       "  'influence',\n",
       "  'action']]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/66.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d3e21883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "WORD COUNT 101\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a76fefcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 15.3\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b84c6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.45544554455445546\n",
      "FOG INDEX: 6.302178217821783\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 15.3\n",
      "COMPLEX WORD COUNT: 46\n",
      "WORD COUNT: 101\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ba0c154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 307\n",
      "I: 0\n",
      "we: 1\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 1\n",
      "PERSONAL PRONOUNS: 1\n",
      "AVG WORD LENGTH: 5.444444444444445\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_66.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45aeb4",
   "metadata": {},
   "source": [
    "# for url 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1c64afb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\2672427143.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5a27e0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In this era, everyone is busy in his life. No one spares time for someone. so robots tackle life loneliness? We have no time to stand and stare. This causes loneliness. Loneliness is due to fast-moving life and hurry and worry. In the 21st century, everyone is spending most of their time earning money. They are day-by-day transforming into money-earning machines. Due to his perception, we are losing our relations as we can’t give enough time to our families. They are busy earning their livelihood. They never get satisfies and always want more. Everyone is in a race of earning and then sends his children far away from himself to make them well settled in order to maintain their status. But one faces the consequences of this kind of lifestyle in his old age. People usually don’t spend time with their children when their children are in their childhood but they yearn for the company of their children in their old age. They feel lonely but have none to talk with. They are still attached to people, places, belongings, and memorable events from the past, although they understand that life cannot continue the same way as earlier, and this may easily result in feelings of loneliness and social isolation. As they become older, they need to be attended to in order to meet their daily needs. Robots can indeed serve the purpose but they can aid only mechanical care. They are just emotionless, feeling fewer entities. Robots aren’t creative. They can work only according to a pre-programmed system and till now no such software has been created that can transfer human feelings into robots. This is the major loophole of using robots to tackle late-life loneliness. They can undoubtedly serve their masters but their masters can’t share their feelings with them as they are incapable to understand or react to them. They can’t change their activity according to the occasion. They can provide anything except emotional satisfaction and without emotional gratification, loneliness can’t be tackled. A master can be attached to his robot but that attachment is only due to their service. They can’t share their thoughts with them. In this era, we are rendered lonely and in late- life feel the need for a companion with whom we can talk. We feel a need for someone who can listen to us, react, and advise us to tackle our day-to-day life problems. But we can’t find one. We have, undoubtedly, achieved great progress in terms of technology but we can never fill the void in the heart of a person struggling with his late-life loneliness with our advancements. We are in a kind of mental trance in which we experience fame, progress, wealth, etc. but when we gain our consciousness, we find ourselves lonely in this world. Relations in life are actual wealth in a person’s life. We can never enjoy such a bond with a robot. It will follow our commands, take our appropriate care but can’t react to our emotions. It can’t console us. When a man lives in loneliness for a long time, it eats up his conscience and transforms him into a machine. Robots can never become our friends, crack jokes, weep our tears, or establish an emotional connection with us. They can’t understand our feelings. Many people go into depression. Depression or the occurrence of depressive symptoms is a prominent condition amongst older people, with a significant impact on their well-being and quality of life. They remain sick and loneliness directly impacts longevity. Lonely people often think that they are no longer needed in this world and thus they want to die. It impacts their mental, psychological, social, and physical health. Robots prove to be useless in these matters. They can provide motivation, only if they have the software to do so but can’t, themselves, react to such a situation. They don’t know about anger, happiness, or sadness. They don’t themselves bring food when their master is hungry until commanded to do so. They can’t even offer a glass of water themselves. A man living without relations and without fellow feeling no longer remains a human being. He becomes none less than a machine as, due to his loneliness, he becomes mentally ill and goes into a condition like trauma where he no longer enjoys nature’s blessings, becomes happy or sad as he loses the ability to react and hence can’t act. It’s a dangerous situation. We face a plethora of challenges in assisted living facilities such as not being addressed to emotional needs, being neglected, and forcing a withdrawal from social activities. Relations in life, interaction with fellow beings, sharing of joy and happiness, and fellow feeling make a man from mere a ‘being’ to a ‘social being’ and finally a human being.']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1c1a0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:17]))\n",
    "URL_ID_67 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "be9ee09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55 sentences in the string.\n",
      "The number of words in the string is: 803\n",
      "The number of characters in the string is: 3918\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 22:19:52] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 22:20:00] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_67.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_67.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_67.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_67 = re.sub(re_punt, \"\",URL_ID_67)\n",
    "\n",
    "file = open(\"67.txt\", \"w\")\n",
    "file.write(URL_ID_67)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"67.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f7574846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['social',\n",
       "  'being',\n",
       "  'human',\n",
       "  'being',\n",
       "  'in',\n",
       "  'this',\n",
       "  'era',\n",
       "  'everyone',\n",
       "  'is',\n",
       "  'busy',\n",
       "  'in',\n",
       "  'his',\n",
       "  'life',\n",
       "  'no',\n",
       "  'one',\n",
       "  'spares',\n",
       "  'time',\n",
       "  'for',\n",
       "  'someone',\n",
       "  'so',\n",
       "  'robots',\n",
       "  'tackle',\n",
       "  'life',\n",
       "  'loneliness?',\n",
       "  'we',\n",
       "  'have',\n",
       "  'no',\n",
       "  'time',\n",
       "  'to',\n",
       "  'stand',\n",
       "  'and',\n",
       "  'stare',\n",
       "  'this',\n",
       "  'causes',\n",
       "  'loneliness',\n",
       "  'loneliness',\n",
       "  'is',\n",
       "  'due',\n",
       "  'to',\n",
       "  'fastmoving',\n",
       "  'life',\n",
       "  'and',\n",
       "  'hurry',\n",
       "  'and',\n",
       "  'worry',\n",
       "  'in',\n",
       "  'the',\n",
       "  '21st',\n",
       "  'century',\n",
       "  'everyone',\n",
       "  'is',\n",
       "  'spending',\n",
       "  'most',\n",
       "  'of',\n",
       "  'their',\n",
       "  'time',\n",
       "  'earning',\n",
       "  'money',\n",
       "  'they',\n",
       "  'are',\n",
       "  'daybyday',\n",
       "  'transforming',\n",
       "  'into',\n",
       "  'moneyearning',\n",
       "  'machines',\n",
       "  'due',\n",
       "  'to',\n",
       "  'his',\n",
       "  'perception',\n",
       "  'we',\n",
       "  'are',\n",
       "  'losing',\n",
       "  'our',\n",
       "  'relations',\n",
       "  'as',\n",
       "  'we',\n",
       "  'cant',\n",
       "  'give',\n",
       "  'enough',\n",
       "  'time',\n",
       "  'to',\n",
       "  'our',\n",
       "  'families',\n",
       "  'they',\n",
       "  'are',\n",
       "  'busy',\n",
       "  'earning',\n",
       "  'their',\n",
       "  'livelihood',\n",
       "  'they',\n",
       "  'never',\n",
       "  'get',\n",
       "  'satisfies',\n",
       "  'and',\n",
       "  'always',\n",
       "  'want',\n",
       "  'more',\n",
       "  'everyone',\n",
       "  'is',\n",
       "  'in',\n",
       "  'a',\n",
       "  'race',\n",
       "  'of',\n",
       "  'earning',\n",
       "  'and',\n",
       "  'then',\n",
       "  'sends',\n",
       "  'his',\n",
       "  'children',\n",
       "  'far',\n",
       "  'away',\n",
       "  'from',\n",
       "  'himself',\n",
       "  'to',\n",
       "  'make',\n",
       "  'them',\n",
       "  'well',\n",
       "  'settled',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'maintain',\n",
       "  'their',\n",
       "  'status',\n",
       "  'but',\n",
       "  'one',\n",
       "  'faces',\n",
       "  'the',\n",
       "  'consequences',\n",
       "  'of',\n",
       "  'this',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'lifestyle',\n",
       "  'in',\n",
       "  'his',\n",
       "  'old',\n",
       "  'age',\n",
       "  'people',\n",
       "  'usually',\n",
       "  'dont',\n",
       "  'spend',\n",
       "  'time',\n",
       "  'with',\n",
       "  'their',\n",
       "  'children',\n",
       "  'when',\n",
       "  'their',\n",
       "  'children',\n",
       "  'are',\n",
       "  'in',\n",
       "  'their',\n",
       "  'childhood',\n",
       "  'but',\n",
       "  'they',\n",
       "  'yearn',\n",
       "  'for',\n",
       "  'the',\n",
       "  'company',\n",
       "  'of',\n",
       "  'their',\n",
       "  'children',\n",
       "  'in',\n",
       "  'their',\n",
       "  'old',\n",
       "  'age',\n",
       "  'they',\n",
       "  'feel',\n",
       "  'lonely',\n",
       "  'but',\n",
       "  'have',\n",
       "  'none',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'with',\n",
       "  'they',\n",
       "  'are',\n",
       "  'still',\n",
       "  'attached',\n",
       "  'to',\n",
       "  'people',\n",
       "  'places',\n",
       "  'belongings',\n",
       "  'and',\n",
       "  'memorable',\n",
       "  'events',\n",
       "  'from',\n",
       "  'the',\n",
       "  'past',\n",
       "  'although',\n",
       "  'they',\n",
       "  'understand',\n",
       "  'that',\n",
       "  'life',\n",
       "  'cannot',\n",
       "  'continue',\n",
       "  'the',\n",
       "  'same',\n",
       "  'way',\n",
       "  'as',\n",
       "  'earlier',\n",
       "  'and',\n",
       "  'this',\n",
       "  'may',\n",
       "  'easily',\n",
       "  'result',\n",
       "  'in',\n",
       "  'feelings',\n",
       "  'of',\n",
       "  'loneliness',\n",
       "  'and',\n",
       "  'social',\n",
       "  'isolation',\n",
       "  'as',\n",
       "  'they',\n",
       "  'become',\n",
       "  'older',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'attended',\n",
       "  'to',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'meet',\n",
       "  'their',\n",
       "  'daily',\n",
       "  'needs',\n",
       "  'robots',\n",
       "  'can',\n",
       "  'indeed',\n",
       "  'serve',\n",
       "  'the',\n",
       "  'purpose',\n",
       "  'but',\n",
       "  'they',\n",
       "  'can',\n",
       "  'aid',\n",
       "  'only',\n",
       "  'mechanical',\n",
       "  'care',\n",
       "  'they',\n",
       "  'are',\n",
       "  'just',\n",
       "  'emotionless',\n",
       "  'feeling',\n",
       "  'fewer',\n",
       "  'entities',\n",
       "  'robots',\n",
       "  'arent',\n",
       "  'creative',\n",
       "  'they',\n",
       "  'can',\n",
       "  'work',\n",
       "  'only',\n",
       "  'according',\n",
       "  'to',\n",
       "  'a',\n",
       "  'preprogrammed',\n",
       "  'system',\n",
       "  'and',\n",
       "  'till',\n",
       "  'now',\n",
       "  'no',\n",
       "  'such',\n",
       "  'software',\n",
       "  'has',\n",
       "  'been',\n",
       "  'created',\n",
       "  'that',\n",
       "  'can',\n",
       "  'transfer',\n",
       "  'human',\n",
       "  'feelings',\n",
       "  'into',\n",
       "  'robots',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'major',\n",
       "  'loophole',\n",
       "  'of',\n",
       "  'using',\n",
       "  'robots',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'latelife',\n",
       "  'loneliness',\n",
       "  'they',\n",
       "  'can',\n",
       "  'undoubtedly',\n",
       "  'serve',\n",
       "  'their',\n",
       "  'masters',\n",
       "  'but',\n",
       "  'their',\n",
       "  'masters',\n",
       "  'cant',\n",
       "  'share',\n",
       "  'their',\n",
       "  'feelings',\n",
       "  'with',\n",
       "  'them',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'incapable',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'or',\n",
       "  'react',\n",
       "  'to',\n",
       "  'them',\n",
       "  'they',\n",
       "  'cant',\n",
       "  'change',\n",
       "  'their',\n",
       "  'activity',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'occasion',\n",
       "  'they',\n",
       "  'can',\n",
       "  'provide',\n",
       "  'anything',\n",
       "  'except',\n",
       "  'emotional',\n",
       "  'satisfaction',\n",
       "  'and',\n",
       "  'without',\n",
       "  'emotional',\n",
       "  'gratification',\n",
       "  'loneliness',\n",
       "  'cant',\n",
       "  'be',\n",
       "  'tackled',\n",
       "  'a',\n",
       "  'master',\n",
       "  'can',\n",
       "  'be',\n",
       "  'attached',\n",
       "  'to',\n",
       "  'his',\n",
       "  'robot',\n",
       "  'but',\n",
       "  'that',\n",
       "  'attachment',\n",
       "  'is',\n",
       "  'only',\n",
       "  'due',\n",
       "  'to',\n",
       "  'their',\n",
       "  'service',\n",
       "  'they',\n",
       "  'cant',\n",
       "  'share',\n",
       "  'their',\n",
       "  'thoughts',\n",
       "  'with',\n",
       "  'them',\n",
       "  'in',\n",
       "  'this',\n",
       "  'era',\n",
       "  'we',\n",
       "  'are',\n",
       "  'rendered',\n",
       "  'lonely',\n",
       "  'and',\n",
       "  'in',\n",
       "  'late',\n",
       "  'life',\n",
       "  'feel',\n",
       "  'the',\n",
       "  'need',\n",
       "  'for',\n",
       "  'a',\n",
       "  'companion',\n",
       "  'with',\n",
       "  'whom',\n",
       "  'we',\n",
       "  'can',\n",
       "  'talk',\n",
       "  'we',\n",
       "  'feel',\n",
       "  'a',\n",
       "  'need',\n",
       "  'for',\n",
       "  'someone',\n",
       "  'who',\n",
       "  'can',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'us',\n",
       "  'react',\n",
       "  'and',\n",
       "  'advise',\n",
       "  'us',\n",
       "  'to',\n",
       "  'tackle',\n",
       "  'our',\n",
       "  'daytoday',\n",
       "  'life',\n",
       "  'problems',\n",
       "  'but',\n",
       "  'we',\n",
       "  'cant',\n",
       "  'find',\n",
       "  'one',\n",
       "  'we',\n",
       "  'have',\n",
       "  'undoubtedly',\n",
       "  'achieved',\n",
       "  'great',\n",
       "  'progress',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'technology',\n",
       "  'but',\n",
       "  'we',\n",
       "  'can',\n",
       "  'never',\n",
       "  'fill',\n",
       "  'the',\n",
       "  'void',\n",
       "  'in',\n",
       "  'the',\n",
       "  'heart',\n",
       "  'of',\n",
       "  'a',\n",
       "  'person',\n",
       "  'struggling',\n",
       "  'with',\n",
       "  'his',\n",
       "  'latelife',\n",
       "  'loneliness',\n",
       "  'with',\n",
       "  'our',\n",
       "  'advancements',\n",
       "  'we',\n",
       "  'are',\n",
       "  'in',\n",
       "  'a',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'mental',\n",
       "  'trance',\n",
       "  'in',\n",
       "  'which',\n",
       "  'we',\n",
       "  'experience',\n",
       "  'fame',\n",
       "  'progress',\n",
       "  'wealth',\n",
       "  'etc',\n",
       "  'but',\n",
       "  'when',\n",
       "  'we',\n",
       "  'gain',\n",
       "  'our',\n",
       "  'consciousness',\n",
       "  'we',\n",
       "  'find',\n",
       "  'ourselves',\n",
       "  'lonely',\n",
       "  'in',\n",
       "  'this',\n",
       "  'world',\n",
       "  'relations',\n",
       "  'in',\n",
       "  'life',\n",
       "  'are',\n",
       "  'actual',\n",
       "  'wealth',\n",
       "  'in',\n",
       "  'a',\n",
       "  'persons',\n",
       "  'life',\n",
       "  'we',\n",
       "  'can',\n",
       "  'never',\n",
       "  'enjoy',\n",
       "  'such',\n",
       "  'a',\n",
       "  'bond',\n",
       "  'with',\n",
       "  'a',\n",
       "  'robot',\n",
       "  'it',\n",
       "  'will',\n",
       "  'follow',\n",
       "  'our',\n",
       "  'commands',\n",
       "  'take',\n",
       "  'our',\n",
       "  'appropriate',\n",
       "  'care',\n",
       "  'but',\n",
       "  'cant',\n",
       "  'react',\n",
       "  'to',\n",
       "  'our',\n",
       "  'emotions',\n",
       "  'it',\n",
       "  'cant',\n",
       "  'console',\n",
       "  'us',\n",
       "  'when',\n",
       "  'a',\n",
       "  'man',\n",
       "  'lives',\n",
       "  'in',\n",
       "  'loneliness',\n",
       "  'for',\n",
       "  'a',\n",
       "  'long',\n",
       "  'time',\n",
       "  'it',\n",
       "  'eats',\n",
       "  'up',\n",
       "  'his',\n",
       "  'conscience',\n",
       "  'and',\n",
       "  'transforms',\n",
       "  'him',\n",
       "  'into',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'robots',\n",
       "  'can',\n",
       "  'never',\n",
       "  'become',\n",
       "  'our',\n",
       "  'friends',\n",
       "  'crack',\n",
       "  'jokes',\n",
       "  'weep',\n",
       "  'our',\n",
       "  'tears',\n",
       "  'or',\n",
       "  'establish',\n",
       "  'an',\n",
       "  'emotional',\n",
       "  'connection',\n",
       "  'with',\n",
       "  'us',\n",
       "  'they',\n",
       "  'cant',\n",
       "  'understand',\n",
       "  'our',\n",
       "  'feelings',\n",
       "  'many',\n",
       "  'people',\n",
       "  'go',\n",
       "  'into',\n",
       "  'depression',\n",
       "  'depression',\n",
       "  'or',\n",
       "  'the',\n",
       "  'occurrence',\n",
       "  'of',\n",
       "  'depressive',\n",
       "  'symptoms',\n",
       "  'is',\n",
       "  'a',\n",
       "  'prominent',\n",
       "  'condition',\n",
       "  'amongst',\n",
       "  'older',\n",
       "  'people',\n",
       "  'with',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'impact',\n",
       "  'on',\n",
       "  'their',\n",
       "  'wellbeing',\n",
       "  'and',\n",
       "  'quality',\n",
       "  'of',\n",
       "  'life',\n",
       "  'they',\n",
       "  'remain',\n",
       "  'sick',\n",
       "  'and',\n",
       "  'loneliness',\n",
       "  'directly',\n",
       "  'impacts',\n",
       "  'longevity',\n",
       "  'lonely',\n",
       "  'people',\n",
       "  'often',\n",
       "  'think',\n",
       "  'that',\n",
       "  'they',\n",
       "  'are',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'needed',\n",
       "  'in',\n",
       "  'this',\n",
       "  'world',\n",
       "  'and',\n",
       "  'thus',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'die',\n",
       "  'it',\n",
       "  'impacts',\n",
       "  'their',\n",
       "  'mental',\n",
       "  'psychological',\n",
       "  'social',\n",
       "  'and',\n",
       "  'physical',\n",
       "  'health',\n",
       "  'robots',\n",
       "  'prove',\n",
       "  'to',\n",
       "  'be',\n",
       "  'useless',\n",
       "  'in',\n",
       "  'these',\n",
       "  'matters',\n",
       "  'they',\n",
       "  'can',\n",
       "  'provide',\n",
       "  'motivation',\n",
       "  'only',\n",
       "  'if',\n",
       "  'they',\n",
       "  'have',\n",
       "  'the',\n",
       "  'software',\n",
       "  'to',\n",
       "  'do',\n",
       "  'so',\n",
       "  'but',\n",
       "  'cant',\n",
       "  'themselves',\n",
       "  'react',\n",
       "  'to',\n",
       "  'such',\n",
       "  'a',\n",
       "  'situation',\n",
       "  'they',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'about',\n",
       "  'anger',\n",
       "  'happiness',\n",
       "  'or',\n",
       "  'sadness',\n",
       "  'they',\n",
       "  'dont',\n",
       "  'themselves',\n",
       "  'bring',\n",
       "  'food',\n",
       "  'when',\n",
       "  'their',\n",
       "  'master',\n",
       "  'is',\n",
       "  'hungry',\n",
       "  'until',\n",
       "  'commanded',\n",
       "  'to',\n",
       "  'do',\n",
       "  'so',\n",
       "  'they',\n",
       "  'cant',\n",
       "  'even',\n",
       "  'offer',\n",
       "  'a',\n",
       "  'glass',\n",
       "  'of',\n",
       "  'water',\n",
       "  'themselves',\n",
       "  'a',\n",
       "  'man',\n",
       "  'living',\n",
       "  'without',\n",
       "  'relations',\n",
       "  'and',\n",
       "  'without',\n",
       "  'fellow',\n",
       "  'feeling',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'remains',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'he',\n",
       "  'becomes',\n",
       "  'none',\n",
       "  'less',\n",
       "  'than',\n",
       "  'a',\n",
       "  'machine',\n",
       "  'as',\n",
       "  'due',\n",
       "  'to',\n",
       "  'his',\n",
       "  'loneliness',\n",
       "  'he',\n",
       "  'becomes',\n",
       "  'mentally',\n",
       "  'ill',\n",
       "  'and',\n",
       "  'goes',\n",
       "  'into',\n",
       "  'a',\n",
       "  'condition',\n",
       "  'like',\n",
       "  'trauma',\n",
       "  'where',\n",
       "  'he',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'enjoys',\n",
       "  'natures',\n",
       "  'blessings',\n",
       "  'becomes',\n",
       "  'happy',\n",
       "  'or',\n",
       "  'sad',\n",
       "  'as',\n",
       "  'he',\n",
       "  'loses',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'react',\n",
       "  'and',\n",
       "  'hence',\n",
       "  'cant',\n",
       "  'act',\n",
       "  'its',\n",
       "  'a',\n",
       "  'dangerous',\n",
       "  'situation',\n",
       "  'we',\n",
       "  'face',\n",
       "  'a',\n",
       "  'plethora',\n",
       "  'of',\n",
       "  'challenges',\n",
       "  'in',\n",
       "  'assisted',\n",
       "  'living',\n",
       "  'facilities',\n",
       "  'such',\n",
       "  'as',\n",
       "  'not',\n",
       "  'being',\n",
       "  'addressed',\n",
       "  'to',\n",
       "  'emotional',\n",
       "  'needs',\n",
       "  'being',\n",
       "  'neglected',\n",
       "  'and',\n",
       "  'forcing',\n",
       "  'a',\n",
       "  'withdrawal',\n",
       "  'from',\n",
       "  'social',\n",
       "  'activities',\n",
       "  'relations',\n",
       "  'in',\n",
       "  'life',\n",
       "  'interaction',\n",
       "  'with',\n",
       "  'fellow',\n",
       "  'beings',\n",
       "  'sharing',\n",
       "  'of',\n",
       "  'joy',\n",
       "  'and',\n",
       "  'happiness',\n",
       "  'and',\n",
       "  'fellow',\n",
       "  'feeling',\n",
       "  'make',\n",
       "  'a',\n",
       "  'man',\n",
       "  'from',\n",
       "  'mere',\n",
       "  'a',\n",
       "  'being',\n",
       "  'to',\n",
       "  'a',\n",
       "  'social',\n",
       "  'being',\n",
       "  'and',\n",
       "  'finally',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being']]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/67.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b8095b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803\n",
      "WORD COUNT 495\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "39a40738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 14.6\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8b6e9294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.2767676767676768\n",
      "FOG INDEX: 5.950707070707071\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 14.6\n",
      "COMPLEX WORD COUNT: 137\n",
      "WORD COUNT: 495\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e20feff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1441\n",
      "I: 0\n",
      "we: 15\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 4\n",
      "Total count: 19\n",
      "PERSONAL PRONOUNS: 19\n",
      "AVG WORD LENGTH: 4.87920298879203\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_67.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61fe12",
   "metadata": {},
   "source": [
    "# url 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "49bdd92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\1333894757.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "98ff05b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Care Robots, as the name suggests, are robots that are used for hospitality purposes like fetching water, cracking jokes and keeping a patient in good harmony, etc.',\n",
       " 'The senior care industry has been at the forefront for quite a period. The reason being, Nuclear families becoming very busy in their schedule that one day when the parents of this nuclear family are old, children are nowhere to take care of. Instead, nursing homes have become a trend.  Parents with mental illness are being put in rehab.',\n",
       " 'As observed for a few decades robots are taking care of many activities and they are even dominating a few fields like the automobile industry. So, Machines can indeed help humankind in achieving remarkable success in many fields.',\n",
       " 'Do senior citizens love machines ?, You should look at them when they watch TV when they love to play video games on a smartphone. So, If we give them a human-like structure with the ability of a smartphone to make these people happy then it would be quite a monstrous feat.']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "26eea816",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts=(' '.join(str(x) for x in texts[16:20]))\n",
    "URL_ID_68 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f0816ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 sentences in the string.\n",
      "The number of words in the string is: 176\n",
      "The number of characters in the string is: 834\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 22:42:49] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 22:42:56] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_68.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_68.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_68.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_68 = re.sub(re_punt, \"\",URL_ID_68)\n",
    "\n",
    "file = open(\"68.txt\", \"w\")\n",
    "file.write(URL_ID_68)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"68.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3bde1e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['care',\n",
       "  'robots',\n",
       "  'as',\n",
       "  'the',\n",
       "  'name',\n",
       "  'suggests',\n",
       "  'are',\n",
       "  'robots',\n",
       "  'that',\n",
       "  'are',\n",
       "  'used',\n",
       "  'for',\n",
       "  'hospitality',\n",
       "  'purposes',\n",
       "  'like',\n",
       "  'fetching',\n",
       "  'water',\n",
       "  'cracking',\n",
       "  'jokes',\n",
       "  'and',\n",
       "  'keeping',\n",
       "  'a',\n",
       "  'patient',\n",
       "  'in',\n",
       "  'good',\n",
       "  'harmony',\n",
       "  'etc',\n",
       "  'the',\n",
       "  'senior',\n",
       "  'care',\n",
       "  'industry',\n",
       "  'has',\n",
       "  'been',\n",
       "  'at',\n",
       "  'the',\n",
       "  'forefront',\n",
       "  'for',\n",
       "  'quite',\n",
       "  'a',\n",
       "  'period',\n",
       "  'the',\n",
       "  'reason',\n",
       "  'being',\n",
       "  'nuclear',\n",
       "  'families',\n",
       "  'becoming',\n",
       "  'very',\n",
       "  'busy',\n",
       "  'in',\n",
       "  'their',\n",
       "  'schedule',\n",
       "  'that',\n",
       "  'one',\n",
       "  'day',\n",
       "  'when',\n",
       "  'the',\n",
       "  'parents',\n",
       "  'of',\n",
       "  'this',\n",
       "  'nuclear',\n",
       "  'family',\n",
       "  'are',\n",
       "  'old',\n",
       "  'children',\n",
       "  'are',\n",
       "  'nowhere',\n",
       "  'to',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'instead',\n",
       "  'nursing',\n",
       "  'homes',\n",
       "  'have',\n",
       "  'become',\n",
       "  'a',\n",
       "  'trend',\n",
       "  'parents',\n",
       "  'with',\n",
       "  'mental',\n",
       "  'illness',\n",
       "  'are',\n",
       "  'being',\n",
       "  'put',\n",
       "  'in',\n",
       "  'rehab',\n",
       "  'as',\n",
       "  'observed',\n",
       "  'for',\n",
       "  'a',\n",
       "  'few',\n",
       "  'decades',\n",
       "  'robots',\n",
       "  'are',\n",
       "  'taking',\n",
       "  'care',\n",
       "  'of',\n",
       "  'many',\n",
       "  'activities',\n",
       "  'and',\n",
       "  'they',\n",
       "  'are',\n",
       "  'even',\n",
       "  'dominating',\n",
       "  'a',\n",
       "  'few',\n",
       "  'fields',\n",
       "  'like',\n",
       "  'the',\n",
       "  'automobile',\n",
       "  'industry',\n",
       "  'so',\n",
       "  'machines',\n",
       "  'can',\n",
       "  'indeed',\n",
       "  'help',\n",
       "  'humankind',\n",
       "  'in',\n",
       "  'achieving',\n",
       "  'remarkable',\n",
       "  'success',\n",
       "  'in',\n",
       "  'many',\n",
       "  'fields',\n",
       "  'do',\n",
       "  'senior',\n",
       "  'citizens',\n",
       "  'love',\n",
       "  'machines',\n",
       "  '?',\n",
       "  'you',\n",
       "  'should',\n",
       "  'look',\n",
       "  'at',\n",
       "  'them',\n",
       "  'when',\n",
       "  'they',\n",
       "  'watch',\n",
       "  'tv',\n",
       "  'when',\n",
       "  'they',\n",
       "  'love',\n",
       "  'to',\n",
       "  'play',\n",
       "  'video',\n",
       "  'games',\n",
       "  'on',\n",
       "  'a',\n",
       "  'smartphone',\n",
       "  'so',\n",
       "  'if',\n",
       "  'we',\n",
       "  'give',\n",
       "  'them',\n",
       "  'a',\n",
       "  'humanlike',\n",
       "  'structure',\n",
       "  'with',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'of',\n",
       "  'a',\n",
       "  'smartphone',\n",
       "  'to',\n",
       "  'make',\n",
       "  'these',\n",
       "  'people',\n",
       "  'happy',\n",
       "  'then',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'quite',\n",
       "  'a',\n",
       "  'monstrous',\n",
       "  'feat']]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/68.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f2c7414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "WORD COUNT 110\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "98d24052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 17.6\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d641bc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.2545454545454545\n",
      "FOG INDEX: 7.1418181818181825\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 17.6\n",
      "COMPLEX WORD COUNT: 28\n",
      "WORD COUNT: 110\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "64557134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 311\n",
      "I: 0\n",
      "we: 1\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 1\n",
      "PERSONAL PRONOUNS: 1\n",
      "AVG WORD LENGTH: 4.738636363636363\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_68.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b339339",
   "metadata": {},
   "source": [
    "# 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2657fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\136377873.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "bbcb4ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Management acts as a guide to a group of people working in the organization and coordinating their efforts, towards the attainment of the common objective.Management challenges for future digitalization of healthcare services',\n",
       " '    In the current day and age, a wave of digitization has taken over the world. All the emerging technologies like Artificial Intelligence and others are helping people live better and easier life. The service sector has also benefited a lot from digitization. It got further boost when Prime Minister Narendra Modi, in the year 2015, launched a campaign known as ‘Digital India.’ Among the various industries in the service sector, digitization has had a massive impact on the operation of the healthcare and diagnostic industry. It has helped in the development of this industry and enhances life for millions of people. The condition of India in terms of healthcare has been quite grim. Patients who need attention are neglected and are unable to avail proper treatment or diagnosis. However, with the coming up of digitization, there has been hoped for this industry also.',\n",
       " 'According to Dr. Keshab Panda, CEO & MD, L&T Technology Services,',\n",
       " 'This is a model of healthcare where doctors and hospitals are paid based on patient health outcomes. The coming up of digital tools in this segment of healthcare can be considered as the starting tool. Dr. Panda further says that the implementation of advanced digital technologies in patient-care domains like- mobile health apps, telehealth, wearables, and remote monitoring can help in enhancing accessibility, boost efficiency and augment the effectiveness of treatment and preventive care.',\n",
       " 'The healthcare industry over the past few decades has changed drastically. With the coming of emerging technologies, new surgical procedures and medical devices have been made available.',\n",
       " 'While talking about connectivity in healthcare, Dr. Panda said that with digitization taking over the industry, it is only a matter of time when with the help of the internet and smartphones, digital healthcare will be everywhere. The internet for once has helped doctors connect to their patients and also with one another. This has helped in enhancing the doctor-patient engagement by increasing their interaction time.',\n",
       " 'Big data aggregates information about a business through formats such as social media, eCommerce, online transactions, and financial transactions, and identifies patterns and trends for future use.',\n",
       " 'Although ransomware, data breaches, and other cybersecurity concerns are nothing new to the healthcare industry, the 2020 Covid-19 pandemic revealed just how vulnerable sensitive patient health information really is.',\n",
       " 'The recent growth of digital health initiatives- like telehealth doctor visits — is a major contributor to the severe increase in breached patient records. As more healthcare functions continue to move online over the next year, it’s extremely important to ensure these processes are protected from outside threats.',\n",
       " 'Medical practices are citing patient collections as their top revenue cycle management struggle as patients are becoming responsible for a larger portion of their medical bills. In order to help encourage patients to submit payments in a timely manner, providers must adhere to patient payment preferences.',\n",
       " 'To meet patient expectations and improve the user experience, ensure billing statements are patient-friendly. You should offer paperless statements and a variety of payment options (e.g. credit card, etc.) via an online patient portal and utilize the latest payment technologies, such as mobile and text-to-pay. New features like text or email reminders help effectively communicate with patients and encourage them to pay their financial obligations.',\n",
       " 'The medical insurance landscape has experienced some significant changes in recent years. As more patients are responsible for a larger portion of their healthcare bill, they naturally demand better services from their providers.',\n",
       " 'Healthcare organizations will face tougher competition in attracting and retaining patients who demand an experience that matches the level of customer service they expect from other consumer brands.',\n",
       " 'They demand a streamlined patient experience so they can “self-service” to resolve most questions, issues, or concerns (e.g., downloading an immunization record, booking an appointment, paying their bills, or checking their account/insurance status) whenever, wherever, and however is most convenient for them.']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "c058ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:30]))\n",
    "URL_ID_69 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "97ff1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47 sentences in the string.\n",
      "The number of words in the string is: 742\n",
      "The number of characters in the string is: 4307\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 22:56:27] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 22:56:32] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_69.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_69.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_69.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_69 = re.sub(re_punt, \"\",URL_ID_69)\n",
    "\n",
    "file = open(\"69.txt\", \"w\")\n",
    "file.write(URL_ID_69)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"69.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "056407a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['characteristics',\n",
       "  'for',\n",
       "  'future',\n",
       "  'digitalization',\n",
       "  'of',\n",
       "  'healthcare',\n",
       "  'universal',\n",
       "  'levels',\n",
       "  'of',\n",
       "  'management',\n",
       "  'toplevel',\n",
       "  'management',\n",
       "  'supervisors',\n",
       "  'future',\n",
       "  'digitalization',\n",
       "  'of',\n",
       "  'healthcare',\n",
       "  'there',\n",
       "  'are',\n",
       "  'three',\n",
       "  'trends',\n",
       "  'emerging',\n",
       "  'in',\n",
       "  'the',\n",
       "  'healthcare',\n",
       "  'and',\n",
       "  'diagnostics',\n",
       "  'ecosystem',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'digitization',\n",
       "  '1',\n",
       "  'valuebased',\n",
       "  'healthcare',\n",
       "  '2',\n",
       "  'new',\n",
       "  'product',\n",
       "  'development',\n",
       "  '3',\n",
       "  'connectivity',\n",
       "  'for',\n",
       "  'the',\n",
       "  'healthcare',\n",
       "  'industry',\n",
       "  'big',\n",
       "  'data',\n",
       "  'can',\n",
       "  'provide',\n",
       "  'several',\n",
       "  'important',\n",
       "  'benefits',\n",
       "  'including',\n",
       "  'challenges',\n",
       "  'for',\n",
       "  'future',\n",
       "  'digitalization',\n",
       "  'of',\n",
       "  'healthcare',\n",
       "  '1',\n",
       "  'cybersecurity',\n",
       "  '2',\n",
       "  'invoicing',\n",
       "  'and',\n",
       "  'payment',\n",
       "  'processing',\n",
       "  '3',\n",
       "  'patient',\n",
       "  'experience',\n",
       "  'management',\n",
       "  'acts',\n",
       "  'as',\n",
       "  'a',\n",
       "  'guide',\n",
       "  'to',\n",
       "  'a',\n",
       "  'group',\n",
       "  'of',\n",
       "  'people',\n",
       "  'working',\n",
       "  'in',\n",
       "  'the',\n",
       "  'organization',\n",
       "  'and',\n",
       "  'coordinating',\n",
       "  'their',\n",
       "  'efforts',\n",
       "  'towards',\n",
       "  'the',\n",
       "  'attainment',\n",
       "  'of',\n",
       "  'the',\n",
       "  'common',\n",
       "  'objectivemanagement',\n",
       "  'challenges',\n",
       "  'for',\n",
       "  'future',\n",
       "  'digitalization',\n",
       "  'of',\n",
       "  'healthcare',\n",
       "  'services',\n",
       "  'in',\n",
       "  'the',\n",
       "  'current',\n",
       "  'day',\n",
       "  'and',\n",
       "  'age',\n",
       "  'a',\n",
       "  'wave',\n",
       "  'of',\n",
       "  'digitization',\n",
       "  'has',\n",
       "  'taken',\n",
       "  'over',\n",
       "  'the',\n",
       "  'world',\n",
       "  'all',\n",
       "  'the',\n",
       "  'emerging',\n",
       "  'technologies',\n",
       "  'like',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'and',\n",
       "  'others',\n",
       "  'are',\n",
       "  'helping',\n",
       "  'people',\n",
       "  'live',\n",
       "  'better',\n",
       "  'and',\n",
       "  'easier',\n",
       "  'life',\n",
       "  'the',\n",
       "  'service',\n",
       "  'sector',\n",
       "  'has',\n",
       "  'also',\n",
       "  'benefited',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'from',\n",
       "  'digitization',\n",
       "  'it',\n",
       "  'got',\n",
       "  'further',\n",
       "  'boost',\n",
       "  'when',\n",
       "  'prime',\n",
       "  'minister',\n",
       "  'narendra',\n",
       "  'modi',\n",
       "  'in',\n",
       "  'the',\n",
       "  'year',\n",
       "  '2015',\n",
       "  'launched',\n",
       "  'a',\n",
       "  'campaign',\n",
       "  'known',\n",
       "  'as',\n",
       "  'digital',\n",
       "  'india',\n",
       "  'among',\n",
       "  'the',\n",
       "  'various',\n",
       "  'industries',\n",
       "  'in',\n",
       "  'the',\n",
       "  'service',\n",
       "  'sector',\n",
       "  'digitization',\n",
       "  'has',\n",
       "  'had',\n",
       "  'a',\n",
       "  'massive',\n",
       "  'impact',\n",
       "  'on',\n",
       "  'the',\n",
       "  'operation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'healthcare',\n",
       "  'and',\n",
       "  'diagnostic',\n",
       "  'industry',\n",
       "  'it',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'in',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'this',\n",
       "  'industry',\n",
       "  'and',\n",
       "  'enhances',\n",
       "  'life',\n",
       "  'for',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'people',\n",
       "  'the',\n",
       "  'condition',\n",
       "  'of',\n",
       "  'india',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'healthcare',\n",
       "  'has',\n",
       "  'been',\n",
       "  'quite',\n",
       "  'grim',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'need',\n",
       "  'attention',\n",
       "  'are',\n",
       "  'neglected',\n",
       "  'and',\n",
       "  'are',\n",
       "  'unable',\n",
       "  'to',\n",
       "  'avail',\n",
       "  'proper',\n",
       "  'treatment',\n",
       "  'or',\n",
       "  'diagnosis',\n",
       "  'however',\n",
       "  'with',\n",
       "  'the',\n",
       "  'coming',\n",
       "  'up',\n",
       "  'of',\n",
       "  'digitization',\n",
       "  'there',\n",
       "  'has',\n",
       "  'been',\n",
       "  'hoped',\n",
       "  'for',\n",
       "  'this',\n",
       "  'industry',\n",
       "  'also',\n",
       "  'according',\n",
       "  'to',\n",
       "  'dr',\n",
       "  'keshab',\n",
       "  'panda',\n",
       "  'ceo',\n",
       "  'md',\n",
       "  'lt',\n",
       "  'technology',\n",
       "  'services',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'model',\n",
       "  'of',\n",
       "  'healthcare',\n",
       "  'where',\n",
       "  'doctors',\n",
       "  'and',\n",
       "  'hospitals',\n",
       "  'are',\n",
       "  'paid',\n",
       "  'based',\n",
       "  'on',\n",
       "  'patient',\n",
       "  'health',\n",
       "  'outcomes',\n",
       "  'the',\n",
       "  'coming',\n",
       "  'up',\n",
       "  'of',\n",
       "  'digital',\n",
       "  'tools',\n",
       "  'in',\n",
       "  'this',\n",
       "  'segment',\n",
       "  'of',\n",
       "  'healthcare',\n",
       "  'can',\n",
       "  'be',\n",
       "  'considered',\n",
       "  'as',\n",
       "  'the',\n",
       "  'starting',\n",
       "  'tool',\n",
       "  'dr',\n",
       "  'panda',\n",
       "  'further',\n",
       "  'says',\n",
       "  'that',\n",
       "  'the',\n",
       "  'implementation',\n",
       "  'of',\n",
       "  'advanced',\n",
       "  'digital',\n",
       "  'technologies',\n",
       "  'in',\n",
       "  'patientcare',\n",
       "  'domains',\n",
       "  'like',\n",
       "  'mobile',\n",
       "  'health',\n",
       "  'apps',\n",
       "  'telehealth',\n",
       "  'wearables',\n",
       "  'and',\n",
       "  'remote',\n",
       "  'monitoring',\n",
       "  'can',\n",
       "  'help',\n",
       "  'in',\n",
       "  'enhancing',\n",
       "  'accessibility',\n",
       "  'boost',\n",
       "  'efficiency',\n",
       "  'and',\n",
       "  'augment',\n",
       "  'the',\n",
       "  'effectiveness',\n",
       "  'of',\n",
       "  'treatment',\n",
       "  'and',\n",
       "  'preventive',\n",
       "  'care',\n",
       "  'the',\n",
       "  'healthcare',\n",
       "  'industry',\n",
       "  'over',\n",
       "  'the',\n",
       "  'past',\n",
       "  'few',\n",
       "  'decades',\n",
       "  'has',\n",
       "  'changed',\n",
       "  'drastically',\n",
       "  'with',\n",
       "  'the',\n",
       "  'coming',\n",
       "  'of',\n",
       "  'emerging',\n",
       "  'technologies',\n",
       "  'new',\n",
       "  'surgical',\n",
       "  'procedures',\n",
       "  'and',\n",
       "  'medical',\n",
       "  'devices',\n",
       "  'have',\n",
       "  'been',\n",
       "  'made',\n",
       "  'available',\n",
       "  'while',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'connectivity',\n",
       "  'in',\n",
       "  'healthcare',\n",
       "  'dr',\n",
       "  'panda',\n",
       "  'said',\n",
       "  'that',\n",
       "  'with',\n",
       "  'digitization',\n",
       "  'taking',\n",
       "  'over',\n",
       "  'the',\n",
       "  'industry',\n",
       "  'it',\n",
       "  'is',\n",
       "  'only',\n",
       "  'a',\n",
       "  'matter',\n",
       "  'of',\n",
       "  'time',\n",
       "  'when',\n",
       "  'with',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'and',\n",
       "  'smartphones',\n",
       "  'digital',\n",
       "  'healthcare',\n",
       "  'will',\n",
       "  'be',\n",
       "  'everywhere',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'for',\n",
       "  'once',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'doctors',\n",
       "  'connect',\n",
       "  'to',\n",
       "  'their',\n",
       "  'patients',\n",
       "  'and',\n",
       "  'also',\n",
       "  'with',\n",
       "  'one',\n",
       "  'another',\n",
       "  'this',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'in',\n",
       "  'enhancing',\n",
       "  'the',\n",
       "  'doctorpatient',\n",
       "  'engagement',\n",
       "  'by',\n",
       "  'increasing',\n",
       "  'their',\n",
       "  'interaction',\n",
       "  'time',\n",
       "  'big',\n",
       "  'data',\n",
       "  'aggregates',\n",
       "  'information',\n",
       "  'about',\n",
       "  'a',\n",
       "  'business',\n",
       "  'through',\n",
       "  'formats',\n",
       "  'such',\n",
       "  'as',\n",
       "  'social',\n",
       "  'media',\n",
       "  'ecommerce',\n",
       "  'online',\n",
       "  'transactions',\n",
       "  'and',\n",
       "  'financial',\n",
       "  'transactions',\n",
       "  'and',\n",
       "  'identifies',\n",
       "  'patterns',\n",
       "  'and',\n",
       "  'trends',\n",
       "  'for',\n",
       "  'future',\n",
       "  'use',\n",
       "  'although',\n",
       "  'ransomware',\n",
       "  'data',\n",
       "  'breaches',\n",
       "  'and',\n",
       "  'other',\n",
       "  'cybersecurity',\n",
       "  'concerns',\n",
       "  'are',\n",
       "  'nothing',\n",
       "  'new',\n",
       "  'to',\n",
       "  'the',\n",
       "  'healthcare',\n",
       "  'industry',\n",
       "  'the',\n",
       "  '2020',\n",
       "  'covid19',\n",
       "  'pandemic',\n",
       "  'revealed',\n",
       "  'just',\n",
       "  'how',\n",
       "  'vulnerable',\n",
       "  'sensitive',\n",
       "  'patient',\n",
       "  'health',\n",
       "  'information',\n",
       "  'really',\n",
       "  'is',\n",
       "  'the',\n",
       "  'recent',\n",
       "  'growth',\n",
       "  'of',\n",
       "  'digital',\n",
       "  'health',\n",
       "  'initiatives',\n",
       "  'like',\n",
       "  'telehealth',\n",
       "  'doctor',\n",
       "  'visits',\n",
       "  'is',\n",
       "  'a',\n",
       "  'major',\n",
       "  'contributor',\n",
       "  'to',\n",
       "  'the',\n",
       "  'severe',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'breached',\n",
       "  'patient',\n",
       "  'records',\n",
       "  'as',\n",
       "  'more',\n",
       "  'healthcare',\n",
       "  'functions',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'move',\n",
       "  'online',\n",
       "  'over',\n",
       "  'the',\n",
       "  'next',\n",
       "  'year',\n",
       "  'its',\n",
       "  'extremely',\n",
       "  'important',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'these',\n",
       "  'processes',\n",
       "  'are',\n",
       "  'protected',\n",
       "  'from',\n",
       "  'outside',\n",
       "  'threats',\n",
       "  'medical',\n",
       "  'practices',\n",
       "  'are',\n",
       "  'citing',\n",
       "  'patient',\n",
       "  'collections',\n",
       "  'as',\n",
       "  'their',\n",
       "  'top',\n",
       "  'revenue',\n",
       "  'cycle',\n",
       "  'management',\n",
       "  'struggle',\n",
       "  'as',\n",
       "  'patients',\n",
       "  'are',\n",
       "  'becoming',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'a',\n",
       "  'larger',\n",
       "  'portion',\n",
       "  'of',\n",
       "  'their',\n",
       "  'medical',\n",
       "  'bills',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'help',\n",
       "  'encourage',\n",
       "  'patients',\n",
       "  'to',\n",
       "  'submit',\n",
       "  'payments',\n",
       "  'in',\n",
       "  'a',\n",
       "  'timely',\n",
       "  'manner',\n",
       "  'providers',\n",
       "  'must',\n",
       "  'adhere',\n",
       "  'to',\n",
       "  'patient',\n",
       "  'payment',\n",
       "  'preferences',\n",
       "  'to',\n",
       "  'meet',\n",
       "  'patient',\n",
       "  'expectations',\n",
       "  'and',\n",
       "  'improve',\n",
       "  'the',\n",
       "  'user',\n",
       "  'experience',\n",
       "  'ensure',\n",
       "  'billing',\n",
       "  'statements',\n",
       "  'are',\n",
       "  'patientfriendly',\n",
       "  'you',\n",
       "  'should',\n",
       "  'offer',\n",
       "  'paperless',\n",
       "  'statements',\n",
       "  'and',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'payment',\n",
       "  'options',\n",
       "  'eg',\n",
       "  'credit',\n",
       "  'card',\n",
       "  'etc',\n",
       "  'via',\n",
       "  'an',\n",
       "  'online',\n",
       "  'patient',\n",
       "  'portal',\n",
       "  'and',\n",
       "  'utilize',\n",
       "  'the',\n",
       "  'latest',\n",
       "  'payment',\n",
       "  'technologies',\n",
       "  'such',\n",
       "  'as',\n",
       "  'mobile',\n",
       "  'and',\n",
       "  'texttopay',\n",
       "  'new',\n",
       "  'features',\n",
       "  'like',\n",
       "  'text',\n",
       "  'or',\n",
       "  'email',\n",
       "  'reminders',\n",
       "  'help',\n",
       "  'effectively',\n",
       "  'communicate',\n",
       "  'with',\n",
       "  'patients',\n",
       "  'and',\n",
       "  'encourage',\n",
       "  'them',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'their',\n",
       "  'financial',\n",
       "  'obligations',\n",
       "  'the',\n",
       "  'medical',\n",
       "  'insurance',\n",
       "  'landscape',\n",
       "  'has',\n",
       "  'experienced',\n",
       "  'some',\n",
       "  'significant',\n",
       "  'changes',\n",
       "  'in',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'as',\n",
       "  'more',\n",
       "  'patients',\n",
       "  'are',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'a',\n",
       "  'larger',\n",
       "  'portion',\n",
       "  'of',\n",
       "  'their',\n",
       "  'healthcare',\n",
       "  'bill',\n",
       "  'they',\n",
       "  'naturally',\n",
       "  'demand',\n",
       "  'better',\n",
       "  'services',\n",
       "  'from',\n",
       "  'their',\n",
       "  'providers',\n",
       "  'healthcare',\n",
       "  'organizations',\n",
       "  'will',\n",
       "  'face',\n",
       "  'tougher',\n",
       "  'competition',\n",
       "  'in',\n",
       "  'attracting',\n",
       "  'and',\n",
       "  'retaining',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'demand',\n",
       "  'an',\n",
       "  'experience',\n",
       "  'that',\n",
       "  'matches',\n",
       "  'the',\n",
       "  'level',\n",
       "  'of',\n",
       "  'customer',\n",
       "  'service',\n",
       "  'they',\n",
       "  'expect',\n",
       "  'from',\n",
       "  'other',\n",
       "  'consumer',\n",
       "  'brands',\n",
       "  'they',\n",
       "  'demand',\n",
       "  'a',\n",
       "  'streamlined',\n",
       "  'patient',\n",
       "  'experience',\n",
       "  'so',\n",
       "  'they',\n",
       "  'can',\n",
       "  'selfservice',\n",
       "  'to',\n",
       "  'resolve',\n",
       "  'most',\n",
       "  'questions',\n",
       "  'issues',\n",
       "  'or',\n",
       "  'concerns',\n",
       "  'eg',\n",
       "  'downloading',\n",
       "  'an',\n",
       "  'immunization',\n",
       "  'record',\n",
       "  'booking',\n",
       "  'an',\n",
       "  'appointment',\n",
       "  'paying',\n",
       "  'their',\n",
       "  'bills',\n",
       "  'or',\n",
       "  'checking',\n",
       "  'their',\n",
       "  'accountinsurance',\n",
       "  'status',\n",
       "  'whenever',\n",
       "  'wherever',\n",
       "  'and',\n",
       "  'however',\n",
       "  'is',\n",
       "  'most',\n",
       "  'convenient',\n",
       "  'for',\n",
       "  'them']]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/69.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f512ea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739\n",
      "WORD COUNT 493\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5b71114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 15.787234042553191\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ccfd0c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.45233265720081134\n",
      "FOG INDEX: 6.495826679901602\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 15.787234042553191\n",
      "COMPLEX WORD COUNT: 223\n",
      "WORD COUNT: 493\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "1fd97b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1607\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 5.804582210242588\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_69.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b37bc",
   "metadata": {},
   "source": [
    "# 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a1e7683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\3249470483.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "87396076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One thought always comes to my mind…\\nWhat if we lived without that dander hanging over our heads?\\nAnd you all know what is that danger is. For more than 70 years the world has faced the very real threat of nuclear war.\\nNuclear war is a real and growing threat. The United States and Russia have left critical agreements and treaties, while actively planning to add new types of weapons to their arsenals.\\nMeanwhile, US nuclear policy remains rooted in the Cold War, increasing the risk that nuclear weapons could be used again.\\nIt doesn’t have to be this way. With the right policy changes and a commitment to diplomacy, the United States can be a leader in reducing the nuclear threat and we can also help them. But the question arises is what are the activities are being done for the prevention of nuclear holocaust?\\nAnd they are :',\n",
       " 'We provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "419e761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts=(' '.join(str(x) for x in texts[16:18]))\n",
    "URL_ID_70 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f3ac51c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 sentences in the string.\n",
      "The number of words in the string is: 187\n",
      "The number of characters in the string is: 963\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 23:11:30] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 23:11:36] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_70.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_70.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_70.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_70 = re.sub(re_punt, \"\",URL_ID_70)\n",
    "\n",
    "file = open(\"70.txt\", \"w\")\n",
    "file.write(URL_ID_70)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"70.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "0e29697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['one', 'thought', 'always', 'comes', 'to', 'my', 'mind'],\n",
       " ['what',\n",
       "  'if',\n",
       "  'we',\n",
       "  'lived',\n",
       "  'without',\n",
       "  'that',\n",
       "  'dander',\n",
       "  'hanging',\n",
       "  'over',\n",
       "  'our',\n",
       "  'heads?'],\n",
       " ['and',\n",
       "  'you',\n",
       "  'all',\n",
       "  'know',\n",
       "  'what',\n",
       "  'is',\n",
       "  'that',\n",
       "  'danger',\n",
       "  'is',\n",
       "  'for',\n",
       "  'more',\n",
       "  'than',\n",
       "  '70',\n",
       "  'years',\n",
       "  'the',\n",
       "  'world',\n",
       "  'has',\n",
       "  'faced',\n",
       "  'the',\n",
       "  'very',\n",
       "  'real',\n",
       "  'threat',\n",
       "  'of',\n",
       "  'nuclear',\n",
       "  'war'],\n",
       " ['nuclear',\n",
       "  'war',\n",
       "  'is',\n",
       "  'a',\n",
       "  'real',\n",
       "  'and',\n",
       "  'growing',\n",
       "  'threat',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  'and',\n",
       "  'russia',\n",
       "  'have',\n",
       "  'left',\n",
       "  'critical',\n",
       "  'agreements',\n",
       "  'and',\n",
       "  'treaties',\n",
       "  'while',\n",
       "  'actively',\n",
       "  'planning',\n",
       "  'to',\n",
       "  'add',\n",
       "  'new',\n",
       "  'types',\n",
       "  'of',\n",
       "  'weapons',\n",
       "  'to',\n",
       "  'their',\n",
       "  'arsenals'],\n",
       " ['meanwhile',\n",
       "  'us',\n",
       "  'nuclear',\n",
       "  'policy',\n",
       "  'remains',\n",
       "  'rooted',\n",
       "  'in',\n",
       "  'the',\n",
       "  'cold',\n",
       "  'war',\n",
       "  'increasing',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'that',\n",
       "  'nuclear',\n",
       "  'weapons',\n",
       "  'could',\n",
       "  'be',\n",
       "  'used',\n",
       "  'again'],\n",
       " ['it',\n",
       "  'doesnt',\n",
       "  'have',\n",
       "  'to',\n",
       "  'be',\n",
       "  'this',\n",
       "  'way',\n",
       "  'with',\n",
       "  'the',\n",
       "  'right',\n",
       "  'policy',\n",
       "  'changes',\n",
       "  'and',\n",
       "  'a',\n",
       "  'commitment',\n",
       "  'to',\n",
       "  'diplomacy',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  'can',\n",
       "  'be',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'in',\n",
       "  'reducing',\n",
       "  'the',\n",
       "  'nuclear',\n",
       "  'threat',\n",
       "  'and',\n",
       "  'we',\n",
       "  'can',\n",
       "  'also',\n",
       "  'help',\n",
       "  'them',\n",
       "  'but',\n",
       "  'the',\n",
       "  'question',\n",
       "  'arises',\n",
       "  'is',\n",
       "  'what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'activities',\n",
       "  'are',\n",
       "  'being',\n",
       "  'done',\n",
       "  'for',\n",
       "  'the',\n",
       "  'prevention',\n",
       "  'of',\n",
       "  'nuclear',\n",
       "  'holocaust?'],\n",
       " ['and',\n",
       "  'they',\n",
       "  'are',\n",
       "  'we',\n",
       "  'provide',\n",
       "  'intelligence',\n",
       "  'accelerate',\n",
       "  'innovation',\n",
       "  'and',\n",
       "  'implement',\n",
       "  'technology',\n",
       "  'with',\n",
       "  'extraordinary',\n",
       "  'breadth',\n",
       "  'and',\n",
       "  'depth',\n",
       "  'global',\n",
       "  'insights',\n",
       "  'into',\n",
       "  'the',\n",
       "  'big',\n",
       "  'datadatadriven',\n",
       "  'dashboards',\n",
       "  'applications',\n",
       "  'development',\n",
       "  'and',\n",
       "  'information',\n",
       "  'management',\n",
       "  'for',\n",
       "  'organizations',\n",
       "  'through',\n",
       "  'combining',\n",
       "  'unique',\n",
       "  'specialist',\n",
       "  'services',\n",
       "  'and',\n",
       "  'highlvel',\n",
       "  'human',\n",
       "  'expertise']]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/70.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "c0628ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "WORD COUNT 118\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "79b976a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 20.77777777777778\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "52657e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.2796610169491525\n",
      "FOG INDEX: 8.422975517890773\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 20.77777777777778\n",
      "COMPLEX WORD COUNT: 33\n",
      "WORD COUNT: 118\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e2a032ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 350\n",
      "I: 0\n",
      "we: 3\n",
      "my: 1\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 5\n",
      "PERSONAL PRONOUNS: 5\n",
      "AVG WORD LENGTH: 5.149732620320855\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_70.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9eb1db",
   "metadata": {},
   "source": [
    "# 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "21151702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\1093270288.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9b88b691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Imagine yourself as a being who can speak but no one can comprehend you. You are kept in captivity, in a place where you can hardly breathe. You are finally selected and taken out of that place, it is a happy moment for you. You can finally have your freedom but sadly instead of being free, you are prodded by rods and fed toxic substances against your will. The only thing you can do is scream in vain. Your voice is heard by everyone but it gets lost in the noise of scientific advancement. You writhe in pain as the substances take effect on your body, the pain slowly creeps into your body and you slowly succumb to it, never to wake up again.  ',\n",
       " 'Since the time of Aristotle, animals have been subjected to various inhumane experiments for the sake of knowledge. These experiments though unethical were very necessary for the advancement of science. Animal testing has become an important part of experimenting on living organisms to ensure that a product is safe for humans to consume. The lab animals are generally subjected to high levels of toxicity while being kept in isolation due to which they have to suffer a lot of stress and discomfort. Animal testing has a large number of drawbacks:',\n",
       " 'All of these things make us question ourselves. Is it even worth it? Is it possible to stop this cruelty without hampering our growth?',\n",
       " 'With the advancement in science, it can be made possible that we don’t have to use animals ever again.  ',\n",
       " 'These bio-printed models can also be used by the researchers to conduct experiments on them without using animals for it. A French company is working on a bio-printed liver model to test liver toxicity without having to use animals at all. This is a breakthrough in the field of bio-technology as it can bring down animal experimentation by a large percentage.   ',\n",
       " 'These alternatives can help in bringing down animal experimentation to a large extent. If science can progress without harming animals then we should go for it rather than putting them through excruciating pain. We must protect the animals as much as we can or else we would soon be living in a world without them. ']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[17:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "0ab6c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:23]))\n",
    "URL_ID_71 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a3d20e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 sentences in the string.\n",
      "The number of words in the string is: 383\n",
      "The number of characters in the string is: 1813\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 23:33:49] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 23:33:54] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_71.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_71.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_71.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_71 = re.sub(re_punt, \"\",URL_ID_71)\n",
    "\n",
    "file = open(\"71.txt\", \"w\")\n",
    "file.write(URL_ID_71)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"71.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "97c0f305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['advanced',\n",
       "  'computing',\n",
       "  'tissue',\n",
       "  'culture',\n",
       "  '3d',\n",
       "  'printing',\n",
       "  'organonachip',\n",
       "  'method',\n",
       "  'micro',\n",
       "  'dosing',\n",
       "  'imagine',\n",
       "  'yourself',\n",
       "  'as',\n",
       "  'a',\n",
       "  'being',\n",
       "  'who',\n",
       "  'can',\n",
       "  'speak',\n",
       "  'but',\n",
       "  'no',\n",
       "  'one',\n",
       "  'can',\n",
       "  'comprehend',\n",
       "  'you',\n",
       "  'you',\n",
       "  'are',\n",
       "  'kept',\n",
       "  'in',\n",
       "  'captivity',\n",
       "  'in',\n",
       "  'a',\n",
       "  'place',\n",
       "  'where',\n",
       "  'you',\n",
       "  'can',\n",
       "  'hardly',\n",
       "  'breathe',\n",
       "  'you',\n",
       "  'are',\n",
       "  'finally',\n",
       "  'selected',\n",
       "  'and',\n",
       "  'taken',\n",
       "  'out',\n",
       "  'of',\n",
       "  'that',\n",
       "  'place',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'happy',\n",
       "  'moment',\n",
       "  'for',\n",
       "  'you',\n",
       "  'you',\n",
       "  'can',\n",
       "  'finally',\n",
       "  'have',\n",
       "  'your',\n",
       "  'freedom',\n",
       "  'but',\n",
       "  'sadly',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'being',\n",
       "  'free',\n",
       "  'you',\n",
       "  'are',\n",
       "  'prodded',\n",
       "  'by',\n",
       "  'rods',\n",
       "  'and',\n",
       "  'fed',\n",
       "  'toxic',\n",
       "  'substances',\n",
       "  'against',\n",
       "  'your',\n",
       "  'will',\n",
       "  'the',\n",
       "  'only',\n",
       "  'thing',\n",
       "  'you',\n",
       "  'can',\n",
       "  'do',\n",
       "  'is',\n",
       "  'scream',\n",
       "  'in',\n",
       "  'vain',\n",
       "  'your',\n",
       "  'voice',\n",
       "  'is',\n",
       "  'heard',\n",
       "  'by',\n",
       "  'everyone',\n",
       "  'but',\n",
       "  'it',\n",
       "  'gets',\n",
       "  'lost',\n",
       "  'in',\n",
       "  'the',\n",
       "  'noise',\n",
       "  'of',\n",
       "  'scientific',\n",
       "  'advancement',\n",
       "  'you',\n",
       "  'writhe',\n",
       "  'in',\n",
       "  'pain',\n",
       "  'as',\n",
       "  'the',\n",
       "  'substances',\n",
       "  'take',\n",
       "  'effect',\n",
       "  'on',\n",
       "  'your',\n",
       "  'body',\n",
       "  'the',\n",
       "  'pain',\n",
       "  'slowly',\n",
       "  'creeps',\n",
       "  'into',\n",
       "  'your',\n",
       "  'body',\n",
       "  'and',\n",
       "  'you',\n",
       "  'slowly',\n",
       "  'succumb',\n",
       "  'to',\n",
       "  'it',\n",
       "  'never',\n",
       "  'to',\n",
       "  'wake',\n",
       "  'up',\n",
       "  'again',\n",
       "  'since',\n",
       "  'the',\n",
       "  'time',\n",
       "  'of',\n",
       "  'aristotle',\n",
       "  'animals',\n",
       "  'have',\n",
       "  'been',\n",
       "  'subjected',\n",
       "  'to',\n",
       "  'various',\n",
       "  'inhumane',\n",
       "  'experiments',\n",
       "  'for',\n",
       "  'the',\n",
       "  'sake',\n",
       "  'of',\n",
       "  'knowledge',\n",
       "  'these',\n",
       "  'experiments',\n",
       "  'though',\n",
       "  'unethical',\n",
       "  'were',\n",
       "  'very',\n",
       "  'necessary',\n",
       "  'for',\n",
       "  'the',\n",
       "  'advancement',\n",
       "  'of',\n",
       "  'science',\n",
       "  'animal',\n",
       "  'testing',\n",
       "  'has',\n",
       "  'become',\n",
       "  'an',\n",
       "  'important',\n",
       "  'part',\n",
       "  'of',\n",
       "  'experimenting',\n",
       "  'on',\n",
       "  'living',\n",
       "  'organisms',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'that',\n",
       "  'a',\n",
       "  'product',\n",
       "  'is',\n",
       "  'safe',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'to',\n",
       "  'consume',\n",
       "  'the',\n",
       "  'lab',\n",
       "  'animals',\n",
       "  'are',\n",
       "  'generally',\n",
       "  'subjected',\n",
       "  'to',\n",
       "  'high',\n",
       "  'levels',\n",
       "  'of',\n",
       "  'toxicity',\n",
       "  'while',\n",
       "  'being',\n",
       "  'kept',\n",
       "  'in',\n",
       "  'isolation',\n",
       "  'due',\n",
       "  'to',\n",
       "  'which',\n",
       "  'they',\n",
       "  'have',\n",
       "  'to',\n",
       "  'suffer',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'stress',\n",
       "  'and',\n",
       "  'discomfort',\n",
       "  'animal',\n",
       "  'testing',\n",
       "  'has',\n",
       "  'a',\n",
       "  'large',\n",
       "  'number',\n",
       "  'of',\n",
       "  'drawbacks',\n",
       "  'all',\n",
       "  'of',\n",
       "  'these',\n",
       "  'things',\n",
       "  'make',\n",
       "  'us',\n",
       "  'question',\n",
       "  'ourselves',\n",
       "  'is',\n",
       "  'it',\n",
       "  'even',\n",
       "  'worth',\n",
       "  'it?',\n",
       "  'is',\n",
       "  'it',\n",
       "  'possible',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'this',\n",
       "  'cruelty',\n",
       "  'without',\n",
       "  'hampering',\n",
       "  'our',\n",
       "  'growth?',\n",
       "  'with',\n",
       "  'the',\n",
       "  'advancement',\n",
       "  'in',\n",
       "  'science',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'made',\n",
       "  'possible',\n",
       "  'that',\n",
       "  'we',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'to',\n",
       "  'use',\n",
       "  'animals',\n",
       "  'ever',\n",
       "  'again',\n",
       "  'these',\n",
       "  'bioprinted',\n",
       "  'models',\n",
       "  'can',\n",
       "  'also',\n",
       "  'be',\n",
       "  'used',\n",
       "  'by',\n",
       "  'the',\n",
       "  'researchers',\n",
       "  'to',\n",
       "  'conduct',\n",
       "  'experiments',\n",
       "  'on',\n",
       "  'them',\n",
       "  'without',\n",
       "  'using',\n",
       "  'animals',\n",
       "  'for',\n",
       "  'it',\n",
       "  'a',\n",
       "  'french',\n",
       "  'company',\n",
       "  'is',\n",
       "  'working',\n",
       "  'on',\n",
       "  'a',\n",
       "  'bioprinted',\n",
       "  'liver',\n",
       "  'model',\n",
       "  'to',\n",
       "  'test',\n",
       "  'liver',\n",
       "  'toxicity',\n",
       "  'without',\n",
       "  'having',\n",
       "  'to',\n",
       "  'use',\n",
       "  'animals',\n",
       "  'at',\n",
       "  'all',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'breakthrough',\n",
       "  'in',\n",
       "  'the',\n",
       "  'field',\n",
       "  'of',\n",
       "  'biotechnology',\n",
       "  'as',\n",
       "  'it',\n",
       "  'can',\n",
       "  'bring',\n",
       "  'down',\n",
       "  'animal',\n",
       "  'experimentation',\n",
       "  'by',\n",
       "  'a',\n",
       "  'large',\n",
       "  'percentage',\n",
       "  'these',\n",
       "  'alternatives',\n",
       "  'can',\n",
       "  'help',\n",
       "  'in',\n",
       "  'bringing',\n",
       "  'down',\n",
       "  'animal',\n",
       "  'experimentation',\n",
       "  'to',\n",
       "  'a',\n",
       "  'large',\n",
       "  'extent',\n",
       "  'if',\n",
       "  'science',\n",
       "  'can',\n",
       "  'progress',\n",
       "  'without',\n",
       "  'harming',\n",
       "  'animals',\n",
       "  'then',\n",
       "  'we',\n",
       "  'should',\n",
       "  'go',\n",
       "  'for',\n",
       "  'it',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'putting',\n",
       "  'them',\n",
       "  'through',\n",
       "  'excruciating',\n",
       "  'pain',\n",
       "  'we',\n",
       "  'must',\n",
       "  'protect',\n",
       "  'the',\n",
       "  'animals',\n",
       "  'as',\n",
       "  'much',\n",
       "  'as',\n",
       "  'we',\n",
       "  'can',\n",
       "  'or',\n",
       "  'else',\n",
       "  'we',\n",
       "  'would',\n",
       "  'soon',\n",
       "  'be',\n",
       "  'living',\n",
       "  'in',\n",
       "  'a',\n",
       "  'world',\n",
       "  'without',\n",
       "  'them']]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/71.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "38970884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n",
      "WORD COUNT 228\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "17c4a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 19.15\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0730de45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.2631578947368421\n",
      "FOG INDEX: 7.765263157894736\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 19.15\n",
      "COMPLEX WORD COUNT: 60\n",
      "WORD COUNT: 228\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "198224f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 683\n",
      "I: 0\n",
      "we: 5\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 6\n",
      "PERSONAL PRONOUNS: 6\n",
      "AVG WORD LENGTH: 4.733681462140992\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_71.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c7fbf",
   "metadata": {},
   "source": [
    "# 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "c956ebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\3657932406.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "60e8b075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Introduction',\n",
       " 'The definition of consciousness has been controversial for centuries, hence it is given the title of the ‘most familiar and yet mysterious aspects of our lives’. An idea of this concept would be an awareness in beings of their surroundings, themselves, and their own perception. The reason this part of our mind remains unascertained is that consciousness isn’t observable, unlike brain matter that is studied scientifically. the physical clarification of awareness is in a general sense incomplete: it doesn’t include what it feels to be the subject, for the subject. There likewise is by all accounts an unbridgeable illustrative gap between the physical world and our consciousness. As suggested by an incident of Eastern and Shamir traditions, consciousness is both universal and primal. Whilst we have made tremendous progress in understanding brain activity over the years, this research hasn’t been able to answer all the questions relating to the nature of emotions and experiences.',\n",
       " 'History',\n",
       " 'Beginning within the late nineteenth century, this was a time that once had psychological queries driven by a philosophical understanding of the mind, which was typically equated with consciousness. As a result, the analysis of brain and behavior naturally thought of the role of consciousness in behavioral management by the brain.',\n",
       " 'The Ancient Mayans were among the first to propose a sorted out feeling of each degree of consciousness, its purpose, and its worldly association with mankind. Since consciousness incorporates stimuli from nature as well as interior stimuli, the Mayans trusted it to be the most essential type of existence, equipped for evolution. The Incas, however, thought about consciousness as a movement of mindfulness as well as of worry for others too.',\n",
       " 'John Locke, an early philosopher, said that consciousness, and so individuality, are freelanced of all substances. He also detected that there is no reason to believe that consciousness is stuck to any specific body or mind, or that consciousness cannot be transferred from one body or mind to a different one. Karl Marx, another early thinker, denies the mind-body classification and holds that consciousness is jeopardized by the material eventualities of one’s settings. William James, an American psychologist, differentiated consciousness to a stream – unbroken and continuous despite several changes and shifts.',\n",
       " 'While the main center of a lot of the analysis moved to strictly note cable behaviors throughout the primary half of the twentieth century, analysis of human consciousness has grown staggeringly after the 1950s.',\n",
       " 'In Sigmund Freud’s psychoanalytic theory, we can see that he believed that all three levels of awareness- preconscious, conscious, and unconscious were responsible for one’s behavior and thinking. He believed that the mid itself was divided into three parts- the id, the ego, and the superego. The Id is present at birth, instinctual, and operates according to the pleasure principle. The ego underseals reality and logic and develops out of the id in infancy. Finally, the superego is an internalization of society’s moral standards and responsible for guilt. Now, the Id is regarded as unconscious, whereas the ego and superego are also conscious and preconscious. Freud constantly revised his own clinical qualities researches, however, and didn’t conduct scientific experiments and hence his work is heavily scrutinized, leaving the questions unanswered.  ',\n",
       " 'Sigmund Freud’s theory differed from the other psychologists since his theories were more understandable and very easily conveyed to the people. Sigmund Freud’s work and hypotheses helped people shape their perspectives on youth, character, memory, sexuality, and therapy. However, his theories were subject to considerable criticism both now and during his own life. Whilst John Locke and William James took a more practical approach to the mystery by conducting experiments, Sigmund Freud didn’t provide any evidence to support his claims.',\n",
       " 'Brain',\n",
       " 'Today, the essential focal point of consciousness research is on understanding what consciousness implies both biologically and mentally. Issues of interest include phenomena such as perception, blindsight, brainwaves during sleep, and altered states of consciousness produced by psychoactive drugs.',\n",
       " 'A greater part of the test assesses consciousness by approaching human subjects for a verbal report of their encounters. However, to confirm the criticalness of these verbal reports, researchers must contrast them with the action that all the while happens in the brain —that is, they should search for the neural connections of consciousness.',\n",
       " 'Hope is to locate that noticeable action in a specific aspect of the brain, or a particular pattern of global brain activity, will be greatly predictive of consciousness mindfulness. A few brain imaging strategies, for example, EEG and MRI scans, have been utilized for physical proportions of brain activities in these examinations.',\n",
       " 'A few investigations have shown that movement in essential primary sensory areas of the brain isn’t adequate to create consciousness: it is workable for subjects to report an absence of awareness in any event, when areas, for example, the primary visual cortex show clear electrical reactions to a stimulus. Higher brain areas are viewed as all the more encouraging, particularly the prefrontal cortex, which is involved in a range of high order functions.',\n",
       " 'One mainstream theory implicates various examples of brain waves in creating various conditions of consciousness. Analysts can record mind waves, or drawings of electrical movement inside the cerebrum, using an electroencephalograph (EEG) and placing electrodes on the scalp. The four types of brain waves (alpha, beta, theta, and delta) each correspond with one mental state (relaxed, alert, lightly asleep, and deeply asleep)',\n",
       " 'Memory',\n",
       " 'Episodic memory can be regarded as the only form of conscious memory. This is because it is the capacity to consciously remember personally experienced events and situations in the past. The hippocampus located in the brain’s temporal lobe is responsible for this type of memory.',\n",
       " 'Consciousness also plays a part in important memory distinctions. One such distinction is the implicit and explicit characteristics; in which explicit memory is what you consciously know and implicit memory includes events you may not be conscious of.',\n",
       " 'Furthermore, several empirical findings suggest that declarative memory is related to consciousness as well; meaning that the retrieval and formation of this memory are connected to awareness. Working memory operates/maintains consciously perceived information as well since it temporarily stores and tampers with information whilst working on tasks.',\n",
       " 'The current ways of testing this information are lacking in several essential aspects, including spatial resolution, temporal resolution, or scope. Examples of such methods are PET, fMRI, EEG, implanted electrodes, etc.',\n",
       " 'PET and fMRI have temporal resolution problems, EEG is well-known to have localizability difficulties, and implanted electrodes whilst great in temporal and spatial resolution can only test a set number of neurons; that is, they are restricted in scope. Hence, huge numbers of our speculations, while testable on a fundamental level, appear to be difficult to test as of now.',\n",
       " 'Mental illness',\n",
       " 'Consciousness has an influence on the way we see objects around us, which encourages us to settle on choices about how to communicate with them. Experiencing difficulty perceiving objects is connected to a few problems, for example, agnosia (a failure to decipher visual data), Alzheimer’s disease, and autism. However, we actually don’t comprehend what visual data is basic for the mind to intentionally perceive an object.',\n",
       " 'Several different disorders of consciousness include locked-in syndrome, minimally conscious state, persistent vegetative state, chronic coma, and brain death.',\n",
       " 'Locked-in syndrome, otherwise called pseudo coma, is a condition wherein a patient is aware however can’t move or impart verbally because of complete loss of motion of essentially all voluntary muscles in the body aside from vertical eye developments and squinting. The individual is conscious and is able to speak with eye movements.',\n",
       " 'In a minimally conscious state, the patient has intermittent periods of awareness and wakefulness. Patients need to give restricted, however reproducible indications of consciousness of themself or their current circumstance. This could be following straightforward orders, comprehensible speech, or purposeful conduct.',\n",
       " 'In a persistent vegetative state, the patient has sleep-wake cycles, but lacks awareness, is not able to communicate, and only displays reflexive and non-purposeful behavior. The term refers to an organic body that is able to grow and develop devoid of intellectual activity or social intercourse',\n",
       " 'Like coma, chronic coma results generally from cortical or white-matter harm after neuronal or axonal injury, or from central brainstem sores. Usually, the metabolism in the grey matter decreases to 50-70% of the normal range. The patient lies with eyes shut and doesn’t know about self or environmental factors.',\n",
       " 'Brain death is the irreversible end of all brain activity, and function (including involuntary activity necessary to sustain life). The main cause is total necrosis of the cerebral neurons following loss of brain oxygenation. After brain death the patient lacks any sense of awareness; sleep-wake cycles or behavior, and typically look as if they are dead or are in a deep sleep state.',\n",
       " 'Future predictions and conclusion',\n",
       " 'As we can see from the history of scholar’s endeavors to study consciousness empirically, its nature is not one that can be defined using scientific methods. In the past, psychologists such as Descartes came up with dualistic theories that did not line up with the fundamental laws of physics. In the battle between realists and illusionists, taking sides is fundamentally impossible as the topic doesn’t allow for concrete evidence.',\n",
       " 'As we can observe from neural examinations of the brain to detect the causes of consciousness, there is no sensory sector of the brain that is the cause for one to be aware during a certain event even if there are clear signs of a reaction to a stimulus. Similarly, even though consciousness plays a major role in memory, we currently lack the facilities to research it fully. In the future, there is a possibility that we will be able to access such facilities, however, which could allow us to find the neural connections and its ties to mental illness as well. Not only would this help several people by making us aware of the causes of our perspective on certain things, but it would also give us a better chance of recognizing signs of possible mental illness or other issues beforehand.',\n",
       " 'As it seems, researchers continue to study this unknown part of our mind and once we are able to fund and recover from the global pandemic, we will be able to answer one of psychology’s most difficult questions.']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "65989735",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:49]))\n",
    "URL_ID_72 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "bed51b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74 sentences in the string.\n",
      "The number of words in the string is: 1719\n",
      "The number of characters in the string is: 9464\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Apr/2023 23:49:02] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Apr/2023 23:49:09] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_72.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_72.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_72.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_72 = re.sub(re_punt, \"\",URL_ID_72)\n",
    "\n",
    "file = open(\"72.txt\", \"w\")\n",
    "file.write(URL_ID_72)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"72.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "9644fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['introduction',\n",
       "  'history',\n",
       "  'brain',\n",
       "  'memory',\n",
       "  'mental',\n",
       "  'illness',\n",
       "  'future',\n",
       "  'predictions',\n",
       "  'and',\n",
       "  'conclusion',\n",
       "  'introduction',\n",
       "  'the',\n",
       "  'definition',\n",
       "  'of',\n",
       "  'consciousness',\n",
       "  'has',\n",
       "  'been',\n",
       "  'controversial',\n",
       "  'for',\n",
       "  'centuries',\n",
       "  'hence',\n",
       "  'it',\n",
       "  'is',\n",
       "  'given',\n",
       "  'the',\n",
       "  'title',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'familiar',\n",
       "  'and',\n",
       "  'yet',\n",
       "  'mysterious',\n",
       "  'aspects',\n",
       "  'of',\n",
       "  'our',\n",
       "  'lives',\n",
       "  'an',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'this',\n",
       "  'concept',\n",
       "  'would',\n",
       "  'be',\n",
       "  'an',\n",
       "  'awareness',\n",
       "  'in',\n",
       "  'beings',\n",
       "  'of',\n",
       "  'their',\n",
       "  'surroundings',\n",
       "  'themselves',\n",
       "  'and',\n",
       "  'their',\n",
       "  'own',\n",
       "  'perception',\n",
       "  'the',\n",
       "  'reason',\n",
       "  'this',\n",
       "  'part',\n",
       "  'of',\n",
       "  'our',\n",
       "  'mind',\n",
       "  'remains',\n",
       "  'unascertained',\n",
       "  'is',\n",
       "  'that',\n",
       "  'consciousness',\n",
       "  'isnt',\n",
       "  'observable',\n",
       "  'unlike',\n",
       "  'brain',\n",
       "  'matter',\n",
       "  'that',\n",
       "  'is',\n",
       "  'studied',\n",
       "  'scientifically',\n",
       "  'the',\n",
       "  'physical',\n",
       "  'clarification',\n",
       "  'of',\n",
       "  'awareness',\n",
       "  'is',\n",
       "  'in',\n",
       "  'a',\n",
       "  'general',\n",
       "  'sense',\n",
       "  'incomplete',\n",
       "  'it',\n",
       "  'doesnt',\n",
       "  'include',\n",
       "  'what',\n",
       "  'it',\n",
       "  'feels',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'subject',\n",
       "  'for',\n",
       "  'the',\n",
       "  'subject',\n",
       "  'there',\n",
       "  'likewise',\n",
       "  'is',\n",
       "  'by',\n",
       "  'all',\n",
       "  'accounts',\n",
       "  'an',\n",
       "  'unbridgeable',\n",
       "  'illustrative',\n",
       "  'gap',\n",
       "  'between',\n",
       "  'the',\n",
       "  'physical',\n",
       "  'world',\n",
       "  'and',\n",
       "  'our',\n",
       "  'consciousness',\n",
       "  'as',\n",
       "  'suggested',\n",
       "  'by',\n",
       "  'an',\n",
       "  'incident',\n",
       "  'of',\n",
       "  'eastern',\n",
       "  'and',\n",
       "  'shamir',\n",
       "  'traditions',\n",
       "  'consciousness',\n",
       "  'is',\n",
       "  'both',\n",
       "  'universal',\n",
       "  'and',\n",
       "  'primal',\n",
       "  'whilst',\n",
       "  'we',\n",
       "  'have',\n",
       "  'made',\n",
       "  'tremendous',\n",
       "  'progress',\n",
       "  'in',\n",
       "  'understanding',\n",
       "  'brain',\n",
       "  'activity',\n",
       "  'over',\n",
       "  'the',\n",
       "  'years',\n",
       "  'this',\n",
       "  'research',\n",
       "  'hasnt',\n",
       "  'been',\n",
       "  'able',\n",
       "  'to',\n",
       "  'answer',\n",
       "  'all',\n",
       "  'the',\n",
       "  'questions',\n",
       "  'relating',\n",
       "  'to',\n",
       "  'the',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'emotions',\n",
       "  'and',\n",
       "  'experiences',\n",
       "  'history',\n",
       "  'beginning',\n",
       "  'within',\n",
       "  'the',\n",
       "  'late',\n",
       "  'nineteenth',\n",
       "  'century',\n",
       "  'this',\n",
       "  'was',\n",
       "  'a',\n",
       "  'time',\n",
       "  'that',\n",
       "  'once',\n",
       "  'had',\n",
       "  'psychological',\n",
       "  'queries',\n",
       "  'driven',\n",
       "  'by',\n",
       "  'a',\n",
       "  'philosophical',\n",
       "  'understanding',\n",
       "  'of',\n",
       "  'the',\n",
       "  'mind',\n",
       "  'which',\n",
       "  'was',\n",
       "  'typically',\n",
       "  'equated',\n",
       "  'with',\n",
       "  'consciousness',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'the',\n",
       "  'analysis',\n",
       "  'of',\n",
       "  'brain',\n",
       "  'and',\n",
       "  'behavior',\n",
       "  'naturally',\n",
       "  'thought',\n",
       "  'of',\n",
       "  'the',\n",
       "  'role',\n",
       "  'of',\n",
       "  'consciousness',\n",
       "  'in',\n",
       "  'behavioral',\n",
       "  'management',\n",
       "  'by',\n",
       "  'the',\n",
       "  'brain',\n",
       "  'the',\n",
       "  'ancient',\n",
       "  'mayans',\n",
       "  'were',\n",
       "  'among',\n",
       "  'the',\n",
       "  'first',\n",
       "  'to',\n",
       "  'propose',\n",
       "  'a',\n",
       "  'sorted',\n",
       "  'out',\n",
       "  'feeling',\n",
       "  'of',\n",
       "  'each',\n",
       "  'degree',\n",
       "  'of',\n",
       "  'consciousness',\n",
       "  'its',\n",
       "  'purpose',\n",
       "  'and',\n",
       "  'its',\n",
       "  'worldly',\n",
       "  'association',\n",
       "  'with',\n",
       "  'mankind',\n",
       "  'since',\n",
       "  'consciousness',\n",
       "  'incorporates',\n",
       "  'stimuli',\n",
       "  'from',\n",
       "  'nature',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'interior',\n",
       "  'stimuli',\n",
       "  'the',\n",
       "  'mayans',\n",
       "  'trusted',\n",
       "  'it',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'most',\n",
       "  'essential',\n",
       "  'type',\n",
       "  'of',\n",
       "  'existence',\n",
       "  'equipped',\n",
       "  'for',\n",
       "  'evolution',\n",
       "  'the',\n",
       "  'incas',\n",
       "  'however',\n",
       "  'thought',\n",
       "  'about',\n",
       "  'consciousness',\n",
       "  'as',\n",
       "  'a',\n",
       "  'movement',\n",
       "  'of',\n",
       "  'mindfulness',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'of',\n",
       "  'worry',\n",
       "  'for',\n",
       "  'others',\n",
       "  'too',\n",
       "  'john',\n",
       "  'locke',\n",
       "  'an',\n",
       "  'early',\n",
       "  'philosopher',\n",
       "  'said',\n",
       "  'that',\n",
       "  'consciousness',\n",
       "  'and',\n",
       "  'so',\n",
       "  'individuality',\n",
       "  'are',\n",
       "  'freelanced',\n",
       "  'of',\n",
       "  'all',\n",
       "  'substances',\n",
       "  'he',\n",
       "  'also',\n",
       "  'detected',\n",
       "  'that',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'reason',\n",
       "  'to',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'consciousness',\n",
       "  'is',\n",
       "  'stuck',\n",
       "  'to',\n",
       "  'any',\n",
       "  'specific',\n",
       "  'body',\n",
       "  'or',\n",
       "  'mind',\n",
       "  'or',\n",
       "  'that',\n",
       "  'consciousness',\n",
       "  'cannot',\n",
       "  'be',\n",
       "  'transferred',\n",
       "  'from',\n",
       "  'one',\n",
       "  'body',\n",
       "  'or',\n",
       "  'mind',\n",
       "  'to',\n",
       "  'a',\n",
       "  'different',\n",
       "  'one',\n",
       "  'karl',\n",
       "  'marx',\n",
       "  'another',\n",
       "  'early',\n",
       "  'thinker',\n",
       "  'denies',\n",
       "  'the',\n",
       "  'mindbody',\n",
       "  'classification',\n",
       "  'and',\n",
       "  'holds',\n",
       "  'that',\n",
       "  'consciousness',\n",
       "  'is',\n",
       "  'jeopardized',\n",
       "  'by',\n",
       "  'the',\n",
       "  'material',\n",
       "  'eventualities',\n",
       "  'of',\n",
       "  'ones',\n",
       "  'settings',\n",
       "  'william',\n",
       "  'james',\n",
       "  'an',\n",
       "  'american',\n",
       "  'psychologist',\n",
       "  'differentiated',\n",
       "  'consciousness',\n",
       "  'to',\n",
       "  'a',\n",
       "  'stream',\n",
       "  'unbroken',\n",
       "  'and',\n",
       "  'continuous',\n",
       "  'despite',\n",
       "  'several',\n",
       "  'changes',\n",
       "  'and',\n",
       "  'shifts',\n",
       "  'while',\n",
       "  'the',\n",
       "  'main',\n",
       "  'center',\n",
       "  'of',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'the',\n",
       "  'analysis',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'strictly',\n",
       "  'note',\n",
       "  'cable',\n",
       "  'behaviors',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'primary',\n",
       "  'half',\n",
       "  'of',\n",
       "  'the',\n",
       "  'twentieth',\n",
       "  'century',\n",
       "  'analysis',\n",
       "  'of',\n",
       "  'human',\n",
       "  'consciousness',\n",
       "  'has',\n",
       "  'grown',\n",
       "  'staggeringly',\n",
       "  'after',\n",
       "  'the',\n",
       "  '1950s',\n",
       "  'in',\n",
       "  'sigmund',\n",
       "  'freuds',\n",
       "  'psychoanalytic',\n",
       "  'theory',\n",
       "  'we',\n",
       "  'can',\n",
       "  'see',\n",
       "  'that',\n",
       "  'he',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'all',\n",
       "  'three',\n",
       "  'levels',\n",
       "  'of',\n",
       "  'awareness',\n",
       "  'preconscious',\n",
       "  'conscious',\n",
       "  'and',\n",
       "  'unconscious',\n",
       "  'were',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'ones',\n",
       "  'behavior',\n",
       "  'and',\n",
       "  'thinking',\n",
       "  'he',\n",
       "  'believed',\n",
       "  'that',\n",
       "  'the',\n",
       "  'mid',\n",
       "  'itself',\n",
       "  'was',\n",
       "  'divided',\n",
       "  'into',\n",
       "  'three',\n",
       "  'parts',\n",
       "  'the',\n",
       "  'id',\n",
       "  'the',\n",
       "  'ego',\n",
       "  'and',\n",
       "  'the',\n",
       "  'superego',\n",
       "  'the',\n",
       "  'id',\n",
       "  'is',\n",
       "  'present',\n",
       "  'at',\n",
       "  'birth',\n",
       "  'instinctual',\n",
       "  'and',\n",
       "  'operates',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pleasure',\n",
       "  'principle',\n",
       "  'the',\n",
       "  'ego',\n",
       "  'underseals',\n",
       "  'reality',\n",
       "  'and',\n",
       "  'logic',\n",
       "  'and',\n",
       "  'develops',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'id',\n",
       "  'in',\n",
       "  'infancy',\n",
       "  'finally',\n",
       "  'the',\n",
       "  'superego',\n",
       "  'is',\n",
       "  'an',\n",
       "  'internalization',\n",
       "  'of',\n",
       "  'societys',\n",
       "  'moral',\n",
       "  'standards',\n",
       "  'and',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'guilt',\n",
       "  'now',\n",
       "  'the',\n",
       "  'id',\n",
       "  'is',\n",
       "  'regarded',\n",
       "  'as',\n",
       "  'unconscious',\n",
       "  'whereas',\n",
       "  'the',\n",
       "  'ego',\n",
       "  'and',\n",
       "  'superego',\n",
       "  'are',\n",
       "  'also',\n",
       "  'conscious',\n",
       "  'and',\n",
       "  'preconscious',\n",
       "  'freud',\n",
       "  'constantly',\n",
       "  'revised',\n",
       "  'his',\n",
       "  'own',\n",
       "  'clinical',\n",
       "  'qualities',\n",
       "  'researches',\n",
       "  'however',\n",
       "  'and',\n",
       "  'didnt',\n",
       "  'conduct',\n",
       "  'scientific',\n",
       "  'experiments',\n",
       "  'and',\n",
       "  'hence',\n",
       "  'his',\n",
       "  'work',\n",
       "  'is',\n",
       "  'heavily',\n",
       "  'scrutinized',\n",
       "  'leaving',\n",
       "  'the',\n",
       "  'questions',\n",
       "  'unanswered',\n",
       "  'sigmund',\n",
       "  'freuds',\n",
       "  'theory',\n",
       "  'differed',\n",
       "  'from',\n",
       "  'the',\n",
       "  'other',\n",
       "  'psychologists',\n",
       "  'since',\n",
       "  'his',\n",
       "  'theories',\n",
       "  'were',\n",
       "  'more',\n",
       "  'understandable',\n",
       "  'and',\n",
       "  'very',\n",
       "  'easily',\n",
       "  'conveyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'people',\n",
       "  'sigmund',\n",
       "  'freuds',\n",
       "  'work',\n",
       "  'and',\n",
       "  'hypotheses',\n",
       "  'helped',\n",
       "  'people',\n",
       "  'shape',\n",
       "  'their',\n",
       "  'perspectives',\n",
       "  'on',\n",
       "  'youth',\n",
       "  'character',\n",
       "  'memory',\n",
       "  'sexuality',\n",
       "  'and',\n",
       "  'therapy',\n",
       "  'however',\n",
       "  'his',\n",
       "  'theories',\n",
       "  'were',\n",
       "  'subject',\n",
       "  'to',\n",
       "  'considerable',\n",
       "  'criticism',\n",
       "  'both',\n",
       "  'now',\n",
       "  'and',\n",
       "  'during',\n",
       "  'his',\n",
       "  'own',\n",
       "  'life',\n",
       "  'whilst',\n",
       "  'john',\n",
       "  'locke',\n",
       "  'and',\n",
       "  'william',\n",
       "  'james',\n",
       "  'took',\n",
       "  'a',\n",
       "  'more',\n",
       "  'practical',\n",
       "  'approach',\n",
       "  'to',\n",
       "  'the',\n",
       "  'mystery',\n",
       "  'by',\n",
       "  'conducting',\n",
       "  'experiments',\n",
       "  'sigmund',\n",
       "  'freud',\n",
       "  'didnt',\n",
       "  'provide',\n",
       "  'any',\n",
       "  'evidence',\n",
       "  'to',\n",
       "  'support',\n",
       "  'his',\n",
       "  'claims',\n",
       "  'brain',\n",
       "  'today',\n",
       "  'the',\n",
       "  'essential',\n",
       "  'focal',\n",
       "  'point',\n",
       "  'of',\n",
       "  'consciousness',\n",
       "  'research',\n",
       "  'is',\n",
       "  'on',\n",
       "  'understanding',\n",
       "  'what',\n",
       "  'consciousness',\n",
       "  'implies',\n",
       "  'both',\n",
       "  'biologically',\n",
       "  'and',\n",
       "  'mentally',\n",
       "  'issues',\n",
       "  'of',\n",
       "  'interest',\n",
       "  'include',\n",
       "  'phenomena',\n",
       "  'such',\n",
       "  'as',\n",
       "  'perception',\n",
       "  'blindsight',\n",
       "  'brainwaves',\n",
       "  'during',\n",
       "  'sleep',\n",
       "  'and',\n",
       "  'altered',\n",
       "  'states',\n",
       "  'of',\n",
       "  'consciousness',\n",
       "  'produced',\n",
       "  'by',\n",
       "  'psychoactive',\n",
       "  'drugs',\n",
       "  'a',\n",
       "  'greater',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'test',\n",
       "  'assesses',\n",
       "  'consciousness',\n",
       "  'by',\n",
       "  'approaching',\n",
       "  'human',\n",
       "  'subjects',\n",
       "  'for',\n",
       "  'a',\n",
       "  'verbal',\n",
       "  'report',\n",
       "  'of',\n",
       "  'their',\n",
       "  'encounters',\n",
       "  'however',\n",
       "  'to',\n",
       "  'confirm',\n",
       "  'the',\n",
       "  'criticalness',\n",
       "  'of',\n",
       "  'these',\n",
       "  'verbal',\n",
       "  'reports',\n",
       "  'researchers',\n",
       "  'must',\n",
       "  'contrast',\n",
       "  'them',\n",
       "  'with',\n",
       "  'the',\n",
       "  'action',\n",
       "  'that',\n",
       "  'all',\n",
       "  'the',\n",
       "  'while',\n",
       "  'happens',\n",
       "  'in',\n",
       "  'the',\n",
       "  'brain',\n",
       "  'that',\n",
       "  'is',\n",
       "  'they',\n",
       "  'should',\n",
       "  'search',\n",
       "  'for',\n",
       "  'the',\n",
       "  'neural',\n",
       "  'connections',\n",
       "  'of',\n",
       "  'consciousness',\n",
       "  'hope',\n",
       "  'is',\n",
       "  'to',\n",
       "  'locate',\n",
       "  'that',\n",
       "  'noticeable',\n",
       "  'action',\n",
       "  'in',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'aspect',\n",
       "  'of',\n",
       "  'the',\n",
       "  'brain',\n",
       "  'or',\n",
       "  'a',\n",
       "  'particular',\n",
       "  'pattern',\n",
       "  'of',\n",
       "  'global',\n",
       "  'brain',\n",
       "  'activity',\n",
       "  'will',\n",
       "  'be',\n",
       "  'greatly',\n",
       "  'predictive',\n",
       "  'of',\n",
       "  'consciousness',\n",
       "  'mindfulness',\n",
       "  'a',\n",
       "  'few',\n",
       "  'brain',\n",
       "  'imaging',\n",
       "  'strategies',\n",
       "  'for',\n",
       "  'example',\n",
       "  'eeg',\n",
       "  'and',\n",
       "  'mri',\n",
       "  'scans',\n",
       "  'have',\n",
       "  'been',\n",
       "  'utilized',\n",
       "  'for',\n",
       "  'physical',\n",
       "  'proportions',\n",
       "  'of',\n",
       "  'brain',\n",
       "  'activities',\n",
       "  'in',\n",
       "  'these',\n",
       "  'examinations',\n",
       "  'a',\n",
       "  'few',\n",
       "  'investigations',\n",
       "  'have',\n",
       "  'shown',\n",
       "  'that',\n",
       "  'movement',\n",
       "  'in',\n",
       "  'essential',\n",
       "  'primary',\n",
       "  'sensory',\n",
       "  'areas',\n",
       "  'of',\n",
       "  'the',\n",
       "  'brain',\n",
       "  'isnt',\n",
       "  'adequate',\n",
       "  'to',\n",
       "  'create',\n",
       "  'consciousness',\n",
       "  'it',\n",
       "  'is',\n",
       "  'workable',\n",
       "  'for',\n",
       "  'subjects',\n",
       "  'to',\n",
       "  'report',\n",
       "  'an',\n",
       "  'absence',\n",
       "  'of',\n",
       "  'awareness',\n",
       "  'in',\n",
       "  'any',\n",
       "  'event',\n",
       "  'when',\n",
       "  'areas',\n",
       "  'for',\n",
       "  'example',\n",
       "  'the',\n",
       "  'primary',\n",
       "  'visual',\n",
       "  'cortex',\n",
       "  'show',\n",
       "  'clear',\n",
       "  'electrical',\n",
       "  'reactions',\n",
       "  'to',\n",
       "  'a',\n",
       "  'stimulus',\n",
       "  'higher',\n",
       "  'brain',\n",
       "  'areas',\n",
       "  'are',\n",
       "  'viewed',\n",
       "  'as',\n",
       "  'all',\n",
       "  'the',\n",
       "  'more',\n",
       "  'encouraging',\n",
       "  'particularly',\n",
       "  'the',\n",
       "  'prefrontal',\n",
       "  'cortex',\n",
       "  'which',\n",
       "  'is',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'a',\n",
       "  'range',\n",
       "  'of',\n",
       "  'high',\n",
       "  'order',\n",
       "  'functions',\n",
       "  'one',\n",
       "  'mainstream',\n",
       "  'theory',\n",
       "  'implicates',\n",
       "  'various',\n",
       "  'examples',\n",
       "  'of',\n",
       "  'brain',\n",
       "  'waves',\n",
       "  'in',\n",
       "  'creating',\n",
       "  'various',\n",
       "  'conditions',\n",
       "  'of',\n",
       "  'consciousness',\n",
       "  'analysts',\n",
       "  'can',\n",
       "  'record',\n",
       "  'mind',\n",
       "  'waves',\n",
       "  'or',\n",
       "  'drawings',\n",
       "  'of',\n",
       "  'electrical',\n",
       "  'movement',\n",
       "  'inside',\n",
       "  'the',\n",
       "  'cerebrum',\n",
       "  'using',\n",
       "  'an',\n",
       "  'electroencephalograph',\n",
       "  'eeg',\n",
       "  'and',\n",
       "  'placing',\n",
       "  'electrodes',\n",
       "  'on',\n",
       "  'the',\n",
       "  'scalp',\n",
       "  'the',\n",
       "  'four',\n",
       "  'types',\n",
       "  'of',\n",
       "  'brain',\n",
       "  'waves',\n",
       "  'alpha',\n",
       "  'beta',\n",
       "  'theta',\n",
       "  'and',\n",
       "  'delta',\n",
       "  'each',\n",
       "  'correspond',\n",
       "  'with',\n",
       "  'one',\n",
       "  'mental',\n",
       "  'state',\n",
       "  'relaxed',\n",
       "  'alert',\n",
       "  'lightly',\n",
       "  'asleep',\n",
       "  'and',\n",
       "  'deeply',\n",
       "  'asleep',\n",
       "  'memory',\n",
       "  'episodic',\n",
       "  'memory',\n",
       "  'can',\n",
       "  'be',\n",
       "  'regarded',\n",
       "  'as',\n",
       "  'the',\n",
       "  'only',\n",
       "  'form',\n",
       "  'of',\n",
       "  'conscious',\n",
       "  'memory',\n",
       "  'this',\n",
       "  'is',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'capacity',\n",
       "  'to',\n",
       "  'consciously',\n",
       "  'remember',\n",
       "  'personally',\n",
       "  'experienced',\n",
       "  'events',\n",
       "  'and',\n",
       "  'situations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  'the',\n",
       "  'hippocampus',\n",
       "  'located',\n",
       "  'in',\n",
       "  'the',\n",
       "  'brains',\n",
       "  'temporal',\n",
       "  'lobe',\n",
       "  'is',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'this',\n",
       "  'type',\n",
       "  'of',\n",
       "  'memory',\n",
       "  'consciousness',\n",
       "  'also',\n",
       "  'plays',\n",
       "  'a',\n",
       "  'part',\n",
       "  'in',\n",
       "  'important',\n",
       "  'memory',\n",
       "  'distinctions',\n",
       "  'one',\n",
       "  'such',\n",
       "  'distinction',\n",
       "  'is',\n",
       "  'the',\n",
       "  'implicit',\n",
       "  'and',\n",
       "  'explicit',\n",
       "  'characteristics',\n",
       "  'in',\n",
       "  'which',\n",
       "  'explicit',\n",
       "  'memory',\n",
       "  'is',\n",
       "  'what',\n",
       "  'you',\n",
       "  'consciously',\n",
       "  'know',\n",
       "  'and',\n",
       "  'implicit',\n",
       "  'memory',\n",
       "  'includes',\n",
       "  'events',\n",
       "  'you',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'conscious',\n",
       "  'of',\n",
       "  'furthermore',\n",
       "  'several',\n",
       "  'empirical',\n",
       "  'findings',\n",
       "  'suggest',\n",
       "  'that',\n",
       "  'declarative',\n",
       "  'memory',\n",
       "  'is',\n",
       "  'related',\n",
       "  'to',\n",
       "  'consciousness',\n",
       "  ...]]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/72.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "61157c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718\n",
      "WORD COUNT 1107\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "3ecf8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 23.22972972972973\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9e58eb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.4101174345076784\n",
      "FOG INDEX: 9.455938865694964\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 23.22972972972973\n",
      "COMPLEX WORD COUNT: 454\n",
      "WORD COUNT: 1107\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "2096b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3471\n",
      "I: 0\n",
      "we: 10\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 5\n",
      "Total count: 15\n",
      "PERSONAL PRONOUNS: 15\n",
      "AVG WORD LENGTH: 5.505526468877254\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_72.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d6c240",
   "metadata": {},
   "source": [
    "# 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "7b887334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\4025872128.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f85dde5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nature has blessed humanity with earth, a rounded globe where all essential necessity lies in the hand of a human. Though in this 21st-century building Space shuttle and exploring space has become an obvious activity among the human raise, now with the inclusion of Start-ups like Space X once dreamed for reaching out at space now is coming true. We all have to agree upon a fact that in the Growth of industrialization we have generated a humungous carbon footprint and colonize at outer space will create a much-needed area for our survival.',\n",
       " 'With time the human race has visualized and has undergone many transformations, and these transformations may for starters were not that effective but were a major role at existence to this age. Be it a natural transformation like shifting of tectonic plates or manmade like Dumping water and damaging water bodies, somehow have affected usual life of humans so creating space of humans is what next humans are eyeing for.',\n",
       " 'All this idea for Colonizing in outer space emerged when NASA was able to launch a space shuttle with a heavy payload in the late 1990s this idea didn’t stir brain at that time but later was like apple eyes when various articles from astronauts and their writeup came into limelight and this idea saw its progression, space exploration was not a new normal, companies were petrified by the number of investments that these kinds of projects ask for. But things change with the entry of PayPal’s owner Elon Musk, in 2002 where he laid stones of Space X, with NASA providing the launchpad for their exploration.',\n",
       " 'Being space travel legitimate there where many bottlenecks knowing the nature of outer space will boost the idea of colonizing, here one has to realize the optimum. But the main target that these company put forward with themself was to not just get into other planet but to get back at earth safely, earlier these projects due to high fund was always subdued and priority was given to the rocket technology. Thus, this unimaginable quest for the search of space was far-fetched though.',\n",
       " 'Now being in 2020 we do not find it out of a place of colonizing outside of space, the kind of emergence of technologies has led to the escalation of spreading the roots of human existence, the plan for reaching out to outer space too plays a key role for this idea too. Proper Planning, Analysing, Organising, and Executing were required for these projects to be successful for deeper know how I would like to mention here an example of Space X, According to them they wud be successful for sending Rockets by 2022 and would able to colonize by 2050, For achieving these vision they have planned a total of 36 times pre-launch of the same rocket which they will be launching by 2020. Not only that they have already placed their star link satellites which will provide the basic network connectivity for their colonized world, they have planned this to that extent that they have targeted a profit of $ 22 billion yearly by 2025. Already they have sent the first manned rocket successfully what Elon musk plan is to create that infrastructure by which going to Mars with cost as a regular air flight ticket all this will lead to better chances for colonizing at another planet. With setting up their commercial flight once started to the red planet it wud just be a stepping stone for the colonizing at the outer space.',\n",
       " 'But the fundamental change that people have to undergo while living on another planet will be a change in gravity and being able to be near to live support if any technical issues arise to their suit until unless we find a similar place like the earth that is the change which humans have to adjust. Aspects like Ultraviolet rays too will play an immense role in the survival, but with the rate of technology expanding and challenging at very boundaries there are not many days left when we find solutions to these aspects but this idea of colonizing has more to do with monetary terms it has been projected that building a colony at space will cost at about $10 Trillian which is more than many countries GDP. Placing that much of an amount and getting funding for such highly anticipated projects is tough. Elon to have addressed with these questions with an open Door he believes that this cost is nothing when we find a route to colonize space and these costs will be justifiable when space exploration will reach new heights.',\n",
       " 'Also, our world is around water and the percentage of land comparison to water is too less. Whereas the population is increasing with the speed and the level of excitement in order to search for new things and the obsession with the new and innovative things never going to finish. Because in the end, we do not satisfy what we have achieved, we are only looking for other things and crave to achieve that.',\n",
       " 'In order to achieve that planning is most crucial stage. As of now we have searched 9 planets but still didn’t shortlisted the outcomes. But according to the 3-decade theory of ELON MUSK, it seems to be possible.',\n",
       " 'As the most important thing to survive is the atmospheric environment, whether is this suitable or not, and in order to make it suitable what steps had to take and maintain the suitable level of oxygen.  The missions are now what everyone is focusing about. Finding the source of water, because its 2nd crucial thing which is needed to survive.',\n",
       " 'Apart from the excitement and the things, the threats or the uncertainties are bound to happen like any kind of mammal which could occur during construction or after that. So the security for that or any protection so that uncertainties could be replicated.',\n",
       " 'After the basic things, other factors like what are the natural habitats available there, whether the plants could be grown over there or not. If yes, then what types of plants could survive there.',\n",
       " 'The environment for the animals is safe or not. Because to balance the nature we need all types of animals, natural habitat, even insects and other small things which seems to be ignorable but plays an important role in maintaining the environmental balance. For e.g.  – Ants are among the leading predators of other insects, helping to keep pest populations low.  Ants move approximately the same amount of soil as earthworms, loosening the soil in the process and increasing air and water movement into the ground.  They keep the ecosystem clean of dead insect carcasses and aid in the destruction and decomposition of plant and animal matter. So, every small thing contributes in its own way.',\n",
       " 'Another matter of concern is the level of artificial intelligence and machine learning required to maintain that kind of requirement. Because as the current scenario, we need energy to run any vehicle or even for the robotics. So, the availability of the energy and the source of energy is needed.',\n",
       " 'And apart from this, the heat of sun is equally important in order to maintain the level. Because with artificial air we can survive but not for so long. So, in order to remain healthy as well the calculation has to be done. When thinking about disease, you may have heard in the news about the concern that antibiotics (such as penicillin) – which help fight infections – may eventually stop working. Global health organisations are trying to reduce the use of antibiotics, especially for conditions that aren’t serious. This is because their overuse in recent years means that they’re becoming less effective.',\n",
       " 'But still we can survive without antibiotics. Because there are ways of dealing with diseases caused by bacteria such as isolation which is how they were treated before penicillin.',\n",
       " 'It might sound like something set firmly in the realm of fantasy, but experts in private industry and governments around the world are trying to understand how feasible it would be to establish a lunar base. Some scientists think humans could survive comfortably on the moon. In some ways, the very minimal gravity of the moon might actually be more conducive to life than the microgravity astronauts experience on the International Space Station.',\n",
       " 'Although it hasn’t been formally tested, some experts hypothesize that the small amount of gravitational force put on an astronaut’s body when on the moon could help stem some of the adverse effects like bone-density and muscle loss that space flyers experience while living in microgravity on the International Space Station.',\n",
       " 'By using the moon’s indigenous material, space agencies can save money on the cost of flying pricey missions to and from the moon’s surface. Once on the moon, instead of having to stage costly missions aimed at delivering oxygen and other necessary resources from Earth, experts might be able to actually use the material to manufacture gasses needed to sustain life on the satellite.',\n",
       " 'On earth, we are protected from radioactive solar winds and cosmic rays by our own magnet field known as the magnetosphere. But out in the space, we can’t rely on this type of protection, and in order to make that protection, it could take a lot but yes with more upgraded technology it could achieve.',\n",
       " 'Although till now the approximate value of the project is $10 trillion. But the aim is to make the fare equivalent to the normal air fare.',\n",
       " 'As once we are comfortable with all the resources, securities for uncertainties, risk analysis, and the probability of survival of the human being and many other factors after consideration, then development won’t take much time.',\n",
       " 'Because to construct a building it take normally 8-9 months. Which is totally acceptable.',\n",
       " 'But the main concern is the density of the land, i.e. whether the land has the capacity to bear that much weight or not. And the type of land is adaptable for cultivation or nor. Although land can be converted into different types of cultivation but with the help of upgraded technology.',\n",
       " 'In order to transport the equipments on the regular basis, a large amount of fuel Is required, and other factors as well and Built the propellor depo for rocket landing building various infrastructure for the city one by one will create a way forward for idea of Colonizing at outer space.']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e8dc6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts=(' '.join(str(x) for x in texts[16:40]))\n",
    "URL_ID_73 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "bc1d86c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 71 sentences in the string.\n",
      "The number of words in the string is: 1741\n",
      "The number of characters in the string is: 8379\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 00:14:48] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 00:15:00] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 00:15:06] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_73.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_73.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_73.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_73 = re.sub(re_punt, \"\",URL_ID_73)\n",
    "\n",
    "file = open(\"73.txt\", \"w\")\n",
    "file.write(URL_ID_73)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"73.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "38c17252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nature',\n",
       "  'has',\n",
       "  'blessed',\n",
       "  'humanity',\n",
       "  'with',\n",
       "  'earth',\n",
       "  'a',\n",
       "  'rounded',\n",
       "  'globe',\n",
       "  'where',\n",
       "  'all',\n",
       "  'essential',\n",
       "  'necessity',\n",
       "  'lies',\n",
       "  'in',\n",
       "  'the',\n",
       "  'hand',\n",
       "  'of',\n",
       "  'a',\n",
       "  'human',\n",
       "  'though',\n",
       "  'in',\n",
       "  'this',\n",
       "  '21stcentury',\n",
       "  'building',\n",
       "  'space',\n",
       "  'shuttle',\n",
       "  'and',\n",
       "  'exploring',\n",
       "  'space',\n",
       "  'has',\n",
       "  'become',\n",
       "  'an',\n",
       "  'obvious',\n",
       "  'activity',\n",
       "  'among',\n",
       "  'the',\n",
       "  'human',\n",
       "  'raise',\n",
       "  'now',\n",
       "  'with',\n",
       "  'the',\n",
       "  'inclusion',\n",
       "  'of',\n",
       "  'startups',\n",
       "  'like',\n",
       "  'space',\n",
       "  'x',\n",
       "  'once',\n",
       "  'dreamed',\n",
       "  'for',\n",
       "  'reaching',\n",
       "  'out',\n",
       "  'at',\n",
       "  'space',\n",
       "  'now',\n",
       "  'is',\n",
       "  'coming',\n",
       "  'true',\n",
       "  'we',\n",
       "  'all',\n",
       "  'have',\n",
       "  'to',\n",
       "  'agree',\n",
       "  'upon',\n",
       "  'a',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'in',\n",
       "  'the',\n",
       "  'growth',\n",
       "  'of',\n",
       "  'industrialization',\n",
       "  'we',\n",
       "  'have',\n",
       "  'generated',\n",
       "  'a',\n",
       "  'humungous',\n",
       "  'carbon',\n",
       "  'footprint',\n",
       "  'and',\n",
       "  'colonize',\n",
       "  'at',\n",
       "  'outer',\n",
       "  'space',\n",
       "  'will',\n",
       "  'create',\n",
       "  'a',\n",
       "  'muchneeded',\n",
       "  'area',\n",
       "  'for',\n",
       "  'our',\n",
       "  'survival',\n",
       "  'with',\n",
       "  'time',\n",
       "  'the',\n",
       "  'human',\n",
       "  'race',\n",
       "  'has',\n",
       "  'visualized',\n",
       "  'and',\n",
       "  'has',\n",
       "  'undergone',\n",
       "  'many',\n",
       "  'transformations',\n",
       "  'and',\n",
       "  'these',\n",
       "  'transformations',\n",
       "  'may',\n",
       "  'for',\n",
       "  'starters',\n",
       "  'were',\n",
       "  'not',\n",
       "  'that',\n",
       "  'effective',\n",
       "  'but',\n",
       "  'were',\n",
       "  'a',\n",
       "  'major',\n",
       "  'role',\n",
       "  'at',\n",
       "  'existence',\n",
       "  'to',\n",
       "  'this',\n",
       "  'age',\n",
       "  'be',\n",
       "  'it',\n",
       "  'a',\n",
       "  'natural',\n",
       "  'transformation',\n",
       "  'like',\n",
       "  'shifting',\n",
       "  'of',\n",
       "  'tectonic',\n",
       "  'plates',\n",
       "  'or',\n",
       "  'manmade',\n",
       "  'like',\n",
       "  'dumping',\n",
       "  'water',\n",
       "  'and',\n",
       "  'damaging',\n",
       "  'water',\n",
       "  'bodies',\n",
       "  'somehow',\n",
       "  'have',\n",
       "  'affected',\n",
       "  'usual',\n",
       "  'life',\n",
       "  'of',\n",
       "  'humans',\n",
       "  'so',\n",
       "  'creating',\n",
       "  'space',\n",
       "  'of',\n",
       "  'humans',\n",
       "  'is',\n",
       "  'what',\n",
       "  'next',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'eyeing',\n",
       "  'for',\n",
       "  'all',\n",
       "  'this',\n",
       "  'idea',\n",
       "  'for',\n",
       "  'colonizing',\n",
       "  'in',\n",
       "  'outer',\n",
       "  'space',\n",
       "  'emerged',\n",
       "  'when',\n",
       "  'nasa',\n",
       "  'was',\n",
       "  'able',\n",
       "  'to',\n",
       "  'launch',\n",
       "  'a',\n",
       "  'space',\n",
       "  'shuttle',\n",
       "  'with',\n",
       "  'a',\n",
       "  'heavy',\n",
       "  'payload',\n",
       "  'in',\n",
       "  'the',\n",
       "  'late',\n",
       "  '1990s',\n",
       "  'this',\n",
       "  'idea',\n",
       "  'didnt',\n",
       "  'stir',\n",
       "  'brain',\n",
       "  'at',\n",
       "  'that',\n",
       "  'time',\n",
       "  'but',\n",
       "  'later',\n",
       "  'was',\n",
       "  'like',\n",
       "  'apple',\n",
       "  'eyes',\n",
       "  'when',\n",
       "  'various',\n",
       "  'articles',\n",
       "  'from',\n",
       "  'astronauts',\n",
       "  'and',\n",
       "  'their',\n",
       "  'writeup',\n",
       "  'came',\n",
       "  'into',\n",
       "  'limelight',\n",
       "  'and',\n",
       "  'this',\n",
       "  'idea',\n",
       "  'saw',\n",
       "  'its',\n",
       "  'progression',\n",
       "  'space',\n",
       "  'exploration',\n",
       "  'was',\n",
       "  'not',\n",
       "  'a',\n",
       "  'new',\n",
       "  'normal',\n",
       "  'companies',\n",
       "  'were',\n",
       "  'petrified',\n",
       "  'by',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'investments',\n",
       "  'that',\n",
       "  'these',\n",
       "  'kinds',\n",
       "  'of',\n",
       "  'projects',\n",
       "  'ask',\n",
       "  'for',\n",
       "  'but',\n",
       "  'things',\n",
       "  'change',\n",
       "  'with',\n",
       "  'the',\n",
       "  'entry',\n",
       "  'of',\n",
       "  'paypals',\n",
       "  'owner',\n",
       "  'elon',\n",
       "  'musk',\n",
       "  'in',\n",
       "  '2002',\n",
       "  'where',\n",
       "  'he',\n",
       "  'laid',\n",
       "  'stones',\n",
       "  'of',\n",
       "  'space',\n",
       "  'x',\n",
       "  'with',\n",
       "  'nasa',\n",
       "  'providing',\n",
       "  'the',\n",
       "  'launchpad',\n",
       "  'for',\n",
       "  'their',\n",
       "  'exploration',\n",
       "  'being',\n",
       "  'space',\n",
       "  'travel',\n",
       "  'legitimate',\n",
       "  'there',\n",
       "  'where',\n",
       "  'many',\n",
       "  'bottlenecks',\n",
       "  'knowing',\n",
       "  'the',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'outer',\n",
       "  'space',\n",
       "  'will',\n",
       "  'boost',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'colonizing',\n",
       "  'here',\n",
       "  'one',\n",
       "  'has',\n",
       "  'to',\n",
       "  'realize',\n",
       "  'the',\n",
       "  'optimum',\n",
       "  'but',\n",
       "  'the',\n",
       "  'main',\n",
       "  'target',\n",
       "  'that',\n",
       "  'these',\n",
       "  'company',\n",
       "  'put',\n",
       "  'forward',\n",
       "  'with',\n",
       "  'themself',\n",
       "  'was',\n",
       "  'to',\n",
       "  'not',\n",
       "  'just',\n",
       "  'get',\n",
       "  'into',\n",
       "  'other',\n",
       "  'planet',\n",
       "  'but',\n",
       "  'to',\n",
       "  'get',\n",
       "  'back',\n",
       "  'at',\n",
       "  'earth',\n",
       "  'safely',\n",
       "  'earlier',\n",
       "  'these',\n",
       "  'projects',\n",
       "  'due',\n",
       "  'to',\n",
       "  'high',\n",
       "  'fund',\n",
       "  'was',\n",
       "  'always',\n",
       "  'subdued',\n",
       "  'and',\n",
       "  'priority',\n",
       "  'was',\n",
       "  'given',\n",
       "  'to',\n",
       "  'the',\n",
       "  'rocket',\n",
       "  'technology',\n",
       "  'thus',\n",
       "  'this',\n",
       "  'unimaginable',\n",
       "  'quest',\n",
       "  'for',\n",
       "  'the',\n",
       "  'search',\n",
       "  'of',\n",
       "  'space',\n",
       "  'was',\n",
       "  'farfetched',\n",
       "  'though',\n",
       "  'now',\n",
       "  'being',\n",
       "  'in',\n",
       "  '2020',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'find',\n",
       "  'it',\n",
       "  'out',\n",
       "  'of',\n",
       "  'a',\n",
       "  'place',\n",
       "  'of',\n",
       "  'colonizing',\n",
       "  'outside',\n",
       "  'of',\n",
       "  'space',\n",
       "  'the',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'emergence',\n",
       "  'of',\n",
       "  'technologies',\n",
       "  'has',\n",
       "  'led',\n",
       "  'to',\n",
       "  'the',\n",
       "  'escalation',\n",
       "  'of',\n",
       "  'spreading',\n",
       "  'the',\n",
       "  'roots',\n",
       "  'of',\n",
       "  'human',\n",
       "  'existence',\n",
       "  'the',\n",
       "  'plan',\n",
       "  'for',\n",
       "  'reaching',\n",
       "  'out',\n",
       "  'to',\n",
       "  'outer',\n",
       "  'space',\n",
       "  'too',\n",
       "  'plays',\n",
       "  'a',\n",
       "  'key',\n",
       "  'role',\n",
       "  'for',\n",
       "  'this',\n",
       "  'idea',\n",
       "  'too',\n",
       "  'proper',\n",
       "  'planning',\n",
       "  'analysing',\n",
       "  'organising',\n",
       "  'and',\n",
       "  'executing',\n",
       "  'were',\n",
       "  'required',\n",
       "  'for',\n",
       "  'these',\n",
       "  'projects',\n",
       "  'to',\n",
       "  'be',\n",
       "  'successful',\n",
       "  'for',\n",
       "  'deeper',\n",
       "  'know',\n",
       "  'how',\n",
       "  'i',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'mention',\n",
       "  'here',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'space',\n",
       "  'x',\n",
       "  'according',\n",
       "  'to',\n",
       "  'them',\n",
       "  'they',\n",
       "  'wud',\n",
       "  'be',\n",
       "  'successful',\n",
       "  'for',\n",
       "  'sending',\n",
       "  'rockets',\n",
       "  'by',\n",
       "  '2022',\n",
       "  'and',\n",
       "  'would',\n",
       "  'able',\n",
       "  'to',\n",
       "  'colonize',\n",
       "  'by',\n",
       "  '2050',\n",
       "  'for',\n",
       "  'achieving',\n",
       "  'these',\n",
       "  'vision',\n",
       "  'they',\n",
       "  'have',\n",
       "  'planned',\n",
       "  'a',\n",
       "  'total',\n",
       "  'of',\n",
       "  '36',\n",
       "  'times',\n",
       "  'prelaunch',\n",
       "  'of',\n",
       "  'the',\n",
       "  'same',\n",
       "  'rocket',\n",
       "  'which',\n",
       "  'they',\n",
       "  'will',\n",
       "  'be',\n",
       "  'launching',\n",
       "  'by',\n",
       "  '2020',\n",
       "  'not',\n",
       "  'only',\n",
       "  'that',\n",
       "  'they',\n",
       "  'have',\n",
       "  'already',\n",
       "  'placed',\n",
       "  'their',\n",
       "  'star',\n",
       "  'link',\n",
       "  'satellites',\n",
       "  'which',\n",
       "  'will',\n",
       "  'provide',\n",
       "  'the',\n",
       "  'basic',\n",
       "  'network',\n",
       "  'connectivity',\n",
       "  'for',\n",
       "  'their',\n",
       "  'colonized',\n",
       "  'world',\n",
       "  'they',\n",
       "  'have',\n",
       "  'planned',\n",
       "  'this',\n",
       "  'to',\n",
       "  'that',\n",
       "  'extent',\n",
       "  'that',\n",
       "  'they',\n",
       "  'have',\n",
       "  'targeted',\n",
       "  'a',\n",
       "  'profit',\n",
       "  'of',\n",
       "  '22',\n",
       "  'billion',\n",
       "  'yearly',\n",
       "  'by',\n",
       "  '2025',\n",
       "  'already',\n",
       "  'they',\n",
       "  'have',\n",
       "  'sent',\n",
       "  'the',\n",
       "  'first',\n",
       "  'manned',\n",
       "  'rocket',\n",
       "  'successfully',\n",
       "  'what',\n",
       "  'elon',\n",
       "  'musk',\n",
       "  'plan',\n",
       "  'is',\n",
       "  'to',\n",
       "  'create',\n",
       "  'that',\n",
       "  'infrastructure',\n",
       "  'by',\n",
       "  'which',\n",
       "  'going',\n",
       "  'to',\n",
       "  'mars',\n",
       "  'with',\n",
       "  'cost',\n",
       "  'as',\n",
       "  'a',\n",
       "  'regular',\n",
       "  'air',\n",
       "  'flight',\n",
       "  'ticket',\n",
       "  'all',\n",
       "  'this',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'better',\n",
       "  'chances',\n",
       "  'for',\n",
       "  'colonizing',\n",
       "  'at',\n",
       "  'another',\n",
       "  'planet',\n",
       "  'with',\n",
       "  'setting',\n",
       "  'up',\n",
       "  'their',\n",
       "  'commercial',\n",
       "  'flight',\n",
       "  'once',\n",
       "  'started',\n",
       "  'to',\n",
       "  'the',\n",
       "  'red',\n",
       "  'planet',\n",
       "  'it',\n",
       "  'wud',\n",
       "  'just',\n",
       "  'be',\n",
       "  'a',\n",
       "  'stepping',\n",
       "  'stone',\n",
       "  'for',\n",
       "  'the',\n",
       "  'colonizing',\n",
       "  'at',\n",
       "  'the',\n",
       "  'outer',\n",
       "  'space',\n",
       "  'but',\n",
       "  'the',\n",
       "  'fundamental',\n",
       "  'change',\n",
       "  'that',\n",
       "  'people',\n",
       "  'have',\n",
       "  'to',\n",
       "  'undergo',\n",
       "  'while',\n",
       "  'living',\n",
       "  'on',\n",
       "  'another',\n",
       "  'planet',\n",
       "  'will',\n",
       "  'be',\n",
       "  'a',\n",
       "  'change',\n",
       "  'in',\n",
       "  'gravity',\n",
       "  'and',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'be',\n",
       "  'near',\n",
       "  'to',\n",
       "  'live',\n",
       "  'support',\n",
       "  'if',\n",
       "  'any',\n",
       "  'technical',\n",
       "  'issues',\n",
       "  'arise',\n",
       "  'to',\n",
       "  'their',\n",
       "  'suit',\n",
       "  'until',\n",
       "  'unless',\n",
       "  'we',\n",
       "  'find',\n",
       "  'a',\n",
       "  'similar',\n",
       "  'place',\n",
       "  'like',\n",
       "  'the',\n",
       "  'earth',\n",
       "  'that',\n",
       "  'is',\n",
       "  'the',\n",
       "  'change',\n",
       "  'which',\n",
       "  'humans',\n",
       "  'have',\n",
       "  'to',\n",
       "  'adjust',\n",
       "  'aspects',\n",
       "  'like',\n",
       "  'ultraviolet',\n",
       "  'rays',\n",
       "  'too',\n",
       "  'will',\n",
       "  'play',\n",
       "  'an',\n",
       "  'immense',\n",
       "  'role',\n",
       "  'in',\n",
       "  'the',\n",
       "  'survival',\n",
       "  'but',\n",
       "  'with',\n",
       "  'the',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'technology',\n",
       "  'expanding',\n",
       "  'and',\n",
       "  'challenging',\n",
       "  'at',\n",
       "  'very',\n",
       "  'boundaries',\n",
       "  'there',\n",
       "  'are',\n",
       "  'not',\n",
       "  'many',\n",
       "  'days',\n",
       "  'left',\n",
       "  'when',\n",
       "  'we',\n",
       "  'find',\n",
       "  'solutions',\n",
       "  'to',\n",
       "  'these',\n",
       "  'aspects',\n",
       "  'but',\n",
       "  'this',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'colonizing',\n",
       "  'has',\n",
       "  'more',\n",
       "  'to',\n",
       "  'do',\n",
       "  'with',\n",
       "  'monetary',\n",
       "  'terms',\n",
       "  'it',\n",
       "  'has',\n",
       "  'been',\n",
       "  'projected',\n",
       "  'that',\n",
       "  'building',\n",
       "  'a',\n",
       "  'colony',\n",
       "  'at',\n",
       "  'space',\n",
       "  'will',\n",
       "  'cost',\n",
       "  'at',\n",
       "  'about',\n",
       "  '10',\n",
       "  'trillian',\n",
       "  'which',\n",
       "  'is',\n",
       "  'more',\n",
       "  'than',\n",
       "  'many',\n",
       "  'countries',\n",
       "  'gdp',\n",
       "  'placing',\n",
       "  'that',\n",
       "  'much',\n",
       "  'of',\n",
       "  'an',\n",
       "  'amount',\n",
       "  'and',\n",
       "  'getting',\n",
       "  'funding',\n",
       "  'for',\n",
       "  'such',\n",
       "  'highly',\n",
       "  'anticipated',\n",
       "  'projects',\n",
       "  'is',\n",
       "  'tough',\n",
       "  'elon',\n",
       "  'to',\n",
       "  'have',\n",
       "  'addressed',\n",
       "  'with',\n",
       "  'these',\n",
       "  'questions',\n",
       "  'with',\n",
       "  'an',\n",
       "  'open',\n",
       "  'door',\n",
       "  'he',\n",
       "  'believes',\n",
       "  'that',\n",
       "  'this',\n",
       "  'cost',\n",
       "  'is',\n",
       "  'nothing',\n",
       "  'when',\n",
       "  'we',\n",
       "  'find',\n",
       "  'a',\n",
       "  'route',\n",
       "  'to',\n",
       "  'colonize',\n",
       "  'space',\n",
       "  'and',\n",
       "  'these',\n",
       "  'costs',\n",
       "  'will',\n",
       "  'be',\n",
       "  'justifiable',\n",
       "  'when',\n",
       "  'space',\n",
       "  'exploration',\n",
       "  'will',\n",
       "  'reach',\n",
       "  'new',\n",
       "  'heights',\n",
       "  'also',\n",
       "  'our',\n",
       "  'world',\n",
       "  'is',\n",
       "  'around',\n",
       "  'water',\n",
       "  'and',\n",
       "  'the',\n",
       "  'percentage',\n",
       "  'of',\n",
       "  'land',\n",
       "  'comparison',\n",
       "  'to',\n",
       "  'water',\n",
       "  'is',\n",
       "  'too',\n",
       "  'less',\n",
       "  'whereas',\n",
       "  'the',\n",
       "  'population',\n",
       "  'is',\n",
       "  'increasing',\n",
       "  'with',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'and',\n",
       "  'the',\n",
       "  'level',\n",
       "  'of',\n",
       "  'excitement',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'search',\n",
       "  'for',\n",
       "  'new',\n",
       "  'things',\n",
       "  'and',\n",
       "  'the',\n",
       "  'obsession',\n",
       "  'with',\n",
       "  'the',\n",
       "  'new',\n",
       "  'and',\n",
       "  'innovative',\n",
       "  'things',\n",
       "  'never',\n",
       "  'going',\n",
       "  'to',\n",
       "  'finish',\n",
       "  'because',\n",
       "  'in',\n",
       "  'the',\n",
       "  'end',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'satisfy',\n",
       "  'what',\n",
       "  'we',\n",
       "  'have',\n",
       "  'achieved',\n",
       "  'we',\n",
       "  'are',\n",
       "  'only',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'other',\n",
       "  'things',\n",
       "  'and',\n",
       "  'crave',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'that',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'that',\n",
       "  'planning',\n",
       "  'is',\n",
       "  'most',\n",
       "  'crucial',\n",
       "  'stage',\n",
       "  'as',\n",
       "  'of',\n",
       "  'now',\n",
       "  'we',\n",
       "  'have',\n",
       "  'searched',\n",
       "  '9',\n",
       "  'planets',\n",
       "  'but',\n",
       "  'still',\n",
       "  'didnt',\n",
       "  'shortlisted',\n",
       "  'the',\n",
       "  'outcomes',\n",
       "  'but',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  '3decade',\n",
       "  'theory',\n",
       "  'of',\n",
       "  'elon',\n",
       "  'musk',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'be',\n",
       "  'possible',\n",
       "  'as',\n",
       "  'the',\n",
       "  'most',\n",
       "  'important',\n",
       "  'thing',\n",
       "  'to',\n",
       "  'survive',\n",
       "  'is',\n",
       "  'the',\n",
       "  'atmospheric',\n",
       "  'environment',\n",
       "  'whether',\n",
       "  'is',\n",
       "  'this',\n",
       "  'suitable',\n",
       "  'or',\n",
       "  'not',\n",
       "  'and',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'make',\n",
       "  'it',\n",
       "  'suitable',\n",
       "  'what',\n",
       "  'steps',\n",
       "  'had',\n",
       "  'to',\n",
       "  'take',\n",
       "  'and',\n",
       "  'maintain',\n",
       "  'the',\n",
       "  'suitable',\n",
       "  'level',\n",
       "  'of',\n",
       "  'oxygen',\n",
       "  'the',\n",
       "  'missions',\n",
       "  'are',\n",
       "  'now',\n",
       "  'what',\n",
       "  'everyone',\n",
       "  'is',\n",
       "  'focusing',\n",
       "  'about',\n",
       "  'finding',\n",
       "  'the',\n",
       "  'source',\n",
       "  'of',\n",
       "  'water',\n",
       "  'because',\n",
       "  'its',\n",
       "  '2nd',\n",
       "  'crucial',\n",
       "  'thing',\n",
       "  'which',\n",
       "  'is',\n",
       "  'needed',\n",
       "  'to',\n",
       "  'survive',\n",
       "  'apart',\n",
       "  'from',\n",
       "  'the',\n",
       "  'excitement',\n",
       "  'and',\n",
       "  'the',\n",
       "  'things',\n",
       "  'the',\n",
       "  'threats',\n",
       "  'or',\n",
       "  'the',\n",
       "  'uncertainties',\n",
       "  'are',\n",
       "  'bound',\n",
       "  'to',\n",
       "  'happen',\n",
       "  'like',\n",
       "  'any',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'mammal',\n",
       "  'which',\n",
       "  'could',\n",
       "  'occur',\n",
       "  'during',\n",
       "  'construction',\n",
       "  'or',\n",
       "  'after',\n",
       "  'that',\n",
       "  'so',\n",
       "  'the',\n",
       "  'security',\n",
       "  'for',\n",
       "  'that',\n",
       "  'or',\n",
       "  'any',\n",
       "  'protection',\n",
       "  'so',\n",
       "  'that',\n",
       "  'uncertainties',\n",
       "  'could',\n",
       "  'be',\n",
       "  'replicated',\n",
       "  'after',\n",
       "  'the',\n",
       "  'basic',\n",
       "  'things',\n",
       "  'other',\n",
       "  'factors',\n",
       "  'like',\n",
       "  'what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'natural',\n",
       "  'habitats',\n",
       "  'available',\n",
       "  ...]]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/73.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "8bfbf7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1737\n",
      "WORD COUNT 1056\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "77c93257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 24.52112676056338\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "c8adf64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.27367424242424243\n",
      "FOG INDEX: 9.91792040119505\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 24.52112676056338\n",
      "COMPLEX WORD COUNT: 289\n",
      "WORD COUNT: 1056\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "cd4b158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3111\n",
      "i: 1\n",
      "we: 17\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 18\n",
      "PERSONAL PRONOUNS: 18\n",
      "AVG WORD LENGTH: 4.812751292360712\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_73.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9482693",
   "metadata": {},
   "source": [
    "# 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b70b617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\497242233.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "daf9de99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We’ve really done it this year. Like an insatiable glutton, the law of averages has come home to roost. We should’ve taken the hint when on the 1st of January, 66 people lost their lives in the Jakarta floods. What followed was like the highlights reel of a disaster movie franchise – a volcanic eruption in The Philippines, irrepressible bushfires in Australia, earthquakes in Russia, Iran, Turkey, India, and China. And speaking of China.',\n",
       " '2020 has brought home the fragile mortality of the human race into sharp focus. As global Covid-19 deaths stoutly push past the grim 1 million marks, we have no choice but to question our place in the universe – are we the all-conquering masters of our domain, or mere tourists in a ruthlessly apathetic ecosystem? Is the human race on the ubiquitous three-part literary arc that defines every story, every life, every civilization – ascent, apex, and descent? Maybe when Michael Jackson unveiled his moonwalk in 1983, or when Barack Obama stepped into the White House as President of the United States in 2008, or indeed when MS Dhoni lifted the Cricket World Cup in 2011, we peaked, as a species, and everything since then has been a steady unraveling.',\n",
       " '500 years is a long time. For context, the world population in 1500 AD was a mere 461 million. The 16-fold explosion since then is unprecedented in history, but we might just be at the tip of an iceberg. Though fertility rates are dropping and more and more people are foregoing the chance to have babies, we might just have crossed the threshold – the population projections for the year 2050 is 9.8 billion, and for 2100 is a whopping 11.2 billion1. Somewhere out there, Malthus is cackling in his grave. The year 2500 suddenly seems a long way off, and this conversation seems ever-more pertinent today. The Bulletin of Atomic Scientists is not optimistic – the famed Doomsday Clock they maintain is the closest to ‘midnight’ (our proximity to global catastrophe), since its inception in 1947. Global warming? Check. The threat of nuclear war? Check. Ongoing pandemic? Check, check, check.',\n",
       " 'And yet, hope floats, for three reasons. Mankind may just have its back to the wall right now, but there are three shoots of potential that might just help us make it to 2500 AD – the advent of a basket of disruptive technologies (artificial intelligence, bio-enhancement, genetic engineering), the private sector focus on space exploration and terraforming, and good old fashioned human resilience. While the first two factors will no doubt be critical to human survival, it is the third one that we must pin our hopes on – our long-demonstrated history of surviving whatever nature, the universe, or our own self-destructive tendency, throws our way.',\n",
       " 'The Next Superman?',\n",
       " 'In the 13th century, in the Italian town of Pisa, an enterprising tinkerer developed the first eyeglasses, for a local friar with weakening eyesight2. All of a sudden, there existed an external device that could amplify our senses, a tool that gave us an advantage in survival. Today, LASIK surgeries obviate the need for eyeglasses entirely. Hearing aids give the gift of auditory perception back to those who had gotten used to a world of muffled voices and unheard sounds. The iPhone routinely comes with an augmented reality tool that allows us to measure the length of objects in front of us.',\n",
       " 'But the real science starts where the imagination ends – augmented reality glasses, smart wearables, and virtual reality tools will be ubiquitous in the next few decades. But what after that? Science has the answer, and it’s both thrilling and scary. Artificial intelligence has become the stuff of fable, the filler for all questions left unanswered. But AI, combined with bio-enhancement and genetic engineering, might just lead to the evolution of what some are calling Homo nouveau3. Homo nouveau will be smarter, faster, more agile, and better equipped to adapt to what promises to be a world that is VUCA beyond our imaginations. What might such a human being look like?',\n",
       " 'They might have a small chip embedded in their brain that utilizes artificial intelligence for enhanced sensory perception. What does that mean? It means that they would be able to see better, focuses their attention for longer, hears what they want to hear, and communicate the appropriate reaction to the rest of the body. Through a chemical in the blood, this AI chip would be able to demand the appropriate response from the body. Bio-augmentation of limbs and organs, internal and external, would mean that what a person can or cannot do is no longer determined at birth, but can simply be bought. All of a sudden, the average Joe can run faster than Usain Bolt, swim better than Michael Phelps, and…fly? Maybe. Genetic engineering will be the missing link. Already there are feverish conversations about a dystopian future featuring designer babies and a digital divide that simply cannot be overcome because it is inbuilt into one’s DNA. The breakthrough with CRISPR-Cas9 might just be the key to unlock the mysteries of DNA manipulation. So what if there’s no food left? Our body AI will adjust our appetite accordingly. No water? Absorb humidity from the air through specialized pores in the skin. The human being in 2500 AD may not be how we recognize one today. That may be our only shot.',\n",
       " 'Galactic Dominance',\n",
       " 'SpaceX, led by its mercurial leader Elon Musk, has been the leader here. The SpaceX Mars Programme is based on a very simple premise – as the earth’s closest planet in terms of distance and terrestrial conditions, Mars would be our best bet for colonization. Musk has invested billions of dollars in the Mars Space Programme and remains a fervent believer in the concept. And among tech visionaries, Musk is not alone. Jeff Bezos, the richest man in the world, owns Blue Origin, which simply aims to make spaceflight cheaper through incremental technological growth. Bezos, who took an online retailer of books and turned it into an ever-expanding behemoth, is not a man who thinks small. With more and more business leaders finding spaceflight and planetary colonization a tantalizing prospect, there will inevitably be a concerted push to developing an actual colony on another planet. And when the pull-factor to this development starts hitting diminishing returns, there will be the inevitable push factor as global warming and the possible increase in the eruption of pandemics begin to take their toll. It might just become a more feasible option for people to find an alternate home, if not on Mars, then on one of Saturn’s moons.',\n",
       " 'A human colony on Mars sounds like a concept straight out of science fiction, but so did a permanent station in Antarctica until a few decades ago. Mount Everest seemed like an unapproachable summit until someone went ahead and planted a flag at the peak. Today, hundreds of people every year attempt the climb. As spaceflight becomes more reasonable, as the urge to explore supersedes the inertia of investment, we become closer to our best chance of survival – leaving planet earth behind and finding another home, perhaps one more forgiving of our follies.',\n",
       " 'The Human Spirit',\n",
       " 'The introduction to this article includes an illustrative list of disasters and misfortunes that have struck the global community this year. And yet, we survive. Businesses surge ahead, people adapt to a world of masks and social distancing, the world goes on. Earthquakes, tsunamis, pandemics, we’ve seen them all before and survived, and the human race, in its intrepid exploration of the world, pushes onward and upward. Technological visionaries envision a future that the rest of us cannot see, and then invest money in their vision. Gradually, what seemed unthinkable suddenly becomes real – the moon landing is the best possible example of that. Google launched Google Glass as the first augmented reality wearable technology, and suddenly we could foresee a future with smart eyewear. While the product didn’t quite catch on, that doesn’t mean other companies aren’t trying. Bio-augmentation is already a fast-developing industry, while CRISPR-Cas9, the “genetic scissors” is being held back only by regulatory bottlenecks. How long before the prospect of fiddling with the gene code becomes not a luxury but a necessity? The human spirit, the tendency to survive and thrive at all costs, will eventually win.',\n",
       " 'The human race will survive to 2500, of that there is no doubt. The real question is, will the person who exists in 2500, with bionic chips and a bio-enhanced body structure and a modified genetic code, be called a Homo sapien? Or is Homo nouveau the way forward?']"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8a25f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:30]))\n",
    "URL_ID_74 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "361080e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69 sentences in the string.\n",
      "The number of words in the string is: 1452\n",
      "The number of characters in the string is: 7255\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 01:40:28] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 01:40:49] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_74.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_74.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_74.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_74 = re.sub(re_punt, \"\",URL_ID_74)\n",
    "\n",
    "file = open(\"74.txt\", \"w\")\n",
    "file.write(URL_ID_74)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"74.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9ba1bd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'next',\n",
       "  'superman?',\n",
       "  'galactic',\n",
       "  'dominance',\n",
       "  'the',\n",
       "  'human',\n",
       "  'spirit',\n",
       "  'weve',\n",
       "  'really',\n",
       "  'done',\n",
       "  'it',\n",
       "  'this',\n",
       "  'year',\n",
       "  'like',\n",
       "  'an',\n",
       "  'insatiable',\n",
       "  'glutton',\n",
       "  'the',\n",
       "  'law',\n",
       "  'of',\n",
       "  'averages',\n",
       "  'has',\n",
       "  'come',\n",
       "  'home',\n",
       "  'to',\n",
       "  'roost',\n",
       "  'we',\n",
       "  'shouldve',\n",
       "  'taken',\n",
       "  'the',\n",
       "  'hint',\n",
       "  'when',\n",
       "  'on',\n",
       "  'the',\n",
       "  '1st',\n",
       "  'of',\n",
       "  'january',\n",
       "  '66',\n",
       "  'people',\n",
       "  'lost',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'in',\n",
       "  'the',\n",
       "  'jakarta',\n",
       "  'floods',\n",
       "  'what',\n",
       "  'followed',\n",
       "  'was',\n",
       "  'like',\n",
       "  'the',\n",
       "  'highlights',\n",
       "  'reel',\n",
       "  'of',\n",
       "  'a',\n",
       "  'disaster',\n",
       "  'movie',\n",
       "  'franchise',\n",
       "  'a',\n",
       "  'volcanic',\n",
       "  'eruption',\n",
       "  'in',\n",
       "  'the',\n",
       "  'philippines',\n",
       "  'irrepressible',\n",
       "  'bushfires',\n",
       "  'in',\n",
       "  'australia',\n",
       "  'earthquakes',\n",
       "  'in',\n",
       "  'russia',\n",
       "  'iran',\n",
       "  'turkey',\n",
       "  'india',\n",
       "  'and',\n",
       "  'china',\n",
       "  'and',\n",
       "  'speaking',\n",
       "  'of',\n",
       "  'china',\n",
       "  '2020',\n",
       "  'has',\n",
       "  'brought',\n",
       "  'home',\n",
       "  'the',\n",
       "  'fragile',\n",
       "  'mortality',\n",
       "  'of',\n",
       "  'the',\n",
       "  'human',\n",
       "  'race',\n",
       "  'into',\n",
       "  'sharp',\n",
       "  'focus',\n",
       "  'as',\n",
       "  'global',\n",
       "  'covid19',\n",
       "  'deaths',\n",
       "  'stoutly',\n",
       "  'push',\n",
       "  'past',\n",
       "  'the',\n",
       "  'grim',\n",
       "  '1',\n",
       "  'million',\n",
       "  'marks',\n",
       "  'we',\n",
       "  'have',\n",
       "  'no',\n",
       "  'choice',\n",
       "  'but',\n",
       "  'to',\n",
       "  'question',\n",
       "  'our',\n",
       "  'place',\n",
       "  'in',\n",
       "  'the',\n",
       "  'universe',\n",
       "  'are',\n",
       "  'we',\n",
       "  'the',\n",
       "  'allconquering',\n",
       "  'masters',\n",
       "  'of',\n",
       "  'our',\n",
       "  'domain',\n",
       "  'or',\n",
       "  'mere',\n",
       "  'tourists',\n",
       "  'in',\n",
       "  'a',\n",
       "  'ruthlessly',\n",
       "  'apathetic',\n",
       "  'ecosystem?',\n",
       "  'is',\n",
       "  'the',\n",
       "  'human',\n",
       "  'race',\n",
       "  'on',\n",
       "  'the',\n",
       "  'ubiquitous',\n",
       "  'threepart',\n",
       "  'literary',\n",
       "  'arc',\n",
       "  'that',\n",
       "  'defines',\n",
       "  'every',\n",
       "  'story',\n",
       "  'every',\n",
       "  'life',\n",
       "  'every',\n",
       "  'civilization',\n",
       "  'ascent',\n",
       "  'apex',\n",
       "  'and',\n",
       "  'descent?',\n",
       "  'maybe',\n",
       "  'when',\n",
       "  'michael',\n",
       "  'jackson',\n",
       "  'unveiled',\n",
       "  'his',\n",
       "  'moonwalk',\n",
       "  'in',\n",
       "  '1983',\n",
       "  'or',\n",
       "  'when',\n",
       "  'barack',\n",
       "  'obama',\n",
       "  'stepped',\n",
       "  'into',\n",
       "  'the',\n",
       "  'white',\n",
       "  'house',\n",
       "  'as',\n",
       "  'president',\n",
       "  'of',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  'in',\n",
       "  '2008',\n",
       "  'or',\n",
       "  'indeed',\n",
       "  'when',\n",
       "  'ms',\n",
       "  'dhoni',\n",
       "  'lifted',\n",
       "  'the',\n",
       "  'cricket',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'in',\n",
       "  '2011',\n",
       "  'we',\n",
       "  'peaked',\n",
       "  'as',\n",
       "  'a',\n",
       "  'species',\n",
       "  'and',\n",
       "  'everything',\n",
       "  'since',\n",
       "  'then',\n",
       "  'has',\n",
       "  'been',\n",
       "  'a',\n",
       "  'steady',\n",
       "  'unraveling',\n",
       "  '500',\n",
       "  'years',\n",
       "  'is',\n",
       "  'a',\n",
       "  'long',\n",
       "  'time',\n",
       "  'for',\n",
       "  'context',\n",
       "  'the',\n",
       "  'world',\n",
       "  'population',\n",
       "  'in',\n",
       "  '1500',\n",
       "  'ad',\n",
       "  'was',\n",
       "  'a',\n",
       "  'mere',\n",
       "  '461',\n",
       "  'million',\n",
       "  'the',\n",
       "  '16fold',\n",
       "  'explosion',\n",
       "  'since',\n",
       "  'then',\n",
       "  'is',\n",
       "  'unprecedented',\n",
       "  'in',\n",
       "  'history',\n",
       "  'but',\n",
       "  'we',\n",
       "  'might',\n",
       "  'just',\n",
       "  'be',\n",
       "  'at',\n",
       "  'the',\n",
       "  'tip',\n",
       "  'of',\n",
       "  'an',\n",
       "  'iceberg',\n",
       "  'though',\n",
       "  'fertility',\n",
       "  'rates',\n",
       "  'are',\n",
       "  'dropping',\n",
       "  'and',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'people',\n",
       "  'are',\n",
       "  'foregoing',\n",
       "  'the',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'have',\n",
       "  'babies',\n",
       "  'we',\n",
       "  'might',\n",
       "  'just',\n",
       "  'have',\n",
       "  'crossed',\n",
       "  'the',\n",
       "  'threshold',\n",
       "  'the',\n",
       "  'population',\n",
       "  'projections',\n",
       "  'for',\n",
       "  'the',\n",
       "  'year',\n",
       "  '2050',\n",
       "  'is',\n",
       "  '98',\n",
       "  'billion',\n",
       "  'and',\n",
       "  'for',\n",
       "  '2100',\n",
       "  'is',\n",
       "  'a',\n",
       "  'whopping',\n",
       "  '112',\n",
       "  'billion1',\n",
       "  'somewhere',\n",
       "  'out',\n",
       "  'there',\n",
       "  'malthus',\n",
       "  'is',\n",
       "  'cackling',\n",
       "  'in',\n",
       "  'his',\n",
       "  'grave',\n",
       "  'the',\n",
       "  'year',\n",
       "  '2500',\n",
       "  'suddenly',\n",
       "  'seems',\n",
       "  'a',\n",
       "  'long',\n",
       "  'way',\n",
       "  'off',\n",
       "  'and',\n",
       "  'this',\n",
       "  'conversation',\n",
       "  'seems',\n",
       "  'evermore',\n",
       "  'pertinent',\n",
       "  'today',\n",
       "  'the',\n",
       "  'bulletin',\n",
       "  'of',\n",
       "  'atomic',\n",
       "  'scientists',\n",
       "  'is',\n",
       "  'not',\n",
       "  'optimistic',\n",
       "  'the',\n",
       "  'famed',\n",
       "  'doomsday',\n",
       "  'clock',\n",
       "  'they',\n",
       "  'maintain',\n",
       "  'is',\n",
       "  'the',\n",
       "  'closest',\n",
       "  'to',\n",
       "  'midnight',\n",
       "  'our',\n",
       "  'proximity',\n",
       "  'to',\n",
       "  'global',\n",
       "  'catastrophe',\n",
       "  'since',\n",
       "  'its',\n",
       "  'inception',\n",
       "  'in',\n",
       "  '1947',\n",
       "  'global',\n",
       "  'warming?',\n",
       "  'check',\n",
       "  'the',\n",
       "  'threat',\n",
       "  'of',\n",
       "  'nuclear',\n",
       "  'war?',\n",
       "  'check',\n",
       "  'ongoing',\n",
       "  'pandemic?',\n",
       "  'check',\n",
       "  'check',\n",
       "  'check',\n",
       "  'and',\n",
       "  'yet',\n",
       "  'hope',\n",
       "  'floats',\n",
       "  'for',\n",
       "  'three',\n",
       "  'reasons',\n",
       "  'mankind',\n",
       "  'may',\n",
       "  'just',\n",
       "  'have',\n",
       "  'its',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'wall',\n",
       "  'right',\n",
       "  'now',\n",
       "  'but',\n",
       "  'there',\n",
       "  'are',\n",
       "  'three',\n",
       "  'shoots',\n",
       "  'of',\n",
       "  'potential',\n",
       "  'that',\n",
       "  'might',\n",
       "  'just',\n",
       "  'help',\n",
       "  'us',\n",
       "  'make',\n",
       "  'it',\n",
       "  'to',\n",
       "  '2500',\n",
       "  'ad',\n",
       "  'the',\n",
       "  'advent',\n",
       "  'of',\n",
       "  'a',\n",
       "  'basket',\n",
       "  'of',\n",
       "  'disruptive',\n",
       "  'technologies',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'bioenhancement',\n",
       "  'genetic',\n",
       "  'engineering',\n",
       "  'the',\n",
       "  'private',\n",
       "  'sector',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'space',\n",
       "  'exploration',\n",
       "  'and',\n",
       "  'terraforming',\n",
       "  'and',\n",
       "  'good',\n",
       "  'old',\n",
       "  'fashioned',\n",
       "  'human',\n",
       "  'resilience',\n",
       "  'while',\n",
       "  'the',\n",
       "  'first',\n",
       "  'two',\n",
       "  'factors',\n",
       "  'will',\n",
       "  'no',\n",
       "  'doubt',\n",
       "  'be',\n",
       "  'critical',\n",
       "  'to',\n",
       "  'human',\n",
       "  'survival',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'third',\n",
       "  'one',\n",
       "  'that',\n",
       "  'we',\n",
       "  'must',\n",
       "  'pin',\n",
       "  'our',\n",
       "  'hopes',\n",
       "  'on',\n",
       "  'our',\n",
       "  'longdemonstrated',\n",
       "  'history',\n",
       "  'of',\n",
       "  'surviving',\n",
       "  'whatever',\n",
       "  'nature',\n",
       "  'the',\n",
       "  'universe',\n",
       "  'or',\n",
       "  'our',\n",
       "  'own',\n",
       "  'selfdestructive',\n",
       "  'tendency',\n",
       "  'throws',\n",
       "  'our',\n",
       "  'way',\n",
       "  'the',\n",
       "  'next',\n",
       "  'superman?',\n",
       "  'in',\n",
       "  'the',\n",
       "  '13th',\n",
       "  'century',\n",
       "  'in',\n",
       "  'the',\n",
       "  'italian',\n",
       "  'town',\n",
       "  'of',\n",
       "  'pisa',\n",
       "  'an',\n",
       "  'enterprising',\n",
       "  'tinkerer',\n",
       "  'developed',\n",
       "  'the',\n",
       "  'first',\n",
       "  'eyeglasses',\n",
       "  'for',\n",
       "  'a',\n",
       "  'local',\n",
       "  'friar',\n",
       "  'with',\n",
       "  'weakening',\n",
       "  'eyesight2',\n",
       "  'all',\n",
       "  'of',\n",
       "  'a',\n",
       "  'sudden',\n",
       "  'there',\n",
       "  'existed',\n",
       "  'an',\n",
       "  'external',\n",
       "  'device',\n",
       "  'that',\n",
       "  'could',\n",
       "  'amplify',\n",
       "  'our',\n",
       "  'senses',\n",
       "  'a',\n",
       "  'tool',\n",
       "  'that',\n",
       "  'gave',\n",
       "  'us',\n",
       "  'an',\n",
       "  'advantage',\n",
       "  'in',\n",
       "  'survival',\n",
       "  'today',\n",
       "  'lasik',\n",
       "  'surgeries',\n",
       "  'obviate',\n",
       "  'the',\n",
       "  'need',\n",
       "  'for',\n",
       "  'eyeglasses',\n",
       "  'entirely',\n",
       "  'hearing',\n",
       "  'aids',\n",
       "  'give',\n",
       "  'the',\n",
       "  'gift',\n",
       "  'of',\n",
       "  'auditory',\n",
       "  'perception',\n",
       "  'back',\n",
       "  'to',\n",
       "  'those',\n",
       "  'who',\n",
       "  'had',\n",
       "  'gotten',\n",
       "  'used',\n",
       "  'to',\n",
       "  'a',\n",
       "  'world',\n",
       "  'of',\n",
       "  'muffled',\n",
       "  'voices',\n",
       "  'and',\n",
       "  'unheard',\n",
       "  'sounds',\n",
       "  'the',\n",
       "  'iphone',\n",
       "  'routinely',\n",
       "  'comes',\n",
       "  'with',\n",
       "  'an',\n",
       "  'augmented',\n",
       "  'reality',\n",
       "  'tool',\n",
       "  'that',\n",
       "  'allows',\n",
       "  'us',\n",
       "  'to',\n",
       "  'measure',\n",
       "  'the',\n",
       "  'length',\n",
       "  'of',\n",
       "  'objects',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'us',\n",
       "  'but',\n",
       "  'the',\n",
       "  'real',\n",
       "  'science',\n",
       "  'starts',\n",
       "  'where',\n",
       "  'the',\n",
       "  'imagination',\n",
       "  'ends',\n",
       "  'augmented',\n",
       "  'reality',\n",
       "  'glasses',\n",
       "  'smart',\n",
       "  'wearables',\n",
       "  'and',\n",
       "  'virtual',\n",
       "  'reality',\n",
       "  'tools',\n",
       "  'will',\n",
       "  'be',\n",
       "  'ubiquitous',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  'few',\n",
       "  'decades',\n",
       "  'but',\n",
       "  'what',\n",
       "  'after',\n",
       "  'that?',\n",
       "  'science',\n",
       "  'has',\n",
       "  'the',\n",
       "  'answer',\n",
       "  'and',\n",
       "  'its',\n",
       "  'both',\n",
       "  'thrilling',\n",
       "  'and',\n",
       "  'scary',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'has',\n",
       "  'become',\n",
       "  'the',\n",
       "  'stuff',\n",
       "  'of',\n",
       "  'fable',\n",
       "  'the',\n",
       "  'filler',\n",
       "  'for',\n",
       "  'all',\n",
       "  'questions',\n",
       "  'left',\n",
       "  'unanswered',\n",
       "  'but',\n",
       "  'ai',\n",
       "  'combined',\n",
       "  'with',\n",
       "  'bioenhancement',\n",
       "  'and',\n",
       "  'genetic',\n",
       "  'engineering',\n",
       "  'might',\n",
       "  'just',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'the',\n",
       "  'evolution',\n",
       "  'of',\n",
       "  'what',\n",
       "  'some',\n",
       "  'are',\n",
       "  'calling',\n",
       "  'homo',\n",
       "  'nouveau3',\n",
       "  'homo',\n",
       "  'nouveau',\n",
       "  'will',\n",
       "  'be',\n",
       "  'smarter',\n",
       "  'faster',\n",
       "  'more',\n",
       "  'agile',\n",
       "  'and',\n",
       "  'better',\n",
       "  'equipped',\n",
       "  'to',\n",
       "  'adapt',\n",
       "  'to',\n",
       "  'what',\n",
       "  'promises',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'world',\n",
       "  'that',\n",
       "  'is',\n",
       "  'vuca',\n",
       "  'beyond',\n",
       "  'our',\n",
       "  'imaginations',\n",
       "  'what',\n",
       "  'might',\n",
       "  'such',\n",
       "  'a',\n",
       "  'human',\n",
       "  'being',\n",
       "  'look',\n",
       "  'like?',\n",
       "  'they',\n",
       "  'might',\n",
       "  'have',\n",
       "  'a',\n",
       "  'small',\n",
       "  'chip',\n",
       "  'embedded',\n",
       "  'in',\n",
       "  'their',\n",
       "  'brain',\n",
       "  'that',\n",
       "  'utilizes',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'for',\n",
       "  'enhanced',\n",
       "  'sensory',\n",
       "  'perception',\n",
       "  'what',\n",
       "  'does',\n",
       "  'that',\n",
       "  'mean?',\n",
       "  'it',\n",
       "  'means',\n",
       "  'that',\n",
       "  'they',\n",
       "  'would',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'see',\n",
       "  'better',\n",
       "  'focuses',\n",
       "  'their',\n",
       "  'attention',\n",
       "  'for',\n",
       "  'longer',\n",
       "  'hears',\n",
       "  'what',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'hear',\n",
       "  'and',\n",
       "  'communicate',\n",
       "  'the',\n",
       "  'appropriate',\n",
       "  'reaction',\n",
       "  'to',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'the',\n",
       "  'body',\n",
       "  'through',\n",
       "  'a',\n",
       "  'chemical',\n",
       "  'in',\n",
       "  'the',\n",
       "  'blood',\n",
       "  'this',\n",
       "  'ai',\n",
       "  'chip',\n",
       "  'would',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'demand',\n",
       "  'the',\n",
       "  'appropriate',\n",
       "  'response',\n",
       "  'from',\n",
       "  'the',\n",
       "  'body',\n",
       "  'bioaugmentation',\n",
       "  'of',\n",
       "  'limbs',\n",
       "  'and',\n",
       "  'organs',\n",
       "  'internal',\n",
       "  'and',\n",
       "  'external',\n",
       "  'would',\n",
       "  'mean',\n",
       "  'that',\n",
       "  'what',\n",
       "  'a',\n",
       "  'person',\n",
       "  'can',\n",
       "  'or',\n",
       "  'cannot',\n",
       "  'do',\n",
       "  'is',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'determined',\n",
       "  'at',\n",
       "  'birth',\n",
       "  'but',\n",
       "  'can',\n",
       "  'simply',\n",
       "  'be',\n",
       "  'bought',\n",
       "  'all',\n",
       "  'of',\n",
       "  'a',\n",
       "  'sudden',\n",
       "  'the',\n",
       "  'average',\n",
       "  'joe',\n",
       "  'can',\n",
       "  'run',\n",
       "  'faster',\n",
       "  'than',\n",
       "  'usain',\n",
       "  'bolt',\n",
       "  'swim',\n",
       "  'better',\n",
       "  'than',\n",
       "  'michael',\n",
       "  'phelps',\n",
       "  'andfly?',\n",
       "  'maybe',\n",
       "  'genetic',\n",
       "  'engineering',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'missing',\n",
       "  'link',\n",
       "  'already',\n",
       "  'there',\n",
       "  'are',\n",
       "  'feverish',\n",
       "  'conversations',\n",
       "  'about',\n",
       "  'a',\n",
       "  'dystopian',\n",
       "  'future',\n",
       "  'featuring',\n",
       "  'designer',\n",
       "  'babies',\n",
       "  'and',\n",
       "  'a',\n",
       "  'digital',\n",
       "  'divide',\n",
       "  'that',\n",
       "  'simply',\n",
       "  'cannot',\n",
       "  'be',\n",
       "  'overcome',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'inbuilt',\n",
       "  'into',\n",
       "  'ones',\n",
       "  'dna',\n",
       "  'the',\n",
       "  'breakthrough',\n",
       "  'with',\n",
       "  'crisprcas9',\n",
       "  'might',\n",
       "  'just',\n",
       "  'be',\n",
       "  'the',\n",
       "  'key',\n",
       "  'to',\n",
       "  'unlock',\n",
       "  'the',\n",
       "  'mysteries',\n",
       "  'of',\n",
       "  'dna',\n",
       "  'manipulation',\n",
       "  'so',\n",
       "  'what',\n",
       "  'if',\n",
       "  'theres',\n",
       "  'no',\n",
       "  'food',\n",
       "  'left?',\n",
       "  'our',\n",
       "  'body',\n",
       "  'ai',\n",
       "  'will',\n",
       "  'adjust',\n",
       "  'our',\n",
       "  'appetite',\n",
       "  'accordingly',\n",
       "  'no',\n",
       "  'water?',\n",
       "  'absorb',\n",
       "  'humidity',\n",
       "  'from',\n",
       "  'the',\n",
       "  'air',\n",
       "  'through',\n",
       "  'specialized',\n",
       "  'pores',\n",
       "  'in',\n",
       "  'the',\n",
       "  'skin',\n",
       "  'the',\n",
       "  'human',\n",
       "  'being',\n",
       "  'in',\n",
       "  '2500',\n",
       "  'ad',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'how',\n",
       "  'we',\n",
       "  'recognize',\n",
       "  'one',\n",
       "  'today',\n",
       "  'that',\n",
       "  'may',\n",
       "  'be',\n",
       "  'our',\n",
       "  'only',\n",
       "  'shot',\n",
       "  'galactic',\n",
       "  'dominance',\n",
       "  'spacex',\n",
       "  'led',\n",
       "  'by',\n",
       "  'its',\n",
       "  'mercurial',\n",
       "  'leader',\n",
       "  'elon',\n",
       "  'musk',\n",
       "  'has',\n",
       "  'been',\n",
       "  'the',\n",
       "  'leader',\n",
       "  'here',\n",
       "  'the',\n",
       "  'spacex',\n",
       "  'mars',\n",
       "  'programme',\n",
       "  'is',\n",
       "  'based',\n",
       "  'on',\n",
       "  'a',\n",
       "  'very',\n",
       "  'simple',\n",
       "  'premise',\n",
       "  'as',\n",
       "  'the',\n",
       "  'earths',\n",
       "  'closest',\n",
       "  'planet',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'distance',\n",
       "  'and',\n",
       "  'terrestrial',\n",
       "  'conditions',\n",
       "  'mars',\n",
       "  'would',\n",
       "  'be',\n",
       "  'our',\n",
       "  'best',\n",
       "  'bet',\n",
       "  'for',\n",
       "  'colonization',\n",
       "  'musk',\n",
       "  'has',\n",
       "  'invested',\n",
       "  'billions',\n",
       "  'of',\n",
       "  'dollars',\n",
       "  'in',\n",
       "  'the',\n",
       "  'mars',\n",
       "  'space',\n",
       "  'programme',\n",
       "  'and',\n",
       "  'remains',\n",
       "  'a',\n",
       "  'fervent',\n",
       "  'believer',\n",
       "  'in',\n",
       "  'the',\n",
       "  'concept',\n",
       "  'and',\n",
       "  'among',\n",
       "  'tech',\n",
       "  'visionaries',\n",
       "  'musk',\n",
       "  'is',\n",
       "  'not',\n",
       "  'alone',\n",
       "  'jeff',\n",
       "  'bezos',\n",
       "  'the',\n",
       "  'richest',\n",
       "  'man',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'owns',\n",
       "  'blue',\n",
       "  'origin',\n",
       "  'which',\n",
       "  'simply',\n",
       "  'aims',\n",
       "  'to',\n",
       "  'make',\n",
       "  'spaceflight',\n",
       "  'cheaper',\n",
       "  'through',\n",
       "  'incremental',\n",
       "  'technological',\n",
       "  'growth',\n",
       "  'bezos',\n",
       "  'who',\n",
       "  'took',\n",
       "  'an',\n",
       "  'online',\n",
       "  ...]]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/74.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "15826198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441\n",
      "WORD COUNT 902\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "dde82038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 21.043478260869566\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "c0519f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.30376940133037694\n",
      "FOG INDEX: 8.538899064879978\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 21.043478260869566\n",
      "COMPLEX WORD COUNT: 274\n",
      "WORD COUNT: 902\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "255230a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2641\n",
      "I: 0\n",
      "we: 11\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 5\n",
      "Total count: 16\n",
      "PERSONAL PRONOUNS: 16\n",
      "AVG WORD LENGTH: 4.996556473829201\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_74.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5874fc0a",
   "metadata": {},
   "source": [
    "# 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "2980acf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\4038436521.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ebf874b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. Sakamoto is a bonsai artist, lives downtown Kyoto, Japan. Bonsai is a Japanese art form that is the cultivation of small trees in a small or medium container. He is in this field of business for the last ten years and he loves what he does on a daily basis. People from different cities in Japan, come to buy his artwork. But, in the early stage of his business, he was just another regular Bosai artist. His popularity has increased because of the stories he tells for every art he is selling. His customer immediately loved him for this while buying A Bonsai art. He loved to sell his customer with his artwork and a story related to that product which resurrects his presence through his art in customers. Soon enough his business thrived and nowadays he is always busy. After the digital revolution, although his sales increased, he was not happy. He was not satisfied. Something is eating up his mind day by day. He could not understand what’s the reason behind his remorse.',\n",
       " 'A chatbot is an awesome invention of the digital revolution. It is the real-life embodiment of Customer Engagement. Every business needs this feature- will be an understatement. Because Customer engagement is the base of any business. The chatbot does the exact thing digitally. It helps customers to answer the queries and tell about the product that the business has to offer is a fully automated way with vibrant customizations.',\n",
       " '            Mr. Sakamoto is running his business for the last fifteen years now. And now he is happy that he was not for the past couple of years. The rationale behind his happiness is the chatbot. Though he has a website and app to sell his Bonsai art, he could not engage with the customers in the way he wanted to. He has trained his employees and apprentices, but they are not providing the same service in the way he does. He was unsatisfied and the chatbot relives him from his sadness. He has done all that at affordable prices in no time.',\n",
       " 'Let’s understand the Mr. Sakamoto’s “Mondai Nai”- perspective about why chatbot is the answer of his problems.',\n",
       " 'This is the fundamental and root cause for which Mr. Sakamoto has to implement the chatbot in the first place. His stories are embedded with each art. The product which he sells needs this story to be with it. His stories which were not been told to all the customers before are now sharing with this chatbot and building the trust between them. We all can agree on this one statement that trust is the most impactful aspect, maybe the best of aspects, in the relation between any customer and business-owner, whether the business is small, medium, or large.',\n",
       " 'Millennials, a word that was not introduced before 1990. The generation which is stuck in between Gen-x and Gen-y. A generation of people accustomed to both digitization and old culture. They are the most targeted audience in this era. What else would be more approachable to this generation than a chatbot? It’s easy, less time consuming to use. Mr. Sakamoto is now one of the few Gen-x persons who can do business with the millennial so easily.',\n",
       " 'Mr. Sakamoto has some employees and apprentices. He has trained them as per his needs. But there is a limit. They can’t deliver the exact things that he can or the way he does. Neither chatbot can do that exactly, it will accurately follow the instructions. Not only the chatbot solve the queries of the customer in his way, but also give a recommendation to the product in the way he wants too. Is there any more attribute he would care about that? Absolutely no!',\n",
       " 'The most expensive thing for any businessman is the return of their customer with an empty hand because of his unavailability. A chatbot is a perfect way to solve it. For Mr. Sakamoto’s customized chatbot is not only present for customers in their availability, but also It was giving the response to the customer in all the time zone, all over the world. Mr. Sakamoto wouldn’t be happier for this feature.',\n",
       " 'In the era of globalization, what is more, helpful than a chatbot? It can be customized in any language. It can be accessed by any human being residing in any part of the world. And at the end of the day, when that foreigner is happy with the buy and the felicitation and says “Arigato” but in his own language, at that moment he feels so warm and happy.',\n",
       " 'Handling a lot of customers is really hard. He assigned employees, but the rate is growing fast. So, in the competition of the market, Mr. Sakamoto took the help of a chatbot. Now this automated customized application is handling a greater number of customers than his employees can do. His business is growing exponentially.',\n",
       " 'Now, when you found out why Mr. Sakamoto is happy and his business is growing in this competitive industry then, do you still have a question in mind that why does your business need a chatbot?']"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "bc76b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:27]))\n",
    "URL_ID_75 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "6fdad0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 67 sentences in the string.\n",
      "The number of words in the string is: 874\n",
      "The number of characters in the string is: 4082\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 02:25:26] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 02:25:32] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_75.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_75.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_75.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_75 = re.sub(re_punt, \"\",URL_ID_75)\n",
    "\n",
    "file = open(\"75.txt\", \"w\")\n",
    "file.write(URL_ID_75)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"75.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "d90448ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['building',\n",
       "  'the',\n",
       "  'trust',\n",
       "  'with',\n",
       "  'customers',\n",
       "  'target',\n",
       "  'the',\n",
       "  'millennial',\n",
       "  'customer',\n",
       "  'better',\n",
       "  'human',\n",
       "  'interactions',\n",
       "  '247',\n",
       "  'service',\n",
       "  'scaling',\n",
       "  'up',\n",
       "  'business',\n",
       "  'in',\n",
       "  'globalization',\n",
       "  'mr',\n",
       "  'sakamoto',\n",
       "  'is',\n",
       "  'a',\n",
       "  'bonsai',\n",
       "  'artist',\n",
       "  'lives',\n",
       "  'downtown',\n",
       "  'kyoto',\n",
       "  'japan',\n",
       "  'bonsai',\n",
       "  'is',\n",
       "  'a',\n",
       "  'japanese',\n",
       "  'art',\n",
       "  'form',\n",
       "  'that',\n",
       "  'is',\n",
       "  'the',\n",
       "  'cultivation',\n",
       "  'of',\n",
       "  'small',\n",
       "  'trees',\n",
       "  'in',\n",
       "  'a',\n",
       "  'small',\n",
       "  'or',\n",
       "  'medium',\n",
       "  'container',\n",
       "  'he',\n",
       "  'is',\n",
       "  'in',\n",
       "  'this',\n",
       "  'field',\n",
       "  'of',\n",
       "  'business',\n",
       "  'for',\n",
       "  'the',\n",
       "  'last',\n",
       "  'ten',\n",
       "  'years',\n",
       "  'and',\n",
       "  'he',\n",
       "  'loves',\n",
       "  'what',\n",
       "  'he',\n",
       "  'does',\n",
       "  'on',\n",
       "  'a',\n",
       "  'daily',\n",
       "  'basis',\n",
       "  'people',\n",
       "  'from',\n",
       "  'different',\n",
       "  'cities',\n",
       "  'in',\n",
       "  'japan',\n",
       "  'come',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'his',\n",
       "  'artwork',\n",
       "  'but',\n",
       "  'in',\n",
       "  'the',\n",
       "  'early',\n",
       "  'stage',\n",
       "  'of',\n",
       "  'his',\n",
       "  'business',\n",
       "  'he',\n",
       "  'was',\n",
       "  'just',\n",
       "  'another',\n",
       "  'regular',\n",
       "  'bosai',\n",
       "  'artist',\n",
       "  'his',\n",
       "  'popularity',\n",
       "  'has',\n",
       "  'increased',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'stories',\n",
       "  'he',\n",
       "  'tells',\n",
       "  'for',\n",
       "  'every',\n",
       "  'art',\n",
       "  'he',\n",
       "  'is',\n",
       "  'selling',\n",
       "  'his',\n",
       "  'customer',\n",
       "  'immediately',\n",
       "  'loved',\n",
       "  'him',\n",
       "  'for',\n",
       "  'this',\n",
       "  'while',\n",
       "  'buying',\n",
       "  'a',\n",
       "  'bonsai',\n",
       "  'art',\n",
       "  'he',\n",
       "  'loved',\n",
       "  'to',\n",
       "  'sell',\n",
       "  'his',\n",
       "  'customer',\n",
       "  'with',\n",
       "  'his',\n",
       "  'artwork',\n",
       "  'and',\n",
       "  'a',\n",
       "  'story',\n",
       "  'related',\n",
       "  'to',\n",
       "  'that',\n",
       "  'product',\n",
       "  'which',\n",
       "  'resurrects',\n",
       "  'his',\n",
       "  'presence',\n",
       "  'through',\n",
       "  'his',\n",
       "  'art',\n",
       "  'in',\n",
       "  'customers',\n",
       "  'soon',\n",
       "  'enough',\n",
       "  'his',\n",
       "  'business',\n",
       "  'thrived',\n",
       "  'and',\n",
       "  'nowadays',\n",
       "  'he',\n",
       "  'is',\n",
       "  'always',\n",
       "  'busy',\n",
       "  'after',\n",
       "  'the',\n",
       "  'digital',\n",
       "  'revolution',\n",
       "  'although',\n",
       "  'his',\n",
       "  'sales',\n",
       "  'increased',\n",
       "  'he',\n",
       "  'was',\n",
       "  'not',\n",
       "  'happy',\n",
       "  'he',\n",
       "  'was',\n",
       "  'not',\n",
       "  'satisfied',\n",
       "  'something',\n",
       "  'is',\n",
       "  'eating',\n",
       "  'up',\n",
       "  'his',\n",
       "  'mind',\n",
       "  'day',\n",
       "  'by',\n",
       "  'day',\n",
       "  'he',\n",
       "  'could',\n",
       "  'not',\n",
       "  'understand',\n",
       "  'whats',\n",
       "  'the',\n",
       "  'reason',\n",
       "  'behind',\n",
       "  'his',\n",
       "  'remorse',\n",
       "  'a',\n",
       "  'chatbot',\n",
       "  'is',\n",
       "  'an',\n",
       "  'awesome',\n",
       "  'invention',\n",
       "  'of',\n",
       "  'the',\n",
       "  'digital',\n",
       "  'revolution',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'reallife',\n",
       "  'embodiment',\n",
       "  'of',\n",
       "  'customer',\n",
       "  'engagement',\n",
       "  'every',\n",
       "  'business',\n",
       "  'needs',\n",
       "  'this',\n",
       "  'feature',\n",
       "  'will',\n",
       "  'be',\n",
       "  'an',\n",
       "  'understatement',\n",
       "  'because',\n",
       "  'customer',\n",
       "  'engagement',\n",
       "  'is',\n",
       "  'the',\n",
       "  'base',\n",
       "  'of',\n",
       "  'any',\n",
       "  'business',\n",
       "  'the',\n",
       "  'chatbot',\n",
       "  'does',\n",
       "  'the',\n",
       "  'exact',\n",
       "  'thing',\n",
       "  'digitally',\n",
       "  'it',\n",
       "  'helps',\n",
       "  'customers',\n",
       "  'to',\n",
       "  'answer',\n",
       "  'the',\n",
       "  'queries',\n",
       "  'and',\n",
       "  'tell',\n",
       "  'about',\n",
       "  'the',\n",
       "  'product',\n",
       "  'that',\n",
       "  'the',\n",
       "  'business',\n",
       "  'has',\n",
       "  'to',\n",
       "  'offer',\n",
       "  'is',\n",
       "  'a',\n",
       "  'fully',\n",
       "  'automated',\n",
       "  'way',\n",
       "  'with',\n",
       "  'vibrant',\n",
       "  'customizations',\n",
       "  'mr',\n",
       "  'sakamoto',\n",
       "  'is',\n",
       "  'running',\n",
       "  'his',\n",
       "  'business',\n",
       "  'for',\n",
       "  'the',\n",
       "  'last',\n",
       "  'fifteen',\n",
       "  'years',\n",
       "  'now',\n",
       "  'and',\n",
       "  'now',\n",
       "  'he',\n",
       "  'is',\n",
       "  'happy',\n",
       "  'that',\n",
       "  'he',\n",
       "  'was',\n",
       "  'not',\n",
       "  'for',\n",
       "  'the',\n",
       "  'past',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'years',\n",
       "  'the',\n",
       "  'rationale',\n",
       "  'behind',\n",
       "  'his',\n",
       "  'happiness',\n",
       "  'is',\n",
       "  'the',\n",
       "  'chatbot',\n",
       "  'though',\n",
       "  'he',\n",
       "  'has',\n",
       "  'a',\n",
       "  'website',\n",
       "  'and',\n",
       "  'app',\n",
       "  'to',\n",
       "  'sell',\n",
       "  'his',\n",
       "  'bonsai',\n",
       "  'art',\n",
       "  'he',\n",
       "  'could',\n",
       "  'not',\n",
       "  'engage',\n",
       "  'with',\n",
       "  'the',\n",
       "  'customers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'way',\n",
       "  'he',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'he',\n",
       "  'has',\n",
       "  'trained',\n",
       "  'his',\n",
       "  'employees',\n",
       "  'and',\n",
       "  'apprentices',\n",
       "  'but',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'providing',\n",
       "  'the',\n",
       "  'same',\n",
       "  'service',\n",
       "  'in',\n",
       "  'the',\n",
       "  'way',\n",
       "  'he',\n",
       "  'does',\n",
       "  'he',\n",
       "  'was',\n",
       "  'unsatisfied',\n",
       "  'and',\n",
       "  'the',\n",
       "  'chatbot',\n",
       "  'relives',\n",
       "  'him',\n",
       "  'from',\n",
       "  'his',\n",
       "  'sadness',\n",
       "  'he',\n",
       "  'has',\n",
       "  'done',\n",
       "  'all',\n",
       "  'that',\n",
       "  'at',\n",
       "  'affordable',\n",
       "  'prices',\n",
       "  'in',\n",
       "  'no',\n",
       "  'time',\n",
       "  'lets',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'mr',\n",
       "  'sakamotos',\n",
       "  'mondai',\n",
       "  'nai',\n",
       "  'perspective',\n",
       "  'about',\n",
       "  'why',\n",
       "  'chatbot',\n",
       "  'is',\n",
       "  'the',\n",
       "  'answer',\n",
       "  'of',\n",
       "  'his',\n",
       "  'problems',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'fundamental',\n",
       "  'and',\n",
       "  'root',\n",
       "  'cause',\n",
       "  'for',\n",
       "  'which',\n",
       "  'mr',\n",
       "  'sakamoto',\n",
       "  'has',\n",
       "  'to',\n",
       "  'implement',\n",
       "  'the',\n",
       "  'chatbot',\n",
       "  'in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'place',\n",
       "  'his',\n",
       "  'stories',\n",
       "  'are',\n",
       "  'embedded',\n",
       "  'with',\n",
       "  'each',\n",
       "  'art',\n",
       "  'the',\n",
       "  'product',\n",
       "  'which',\n",
       "  'he',\n",
       "  'sells',\n",
       "  'needs',\n",
       "  'this',\n",
       "  'story',\n",
       "  'to',\n",
       "  'be',\n",
       "  'with',\n",
       "  'it',\n",
       "  'his',\n",
       "  'stories',\n",
       "  'which',\n",
       "  'were',\n",
       "  'not',\n",
       "  'been',\n",
       "  'told',\n",
       "  'to',\n",
       "  'all',\n",
       "  'the',\n",
       "  'customers',\n",
       "  'before',\n",
       "  'are',\n",
       "  'now',\n",
       "  'sharing',\n",
       "  'with',\n",
       "  'this',\n",
       "  'chatbot',\n",
       "  'and',\n",
       "  'building',\n",
       "  'the',\n",
       "  'trust',\n",
       "  'between',\n",
       "  'them',\n",
       "  'we',\n",
       "  'all',\n",
       "  'can',\n",
       "  'agree',\n",
       "  'on',\n",
       "  'this',\n",
       "  'one',\n",
       "  'statement',\n",
       "  'that',\n",
       "  'trust',\n",
       "  'is',\n",
       "  'the',\n",
       "  'most',\n",
       "  'impactful',\n",
       "  'aspect',\n",
       "  'maybe',\n",
       "  'the',\n",
       "  'best',\n",
       "  'of',\n",
       "  'aspects',\n",
       "  'in',\n",
       "  'the',\n",
       "  'relation',\n",
       "  'between',\n",
       "  'any',\n",
       "  'customer',\n",
       "  'and',\n",
       "  'businessowner',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'business',\n",
       "  'is',\n",
       "  'small',\n",
       "  'medium',\n",
       "  'or',\n",
       "  'large',\n",
       "  'millennials',\n",
       "  'a',\n",
       "  'word',\n",
       "  'that',\n",
       "  'was',\n",
       "  'not',\n",
       "  'introduced',\n",
       "  'before',\n",
       "  '1990',\n",
       "  'the',\n",
       "  'generation',\n",
       "  'which',\n",
       "  'is',\n",
       "  'stuck',\n",
       "  'in',\n",
       "  'between',\n",
       "  'genx',\n",
       "  'and',\n",
       "  'geny',\n",
       "  'a',\n",
       "  'generation',\n",
       "  'of',\n",
       "  'people',\n",
       "  'accustomed',\n",
       "  'to',\n",
       "  'both',\n",
       "  'digitization',\n",
       "  'and',\n",
       "  'old',\n",
       "  'culture',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  'most',\n",
       "  'targeted',\n",
       "  'audience',\n",
       "  'in',\n",
       "  'this',\n",
       "  'era',\n",
       "  'what',\n",
       "  'else',\n",
       "  'would',\n",
       "  'be',\n",
       "  'more',\n",
       "  'approachable',\n",
       "  'to',\n",
       "  'this',\n",
       "  'generation',\n",
       "  'than',\n",
       "  'a',\n",
       "  'chatbot?',\n",
       "  'its',\n",
       "  'easy',\n",
       "  'less',\n",
       "  'time',\n",
       "  'consuming',\n",
       "  'to',\n",
       "  'use',\n",
       "  'mr',\n",
       "  'sakamoto',\n",
       "  'is',\n",
       "  'now',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'few',\n",
       "  'genx',\n",
       "  'persons',\n",
       "  'who',\n",
       "  'can',\n",
       "  'do',\n",
       "  'business',\n",
       "  'with',\n",
       "  'the',\n",
       "  'millennial',\n",
       "  'so',\n",
       "  'easily',\n",
       "  'mr',\n",
       "  'sakamoto',\n",
       "  'has',\n",
       "  'some',\n",
       "  'employees',\n",
       "  'and',\n",
       "  'apprentices',\n",
       "  'he',\n",
       "  'has',\n",
       "  'trained',\n",
       "  'them',\n",
       "  'as',\n",
       "  'per',\n",
       "  'his',\n",
       "  'needs',\n",
       "  'but',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'limit',\n",
       "  'they',\n",
       "  'cant',\n",
       "  'deliver',\n",
       "  'the',\n",
       "  'exact',\n",
       "  'things',\n",
       "  'that',\n",
       "  'he',\n",
       "  'can',\n",
       "  'or',\n",
       "  'the',\n",
       "  'way',\n",
       "  'he',\n",
       "  'does',\n",
       "  'neither',\n",
       "  'chatbot',\n",
       "  'can',\n",
       "  'do',\n",
       "  'that',\n",
       "  'exactly',\n",
       "  'it',\n",
       "  'will',\n",
       "  'accurately',\n",
       "  'follow',\n",
       "  'the',\n",
       "  'instructions',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'chatbot',\n",
       "  'solve',\n",
       "  'the',\n",
       "  'queries',\n",
       "  'of',\n",
       "  'the',\n",
       "  'customer',\n",
       "  'in',\n",
       "  'his',\n",
       "  'way',\n",
       "  'but',\n",
       "  'also',\n",
       "  'give',\n",
       "  'a',\n",
       "  'recommendation',\n",
       "  'to',\n",
       "  'the',\n",
       "  'product',\n",
       "  'in',\n",
       "  'the',\n",
       "  'way',\n",
       "  'he',\n",
       "  'wants',\n",
       "  'too',\n",
       "  'is',\n",
       "  'there',\n",
       "  'any',\n",
       "  'more',\n",
       "  'attribute',\n",
       "  'he',\n",
       "  'would',\n",
       "  'care',\n",
       "  'about',\n",
       "  'that?',\n",
       "  'absolutely',\n",
       "  'no!',\n",
       "  'the',\n",
       "  'most',\n",
       "  'expensive',\n",
       "  'thing',\n",
       "  'for',\n",
       "  'any',\n",
       "  'businessman',\n",
       "  'is',\n",
       "  'the',\n",
       "  'return',\n",
       "  'of',\n",
       "  'their',\n",
       "  'customer',\n",
       "  'with',\n",
       "  'an',\n",
       "  'empty',\n",
       "  'hand',\n",
       "  'because',\n",
       "  'of',\n",
       "  'his',\n",
       "  'unavailability',\n",
       "  'a',\n",
       "  'chatbot',\n",
       "  'is',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  'way',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'it',\n",
       "  'for',\n",
       "  'mr',\n",
       "  'sakamotos',\n",
       "  'customized',\n",
       "  'chatbot',\n",
       "  'is',\n",
       "  'not',\n",
       "  'only',\n",
       "  'present',\n",
       "  'for',\n",
       "  'customers',\n",
       "  'in',\n",
       "  'their',\n",
       "  'availability',\n",
       "  'but',\n",
       "  'also',\n",
       "  'it',\n",
       "  'was',\n",
       "  'giving',\n",
       "  'the',\n",
       "  'response',\n",
       "  'to',\n",
       "  'the',\n",
       "  'customer',\n",
       "  'in',\n",
       "  'all',\n",
       "  'the',\n",
       "  'time',\n",
       "  'zone',\n",
       "  'all',\n",
       "  'over',\n",
       "  'the',\n",
       "  'world',\n",
       "  'mr',\n",
       "  'sakamoto',\n",
       "  'wouldnt',\n",
       "  'be',\n",
       "  'happier',\n",
       "  'for',\n",
       "  'this',\n",
       "  'feature',\n",
       "  'in',\n",
       "  'the',\n",
       "  'era',\n",
       "  'of',\n",
       "  'globalization',\n",
       "  'what',\n",
       "  'is',\n",
       "  'more',\n",
       "  'helpful',\n",
       "  'than',\n",
       "  'a',\n",
       "  'chatbot?',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'customized',\n",
       "  'in',\n",
       "  'any',\n",
       "  'language',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'accessed',\n",
       "  'by',\n",
       "  'any',\n",
       "  'human',\n",
       "  'being',\n",
       "  'residing',\n",
       "  'in',\n",
       "  'any',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  'and',\n",
       "  'at',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'day',\n",
       "  'when',\n",
       "  'that',\n",
       "  'foreigner',\n",
       "  'is',\n",
       "  'happy',\n",
       "  'with',\n",
       "  'the',\n",
       "  'buy',\n",
       "  'and',\n",
       "  'the',\n",
       "  'felicitation',\n",
       "  'and',\n",
       "  'says',\n",
       "  'arigato',\n",
       "  'but',\n",
       "  'in',\n",
       "  'his',\n",
       "  'own',\n",
       "  'language',\n",
       "  'at',\n",
       "  'that',\n",
       "  'moment',\n",
       "  'he',\n",
       "  'feels',\n",
       "  'so',\n",
       "  'warm',\n",
       "  'and',\n",
       "  'happy',\n",
       "  'handling',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'customers',\n",
       "  'is',\n",
       "  'really',\n",
       "  'hard',\n",
       "  'he',\n",
       "  'assigned',\n",
       "  'employees',\n",
       "  'but',\n",
       "  'the',\n",
       "  'rate',\n",
       "  'is',\n",
       "  'growing',\n",
       "  'fast',\n",
       "  'so',\n",
       "  'in',\n",
       "  'the',\n",
       "  'competition',\n",
       "  'of',\n",
       "  'the',\n",
       "  'market',\n",
       "  'mr',\n",
       "  'sakamoto',\n",
       "  'took',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'a',\n",
       "  'chatbot',\n",
       "  'now',\n",
       "  'this',\n",
       "  'automated',\n",
       "  'customized',\n",
       "  'application',\n",
       "  'is',\n",
       "  'handling',\n",
       "  'a',\n",
       "  'greater',\n",
       "  'number',\n",
       "  'of',\n",
       "  'customers',\n",
       "  'than',\n",
       "  'his',\n",
       "  'employees',\n",
       "  'can',\n",
       "  'do',\n",
       "  'his',\n",
       "  'business',\n",
       "  'is',\n",
       "  'growing',\n",
       "  'exponentially',\n",
       "  'now',\n",
       "  'when',\n",
       "  'you',\n",
       "  'found',\n",
       "  'out',\n",
       "  'why',\n",
       "  'mr',\n",
       "  'sakamoto',\n",
       "  'is',\n",
       "  'happy',\n",
       "  'and',\n",
       "  'his',\n",
       "  'business',\n",
       "  'is',\n",
       "  'growing',\n",
       "  'in',\n",
       "  'this',\n",
       "  'competitive',\n",
       "  'industry',\n",
       "  'then',\n",
       "  'do',\n",
       "  'you',\n",
       "  'still',\n",
       "  'have',\n",
       "  'a',\n",
       "  'question',\n",
       "  'in',\n",
       "  'mind',\n",
       "  'that',\n",
       "  'why',\n",
       "  'does',\n",
       "  'your',\n",
       "  'business',\n",
       "  'need',\n",
       "  'a',\n",
       "  'chatbot?']]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/75.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "c7e48328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874\n",
      "WORD COUNT 532\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "3ee7b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 13.044776119402986\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "dbf49129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.2781954887218045\n",
      "FOG INDEX: 5.329188643249917\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 13.044776119402986\n",
      "COMPLEX WORD COUNT: 148\n",
      "WORD COUNT: 532\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "7bc62f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1486\n",
      "I: 0\n",
      "we: 1\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 1\n",
      "PERSONAL PRONOUNS: 1\n",
      "AVG WORD LENGTH: 4.670480549199085\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_75.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fbbdc6",
   "metadata": {},
   "source": [
    "# 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "393df947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\85805472.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f7a0030f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Have you ever wondered what’s common between Sir Alex Ferguson, Pep Guardiola, and Jose Mourinho? I know it might look a lame question, especially to the ardent football followers. At first instinct, the answer is that they are regarded as the top managers in the football universe. #UCLwinners. But when given a closer look, these managers, weren’t that great when it came to their careers as football players. Any naïve observer can build a fallacy of causation and correlation that those who don’t have a great career as a football player will go on to become a great football manager. But is this restricted just to football? Mike Brearley, one of the greatest captains in the history of cricket and the author of the book the art of captaincy, wasn’t the prolific batsman of his time. Our former President, A P J Abdul Kalam didn’t have a political background, but was still appointed as the president of our country and went to become one of the finest presidents our country has ever had. So, can it be stated with confidence that great leaders need not be the expert in their respective fields?\\nLet’s understand the leadership role, types of leaders, and explore a few more perspectives before we arrive at a conclusion. ',\n",
       " 'Let’s start by first understanding what or who is a leader. A leader is not a position or a designation. It’s a virtue if employed correctly. From a janitor to the CEO, from a student to a researcher, from a content writer to a philosopher everybody is a leader. (#leadersareeverywhere) So, what are the virtues of a leader? One of the famous personality trait theories, the Big 5 personality trait theory is always linked closely with leadership. As per the various researches, the personality traits of extraversion, openness, and conscientiousness are associated with leaders more often than the other two traits. Not just these humble and empathetic are also considered as the adjectives that are frequently associated with leaders. But nowhere is technical expertise related to a leader. #NOTSOTECHNICAL',\n",
       " 'As stated by Colin Powell Leadership is the art of accomplishing more than the science of management says is possible. #It’sART If leadership is an art and leaders are the artists then more or less the leaders can be viewed as directors of the films who are organizing, arranging, managing, and directing the scenes. Another analogy for that can be the orchestra where the conductor is using the baton/stick to set the rhythm of the band. So, is it necessary for the conductor to himself or herself by a great violinist? No. When it comes to the corporate sector the leader need not be an expert on the technology but should know how the technology functions so that he/she can utilize it in the best possible way. They can allocate the task of building technology to the right technical experts. And how do the leaders identify the right person for that job? Or how do leaders know what qualities to look for in a person? #Experience. Every great leader once started off as one of the frontline workers or at the bottom of the pyramid in the hierarchical structure. Even though they might not have had the technical expertise in their respective fields, their visionary outlook, their management skills, and the experience they gathered helped them in achieving their targets. Leaders can always take the assistance of the subject matter experts to guide them in situations of technical difficulties. As per the great man, situational and trait theory of leadership, leadership is innate to the person. Leadership though can be conditioned or can be brought out in a person by rewarding him, great leaders show unconditional attachment towards their vision. Everyone knows how to read a map, but which path to choose isn’t something that can be taught. Leaders give the direction or vision to the company and drive it closer to the target that the company wants to achieve. Leadership theories don’t focus on the technical knowledge of the leaders, but rather more on people skills, their approach towards a problem, and how well they guide and hire others to get the job done, which is also evident as per the managerial skills required as per Robert Katz.',\n",
       " 'Though it can be argued that technical experts are also the great leaders in their areas, but these leaders are generally at the middle management level. As per the different leadership styles, a servant leader is the one who always tries to achieve the goal of the team. These leaders are the ones who have a management objective laid out in front of them and they drive the team closer to achieving the target by having the people-first mindset, a collaborative approach towards solving the problem. These are the people or the leaders needed at the execution level of the project or those who are too close to the employees at the bottom-most level. Since the managers at the top of the pyramid don’t get much time to invest in people they appoint the right people on their behalf to get the job done.  ',\n",
       " 'Consider an IT firm. So as per the points mentioned above, does it mean that a leader or the manager shouldn’t know how to code? Depends. If the person is the first line manager then he or she should probably know how to code so that he or she can help the team in achieving the target of producing less garbage which might be one of the project’s KPIs. The project manager, who might be an operations manager, (#MBA) from an IT background, probably need not know what line of code is to be written but should know the algorithms or the logic behind the code so that he or she can validate the code from the client’s perspective. The CEO, might not be from an IT background but should know how to run an IT firm rather than the syntax of the code.',\n",
       " 'But in today’s competitive world leaders can’t be one dimensional. They need to have expertise in multiple areas to be at the top. Mike Brearley if got a chance to play a T20 match, won’t even get picked into aside, not because of his age, but because of his not so great looking batting statistics(#Thegamehaschanged). His leadership skills won’t be enough to get him into the squad. But he can be a great leader if selected to coach the top 15 captains in the world today. As we have already discussed the film directors, their job isn’t to teach the cameramen on how to set up or operate (lens settings, etc) the camera. Their job is to guide the cameramen on what angle it should be held and how he or she should coordinate with the lights crew so that a perfect shot is captured. So even if a leader may not be a technical expert of his field, but if he or she has the right approach and mindset, understands the system and its process, then he or she can hire the best talent for the job and can get the work done by guiding the talent, with his or her vision.',\n",
       " 'So, the answer to the question, which we came across in the first paragraph, is yes and no. Depending upon the position in the hierarchy (yes for a front-line manager and no for a CXO) and the type of the leader you are, the level of technical expertise needed varies. Though as stated earlier by Robert Katz, the CXO’s need to have the least amount of technical expertise, the CXO should know how the technology functions or what are the applications. What processes are to be followed to build the technology.  He or she should now what is to be done rather than how it is to be done, (#itsnothowitswhat). Otherwise, even though the company might be sitting on a gold mine but If the leader isn’t aware of that or isn’t learned enough to know what to do with it, no company can succeed even with having all the resources at their disposal. Leaders command respect and don’t demand it and that’s possible when they give value to their front-line employees, seek timely advice from the technical experts, and put the resources to the best of its uses. Otherwise, you will be surrounded by technical experts like dilberts. (#dilbert)']"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "767b7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:23]))\n",
    "URL_ID_76 = \" \".join((titles, texts))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "31aedc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58 sentences in the string.\n",
      "The number of words in the string is: 1404\n",
      "The number of characters in the string is: 6581\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 03:06:42] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 03:06:49] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_76.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_76.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_76.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_76 = re.sub(re_punt, \"\",URL_ID_76)\n",
    "\n",
    "file = open(\"76.txt\", \"w\")\n",
    "file.write(URL_ID_76)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"76.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "bd4b12bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['notsotechnical',\n",
       "  'itsart',\n",
       "  'dilbert',\n",
       "  'have',\n",
       "  'you',\n",
       "  'ever',\n",
       "  'wondered',\n",
       "  'whats',\n",
       "  'common',\n",
       "  'between',\n",
       "  'sir',\n",
       "  'alex',\n",
       "  'ferguson',\n",
       "  'pep',\n",
       "  'guardiola',\n",
       "  'and',\n",
       "  'jose',\n",
       "  'mourinho?',\n",
       "  'i',\n",
       "  'know',\n",
       "  'it',\n",
       "  'might',\n",
       "  'look',\n",
       "  'a',\n",
       "  'lame',\n",
       "  'question',\n",
       "  'especially',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ardent',\n",
       "  'football',\n",
       "  'followers',\n",
       "  'at',\n",
       "  'first',\n",
       "  'instinct',\n",
       "  'the',\n",
       "  'answer',\n",
       "  'is',\n",
       "  'that',\n",
       "  'they',\n",
       "  'are',\n",
       "  'regarded',\n",
       "  'as',\n",
       "  'the',\n",
       "  'top',\n",
       "  'managers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'football',\n",
       "  'universe',\n",
       "  'uclwinners',\n",
       "  'but',\n",
       "  'when',\n",
       "  'given',\n",
       "  'a',\n",
       "  'closer',\n",
       "  'look',\n",
       "  'these',\n",
       "  'managers',\n",
       "  'werent',\n",
       "  'that',\n",
       "  'great',\n",
       "  'when',\n",
       "  'it',\n",
       "  'came',\n",
       "  'to',\n",
       "  'their',\n",
       "  'careers',\n",
       "  'as',\n",
       "  'football',\n",
       "  'players',\n",
       "  'any',\n",
       "  'nave',\n",
       "  'observer',\n",
       "  'can',\n",
       "  'build',\n",
       "  'a',\n",
       "  'fallacy',\n",
       "  'of',\n",
       "  'causation',\n",
       "  'and',\n",
       "  'correlation',\n",
       "  'that',\n",
       "  'those',\n",
       "  'who',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'a',\n",
       "  'great',\n",
       "  'career',\n",
       "  'as',\n",
       "  'a',\n",
       "  'football',\n",
       "  'player',\n",
       "  'will',\n",
       "  'go',\n",
       "  'on',\n",
       "  'to',\n",
       "  'become',\n",
       "  'a',\n",
       "  'great',\n",
       "  'football',\n",
       "  'manager',\n",
       "  'but',\n",
       "  'is',\n",
       "  'this',\n",
       "  'restricted',\n",
       "  'just',\n",
       "  'to',\n",
       "  'football?',\n",
       "  'mike',\n",
       "  'brearley',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'greatest',\n",
       "  'captains',\n",
       "  'in',\n",
       "  'the',\n",
       "  'history',\n",
       "  'of',\n",
       "  'cricket',\n",
       "  'and',\n",
       "  'the',\n",
       "  'author',\n",
       "  'of',\n",
       "  'the',\n",
       "  'book',\n",
       "  'the',\n",
       "  'art',\n",
       "  'of',\n",
       "  'captaincy',\n",
       "  'wasnt',\n",
       "  'the',\n",
       "  'prolific',\n",
       "  'batsman',\n",
       "  'of',\n",
       "  'his',\n",
       "  'time',\n",
       "  'our',\n",
       "  'former',\n",
       "  'president',\n",
       "  'a',\n",
       "  'p',\n",
       "  'j',\n",
       "  'abdul',\n",
       "  'kalam',\n",
       "  'didnt',\n",
       "  'have',\n",
       "  'a',\n",
       "  'political',\n",
       "  'background',\n",
       "  'but',\n",
       "  'was',\n",
       "  'still',\n",
       "  'appointed',\n",
       "  'as',\n",
       "  'the',\n",
       "  'president',\n",
       "  'of',\n",
       "  'our',\n",
       "  'country',\n",
       "  'and',\n",
       "  'went',\n",
       "  'to',\n",
       "  'become',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'finest',\n",
       "  'presidents',\n",
       "  'our',\n",
       "  'country',\n",
       "  'has',\n",
       "  'ever',\n",
       "  'had',\n",
       "  'so',\n",
       "  'can',\n",
       "  'it',\n",
       "  'be',\n",
       "  'stated',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'that',\n",
       "  'great',\n",
       "  'leaders',\n",
       "  'need',\n",
       "  'not',\n",
       "  'be',\n",
       "  'the',\n",
       "  'expert',\n",
       "  'in',\n",
       "  'their',\n",
       "  'respective',\n",
       "  'fields?'],\n",
       " ['lets',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'leadership',\n",
       "  'role',\n",
       "  'types',\n",
       "  'of',\n",
       "  'leaders',\n",
       "  'and',\n",
       "  'explore',\n",
       "  'a',\n",
       "  'few',\n",
       "  'more',\n",
       "  'perspectives',\n",
       "  'before',\n",
       "  'we',\n",
       "  'arrive',\n",
       "  'at',\n",
       "  'a',\n",
       "  'conclusion',\n",
       "  'lets',\n",
       "  'start',\n",
       "  'by',\n",
       "  'first',\n",
       "  'understanding',\n",
       "  'what',\n",
       "  'or',\n",
       "  'who',\n",
       "  'is',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'position',\n",
       "  'or',\n",
       "  'a',\n",
       "  'designation',\n",
       "  'its',\n",
       "  'a',\n",
       "  'virtue',\n",
       "  'if',\n",
       "  'employed',\n",
       "  'correctly',\n",
       "  'from',\n",
       "  'a',\n",
       "  'janitor',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ceo',\n",
       "  'from',\n",
       "  'a',\n",
       "  'student',\n",
       "  'to',\n",
       "  'a',\n",
       "  'researcher',\n",
       "  'from',\n",
       "  'a',\n",
       "  'content',\n",
       "  'writer',\n",
       "  'to',\n",
       "  'a',\n",
       "  'philosopher',\n",
       "  'everybody',\n",
       "  'is',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'leadersareeverywhere',\n",
       "  'so',\n",
       "  'what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'virtues',\n",
       "  'of',\n",
       "  'a',\n",
       "  'leader?',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'famous',\n",
       "  'personality',\n",
       "  'trait',\n",
       "  'theories',\n",
       "  'the',\n",
       "  'big',\n",
       "  '5',\n",
       "  'personality',\n",
       "  'trait',\n",
       "  'theory',\n",
       "  'is',\n",
       "  'always',\n",
       "  'linked',\n",
       "  'closely',\n",
       "  'with',\n",
       "  'leadership',\n",
       "  'as',\n",
       "  'per',\n",
       "  'the',\n",
       "  'various',\n",
       "  'researches',\n",
       "  'the',\n",
       "  'personality',\n",
       "  'traits',\n",
       "  'of',\n",
       "  'extraversion',\n",
       "  'openness',\n",
       "  'and',\n",
       "  'conscientiousness',\n",
       "  'are',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'leaders',\n",
       "  'more',\n",
       "  'often',\n",
       "  'than',\n",
       "  'the',\n",
       "  'other',\n",
       "  'two',\n",
       "  'traits',\n",
       "  'not',\n",
       "  'just',\n",
       "  'these',\n",
       "  'humble',\n",
       "  'and',\n",
       "  'empathetic',\n",
       "  'are',\n",
       "  'also',\n",
       "  'considered',\n",
       "  'as',\n",
       "  'the',\n",
       "  'adjectives',\n",
       "  'that',\n",
       "  'are',\n",
       "  'frequently',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'leaders',\n",
       "  'but',\n",
       "  'nowhere',\n",
       "  'is',\n",
       "  'technical',\n",
       "  'expertise',\n",
       "  'related',\n",
       "  'to',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'notsotechnical',\n",
       "  'as',\n",
       "  'stated',\n",
       "  'by',\n",
       "  'colin',\n",
       "  'powell',\n",
       "  'leadership',\n",
       "  'is',\n",
       "  'the',\n",
       "  'art',\n",
       "  'of',\n",
       "  'accomplishing',\n",
       "  'more',\n",
       "  'than',\n",
       "  'the',\n",
       "  'science',\n",
       "  'of',\n",
       "  'management',\n",
       "  'says',\n",
       "  'is',\n",
       "  'possible',\n",
       "  'itsart',\n",
       "  'if',\n",
       "  'leadership',\n",
       "  'is',\n",
       "  'an',\n",
       "  'art',\n",
       "  'and',\n",
       "  'leaders',\n",
       "  'are',\n",
       "  'the',\n",
       "  'artists',\n",
       "  'then',\n",
       "  'more',\n",
       "  'or',\n",
       "  'less',\n",
       "  'the',\n",
       "  'leaders',\n",
       "  'can',\n",
       "  'be',\n",
       "  'viewed',\n",
       "  'as',\n",
       "  'directors',\n",
       "  'of',\n",
       "  'the',\n",
       "  'films',\n",
       "  'who',\n",
       "  'are',\n",
       "  'organizing',\n",
       "  'arranging',\n",
       "  'managing',\n",
       "  'and',\n",
       "  'directing',\n",
       "  'the',\n",
       "  'scenes',\n",
       "  'another',\n",
       "  'analogy',\n",
       "  'for',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'the',\n",
       "  'orchestra',\n",
       "  'where',\n",
       "  'the',\n",
       "  'conductor',\n",
       "  'is',\n",
       "  'using',\n",
       "  'the',\n",
       "  'batonstick',\n",
       "  'to',\n",
       "  'set',\n",
       "  'the',\n",
       "  'rhythm',\n",
       "  'of',\n",
       "  'the',\n",
       "  'band',\n",
       "  'so',\n",
       "  'is',\n",
       "  'it',\n",
       "  'necessary',\n",
       "  'for',\n",
       "  'the',\n",
       "  'conductor',\n",
       "  'to',\n",
       "  'himself',\n",
       "  'or',\n",
       "  'herself',\n",
       "  'by',\n",
       "  'a',\n",
       "  'great',\n",
       "  'violinist?',\n",
       "  'no',\n",
       "  'when',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'the',\n",
       "  'corporate',\n",
       "  'sector',\n",
       "  'the',\n",
       "  'leader',\n",
       "  'need',\n",
       "  'not',\n",
       "  'be',\n",
       "  'an',\n",
       "  'expert',\n",
       "  'on',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'but',\n",
       "  'should',\n",
       "  'know',\n",
       "  'how',\n",
       "  'the',\n",
       "  'technology',\n",
       "  'functions',\n",
       "  'so',\n",
       "  'that',\n",
       "  'heshe',\n",
       "  'can',\n",
       "  'utilize',\n",
       "  'it',\n",
       "  'in',\n",
       "  'the',\n",
       "  'best',\n",
       "  'possible',\n",
       "  'way',\n",
       "  'they',\n",
       "  'can',\n",
       "  'allocate',\n",
       "  'the',\n",
       "  'task',\n",
       "  'of',\n",
       "  'building',\n",
       "  'technology',\n",
       "  'to',\n",
       "  'the',\n",
       "  'right',\n",
       "  'technical',\n",
       "  'experts',\n",
       "  'and',\n",
       "  'how',\n",
       "  'do',\n",
       "  'the',\n",
       "  'leaders',\n",
       "  'identify',\n",
       "  'the',\n",
       "  'right',\n",
       "  'person',\n",
       "  'for',\n",
       "  'that',\n",
       "  'job?',\n",
       "  'or',\n",
       "  'how',\n",
       "  'do',\n",
       "  'leaders',\n",
       "  'know',\n",
       "  'what',\n",
       "  'qualities',\n",
       "  'to',\n",
       "  'look',\n",
       "  'for',\n",
       "  'in',\n",
       "  'a',\n",
       "  'person?',\n",
       "  'experience',\n",
       "  'every',\n",
       "  'great',\n",
       "  'leader',\n",
       "  'once',\n",
       "  'started',\n",
       "  'off',\n",
       "  'as',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'frontline',\n",
       "  'workers',\n",
       "  'or',\n",
       "  'at',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  'of',\n",
       "  'the',\n",
       "  'pyramid',\n",
       "  'in',\n",
       "  'the',\n",
       "  'hierarchical',\n",
       "  'structure',\n",
       "  'even',\n",
       "  'though',\n",
       "  'they',\n",
       "  'might',\n",
       "  'not',\n",
       "  'have',\n",
       "  'had',\n",
       "  'the',\n",
       "  'technical',\n",
       "  'expertise',\n",
       "  'in',\n",
       "  'their',\n",
       "  'respective',\n",
       "  'fields',\n",
       "  'their',\n",
       "  'visionary',\n",
       "  'outlook',\n",
       "  'their',\n",
       "  'management',\n",
       "  'skills',\n",
       "  'and',\n",
       "  'the',\n",
       "  'experience',\n",
       "  'they',\n",
       "  'gathered',\n",
       "  'helped',\n",
       "  'them',\n",
       "  'in',\n",
       "  'achieving',\n",
       "  'their',\n",
       "  'targets',\n",
       "  'leaders',\n",
       "  'can',\n",
       "  'always',\n",
       "  'take',\n",
       "  'the',\n",
       "  'assistance',\n",
       "  'of',\n",
       "  'the',\n",
       "  'subject',\n",
       "  'matter',\n",
       "  'experts',\n",
       "  'to',\n",
       "  'guide',\n",
       "  'them',\n",
       "  'in',\n",
       "  'situations',\n",
       "  'of',\n",
       "  'technical',\n",
       "  'difficulties',\n",
       "  'as',\n",
       "  'per',\n",
       "  'the',\n",
       "  'great',\n",
       "  'man',\n",
       "  'situational',\n",
       "  'and',\n",
       "  'trait',\n",
       "  'theory',\n",
       "  'of',\n",
       "  'leadership',\n",
       "  'leadership',\n",
       "  'is',\n",
       "  'innate',\n",
       "  'to',\n",
       "  'the',\n",
       "  'person',\n",
       "  'leadership',\n",
       "  'though',\n",
       "  'can',\n",
       "  'be',\n",
       "  'conditioned',\n",
       "  'or',\n",
       "  'can',\n",
       "  'be',\n",
       "  'brought',\n",
       "  'out',\n",
       "  'in',\n",
       "  'a',\n",
       "  'person',\n",
       "  'by',\n",
       "  'rewarding',\n",
       "  'him',\n",
       "  'great',\n",
       "  'leaders',\n",
       "  'show',\n",
       "  'unconditional',\n",
       "  'attachment',\n",
       "  'towards',\n",
       "  'their',\n",
       "  'vision',\n",
       "  'everyone',\n",
       "  'knows',\n",
       "  'how',\n",
       "  'to',\n",
       "  'read',\n",
       "  'a',\n",
       "  'map',\n",
       "  'but',\n",
       "  'which',\n",
       "  'path',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'isnt',\n",
       "  'something',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'taught',\n",
       "  'leaders',\n",
       "  'give',\n",
       "  'the',\n",
       "  'direction',\n",
       "  'or',\n",
       "  'vision',\n",
       "  'to',\n",
       "  'the',\n",
       "  'company',\n",
       "  'and',\n",
       "  'drive',\n",
       "  'it',\n",
       "  'closer',\n",
       "  'to',\n",
       "  'the',\n",
       "  'target',\n",
       "  'that',\n",
       "  'the',\n",
       "  'company',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'leadership',\n",
       "  'theories',\n",
       "  'dont',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'the',\n",
       "  'technical',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'the',\n",
       "  'leaders',\n",
       "  'but',\n",
       "  'rather',\n",
       "  'more',\n",
       "  'on',\n",
       "  'people',\n",
       "  'skills',\n",
       "  'their',\n",
       "  'approach',\n",
       "  'towards',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'and',\n",
       "  'how',\n",
       "  'well',\n",
       "  'they',\n",
       "  'guide',\n",
       "  'and',\n",
       "  'hire',\n",
       "  'others',\n",
       "  'to',\n",
       "  'get',\n",
       "  'the',\n",
       "  'job',\n",
       "  'done',\n",
       "  'which',\n",
       "  'is',\n",
       "  'also',\n",
       "  'evident',\n",
       "  'as',\n",
       "  'per',\n",
       "  'the',\n",
       "  'managerial',\n",
       "  'skills',\n",
       "  'required',\n",
       "  'as',\n",
       "  'per',\n",
       "  'robert',\n",
       "  'katz',\n",
       "  'though',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'argued',\n",
       "  'that',\n",
       "  'technical',\n",
       "  'experts',\n",
       "  'are',\n",
       "  'also',\n",
       "  'the',\n",
       "  'great',\n",
       "  'leaders',\n",
       "  'in',\n",
       "  'their',\n",
       "  'areas',\n",
       "  'but',\n",
       "  'these',\n",
       "  'leaders',\n",
       "  'are',\n",
       "  'generally',\n",
       "  'at',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'management',\n",
       "  'level',\n",
       "  'as',\n",
       "  'per',\n",
       "  'the',\n",
       "  'different',\n",
       "  'leadership',\n",
       "  'styles',\n",
       "  'a',\n",
       "  'servant',\n",
       "  'leader',\n",
       "  'is',\n",
       "  'the',\n",
       "  'one',\n",
       "  'who',\n",
       "  'always',\n",
       "  'tries',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'the',\n",
       "  'goal',\n",
       "  'of',\n",
       "  'the',\n",
       "  'team',\n",
       "  'these',\n",
       "  'leaders',\n",
       "  'are',\n",
       "  'the',\n",
       "  'ones',\n",
       "  'who',\n",
       "  'have',\n",
       "  'a',\n",
       "  'management',\n",
       "  'objective',\n",
       "  'laid',\n",
       "  'out',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'them',\n",
       "  'and',\n",
       "  'they',\n",
       "  'drive',\n",
       "  'the',\n",
       "  'team',\n",
       "  'closer',\n",
       "  'to',\n",
       "  'achieving',\n",
       "  'the',\n",
       "  'target',\n",
       "  'by',\n",
       "  'having',\n",
       "  'the',\n",
       "  'peoplefirst',\n",
       "  'mindset',\n",
       "  'a',\n",
       "  'collaborative',\n",
       "  'approach',\n",
       "  'towards',\n",
       "  'solving',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'these',\n",
       "  'are',\n",
       "  'the',\n",
       "  'people',\n",
       "  'or',\n",
       "  'the',\n",
       "  'leaders',\n",
       "  'needed',\n",
       "  'at',\n",
       "  'the',\n",
       "  'execution',\n",
       "  'level',\n",
       "  'of',\n",
       "  'the',\n",
       "  'project',\n",
       "  'or',\n",
       "  'those',\n",
       "  'who',\n",
       "  'are',\n",
       "  'too',\n",
       "  'close',\n",
       "  'to',\n",
       "  'the',\n",
       "  'employees',\n",
       "  'at',\n",
       "  'the',\n",
       "  'bottommost',\n",
       "  'level',\n",
       "  'since',\n",
       "  'the',\n",
       "  'managers',\n",
       "  'at',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'the',\n",
       "  'pyramid',\n",
       "  'dont',\n",
       "  'get',\n",
       "  'much',\n",
       "  'time',\n",
       "  'to',\n",
       "  'invest',\n",
       "  'in',\n",
       "  'people',\n",
       "  'they',\n",
       "  'appoint',\n",
       "  'the',\n",
       "  'right',\n",
       "  'people',\n",
       "  'on',\n",
       "  'their',\n",
       "  'behalf',\n",
       "  'to',\n",
       "  'get',\n",
       "  'the',\n",
       "  'job',\n",
       "  'done',\n",
       "  'consider',\n",
       "  'an',\n",
       "  'it',\n",
       "  'firm',\n",
       "  'so',\n",
       "  'as',\n",
       "  'per',\n",
       "  'the',\n",
       "  'points',\n",
       "  'mentioned',\n",
       "  'above',\n",
       "  'does',\n",
       "  'it',\n",
       "  'mean',\n",
       "  'that',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'or',\n",
       "  'the',\n",
       "  'manager',\n",
       "  'shouldnt',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'code?',\n",
       "  'depends',\n",
       "  'if',\n",
       "  'the',\n",
       "  'person',\n",
       "  'is',\n",
       "  'the',\n",
       "  'first',\n",
       "  'line',\n",
       "  'manager',\n",
       "  'then',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'should',\n",
       "  'probably',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'code',\n",
       "  'so',\n",
       "  'that',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'can',\n",
       "  'help',\n",
       "  'the',\n",
       "  'team',\n",
       "  'in',\n",
       "  'achieving',\n",
       "  'the',\n",
       "  'target',\n",
       "  'of',\n",
       "  'producing',\n",
       "  'less',\n",
       "  'garbage',\n",
       "  'which',\n",
       "  'might',\n",
       "  'be',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'projects',\n",
       "  'kpis',\n",
       "  'the',\n",
       "  'project',\n",
       "  'manager',\n",
       "  'who',\n",
       "  'might',\n",
       "  'be',\n",
       "  'an',\n",
       "  'operations',\n",
       "  'manager',\n",
       "  'mba',\n",
       "  'from',\n",
       "  'an',\n",
       "  'it',\n",
       "  'background',\n",
       "  'probably',\n",
       "  'need',\n",
       "  'not',\n",
       "  'know',\n",
       "  'what',\n",
       "  'line',\n",
       "  'of',\n",
       "  'code',\n",
       "  'is',\n",
       "  'to',\n",
       "  'be',\n",
       "  'written',\n",
       "  'but',\n",
       "  'should',\n",
       "  'know',\n",
       "  'the',\n",
       "  'algorithms',\n",
       "  'or',\n",
       "  'the',\n",
       "  'logic',\n",
       "  'behind',\n",
       "  'the',\n",
       "  'code',\n",
       "  'so',\n",
       "  'that',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'can',\n",
       "  'validate',\n",
       "  'the',\n",
       "  'code',\n",
       "  'from',\n",
       "  'the',\n",
       "  'clients',\n",
       "  'perspective',\n",
       "  'the',\n",
       "  'ceo',\n",
       "  'might',\n",
       "  'not',\n",
       "  'be',\n",
       "  'from',\n",
       "  'an',\n",
       "  'it',\n",
       "  'background',\n",
       "  'but',\n",
       "  'should',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'run',\n",
       "  'an',\n",
       "  'it',\n",
       "  'firm',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'the',\n",
       "  'syntax',\n",
       "  'of',\n",
       "  'the',\n",
       "  'code',\n",
       "  'but',\n",
       "  'in',\n",
       "  'todays',\n",
       "  'competitive',\n",
       "  'world',\n",
       "  'leaders',\n",
       "  'cant',\n",
       "  'be',\n",
       "  'one',\n",
       "  'dimensional',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'have',\n",
       "  'expertise',\n",
       "  'in',\n",
       "  'multiple',\n",
       "  'areas',\n",
       "  'to',\n",
       "  'be',\n",
       "  'at',\n",
       "  'the',\n",
       "  'top',\n",
       "  'mike',\n",
       "  'brearley',\n",
       "  'if',\n",
       "  'got',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'play',\n",
       "  'a',\n",
       "  't20',\n",
       "  'match',\n",
       "  'wont',\n",
       "  'even',\n",
       "  'get',\n",
       "  'picked',\n",
       "  'into',\n",
       "  'aside',\n",
       "  'not',\n",
       "  'because',\n",
       "  'of',\n",
       "  'his',\n",
       "  'age',\n",
       "  'but',\n",
       "  'because',\n",
       "  'of',\n",
       "  'his',\n",
       "  'not',\n",
       "  'so',\n",
       "  'great',\n",
       "  'looking',\n",
       "  'batting',\n",
       "  'statisticsthegamehaschanged',\n",
       "  'his',\n",
       "  'leadership',\n",
       "  'skills',\n",
       "  'wont',\n",
       "  'be',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'get',\n",
       "  'him',\n",
       "  'into',\n",
       "  'the',\n",
       "  'squad',\n",
       "  'but',\n",
       "  'he',\n",
       "  'can',\n",
       "  'be',\n",
       "  'a',\n",
       "  'great',\n",
       "  'leader',\n",
       "  'if',\n",
       "  'selected',\n",
       "  'to',\n",
       "  'coach',\n",
       "  'the',\n",
       "  'top',\n",
       "  '15',\n",
       "  'captains',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'today',\n",
       "  'as',\n",
       "  'we',\n",
       "  'have',\n",
       "  'already',\n",
       "  'discussed',\n",
       "  'the',\n",
       "  'film',\n",
       "  'directors',\n",
       "  'their',\n",
       "  'job',\n",
       "  'isnt',\n",
       "  'to',\n",
       "  'teach',\n",
       "  'the',\n",
       "  'cameramen',\n",
       "  'on',\n",
       "  'how',\n",
       "  'to',\n",
       "  'set',\n",
       "  'up',\n",
       "  'or',\n",
       "  'operate',\n",
       "  'lens',\n",
       "  'settings',\n",
       "  'etc',\n",
       "  'the',\n",
       "  'camera',\n",
       "  'their',\n",
       "  'job',\n",
       "  'is',\n",
       "  'to',\n",
       "  'guide',\n",
       "  'the',\n",
       "  'cameramen',\n",
       "  'on',\n",
       "  'what',\n",
       "  'angle',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'held',\n",
       "  'and',\n",
       "  'how',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'should',\n",
       "  'coordinate',\n",
       "  'with',\n",
       "  'the',\n",
       "  'lights',\n",
       "  'crew',\n",
       "  'so',\n",
       "  'that',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  'shot',\n",
       "  'is',\n",
       "  'captured',\n",
       "  'so',\n",
       "  'even',\n",
       "  'if',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'a',\n",
       "  'technical',\n",
       "  'expert',\n",
       "  'of',\n",
       "  'his',\n",
       "  'field',\n",
       "  'but',\n",
       "  'if',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'has',\n",
       "  'the',\n",
       "  'right',\n",
       "  'approach',\n",
       "  'and',\n",
       "  'mindset',\n",
       "  'understands',\n",
       "  'the',\n",
       "  'system',\n",
       "  'and',\n",
       "  'its',\n",
       "  'process',\n",
       "  'then',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'can',\n",
       "  'hire',\n",
       "  'the',\n",
       "  'best',\n",
       "  'talent',\n",
       "  'for',\n",
       "  'the',\n",
       "  'job',\n",
       "  'and',\n",
       "  'can',\n",
       "  'get',\n",
       "  'the',\n",
       "  'work',\n",
       "  'done',\n",
       "  ...]]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/76.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "e511ac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404\n",
      "WORD COUNT 858\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "933a08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 24.20689655172414\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "1b767540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.24592074592074592\n",
      "FOG INDEX: 9.781126919057954\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 24.20689655172414\n",
      "COMPLEX WORD COUNT: 211\n",
      "WORD COUNT: 858\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2d6868f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2399\n",
      "i: 1\n",
      "we: 3\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 4\n",
      "PERSONAL PRONOUNS: 4\n",
      "AVG WORD LENGTH: 4.687321937321937\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_76.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d77f74",
   "metadata": {},
   "source": [
    "# 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "fecb17cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_18760\\755601014.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "348487da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The word “leadership” can bring to mind a variety of images. For example, A political leader, pursuing a passionate, personal cause or An executive, developing his/her company’s strategy to beat the competition. Leaders help themselves and others to do the right things. They set direction, build an inspiring vision, and create something new. Leadership is about mapping out where you need to go to “win” as a team or an organization; and it is dynamic, exciting, and inspiring.',\n",
       " 'In my point of view we cannot become a good leader without technical expertise because every task in the organization it’s required a lot of skills, knowledge, consistent, enthusiastic, patience, motivating, inspiring, industrious, and critical thinking on the basis of the field we are doing. A leader should have the ability to motivate self and others, effective oral and written communication, critical thinking skills at the working team and delegating a task. Good leaders do have these abilities and if we wanted to create a future leader. They need to take in a large volume of information and to take the essential elements that define the core problem to solve. They need to organize a team to solve these problems and to communicate to a group, they need to established trust with a group and use the trust to allow the team to accomplish the work more than it could be done alone. Though all these skills we have but it’s would not sufficient to make us a great leader because to excel and utilize these abilities in practice we need a lot of technical expertise in a particular domain. For example, Like in a hospital if the head of the hospital is lead by other people rather than Doctor then the hospital would become worse at a point because the person from other fields he could not lead and understand the real scenario and mechanism that the hospital is functioning and he would not understand the staff and the patient as well. Hence, to lead the hospital Doctor is deserved who knows his own field how to lead and understand the real scenario of it. That’s why being a leader requires technical expertise to have great knowledge and understanding about his own organization. Every person if they want to become a leader they should have technical expertise on their own organization so that their organization would run smoothly, hence nobody could run other organization if we do not have the technical expertise on that field.',\n",
       " 'So, be a leader, not a boss which makes your life much better, as they’re a saying that “ A good objective of leadership is to help those who are doing poorly to do well and to help those who are doing well to do even better.”']"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "1c75e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts=(' '.join(str(x) for x in texts[16:19]))\n",
    "URL_ID_77 = texts\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "960f624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 sentences in the string.\n",
      "The number of words in the string is: 461\n",
      "The number of characters in the string is: 2196\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 03:36:22] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 03:36:27] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "sentences = URL_ID_77.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_77.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_77.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_77 = re.sub(re_punt, \"\",URL_ID_77)\n",
    "\n",
    "file = open(\"77.txt\", \"w\")\n",
    "file.write(URL_ID_77)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"77.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "e71a865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'word',\n",
       "  'leadership',\n",
       "  'can',\n",
       "  'bring',\n",
       "  'to',\n",
       "  'mind',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'images',\n",
       "  'for',\n",
       "  'example',\n",
       "  'a',\n",
       "  'political',\n",
       "  'leader',\n",
       "  'pursuing',\n",
       "  'a',\n",
       "  'passionate',\n",
       "  'personal',\n",
       "  'cause',\n",
       "  'or',\n",
       "  'an',\n",
       "  'executive',\n",
       "  'developing',\n",
       "  'hisher',\n",
       "  'companys',\n",
       "  'strategy',\n",
       "  'to',\n",
       "  'beat',\n",
       "  'the',\n",
       "  'competition',\n",
       "  'leaders',\n",
       "  'help',\n",
       "  'themselves',\n",
       "  'and',\n",
       "  'others',\n",
       "  'to',\n",
       "  'do',\n",
       "  'the',\n",
       "  'right',\n",
       "  'things',\n",
       "  'they',\n",
       "  'set',\n",
       "  'direction',\n",
       "  'build',\n",
       "  'an',\n",
       "  'inspiring',\n",
       "  'vision',\n",
       "  'and',\n",
       "  'create',\n",
       "  'something',\n",
       "  'new',\n",
       "  'leadership',\n",
       "  'is',\n",
       "  'about',\n",
       "  'mapping',\n",
       "  'out',\n",
       "  'where',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'win',\n",
       "  'as',\n",
       "  'a',\n",
       "  'team',\n",
       "  'or',\n",
       "  'an',\n",
       "  'organization',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'dynamic',\n",
       "  'exciting',\n",
       "  'and',\n",
       "  'inspiring',\n",
       "  'in',\n",
       "  'my',\n",
       "  'point',\n",
       "  'of',\n",
       "  'view',\n",
       "  'we',\n",
       "  'cannot',\n",
       "  'become',\n",
       "  'a',\n",
       "  'good',\n",
       "  'leader',\n",
       "  'without',\n",
       "  'technical',\n",
       "  'expertise',\n",
       "  'because',\n",
       "  'every',\n",
       "  'task',\n",
       "  'in',\n",
       "  'the',\n",
       "  'organization',\n",
       "  'its',\n",
       "  'required',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'skills',\n",
       "  'knowledge',\n",
       "  'consistent',\n",
       "  'enthusiastic',\n",
       "  'patience',\n",
       "  'motivating',\n",
       "  'inspiring',\n",
       "  'industrious',\n",
       "  'and',\n",
       "  'critical',\n",
       "  'thinking',\n",
       "  'on',\n",
       "  'the',\n",
       "  'basis',\n",
       "  'of',\n",
       "  'the',\n",
       "  'field',\n",
       "  'we',\n",
       "  'are',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'should',\n",
       "  'have',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'motivate',\n",
       "  'self',\n",
       "  'and',\n",
       "  'others',\n",
       "  'effective',\n",
       "  'oral',\n",
       "  'and',\n",
       "  'written',\n",
       "  'communication',\n",
       "  'critical',\n",
       "  'thinking',\n",
       "  'skills',\n",
       "  'at',\n",
       "  'the',\n",
       "  'working',\n",
       "  'team',\n",
       "  'and',\n",
       "  'delegating',\n",
       "  'a',\n",
       "  'task',\n",
       "  'good',\n",
       "  'leaders',\n",
       "  'do',\n",
       "  'have',\n",
       "  'these',\n",
       "  'abilities',\n",
       "  'and',\n",
       "  'if',\n",
       "  'we',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'create',\n",
       "  'a',\n",
       "  'future',\n",
       "  'leader',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'in',\n",
       "  'a',\n",
       "  'large',\n",
       "  'volume',\n",
       "  'of',\n",
       "  'information',\n",
       "  'and',\n",
       "  'to',\n",
       "  'take',\n",
       "  'the',\n",
       "  'essential',\n",
       "  'elements',\n",
       "  'that',\n",
       "  'define',\n",
       "  'the',\n",
       "  'core',\n",
       "  'problem',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'organize',\n",
       "  'a',\n",
       "  'team',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'these',\n",
       "  'problems',\n",
       "  'and',\n",
       "  'to',\n",
       "  'communicate',\n",
       "  'to',\n",
       "  'a',\n",
       "  'group',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'established',\n",
       "  'trust',\n",
       "  'with',\n",
       "  'a',\n",
       "  'group',\n",
       "  'and',\n",
       "  'use',\n",
       "  'the',\n",
       "  'trust',\n",
       "  'to',\n",
       "  'allow',\n",
       "  'the',\n",
       "  'team',\n",
       "  'to',\n",
       "  'accomplish',\n",
       "  'the',\n",
       "  'work',\n",
       "  'more',\n",
       "  'than',\n",
       "  'it',\n",
       "  'could',\n",
       "  'be',\n",
       "  'done',\n",
       "  'alone',\n",
       "  'though',\n",
       "  'all',\n",
       "  'these',\n",
       "  'skills',\n",
       "  'we',\n",
       "  'have',\n",
       "  'but',\n",
       "  'its',\n",
       "  'would',\n",
       "  'not',\n",
       "  'sufficient',\n",
       "  'to',\n",
       "  'make',\n",
       "  'us',\n",
       "  'a',\n",
       "  'great',\n",
       "  'leader',\n",
       "  'because',\n",
       "  'to',\n",
       "  'excel',\n",
       "  'and',\n",
       "  'utilize',\n",
       "  'these',\n",
       "  'abilities',\n",
       "  'in',\n",
       "  'practice',\n",
       "  'we',\n",
       "  'need',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'technical',\n",
       "  'expertise',\n",
       "  'in',\n",
       "  'a',\n",
       "  'particular',\n",
       "  'domain',\n",
       "  'for',\n",
       "  'example',\n",
       "  'like',\n",
       "  'in',\n",
       "  'a',\n",
       "  'hospital',\n",
       "  'if',\n",
       "  'the',\n",
       "  'head',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  'is',\n",
       "  'lead',\n",
       "  'by',\n",
       "  'other',\n",
       "  'people',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'doctor',\n",
       "  'then',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  'would',\n",
       "  'become',\n",
       "  'worse',\n",
       "  'at',\n",
       "  'a',\n",
       "  'point',\n",
       "  'because',\n",
       "  'the',\n",
       "  'person',\n",
       "  'from',\n",
       "  'other',\n",
       "  'fields',\n",
       "  'he',\n",
       "  'could',\n",
       "  'not',\n",
       "  'lead',\n",
       "  'and',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'real',\n",
       "  'scenario',\n",
       "  'and',\n",
       "  'mechanism',\n",
       "  'that',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  'is',\n",
       "  'functioning',\n",
       "  'and',\n",
       "  'he',\n",
       "  'would',\n",
       "  'not',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'staff',\n",
       "  'and',\n",
       "  'the',\n",
       "  'patient',\n",
       "  'as',\n",
       "  'well',\n",
       "  'hence',\n",
       "  'to',\n",
       "  'lead',\n",
       "  'the',\n",
       "  'hospital',\n",
       "  'doctor',\n",
       "  'is',\n",
       "  'deserved',\n",
       "  'who',\n",
       "  'knows',\n",
       "  'his',\n",
       "  'own',\n",
       "  'field',\n",
       "  'how',\n",
       "  'to',\n",
       "  'lead',\n",
       "  'and',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'real',\n",
       "  'scenario',\n",
       "  'of',\n",
       "  'it',\n",
       "  'thats',\n",
       "  'why',\n",
       "  'being',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'requires',\n",
       "  'technical',\n",
       "  'expertise',\n",
       "  'to',\n",
       "  'have',\n",
       "  'great',\n",
       "  'knowledge',\n",
       "  'and',\n",
       "  'understanding',\n",
       "  'about',\n",
       "  'his',\n",
       "  'own',\n",
       "  'organization',\n",
       "  'every',\n",
       "  'person',\n",
       "  'if',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'become',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'they',\n",
       "  'should',\n",
       "  'have',\n",
       "  'technical',\n",
       "  'expertise',\n",
       "  'on',\n",
       "  'their',\n",
       "  'own',\n",
       "  'organization',\n",
       "  'so',\n",
       "  'that',\n",
       "  'their',\n",
       "  'organization',\n",
       "  'would',\n",
       "  'run',\n",
       "  'smoothly',\n",
       "  'hence',\n",
       "  'nobody',\n",
       "  'could',\n",
       "  'run',\n",
       "  'other',\n",
       "  'organization',\n",
       "  'if',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'the',\n",
       "  'technical',\n",
       "  'expertise',\n",
       "  'on',\n",
       "  'that',\n",
       "  'field',\n",
       "  'so',\n",
       "  'be',\n",
       "  'a',\n",
       "  'leader',\n",
       "  'not',\n",
       "  'a',\n",
       "  'boss',\n",
       "  'which',\n",
       "  'makes',\n",
       "  'your',\n",
       "  'life',\n",
       "  'much',\n",
       "  'better',\n",
       "  'as',\n",
       "  'theyre',\n",
       "  'a',\n",
       "  'saying',\n",
       "  'that',\n",
       "  'a',\n",
       "  'good',\n",
       "  'objective',\n",
       "  'of',\n",
       "  'leadership',\n",
       "  'is',\n",
       "  'to',\n",
       "  'help',\n",
       "  'those',\n",
       "  'who',\n",
       "  'are',\n",
       "  'doing',\n",
       "  'poorly',\n",
       "  'to',\n",
       "  'do',\n",
       "  'well',\n",
       "  'and',\n",
       "  'to',\n",
       "  'help',\n",
       "  'those',\n",
       "  'who',\n",
       "  'are',\n",
       "  'doing',\n",
       "  'well',\n",
       "  'to',\n",
       "  'do',\n",
       "  'even',\n",
       "  'better']]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/77.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "0707e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n",
      "WORD COUNT 266\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "4c1b7b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 27.11764705882353\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a2d17fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.35714285714285715\n",
      "FOG INDEX: 10.989915966386555\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 27.11764705882353\n",
      "COMPLEX WORD COUNT: 95\n",
      "WORD COUNT: 266\n"
     ]
    }
   ],
   "source": [
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7b87c7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 859\n",
      "I: 0\n",
      "we: 6\n",
      "my: 1\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 8\n",
      "PERSONAL PRONOUNS: 8\n",
      "AVG WORD LENGTH: 4.763557483731019\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_77.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424f943",
   "metadata": {},
   "source": [
    "# 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d0452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\2909515165.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "499d393f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When we talk about AI, different people have different perspectives about it. There is one group of people, having good knowledge about the real potential of AI, who believe that AI can be a novel solution to many problems that the world is facing today. There is another group of people who are merely threatened by the thought of AI taking over the world.',\n",
       " 'The field of AI took birth when Alan Turing in 1950 had this thought “Can machines think?”. Later in the 1980s, with the adoption of “expert systems” by the companies around the world, the booming of the field of AI was initiated. Initially, it was a matter of awe for everyone to see the results of what AI can achieve. AI’s growth in the past few decades has been exponential and it has transformed the way we live, work and solve challenges. AI has made its impact in a wide variety of areas including healthcare, education, business and many more. But, one of the areas of highest impact that AI has made recently is in the environment and climate change.',\n",
       " 'Is AI Revolutionizing the way we deal with Environment and Climate Change?',\n",
       " 'AI can strengthen climate predictions, enable smarter decision-making for decarbonising industries from building to transport, and work out how to allocate renewable energy. In recent years, AI has been a game-changer in how many people, as well as organizations, deal with climate change. Microsoft believes that artificial intelligence, often encompassing machine learning and deep learning, is a “game-changer” for climate change and environmental issues. The company’s ‘AI for Earth’ program has committed $50 million over five years to create and test new applications for AI.',\n",
       " 'AI is increasingly used to manage the intermittency of renewable energy so that more can be incorporated into the grid; it can handle power fluctuations and improve energy storage as well. Wind companies are using AI to get each turbine’s propeller to produce more electricity per rotation by incorporating real-time weather and operational data.',\n",
       " 'AI can also improve energy efficiency on the city scale by incorporating data from smart meters and the Internet of Things (the internet of computing devices that are embedded in everyday objects, enabling them to send and receive data) to forecast energy demand. Besides, artificial intelligence systems can simulate potential zoning laws, building ordinances, and flood plains to help with urban planning and disaster preparedness. One vision for a sustainable city is to create an “urban dashboard” consisting of real-time data on energy and water use and availability, traffic and weather to make cities more energy-efficient and livable.',\n",
       " 'Hotter temperatures will have significant impacts on agriculture as well. Data from sensors in the field that monitor crop moisture, soil composition and temperature help AI improve production and know when crops need watering. Incorporating this information with that from drones, which are also used to monitor conditions, can help increasingly automatic AI systems know the best times to plant, spray and harvest crops, and when to head off diseases and other problems. This will result in increased efficiency, enhanced yields, and lower use of water, fertilizer and pesticides.',\n",
       " 'But, is AI as good as it looks or does it have a downside?',\n",
       " 'When we talk about the effect of AI in the environment and climate, both sides of the coin must be elucidated. So, apart from all the positives discussed above, the usage of AI also has a downside.',\n",
       " 'Last year’s World Economic Forum report showed that while AI can address some of Earth’s environmental challenges, it is important to manage it properly. According to the forum and experts in the field, AI has the potential to accelerate environmental degradation. The use of power-intensive GPUs to run machine learning training has already been cited as contributing to increased C02 emissions.',\n",
       " 'Although AI has been around for about half a century, the question of environmental impact – and other ethical issues – is only arising now because the techniques developed over decades can now be used in combination with an explosion in data and strong computational power.',\n",
       " 'For all the advances enabled by artificial intelligence, from speech recognition to self-driving cars, AI systems consume a lot of power and can generate high volumes of climate-changing carbon emissions.',\n",
       " 'A study last year found that training an off-the-shelf AI language-processing system produced 1,400 pounds of emissions – about the amount produced by flying one person roundtrip between New York and San Francisco. But there are ways to make machine learning cleaner and greener, a movement that has been called “Green AI.” Some algorithms are less power-hungry than others, for example, and many training sessions can be moved to remote locations that get most of their power from renewable sources.',\n",
       " 'The key, however, is for AI developers and companies to know how much their machine learning experiments are spewing and how much those volumes could be reduced.',\n",
       " 'What can be done?',\n",
       " 'To prevent this, the proposition by the World Economic Forum report is that advancements in “safe” AI should be pursued, to ensure that humanity is not developing AI that is harmful to the environment. Specifically, the World Economic Forum said in its report that AI developers “must incorporate the health of the natural environment as a fundamental dimension.” This means safeguarding against models that will demand the consumption of energy or natural resources beyond what is sustainable, among other factors. In a sense, all programs need to be designed with the dimension of environmental protection and improvement in mind.',\n",
       " 'In the future development of AI programs, it will also be important to note the environmental impact of creating these systems in the first place. According to an academic study on energy usage for deep learning processes, the creation of an effective AI might be costly to the environment. Nearly 300,000 kilograms of carbon dioxide equivalent emissions are created during the process of training a single model. This is basically equal to the emissions of five average cars in the United States. Considering the negative environmental impact in addition to the positive implications of AI and climate change will be crucial, moving forward.',\n",
       " 'There is always room for improvement, some pioneers of machine learning recently published a paper called Tackling Climate Change with Machine Learning was discussed at a major AI conference. David Rolnick, a postdoctoral fellow of the University of Pennsylvania said “call to arms” which means to bring researchers together.',\n",
       " 'This paper covers thirteen areas of research where machine learning can be used, including energy production, CO2 removal, education, solar geoengineering, finance and many more. The main idea is to build more energy-efficient buildings, creating new low-carbon materials, high tech monitoring of deforestation and greener transportation sources. Artificial intelligence and machine learning can be a medium but the real work is to be done by us as a caretaker of mother earth.',\n",
       " 'How about better forecasting of climate change?',\n",
       " ' The kick start was already done by climate informatics in 2011 which regulates the collaboration of data science and climate science. It covers a wide range of topics like improving prediction of extreme events such as hurricanes, paleoclimatology, collecting data from ice cores, climate up-down scaling and its impact on us.',\n",
       " '“There’s a lot of uncertainty,” Monteleoni',\n",
       " 'Claire Monteleoni, a computer science professor at the University of Colorado concludes that AI/ ML models generally forecast for the short-term. There is a significant difference when it comes to long-term forecasting.',\n",
       " 'The first system was developed at Princeton in the 1960s. All the AI/ ML models developed till now revolve around atmosphere, oceans, land, cryosphere or ice. AI can help to achieve new heights with the amount of data collected at this point of time, and compute more complex climate conditions using climate modeling algorithms.',\n",
       " 'What about showing the effects of extreme weather?',\n",
       " 'We all know that climate change is real and the rise in atmospheric temperature the proof, but to make it more realistic, Montreal Institute of Learning Algorithms (MILA), Microsoft and ConscientAI Labs uses Generative Adversarial Networks popularly know as GANs to simulate what mother earth will look like with the rising sea levels, atmospheric temperature, air pollution and intensive storms.',\n",
       " '“Our goal is not to convince people climate change is real, it’s to get people who do believe it is real to do more about that,” said Victor Schmidt, a co-author of the paper and Ph.D. candidate at MILA',\n",
       " 'The project is deployed for the people to look at what their places will look like in the future when there will be a significant climate change.',\n",
       " 'Can we track carbon emissions?',\n",
       " 'Short answer, yes. Tracking of carbon emission is one of the agendas of the UN. For this year 2020, the UN’s goal is to prevent new coal plants from being built. Satellite images come into picture using deep learning techniques, data science researchers can analyze these high quality satellite images and track the emission. Google is expanding its horizon of nonprofit’s satellite imagery, including gas-powered plants emissions which can be used by researchers to track the pollution. There are countries organizations which govern CO2 emission on the ground level but these data are unreachable by global monitoring associations.',\n",
       " 'AI can automate the analysis of images of power plants to get regular updates on emissions. It also introduces new ways to measure a plant’s impact, by crunching numbers of nearby infrastructure and electricity use. That’s beneficial for gas-powered plants that don’t have the easy-to-measure plumes that coal-powered plants have.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a53ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68 sentences in the string.\n",
      "The number of words in the string is: 1631\n",
      "The number of characters in the string is: 8555\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of characters in the string is:\u001b[39m\u001b[38;5;124m\"\u001b[39m,total_chars)\n\u001b[0;32m     18\u001b[0m re_punt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^A-Za-z0-9!?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 19\u001b[0m URL_ID_78 \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39msub(re_punt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,URL_ID_78)\n\u001b[0;32m     21\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m78.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m file\u001b[38;5;241m.\u001b[39mwrite(URL_ID_78)\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:47]))\n",
    "URL_ID_78 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_78.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_78.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_78.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df1a44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 12:40:33] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 12:40:33] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 12:40:39] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_78 = re.sub(re_punt, \"\",URL_ID_78)\n",
    "\n",
    "file = open(\"78.txt\", \"w\")\n",
    "file.write(URL_ID_78)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"78.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32be712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628\n",
      "WORD COUNT 1021\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/78.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6511649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 23.985294117647058\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'has_more_than_two_syllables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m AVG_SENTENCE_LENGTH \u001b[38;5;241m=\u001b[39m (The_number_of_words)\u001b[38;5;241m/\u001b[39m(The_number_of_sentences)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAVG SENTENCE lENGTH  :\u001b[39m\u001b[38;5;124m\"\u001b[39m,AVG_SENTENCE_LENGTH)\n\u001b[1;32m---> 20\u001b[0m more_than_two_syllables \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[43mhas_more_than_two_syllables\u001b[49m, word_list)))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(more_than_two_syllables)\n\u001b[0;32m     23\u001b[0m The_number_of_complex_words \u001b[38;5;241m=\u001b[39m more_than_two_syllables\n",
      "\u001b[1;31mNameError\u001b[0m: name 'has_more_than_two_syllables' is not defined"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35987ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3809990205680705\n",
      "FOG INDEX: 9.74651725528605\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 23.985294117647058\n",
      "COMPLEX WORD COUNT: 389\n",
      "WORD COUNT: 1021\n"
     ]
    }
   ],
   "source": [
    "def has_more_than_two_syllables(word):\n",
    "    vowels = 'aeiouy'\n",
    "    syllables = 0\n",
    "    in_vowel_group = False\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            if not in_vowel_group:\n",
    "                syllables += 1\n",
    "                in_vowel_group = True\n",
    "        else:\n",
    "            in_vowel_group = False\n",
    "    return syllables > 2\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61424286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3172\n",
      "I: 0\n",
      "we: 8\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 2\n",
      "Total count: 10\n",
      "PERSONAL PRONOUNS: 10\n",
      "AVG WORD LENGTH: 5.245248313917842\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = \"aeiou\"\n",
    "    vowel_count = 0\n",
    "    \n",
    "    # Count the number of vowels in the word\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            vowel_count += 1\n",
    "    \n",
    "    # Handle exceptions for words ending with \"es\" or \"ed\"\n",
    "    if word[-2:] in [\"es\", \"ed\"]:\n",
    "        vowel_count -= 1\n",
    "    \n",
    "    # Handle words with no vowels\n",
    "    if vowel_count == 0:\n",
    "        vowel_count = 1\n",
    "    \n",
    "    return vowel_count\n",
    "\n",
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_78.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c1cc8",
   "metadata": {},
   "source": [
    "# 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d51bb1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\1031520112.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "858f4b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No one can reduce mistakes to zero, but you can learn to harness your drive to prevent them and channel it into better decision making. Use these tips to become a more effective worrier.',\n",
       " 'Don’t be afraid or ashamed of your fear. ',\n",
       " 'Our culture glorifies fearlessness. The traditional image of a leader is one who is smart, tough, and unafraid. But fear, like any emotion, has an evolutionary purpose and upside. Your concern about making mistakes is there to remind you that we’re in a challenging situation. A cautious leader has value. This is especially true in times like these. So don’t get caught up in ruminating: “I shouldn’t be so fearful.”',\n",
       " 'Don’t be ashamed or afraid of your fear of making mistakes and don’t interpret it as evidence that you’re an indecisive leader, or not bold, not visionary. If you have a natural tendency to be prevention-focused, channel it to be bold and visionary! (If you struggle to believe this, identify leaders who have done just that by figuring out how to prevent disasters.)',\n",
       " 'Use emotional agility skills. ',\n",
       " 'Fear of mistakes can paralyze people. Emotional agility skills are an antidote to this paralysis. This process starts with labeling your thoughts and feelings, such as “I feel anxious I’m not going to be able to control my customers enough to keep my staff safe.” Stating your fears out loud helps diffuse them. It’s like turning the light on in a dark room. Next comes accepting reality. For example, “I understand that people will not always behave in ideal ways.” List off every truth you need to accept. Then comes acting your values. Let’s say one of your highest values is conscientiousness. How might that value apply in this situation? For example, it might involve making sure your employees all have masks that fit them well or feel comfortable airing any grievances they have. Identify your five most important values related to decision-making in a crisis. Then ask yourself how each of those is relevant to the important choices you face.',\n",
       " 'Repeat this process for each of your fears. It will help you tolerate the fact that we sometimes need to act when the course of action isn’t clear and avoid the common anxiety trap whereby people try to reduce uncertainty to zero.',\n",
       " 'Focus on your processes. ',\n",
       " 'Worrying can help you make better decisions if you do it effectively. Most people don’t. When you worry, it should be solutions-focused, not just perseverating on the presence of a threat. Direct your worry towards behaviors that will realistically reduce the chances of failure.',\n",
       " 'We can control systems, not outcomes. What are your systems and processes for avoiding making mistakes? Direct your worries into answering questions like these: Is the data you’re relying on reliable? What are the limitations of it? How do your systems help prevent groupthink? What procedures do you have in place to help you see your blind spots? How do you ensure that you hear valuable perspectives from underrepresented stakeholders? What are your processes for being alerted to a problem quickly and rectifying it if a decision has unexpected consequences?',\n",
       " 'Broaden your thinking. ',\n",
       " 'When we’re scared of making a mistake, our thinking can narrow around that particular scenario. Imagine you’re out walking at night. You’re worried about tripping, so you keep looking down at your feet. Next thing you know you’ve walked into a lamp post. Or, imagine the person who is scared of flying. They drive everywhere, even though driving is objectively more dangerous. When you open the aperture, it can help you see your greatest fears in the broader context of all the other threats out there. This can help you get a better perspective on what you fear the most.',\n",
       " 'It might seem illogical that you could reduce your fear of making a mistake by thinking about other negative outcomes. But this strategy can help kick you into problem-solving mode and lessen the mental grip a particular fear has on you. A leader might be so highly focused on minimizing or optimizing for one particular thing, they don’t realize that other people care most about something else. Find out what other people’s priorities are.',\n",
       " 'Recognize the value of leisure.',\n",
       " 'Fear grabs us. It makes it difficult to direct our attention away. This is how it is designed to work so that we don’t ignore threats. Some people react to fear with extreme hypervigilance. They want to be on guard, at their command post, at all times. This might manifest as behavior like staying up all night to work.',\n",
       " 'That type of adrenalin-fueled behavior can have short-term value, but it can also be myopic. A different approach can be more useful for bigger picture thinking. We need leisure (and sleep!) to step back, integrate the threads of our thinking, see blindspots, and think creatively. Get some silent time. Although much maligned, a game of golf might be exactly what you need to think about tough problems holistically.',\n",
       " 'Detach from judgment-clouding noise. ',\n",
       " 'As mentioned, when people are fearful they can go into always-on monitoring mode. You may have the urge to constantly look at what everyone else is doing, to always be on social media, or check data too frequently. This can result in information overload. Your mind can become so overwhelmed that you start to feel cloudy or shut down. Recognize if you’re doing this and limit over-monitoring or over checking. Avoid panicked, frenzied behavior.',\n",
       " 'On its own, being afraid of making mistakes doesn’t make you more or less likely to make good decisions. If you worry excessively in a way that focuses only on how bad the experience of stress and uncertainty feels, you might make do or say the wrong things. However, if you understand how anxiety works at a cognitive level, you can use it to motivate careful but bold and well-reasoned choices.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68116d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 76 sentences in the string.\n",
      "The number of words in the string is: 1006\n",
      "The number of characters in the string is: 4966\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 13:24:36] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 13:24:46] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 13:24:52] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:35]))\n",
    "URL_ID_79 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_79.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_79.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_79.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_79 = re.sub(re_punt, \"\",URL_ID_79)\n",
    "\n",
    "file = open(\"79.txt\", \"w\")\n",
    "file.write(URL_ID_79)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"79.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9287ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006\n",
      "WORD COUNT 611\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/79.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54914d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 13.236842105263158\n",
      "181\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.29623567921440264\n",
      "FOG INDEX: 5.413231113791024\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 13.236842105263158\n",
      "COMPLEX WORD COUNT: 181\n",
      "WORD COUNT: 611\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30af43c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1877\n",
      "i: 3\n",
      "we: 4\n",
      "my: 2\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 10\n",
      "PERSONAL PRONOUNS: 10\n",
      "AVG WORD LENGTH: 4.936381709741551\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_79.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08a80a",
   "metadata": {},
   "source": [
    "# 80 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2d40996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\3032353225.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4c5cf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What’s perfection really? Does every person expect perfection from oneself or someone else? Or is it in certain amounts? Many times the certain question comes to the mind when we think about what we deem perfect. But how do we verify it?',\n",
       " 'Let us understand this through the work of three individuals who know are to be put on a task in carpentry on a budget. All are given Rs. 5000 (Assumed) to complete this task. They can’t go beyond this budget.',\n",
       " 'Manish, Vinay, and Sameer need to make a stool for themselves each. Manish has no understanding of carpentry; he learns from YouTube. Vinay took his carpentry lessons during engineering, so he has a practical idea of how to make a stool. But Sameer is a Carpenter, so he has a total understanding of the material, process, and final product.',\n",
       " 'Let us start with Manish. Understand that the task is to get their jobs done. Manish has two options here. He can either order parts and assemble it himself or order the material required such as wood, glue, nails, etc and then work on it before the assembly of the final product. The only difference is his lack of expertise in this field.',\n",
       " 'Vinay has the same options but has practical experience from his carpentry classes during the workshop in Engineering. Sameer has an advantage since he has both skill and experience perfected over a course of time.',\n",
       " 'All three are given three days for the task. Since Manish finds it easy to assemble the stool using parts procured from another carpenter; he talks to a carpenter he knows and orders 3 leg parts, 6 horizontal support bars, and one circular base which will sit on the top. Vinay thinks he will be able to shape the parts because of his experience as a student and orders several cylindrical wooden leg parts, cuboidal bars, and a thick sheet. Sameer has all the required material in his shop and he begins to work on the stool on the first day.',\n",
       " 'Manish and Vinay wait for a day for the parts to come. They begin to work on the second day. Manish uses the tricks learned from YouTube videos; uses a hammer to place the nails purchased from a nearby shop in the pre-made hole, applies glue in certain areas as directed in the video, and places weight on the assembled stool. He waits for the glue to cure.',\n",
       " 'Vinay uses borrowed drill bits, drill machines, cutters, sandpapers purchased from a shop, etc, and starts working on the wooden parts as soon as the parts arrive in the morning. He is able to recall his carpentry instructions and attempts to shape the parts based on drawing of his product he made last night. Sameer meanwhile has completed his assembly and has put the assembly to rest for the glue to cure.',\n",
       " 'On the third day, each of them has the stool ready. They evaluate their own work and notice certain facts.',\n",
       " 'Manish notices that he did complete the task but, his stool was wobbly and not glued well. It could fall the moment he sits on it. Also, he forgets to polish the wooden parts and give it a professional finish since he forgot to watch that bit of video over YouTube.',\n",
       " 'Vinay completes the task his stool is sturdy and cured well overnight. But there are minor issues with it. One of the three legs is cut short by a few mm and the stool, a tad unstable.',\n",
       " 'Sameer on the other hand completes the task with a good product. The stool is well-balanced, and polished, as he expected from him. Sameer is satisfied with his work and finds it to stool Perfect. Manish thinks he did his best considering he had no experience of the task to be done. He is satisfied with his work. But Vinay is unhappy, he could have done better and made the product better. He doesn’t find his efforts well put and thinks he wasn’t productive enough and hence his stool is nowhere perfect.',\n",
       " 'Understand that all of them had a set of skills and experience, but only Sameer had the right skills and experience to produce a perfect product. Manish and Sameer were satisfied and happy with their work. Manish made a wobbly stool which could break the moment someone sat on it but happy he gave the task a go. He thinks put the efforts and he did a good job. It was only Vinay who could not overcome the fact that his work was not perfect.',\n",
       " 'In Vinay’s case, it can be observed that he could not deliver what he learned from carpentry classes. The reason is simple, he put effort but didn’t have the experience. Experience mattered. Since Vinay thinks otherwise, he believes he has the perfect skills to complete the task but he could not deliver the results. He is not satisfied with his results and wishes to spend another day working on the stool on his own to get to his idea of the perfect result.',\n",
       " 'In this case, the idea of perfection itself is misplaced. You see, the end product made by Vinay and Manish would not match Sameer’s but the task could have been completed had they understood where their shortcomings lied. For both, it was their skill. Sameer had the perfect skill to get the expected result which resulted in better productivity, others didn’t.',\n",
       " 'And in this story, every individual put effort regardless of the result. But some were satisfied and some dissatisfied. Their satisfaction made their creations perfect in their eyes and dissatisfaction made one believe he wasn’t productive enough.  ',\n",
       " '“Perfection is subjective and productivity is utility extracted given a certain amount of effort”.',\n",
       " 'You can try to be as productive to achieve something but ultimately, it’s the satisfaction you get that defines the boundary of perfection. If you aren’t satisfied, you won’t find anything perfect. You would just waste both your time and effort over something that doesn’t suit you in the first place, as explained in the story before.',\n",
       " '“It isn’t productivity that will be the greatest enemy but your satisfaction”.',\n",
       " 'Satisfaction will determine how you perceive perfection and defines where your threshold for perfection lies. The real enemy is dissatisfaction. You get demotivated and restless. You lose sight and discontinue only because you are unable to pass your own expectation. So, it’s the only obstacle that comes in between productivity, from time to time.',\n",
       " 'Productivity is far from being your enemy. The greatest enemy will be your expectations which lead to dissatisfaction. It will play a major role in crafting your idea of Perfection in every day.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27e511d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73 sentences in the string.\n",
      "The number of words in the string is: 1126\n",
      "The number of characters in the string is: 5259\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 13:31:02] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 13:31:07] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:37]))\n",
    "URL_ID_80 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_80.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_80.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_80.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_80 = re.sub(re_punt, \"\",URL_ID_80)\n",
    "\n",
    "file = open(\"80.txt\", \"w\")\n",
    "file.write(URL_ID_80)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"80.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46bf6039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126\n",
      "WORD COUNT 688\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/80.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc773058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 15.424657534246576\n",
      "168\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.2441860465116279\n",
      "FOG INDEX: 6.267537432303282\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 15.424657534246576\n",
      "COMPLEX WORD COUNT: 168\n",
      "WORD COUNT: 688\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b820a4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1875\n",
      "I: 0\n",
      "we: 3\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 2\n",
      "Total count: 5\n",
      "PERSONAL PRONOUNS: 5\n",
      "AVG WORD LENGTH: 4.6705150976909415\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_80.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859381f",
   "metadata": {},
   "source": [
    "# 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8012062b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\3376498219.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "812bed5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Financial Crisis of 2008 started as a crisis in the subprime mortgage market (i.e. in a market where lending of loans is done to people who may have difficulty in maintaining the repayment schedule or in simple terms, loans were given out to people without proper checks and low credit scores) which ultimately led onto a huge global collapse.',\n",
       " 'The Financial Crisis of 2008 or Great Recession is considered the worst economic crisis since the Great Depression.',\n",
       " 'In the year 1996, there was a dot-com boom (or otherwise known as the dot com bubble) in the United States, a period of massive growth in the use of the internet because of which the stock market prices started increasing rapidly. However, around the year 2000, it dropped which led people and investors to withdraw their investments from the stock market rapidly. It led to the decline of the price of shares in stock markets and the interest rate plummeted to around 1% very quickly in a short span.',\n",
       " 'Investors were now looking for a brighter option than investing in stock markets.',\n",
       " 'Fig – Rise and fall of the Dot Com Bubble',\n",
       " 'As interest rates went lower and lower, real estate prices started rising and the US Govt also encouraged people to buy houses and properties. The demand for the same started rising rapidly and investors now found a great option to invest in (i.e. in Real Estate).',\n",
       " 'During that same time, Investment Banks saw an opportunity, chimed in and started buying loans from Banks in bulk and clubbed multiple loans under a complex derivative called CDO (Collateralized Debt Obligations) and started providing it to these Investors after getting a credit rating of “AAA” (Very Safe Investment) from the Credit Rating Agencies. Investors naturally fell for it and started buying these CDOs.',\n",
       " 'So now, the risk factor of these loans got transferred from the Banks to the Investment Banks and then again to the CDO Investors.',\n",
       " 'With the high buying demand of CDOs, Investment banks started demanding or pressurizing Banks to provide even more Loans so that they can provide more CDOs to the Investors. However, Banks had already provided loans to people with good credit history and regular income people. But in the hope of getting even more credit from Investment Banks, these same banks then started giving out subprime housing loans to people with low credit scores.\\nApproximately $174Bn worth of loans were given out during the period 2000-2007 and most of them were clubbed as CDOs with a “AAA” rating from the Credit Rating Agencies. Approximately 70% of these CDO’s were marked with a “AAA” rating.',\n",
       " 'Investment Banks and Credit Rating Agencies were now enjoying large profits during this time. Moody’s (a credit rating agency) profits increased 4x times during that period (2000-2007).',\n",
       " 'Looking at the huge profits being made by the Investment Banks and Credit Rating Agencies, Insurance companies (like AIG) now started giving out insurance on these CDOs to the investors and they called it CDS (Credit Default Swap). AIG believed that since the CDOs were rated as “AAA” (Very Safe Investment), the failure chances of these CDOs were very minimal. They misjudged or were unaware of the fact that some of the loans that were clubbed under these CDOs were Sub Prime loans.',\n",
       " 'Now CDO Investors started buying out CDS from AIG and other companies to safeguard and protect them from any losses. AIG then started making huge profits because of the premiums that the investors had to pay. But they never realized the outcome if by any chance the CDOs fail at some point in time. Thus, the risk factor again got transferred from the CDO investors to the Insurance Companies.',\n",
       " 'Fig – Flow Diagram showing how the Risk Factors got transferred',\n",
       " 'Coming to the loan borrowers now, Sub Prime Borrowers from banks were unaware of the fact of Adjustable Rate Loans (interest rate of these loans keeps changing) and thus had to pay lower interests at the start but more interest rates later on.',\n",
       " 'The borrowers started defaulting on these loans when the interest rates increased dramatically around 2007 and thus banks had to then resell those houses to make up for the loans defaulted.  Added to the problem was the fact that borrowers were not spending any amount of money from their pockets while taking loans and banks were providing the full amount of loans. Almost 50% of the borrowers did not pay anything from their own pocket and bought the home only using the housing loan.',\n",
       " 'This led to a huge increase in the defaulters of borrowers and ultimately banks had to auction houses to gain credit back. With the high-interest rates and no one to buy the auctioned houses, this ultimately caused a chain reaction and banks were no longer receiving credit. The prices of Real Estate started falling drastically and people with good credit scores who had earlier taken housing loans also started defaulting because the price of their houses/homes fell below the loan amount that they had taken earlier. Banks stopped receiving money and also because of this chain reaction, the value of CDOs ultimately came down to 0.',\n",
       " 'Some Investors went for huge losses and few Investment companies went bankrupt (ex – Lehman Brothers). Moreover, insurance companies had to pay back those investors who had taken insurance. As a result, some of the insurance companies also went bankrupt. AIG too almost lost about $100Bn in paying back the investors who had earlier insured their CDOs. However, the US Govt. finally decided to bail out AIG in order to save them from going bankrupt.',\n",
       " 'CDOs and CDSs were not regulated during that time by the Federal Reserve and thus this whole situation ultimately led to credit crunch (became very difficult to get loans) and the whole economy of the US underwent a crisis that led to a global impact all around the world. Unemployment increased manifold and many new businesses had to shut down. Global trades all around the world also saw a crisis and finally, Global Recession hit the World.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c2dbd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47 sentences in the string.\n",
      "The number of words in the string is: 1046\n",
      "The number of characters in the string is: 5097\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 13:37:20] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 13:37:26] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:34]))\n",
    "URL_ID_81 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_81.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_81.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_81.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_81 = re.sub(re_punt, \"\",URL_ID_81)\n",
    "\n",
    "file = open(\"81.txt\", \"w\")\n",
    "file.write(URL_ID_81)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"81.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f412352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037\n",
      "WORD COUNT 666\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/81.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a58ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 22.25531914893617\n",
      "141\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.21171171171171171\n",
      "FOG INDEX: 8.986812344259153\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 22.25531914893617\n",
      "COMPLEX WORD COUNT: 141\n",
      "WORD COUNT: 666\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb314aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1762\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 3\n",
      "Total count: 3\n",
      "PERSONAL PRONOUNS: 3\n",
      "AVG WORD LENGTH: 4.872848948374761\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_81.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6578eef",
   "metadata": {},
   "source": [
    "# 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "489bbfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\3707122734.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72e796ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender diversity is an equal representation of all genders in workplaces. One of the most important sectors where there is under-representation of gender diversity is the technological industry. Gender diversity means you have an equal opportunity which is not limited by gender. But, the true reality is gender diversity is a far outcry in the world.',\n",
       " 'Gender diversity isn’t a new topic but an old and global phenomenon and technology industry is not a stranger to it.  Women are often underrepresented in the technology sector. To understand the gap, let’s look at some statistics.',\n",
       " 'After looking at these staggering numbers, we see how biased gender diversity is even in the technological sector.',\n",
       " 'With rapid industrialization and education about the importance of rights, gender diversity is very important in today’s world. Gender equality represents a society that has lesser violence and provides a safer world for everyone. It is also directly proportional to sustainable development and ensures human rights to everyone. As today’s markets are increasing along with customers’ preferences, to understand customer profiles and build products we need gender diversity in our organizations. Equal representation helps in a better decision-making process for a positive impact.',\n",
       " 'Men and Women invest back into their families and having gender equality and diversity helps build values into families and households. Empowering individuals not only help themselves but also the economy of the nations. Gender equality and diversity should be built into organizations’ beliefs and values.',\n",
       " 'Global Gender Gap Report (2017)',\n",
       " 'Perception: If we see the word “gender”, it is a socially constructed definition. And this definition changes as per different cultural norms. In a much broader term, our society is also not aware of the concept of binary and non-binary gender, which includes queer, Trans, and Intersex individuals as well. The socially acceptable thing is to have gender expressions as per our gender identity. So, when it comes to choosing their career, people tend to choose a job role that gives them higher social belongingness. E.g. We see more women(as compared to men) in nursing careers as it requires more feminine qualities.',\n",
       " 'There are different versions of this perception: which we can see either in the society(in terms of socially assigned gender roles) or in the workplace(in the form of gender discrimination, stereotypical thinking, sexism, etc.). E.g. As per their assigned roles in society, women are most likely to take care of their family and children, and this affects their income and career growth. The motherhood penalty is a term defined by sociologists which states about the inverse correlation between income level and the number of children, i.e. there is also an income difference between a mother and a non-mother employee. As per OECD data(2012), there is a 7% reduction in wages for women per child.',\n",
       " 'Lack of economic opportunities: Even in the tech industry, women are paid less than men. As per ILO data(2019), on average women are paid 20% less than men worldwide.',\n",
       " 'Even when it comes to promotion, men are preferred more. It is to be noted that the numbers are even worse when there is intersectionality involved. E.g., a transgender woman will be paid less than a white woman and so on. As per the National Centre for Transgender equality, one out of two transgender people faces adverse effects: including 23% were denied a promotion, 44% were passed over for a particular job position and 26% are fired from their workplace just because they are transgender.',\n",
       " 'We can improve this scenario from the perspective of different stakeholders who are involved.',\n",
       " 'For Society :',\n",
       " 'Creating Tech awareness from School level: As per the HDR report( 2017), no. of boys pursuing STEM program is 97% higher than girls. One way to improve this is to introduce more strong role models to advocate for this issue. Minority gender communities should be aware of the multiple job opportunities and career growth available in this field. These job roles are not even gender-specific anymore. For developing countries like India, STEM scholarship programs can be introduced from the secondary education level.',\n",
       " 'Address Bias/Stereotypes: It is to be noted that perceptions, stereotypes, and biases are not just something we learn in school but our upbringing also creates these, the things we watch, listen, and read daily. So, it also becomes the duty of the society to create a more inclusive environment. E.g. A more privileged person should fight for the fundamental right of the less empowered or less privileged person in society.',\n",
       " 'There should be active encouragement from parents, teachers, and educators for students in STEM programs regardless of their gender identity.',\n",
       " 'For Companies:',\n",
       " 'To promote gender diversity in the workplace, companies need to focus on three things:',\n",
       " 'Unbiased Recruitment policies:',\n",
       " 'Generally, there is a lot of unconscious bias and prejudices when hiring women, trans, intersex, and queer individuals. There needs to be a diversity and inclusivity team in the HR itself that addresses these issues. A blind recruitment drive can be conducted where there is no need to mention gender in any of the documents.',\n",
       " 'Having structured questions during the interview might help to remove any unconscious biases.',\n",
       " 'Diversity sensitivity training: Workplace policies need to create a company image that hires everyone irrespective of their gender identity and can even keep it optional in all the job formalities and documents.',\n",
       " 'Conducting proper sensitivity training to employees is essential as they need to use correct pronoun/gender-neutral language.',\n",
       " 'Not just sensitivity training, strong workplace policies need to be in place which deal with any form of harassment or gender discrimination.',\n",
       " ' To create accountability and transparency in their process, companies can also share diversity and inclusivity company data.',\n",
       " 'Retention policies:',\n",
       " 'Creating Mentorship models:',\n",
       " 'Including proper maternity leaves, child care facilities, and flexibility of working hours/remote working arrangements can be helpful for minority gender in keeping their work-life balance.',\n",
       " 'Develop support programs for these communities who are joining after maternity leave. It might be in terms of psychiatric or mentorship support.',\n",
       " 'Increase Pay parities: It can be done in the following ways:',\n",
       " 'Lastly, there needs to be proper government policies in place which provide a constitutional or legal framework starting from the basic education level. It may begin from increasing the gross enrollment rates of all students in schools (irrespective of their gender identity) for developing countries( like India) to have proper compensation policies in the workplace(as similar to what states like California, New York has adopted) to ensure pay parity.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce104dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68 sentences in the string.\n",
      "The number of words in the string is: 1080\n",
      "The number of characters in the string is: 5827\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 13:43:05] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 13:43:10] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:46]))\n",
    "URL_ID_82 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_82.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_82.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_82.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_82 = re.sub(re_punt, \"\",URL_ID_82)\n",
    "\n",
    "file = open(\"82.txt\", \"w\")\n",
    "file.write(URL_ID_82)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"82.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f217f92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n",
      "WORD COUNT 705\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/82.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36db161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 15.882352941176471\n",
      "266\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3773049645390071\n",
      "FOG INDEX: 6.5038631622861915\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 15.882352941176471\n",
      "COMPLEX WORD COUNT: 266\n",
      "WORD COUNT: 705\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10247097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2121\n",
      "I: 0\n",
      "we: 8\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 8\n",
      "PERSONAL PRONOUNS: 8\n",
      "AVG WORD LENGTH: 5.395370370370371\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_82.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff378eb",
   "metadata": {},
   "source": [
    "# 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09b7c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\2309707875.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4aa760d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Covid-19 crisis and its fallout including recession, layoffs, and uneven economic pain-as well as recent protests over police brutality and demands for racial justice, have presented many of us with challenges that we’ve not encountered before. The high-stakes and unfamiliar nature of these situations have left many people feeling fearful of missteps. No one can reduce mistakes to zero, but you can learn to harness your drive to prevent them and channel it into better decision making. Use these tips to become a more effective worrier.',\n",
       " 'Our culture glorifies fearlessness. The traditional image of a leader is one who is smart, tough, and unafraid. But fear, like any emotion, has an evolutionary purpose and upside. Your concern about making mistakes is there to remind you that we’re in a challenging situation. A cautious leader has value. This is especially true in times like these. So don’t get caught up in ruminating: “I shouldn’t be so fearful.”',\n",
       " 'Don’t be ashamed or afraid of your fear of making mistakes and don’t interpret it as evidence that you’re an indecisive leader, or not bold, not visionary. If you have a natural tendency to be prevention-focused, channel it to be bold and visionary! (If you struggle to believe this, identify leaders who have done just that by figuring out how to prevent disasters.)',\n",
       " 'Fear of mistakes can paralyze people. Emotional agility skills are an antidote to this paralysis. This process starts with labeling your thoughts and feelings, such as “I feel anxious I’m not going to be able to control my customers enough to keep my staff safe.” Stating your fears out loud helps diffuse them. It’s like turning the light on in a dark room. Next comes accepting reality. For example, “I understand that people will not always behave in ideal ways.” List off every truth you need to accept. Then comes acting your values. Let’s say one of your highest values is conscientiousness. How might that value apply in this situation? For example, it might involve making sure your employees all have masks that fit them well or feel comfortable airing any grievances they have. Identify your five most important values related to decision-making in a crisis. Then ask yourself how each of those is relevant to the important choices you face.',\n",
       " 'Repeat this process for each of your fears. It will help you tolerate the fact that we sometimes need to act when the course of action isn’t clear and avoid the common anxiety trap whereby people try to reduce uncertainty to zero.',\n",
       " 'Worrying can help you make better decisions if you do it effectively. Most people don’t . When you worry, it should be solutions-focused, not just perseverating on the presence of a threat. Direct your worry towards behaviors that will realistically reduce the chances of failure.',\n",
       " 'We can control systems, not outcomes. What are your systems and processes for avoiding making mistakes? Direct your worries into answering questions like these: Is the data you’re relying on reliable? What are the limitations of it? How do your systems help prevent groupthink? What procedures do you have in place to help you see your blind spots? How do you ensure that you hear valuable perspectives from underrepresented stakeholders? What are your processes for being alerted to a problem quickly and rectifying it if a decision has unexpected consequences?',\n",
       " 'When we’re scared of making a mistake, our thinking can narrow around that particular scenario. Imagine you’re out walking at night. You’re worried about tripping, so you keep looking down at your feet. Next thing you know you’ve walked into a lamp post. Or, imagine the person who is scared of flying. They drive everywhere, even though driving is objectively more dangerous. When you open the aperture, it can help you see your greatest fears in the broader context of all the other threats out there. This can help you get a better perspective on what you fear the most.',\n",
       " 'It might seem illogical that you could reduce your fear of making a mistake by thinking about other negative outcomes. But this strategy can help kick you into problem-solving mode and lessen the mental grip a particular fear has on you. A leader might be so highly focused on minimizing or optimizing for one particular thing, they don’t realize that other people care most about something else. Find out what other people’s priorities are.',\n",
       " 'Fear grabs us. It makes it difficult to direct our attention away. This is how it is designed to work, so that we don’t ignore threats. Some people react to fear with extreme hypervigilance. They want to be on guard, at their command post, at all times. This might manifest as behavior like staying up all night to work.',\n",
       " 'That type of adrenalin-fueled behavior can have short-term value, but it can also be myopic. A different approach can be more useful for bigger picture thinking. We need leisure (and sleep!) to step back, integrate the threads of our thinking, see blindspots, and think creatively. Get some silent time. Although much maligned, a game of golf might be exactly what you need to think about tough problems holistically.',\n",
       " 'As mentioned, when people are fearful they can go into always-on monitoring mode. You may have the urge to constantly look at what everyone else is doing, to always be on social media, or check data too frequently. This can result in information overload. Your mind can become so overwhelmed that you start to feel cloudy or shut down. Recognize if you’re doing this and limit over-monitoring or overchecking. Avoid panicked, frenzied behavior.',\n",
       " 'On its own, being afraid of making mistakes doesn’t make you more or less likely to make good decisions. If you worry excessively in a way that focuses only on how bad the experience of stress and uncertainty feels, you might make do or say the wrong things. However, if you understand how anxiety works at a cognitive level, you can use it to motivate careful but bold and well-reasoned choices.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dea30863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72 sentences in the string.\n",
      "The number of words in the string is: 1031\n",
      "The number of characters in the string is: 5112\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 13:49:04] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 13:49:10] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:29]))\n",
    "URL_ID_84 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_84.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_84.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_84.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_84 = re.sub(re_punt, \"\",URL_ID_84)\n",
    "\n",
    "file = open(\"84.txt\", \"w\")\n",
    "file.write(URL_ID_84)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"84.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5553a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "WORD COUNT 626\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/84.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb63ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 14.319444444444445\n",
      "190\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3035143769968051\n",
      "FOG INDEX: 5.8491835285765\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 14.319444444444445\n",
      "COMPLEX WORD COUNT: 190\n",
      "WORD COUNT: 626\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6485ba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1927\n",
      "i: 3\n",
      "we: 4\n",
      "my: 2\n",
      "ours: 0\n",
      "us: 2\n",
      "Total count: 11\n",
      "PERSONAL PRONOUNS: 11\n",
      "AVG WORD LENGTH: 4.958292919495635\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_84.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efe0da",
   "metadata": {},
   "source": [
    "# 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f858429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\2553750711.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7de23a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The word pandemic may be the most used word for the last decade, and we know why. The year 2020 comes with a lot of unprecedented threats to humans as well as to nature. While no business was left insulated from its effect, small businesses were one of the most affected, as they rely on day to day sales and keep the inventory minimum, based on the demand of customers and have a low margin to maneuver.',\n",
       " 'In an article by HSBC’s Navigator, which described the preparedness and contingency plan for the future, Indian business rated high among its peers. The businesses in India have shown resilience to face adversity which can be attributed to varying degrees of adjustment and adaptability. The businesses, while able to adhere to government guidelines have managed to facilitate their customers efficiently and effectively. However, the impact on micro, small, and medium enterprises cannot be left unattended. ',\n",
       " 'The Indian subcontinent has an estimated ₹ 633.88 lakh of MSME, out of which 51.2% are in rural areas which employ 44.84% of the total employment provided by this Sector. The MSME sector with 1170 lakh people constitutes 40% of the total workforce. As per the ministry of commerce MSME contribution in Gross Domestic Product (GDP) and export are 37% and 43% respectively.',\n",
       " 'With the huge contribution toward GDP as well as export, the impact on the national economy due to the shock in the MSME sector from the pandemic will be equally devastating. While different businesses face different types of obstacles, we have pointed out 8 of the most common issues faced by them.',\n",
       " 'For any business, cash in hand is oxygen. The small business which usually has at most 1-month cash to run the business if the revenue stream dries up, which in this tough time has to improve gradually. To manage the optimal cash balance is the key to success in this tough time. The optimal cash balance here, defined as “the less of the amount of cash outflow in form rent, employee salaries, and raw material without postponing the payable as they are doing what banks have to do, to the inflow from sale”. ',\n",
       " 'In any given situation, business is like juggling between multiple tasks to optimize the performance while maximizing the revenue. The current situation has added another layer of challenge. This challenge will test management skills in various aspects of our business owner. ',\n",
       " 'With this article, we have pointed out the major challenges and possible ways to alleviate the impact. As Anthony Robbins quotes, “Every problem is a gift—without problems we would not grow”, the current market has wiped out their share in the market which gives an opportunity to other businesses to grow and lower the expense.',\n",
       " 'While there may be many facets that need to be handled precisely, communication is one of the major tools that will create a positive environment among workers or teams which will influence the customer behavior and result in terms of revenue. The communication will also help to increase productivity and create trust in a supply chain which will improve the cash conversion cycles and working capital ratio.',\n",
       " 'Marketing through word of mouth has no added cost but the benefit can be scaled too much-required revenue. The choice of an effective marketing tool can also influence our target customer and will influence their will to buy the product or service(s) strategically.',\n",
       " 'Cash from operating activity improves if we were able to lower our expenses. To lower these expenses, small business owners have to create a different plan (good, average, and worst) keeping the 6-month frame in mind. Breaking down them in monthly targets would further help them to identify the actual scenario and update the strategy accordingly.  ',\n",
       " 'As Warren Buffet quotes, “You only have to do a few things right in your life so long as you don’t do too many things wrong.” this is the right time to do the right thing and over time businesses will ripe its benefits. ']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07154540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 sentences in the string.\n",
      "The number of words in the string is: 713\n",
      "The number of characters in the string is: 3556\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 13:54:47] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 13:54:52] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:27]))\n",
    "URL_ID_85 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_85.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_85.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_85.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_85 = re.sub(re_punt, \"\",URL_ID_85)\n",
    "\n",
    "file = open(\"85.txt\", \"w\")\n",
    "file.write(URL_ID_85)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"85.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02507d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711\n",
      "WORD COUNT 442\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/85.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0769627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 19.27027027027027\n",
      "147\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.332579185520362\n",
      "FOG INDEX: 7.841139782316254\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 19.27027027027027\n",
      "COMPLEX WORD COUNT: 147\n",
      "WORD COUNT: 442\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d13b0fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1256\n",
      "I: 0\n",
      "we: 5\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 5\n",
      "PERSONAL PRONOUNS: 5\n",
      "AVG WORD LENGTH: 4.987377279102384\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_85.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b570903",
   "metadata": {},
   "source": [
    "# 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1906ece0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\230842583.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "055e64e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Some vendors (fruit and vegetable sellers) began venturing out after a few days without explicit permission and immediately faced police harassment. After a few weeks, the government eased restrictions and essential vendors were being permitted to vend (due in large part to the advocacy of vendor organizations and activist networks). However, the cost of doing business, as well as the risk, has gone up significantly, with vendors not having access to wholesale markets and suppliers and having to spend more on travel costs due to travel restrictions in place in the city. Also, with the lockdown still partially in place, the number of buyers has gone down and so have earnings. Due to the harsh summer heat, perishable fruits and vegetables also have a reduced shelf life so vendors are unable to capitalize on whatever produce they do have.',\n",
       " 'The state has recently announced a stimulus package of INR 5000 crore for nearly 50 lakh vendors, acknowledging the grave impact of their loss of livelihood. The intended relief for vendors will be a credit loan that will provide an initial working capital of INR 10,000 for all vendors, but this is not sufficient. Instead of credit, the government should think of converting it into direct income benefit, a cash grant, as livelihood support to start the income activity regularly. The vendors need income support to be able to restart work, and if they are not able to do so, how will they return the loan. In the face of the ever-changing crisis, vendor organizations have to step forward and advocate for vendors to be provided the resources they need to be able to resume their livelihoods. To this end, vendors organizations could consider the following for an advocacy agenda:']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a19e3e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 sentences in the string.\n",
      "The number of words in the string is: 289\n",
      "The number of characters in the string is: 1444\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 14:00:13] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 14:00:20] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "texts=(' '.join(str(x) for x in texts[16:18]))\n",
    "URL_ID_86 = texts\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_86.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_86.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_86.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_86 = re.sub(re_punt, \"\",URL_ID_86)\n",
    "\n",
    "file = open(\"86.txt\", \"w\")\n",
    "file.write(URL_ID_86)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"86.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0db6589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "WORD COUNT 183\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/86.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41fb29d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 26.272727272727273\n",
      "59\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.05493482309124767\n",
      "FOG INDEX: 10.53106483832741\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 26.272727272727273\n",
      "COMPLEX WORD COUNT: 59\n",
      "WORD COUNT: 1074\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ca01ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 522\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 4.996539792387543\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_86.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc9244",
   "metadata": {},
   "source": [
    "# 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f576b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\283531272.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0a7b64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The COVID-19 pandemic has grown into one of the most major and socially disruptive health crises in recent memory, with growing worried about how the pandemic’s catastrophic economic and social repercussions are affecting food systems at both the global and local levels. Given the importance of the retail food environment in establishing and sustaining healthy diets, interruptions to specific aspects of it, such as the availability of fresh vegetables, could have a negative influence on population health, which has already been noted as a source of worry.',\n",
       " 'Despite the dominance of national and international supermarket chains, warehouse clubs, and supercenters in grocery retail, vegetables are offered in a number of other food retail settings. Fresh vegetable #vendors are typically smaller and more community-oriented than other restaurant or retail food outlets and can include chain or independent grocery stores, greengrocers, storefront stands, street carts, and even makeshift platforms dedicated to the sale of fresh vegetables. Smaller community fresh vegetable vendors who may conduct business on the sides of major streets or on storefronts have played an integral role in the food environment in large urban centers such as New York City (NYC), particularly in ethnic enclaves, despite the fact that fresh produce does not have a significantly higher nutritional value and fresh produce can also be purchased at these larger food retailers.',\n",
       " 'Since the COVID-19 pandemic began, many fresh fruit and vegetable vendors, notably street carts selling fresh vegetables in cities across the United States, including New York City, have been forced to close owing to a combination of falling demand and fear of catching COVID-19. The importance of fresh vegetable vendors varies by neighborhood within cities. Furthermore, these fresh vegetable vendors attract visitors and interborough shoppers from a variety of cultural backgrounds not only Asian ones who are looking for things that are not available elsewhere in the city or for the same low prices.',\n",
       " 'These fresh vegetable vendors, unlike larger, well-established grocery store vendors, may not have the financial infrastructure to sustain the shifts in supply and demand produced by the COVID-19 epidemic; consequently, the danger of closure or modifications in services may be greater for these vendors.',\n",
       " 'In order to assess the impact of the COVID-19 pandemic on services offered by fresh vegetable vendors, surveillance #data from both before and after the pandemic’s inception is required.',\n",
       " 'After a few days, vegetable dealers began venturing out without explicit permission and were quickly harassed by police. After a few weeks, the government relaxed the limitations, allowing vital traders to sell their wares (due in large part to the advocacy of vendor organizations and activist networks). However, the cost of doing business has increased dramatically, as vendors no longer have access to wholesale markets and suppliers, and they must spend more on travel expenditures owing to city-imposed travel limitations. Furthermore, with the partial lockdown still in place, the number of buyers has decreased, as have earnings. Perishable vegetables have a shorter shelf life in the summer heat, thus vendors are unable to capitalize on whatever produce they do have.',\n",
       " 'Consider the situation of Delhi at the starting of COVID 19. The state has launched an INR 5000 crore stimulus package for over 50 lakh vendors, realizing the serious consequences of their loss of livelihood. The targeted relief for vendors is a credit facility that will provide all sellers with an initial working capital of INR 10,000, but this will not be enough. Instead of credit, the government should consider changing it into a direct income benefit, such as a cash grant, to help people start earning money on a regular basis. The vendors require income support in order to resume work, and how will they repay the loan if they are unable to do so? Vendor organizations must step forth in the face of the ever-changing crises and lobby for vendors to be given the resources they need to continue their livelihoods. Vendor organizations could use the following as part of their advocacy agenda:',\n",
       " 'Finally, some fresh vegetable sellers may have shuttered for a period of time early in the epidemic, only to reopen recently. Alternatively, vendors may have launched soon after the in-person checks were completed, but still within the June-July 2020 endpoint timeframe. This is a drawback of the method; in order to offer the most reliable COVID-19 pandemic monitoring data, data must be collected in a short period of time.']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2896be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 sentences in the string.\n",
      "The number of words in the string is: 739\n",
      "The number of characters in the string is: 3982\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 15:10:45] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 15:10:52] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:24]))\n",
    "URL_ID_86 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_86.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_86.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_86.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_86 = re.sub(re_punt, \"\",URL_ID_86)\n",
    "\n",
    "file = open(\"86.txt\", \"w\")\n",
    "file.write(URL_ID_86)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"86.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8b179568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "WORD COUNT 183\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/86.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b3227d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 30.791666666666668\n",
      "171\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.9344262295081968\n",
      "FOG INDEX: 12.690437158469948\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 30.791666666666668\n",
      "COMPLEX WORD COUNT: 171\n",
      "WORD COUNT: 183\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b7f4e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1427\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 5.388362652232747\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_86.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11320913",
   "metadata": {},
   "source": [
    " # 87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "404e2239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\1530816161.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd1c1a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As the Coronavirus pandemic unfolds, most industries face problems they had never imagined or prepared for. The Aviation and Tourism industries face the highest stress as Coronavirus spreads because not only are they a (usually) a leisure spending but also the nature of the disease directly conflicts with the industries’ innate business models. In this article, we will look at the impact of COVID-19 pandemic on the Tourism and Aviation industries both from the demand side and the supply side.',\n",
       " 'The Aviation and Tourism industries has two major customers: tourists and business travellers. Let us base this essay in the India and see what the reaction of the customer segments is expected to be like.',\n",
       " 'Almost all tourists will avoid vacationing for the foreseeable future because of:',\n",
       " 'Now, let us look at different types of holiday revellers. Tourists can be foreigners or domestic tourists. According to Business Insider “In 2019, almost 10 million foreign tourists visited India — spending over ₹1,800 billion during January to November period.”. However, because of the pandemic, almost all this business has been lost.',\n",
       " 'Due to the reasons stated above most foreigners will not prefer to travel. Those who do dare to venture out, perhaps wooed by discounted deals to places which would have otherwise been out of their budgets, will possibly be warded off by the one of the following factors:',\n",
       " 'Moving our focus to domestic tourists, we subdivide our population according to income levels:',\n",
       " 'In order to attract well paying customers, the Aviation and Tourism industries will have to spend a considerable amount of money to become sanitation compliant which will push profit margins even lower. Most Aviation and Tourism activities made money not on individual margins but on collective volumes, thus, they are inherently incompatible with the concept of social distancing.',\n",
       " 'Because of COVID-19 pandemic, businesses have realized that more and more meetings can be handled over video calls, thus, the movement of business personnel will be restricted. There will still be some representatives who will fly out to conduct business, but the industry can expect a permanent drop in revenue from this sector.',\n",
       " 'Moving over to the supply side, the Aviation and Tourism industries face strong disruptions in their supply chain. Because the industry is a leisure expense, manufacturing of many supporting equipment like the adventure sports gears and even parts of planes themselves has stopped. Because of the drop in demand, it is going to be tough to get the supply chain back up again. Furthermore, workers are afraid to show up to their jobs because of the high risk of contracting the virus due to exposure to multiple customers from different geographies.',\n",
       " 'Let us now see some examples of how the industry has done through March and April.',\n",
       " 'The bookings vanished in mid-March. Property owners had bought or leased real estate to list on the app were severely affected. The sharing economy, like Uber, Lyft and DoorDash had taken a hit but Airbnb was worse off because their expenses include cleaning services, interior design (one-time spend), and property maintenance which are fixed costs.',\n",
       " 'Thus, because of the pandemic the revenue was gone but the costs exist. They have people who depend on the owner’s rental income which made the problem worse.',\n",
       " 'Hosts usually decide cancellation policy, but under extreme circumstances, like this one, the company decided to override all existing policies (many of whom weren’t strict) and gave full refund to the guests. The company got $2 billion loan and has helped out the owners, financially by paying 25% for cancelled bookings capping at 5k/host. They have helped some hosts by getting them eligible for small business loans and avoid eviction.',\n",
       " 'Thankfully, there are too few properties to cause a housing crisis, but breakdown could cause strain on lenders and undermine property values (all want to sell to avoid foreclosure or defaulting on loans). AirDNA states that the listing split-up for Airbnb is: 33% list single property, 33% owners list 2-24 properties, 33% hosts have 25+ properties.',\n",
       " 'Some state governments in America have banned short-term rentals. This hurt the Airbnb owners because people looking to quarantine outside their homes or near relatives could’ve generated revenues.',\n",
       " 'So, what are hosts doing now?',\n",
       " 'Many are discounting units and looking for long-term tenants (12 months). Many are planning to apply for a small-business loan, seek forbearance from banks, find long-term tenants independently of Airbnb and sell property.',\n",
       " 'According to the Wall Street Journal, roughly half of all US workers stand to earn more from the Coronavirus rather than their work pay cheques. However, it must be noted that some have not gotten their money due to bureaucratical issues.',\n",
       " 'This complicates reopening because workers don’t want to come back and expose themselves to the virus and earn less. But businesses want workers to come back so that their small business loans can be forgiven, and business can reopen. However, money in the consumer’s pockets means the economy expected to rebound quickly when businesses open. About 40 million Americans are now on unemployment benefits, majorly from restaurant, hospitality, and retail industries.',\n",
       " 'Congress chose a flat amount of relief because it was really time-consuming for payments to be calibrated to each worker’s lost wages. Their $600 federal payment corresponds to $15/hours wage, but 21 states follow $7.25/hours.',\n",
       " 'Most workers don’t want to sit at home and are anxious to get back to work, but right now staying at home is the smartest financial decision for their families.',\n",
       " 'Workers should be ineligible for unemployment benefits if a job is made available to them. But owners are reluctant to report workers to authorities and sever relationships with employees they may need more later in the year when tourism demand is expected to pick up. Without income support, low-wage workers would likely seek out other jobs, including side hustles and gig work, which could expose them and their households to the virus. Thus, according to the government, it was important to give such a large stimulus to the economy.',\n",
       " 'Studies of SARs suggested that people sitting close to infectious persons were at large risk. Combined with that, in long journeys, passengers may take off masks. Thus, the risks of transmission are large and airlines need to focus on figuring out how to prevent transmission in planes.',\n",
       " 'Currently, the airlines plan on using self-cleaning material, long-lasting disinfectant, touchless lavatories, UV light as a disinfectant, antimicrobial coating for frequently touched surfaces, and cleaning between flights.',\n",
       " 'However, even after these efforts, only 12% of people are flying (compared to last year, same time) as of 27th May 2020.',\n",
       " 'Aviation and Tourism industries have the curse of being a luxury expense and thus, as the Coronavirus pandemic spread, the entire industry jolted to a halt. They are one of the hardest-hit sectors and have to adapt to a new normal wherein the revenue levels are unlikely to match to pre-COVID levels and margins have also reduced. However, in with a bleak future, this industry is here to stay because people have to travel, and eventually they will vacation as well. Coronavirus has become a “survival of the fittest” test for this industry and the stakeholders will come out of this disaster with strong business processes.']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37f2ef53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58 sentences in the string.\n",
      "The number of words in the string is: 1360\n",
      "The number of characters in the string is: 7255\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 15:20:42] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 15:20:47] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:42]))\n",
    "URL_ID_87 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_87.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_87.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_87.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_87 = re.sub(re_punt, \"\",URL_ID_87)\n",
    "\n",
    "file = open(\"87.txt\", \"w\")\n",
    "file.write(URL_ID_87)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"87.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "117bba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359\n",
      "WORD COUNT 887\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/87.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "47a9e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 23.448275862068964\n",
      "307\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3461104847801578\n",
      "FOG INDEX: 9.51775453873965\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 23.448275862068964\n",
      "COMPLEX WORD COUNT: 307\n",
      "WORD COUNT: 887\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "748ba803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2600\n",
      "I: 0\n",
      "we: 2\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 4\n",
      "Total count: 6\n",
      "PERSONAL PRONOUNS: 6\n",
      "AVG WORD LENGTH: 5.334558823529412\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_87.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb51cf2",
   "metadata": {},
   "source": [
    "# 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17289fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\202155591.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "242\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0f524c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The COVID-19 pandemic has caused the most significant disruption to the worldwide sporting calender since World war II. Across the world and to varying degrees, sports events have been canceled or postponed. The 2020 Summer Olympics in Tokyo were rescheduled to 2021. Spectators have no games to watch and players no games to play. Only a few countries, such as Turkmenistan Belarus and Nicaragua, have continued professional sporting matches as planned.',\n",
       " 'SOCCER',\n",
       " 'For an overview of the state of play in Europe’s soccer leagues amid the coronavirus outbreak click here:',\n",
       " '* Major League Soccer players returned to voluntary training on May 6.',\n",
       " '* The 2020 K-League season kicked off on May 8 behind closed doors.',\n",
       " '* Euro 2020 and Copa America were postponed. The two tournaments will now be staged from June 11 to July 11, 2021.',\n",
       " '* The Euro 2021 Women’s Championship has been pushed back to July 6-31, 2022.',\n",
       " '* Asian Champions League: The start of the knockout rounds was moved back to September.',\n",
       " '* The Chinese Football Association (CFA) has drawn up three plans to complete the 2020 Chinese Super League (CSL) season, one of which would see the campaign begin in late June and finish in December.',\n",
       " '* The women’s Bundesliga season will resume from May 29.',\n",
       " '* The Portuguese league approved nine stadiums for the league’s restart.',\n",
       " '* Costa Rica became the first country in the Americas to restart their professional league.',\n",
       " '* The women’s Under-20 World Cup in Costa Rica and Panama, postponed from August-September, has been rescheduled for Jan. 20-Feb. 6, 2021.',\n",
       " '* The National Women’s Soccer League (NWSL) said clubs could begin small group training sessions from May 25. The league is aiming for a late June return with a single city month-long tournament.',\n",
       " 'OLYMPICS',\n",
       " '* The postponed Tokyo Olympic Games will now begin on July 23, 2021 and run until Aug. 8.',\n",
       " '* World Athletics has suspended Olympic qualification until December.',\n",
       " 'PARALYMPICS',\n",
       " 'The postponed Paralympic Games will run from Aug. 24-Sep. 5, 2021.',\n",
       " 'WORLD BEACH GAMES',\n",
       " 'The 2021 World Beach Games were moved to 2023.',\n",
       " 'WORLD GAMES',\n",
       " '* The 2021 World Games have been pushed back by a year to avoid clashing with the Olympics.',\n",
       " 'ATHLETICS',\n",
       " '* The World Athletics Championships scheduled for 2021 in Eugene, Oregon have been moved to the summer of 2022 because of the Olympic Games rescheduling.',\n",
       " '* The World Athletics Indoor Championships (Nanjing, March 13-15) were postponed to March 19-21, 2021.',\n",
       " '* Boston Marathon organisers have postponed the race from April 20 to Sept. 14.',\n",
       " '* The London Marathon which was due to take place on April 26 has been postponed to Oct. 4.',\n",
       " '* The Diamond League plans to hold three meetings in August in Monaco, Gateshead and Stockholm followed by September events in Lausanne, Brussels, Paris, Shanghai, and possibly Rome or Naples. Meetings in Eugene, Doha, and China have been scheduled for October.',\n",
       " '* World Athletics released its calendar for the international season beginning with a Continental Tour Gold event in Finland on Aug. 11 and ending with a Diamond League meeting in China.',\n",
       " '* This year’s Biathle/Triathle World Championships in Weiden have been moved to 2021.',\n",
       " '* The World Triathlon Series (WTS) event and Mixed Relay World Championships in Hamburg have been rescheduled for the weekend of Sept. 5-6.',\n",
       " '* The Ironman triathlon has been pushed back to Sept. 6 from its original June 21 start.',\n",
       " 'AUSTRALIAN RULES',\n",
       " '* The Australian Football League season will resume on June 11, with four clubs moving to the Gold Coast due to tighter COVID-19 restrictions in their home states.',\n",
       " 'BADMINTON',\n",
       " '* The Thomas and Uber Cup will be held from Oct. 3-11.',\n",
       " '* The 2021 World Championships will begin in late November instead of August to avoid clashing with the rescheduled Tokyo Olympics.',\n",
       " '* The BWF announced a new 2020 calendar with the World Tour set to return with the Taipei Open from Sept. 1-6.',\n",
       " 'BASEBALL',\n",
       " '* The South Korean league started on May 5 without fans.',\n",
       " '* Taiwan’s baseball season resumed in April behind closed doors. On May 9, fans were allowed in for the first time, with 1,000 spectators watching games in New Taipei and Taichung.',\n",
       " '* Major League Baseball team owners on May 11 agreed a plan to start playing in empty stadiums in early July.',\n",
       " '* Japan’s Nippon Professional Baseball (NPB) league will begin its 2020 season on June 19 with games played in empty stadiums.',\n",
       " 'BOXING',\n",
       " '* Dillian Whyte’s heavyweight fight against Alexander Povetkin has been rescheduled for July 4.',\n",
       " 'CANOEING',\n",
       " '* Canoe Slalom World Cups in France and Czech Republic have been tentatively rescheduled to October or November.',\n",
       " '* The Canoe Slalom World Cup Final and non-Olympic World Championships in Germany have been moved from September to October.',\n",
       " '* Canoe Polo World Championships in Rome have been pushed back until April 2021.',\n",
       " 'CRICKET',\n",
       " '* English cricket’s The Hundred, originally scheduled to begin on July 17, was pushed back to 2021.',\n",
       " 'CYCLING',\n",
       " '* Giro d’Italia will begin on Oct. 3, while the Spanish Vuelta will be held from Oct. 20.',\n",
       " '* Milan-Sanremo will be held on Aug. 8, Liege-Bastogne-Liege on Oct. 4, the Tour des Flandres on Oct. 18, Paris-Roubaix on Oct. 25 and the Tour of Lombardy on Oct. 31.',\n",
       " '* The Tour de France that was due to be held from June 27-July 19 has been postponed to Aug. 29-Sept 20.',\n",
       " '* The European Road Cycling Championships, scheduled for Sept. 9-13, have been postponed by a year.',\n",
       " 'GOLF',\n",
       " '* Tiger Woods and Peyton Manning defeated Phil Mickelson and Tom Brady in a charity golf match in Florida on May 24 at Medalist Golf Club in Hobe Sound, Florida.',\n",
       " '* The Masters at Augusta National Golf Club has been rescheduled for Nov. 12-15 from April 9-12.',\n",
       " '* The PGA Championships at TPC Harding Park San Francisco, has been rescheduled for Aug. 6-9 from May 14-17.',\n",
       " '* The U.S. Open at Winged Foot Golf Club, Mamaroneck, New York, was rescheduled to Sept. 17-20 from June 8-21.',\n",
       " '* The Ladies Professional Golf Association (LPGA) is hoping to get the 2020 season underway with the Dow Great Lakes Bay Invitational from July 15-18.',\n",
       " '* The Women’s PGA Championship has been postponed from late June to Oct. 8-11.',\n",
       " '* The Australian PGA Championship will take place at the Royal Queensland Golf Club from Dec. 3-6.',\n",
       " '* The first major of the 2020 golf season got underway on May 14 when South Korea hosted the Korea Ladies Professional Golf Association (KLPGA) Championship. Park Hyun-kyung won the title.',\n",
       " '* World number one Ko Jin-young will take on No. 3 Park Sung-hyun in a charity skins match on May 24 at the Sky 72 Golf & Resort in Incheon.',\n",
       " 'HORSE RACING',\n",
       " '* Racing in France began without spectators at ParisLongchamp on May 11.',\n",
       " '* Horse racing resumed in Germany on May 7 with a limited number of races in front of empty stands in Hanover. Races were also scheduled for May 8 in Cologne.',\n",
       " '* The Kentucky Derby, the first jewel in North American horse racing’s Triple Crown (May 2) was postponed to Sept. 5.',\n",
       " '* Churchill Downs, the home of the Kentucky Derby, opened for spectator-free racing on May 16.',\n",
       " '* The British Horseracing Authority (BHA) has said it is planning to resume the season on June 1.',\n",
       " '* Horse racing will be allowed to resume in Ireland without spectators on June 8.',\n",
       " '* The shortened Belmont Stakes will be run on June 20 without spectators.',\n",
       " 'MOTOR SPORTS',\n",
       " '* The NASCAR season resumed with races at the Darlington Raceway in South Carolina on May 17 and May 20.',\n",
       " '* The Le Mans 24 hours race was postponed from June 13-14 to Sept. 19-20.',\n",
       " '* The Indianapolis 500 has been postponed until Aug. 23.',\n",
       " '* MotoGP intends to start its season with races on July 19 and 26 at the Jerez circuit in southern Spain.',\n",
       " '* IndyCar will open its delayed season on June 6 with the Genesys 300 at Texas Motor Speedway (TMS) without fans in attendance. The race at St. Petersburg, Florida scheduled for March 15 has been pushed back to Oct. 25.',\n",
       " '* Formula One hopes to start the delayed season in Austria in July without spectators before ending in Abu Dhabi in December. Silverstone have agreed terms for two races without spectators at the circuit this season.',\n",
       " 'NBA',\n",
       " 'The NBA is in talks with The Walt Disney Company about restarting its suspended season at Disney World in Florida in late July.',\n",
       " 'NFL',\n",
       " '* The NFL season will begin on Sept. 10 with a game between Super Bowl champions Kansas City Chiefs and Houston Texans.',\n",
       " 'NHL',\n",
       " 'The National Hockey League has scrapped plans to play regular-season games in the Czech Republic and Finland this year.',\n",
       " 'The NHL suspended play in mid-March, but hopes to reopen training facilities in June. The league on May 24 released a set of safety protocols that allow players to return to clubs for small-group workouts.',\n",
       " 'RUGBY',\n",
       " '* Australia’s National Rugby League is set for a May 28 restart after players agreed to 20% pay-cuts for the abridged 2020 season.',\n",
       " '* Rugby Australia hopes to get players back in training in June for matches in July.',\n",
       " '* New Zealand’s five Super Rugby teams will play each other in a 10-week domestic competition from June 13.',\n",
       " '* The Mitre 10 Cup, New Zealand’s annual provincial competition, will start with a full 14-team championship from Sept. 11.',\n",
       " '* Rugby Australia are looking at potentially including both the Western Force and Japan’s Sunwolves in a competition with their four Super Rugby sides to start in early July.',\n",
       " 'SNOOKER',\n",
       " '* The World Snooker Championship, originally scheduled to begin on April 18, will start on July 31 at the Crucible Theatre in Sheffield.',\n",
       " '* Snooker will resume in the United Kingdom on June 1 with the Championship League event which will be held without fans at the Marshall Arena in Milton Keynes.',\n",
       " 'SWIMMING',\n",
       " '* The 2020 European Aquatics Championships scheduled to take place from May 11-24 in Budapest, Hungary, have been postponed to next year.',\n",
       " '* The World Aquatics Championships, scheduled for July 16-Aug. 1, 2021, were pushed back to May 13-29, 2022.',\n",
       " '* The World Swimming Championships in Abu Dhabi, scheduled to take place in December, have been pushed back by a year.',\n",
       " 'TENNIS',\n",
       " '* The French Open was postponed until Sept. 20-Oct. 4.',\n",
       " '* The women’s Rogers Cup tournament in Montreal was postponed until 2021.',\n",
       " '* Professional tennis returned with the Tennis Point Exhibition Series event in Germany on May 1.',\n",
       " '* Hubert Hurkacz, Miomir Kecmanovic, Reilly Opelka and Tommy Paul took part in the UTR Pro Match Series in Florida that began on May 8.',\n",
       " '* Patrick Mouratoglou’s tennis academy in France will host a five-week series starting in May.',\n",
       " '* Bianca Andreescu and Sofia Kenin will be among 16 WTA players who will launch the Credit One Bank Invitational in Charleston on June 23.',\n",
       " '* Novak Djokovic is bringing together some of the world’s top tennis players for a series of matches to run from June 13-July 5 in the Balkan region.',\n",
       " '* New Zealand will stage a team-based tennis tournament for local-based men’s players from June 3.',\n",
       " '* World TeamTennis, an innovative mixed-gender professional tennis league, will start from July 5 at the Greenbrier, West Virginia, and up to 500 fans will be allowed to attend matches.',\n",
       " 'ULTIMATE FIGHTING CHAMPIONSHIP',\n",
       " '* UFC action returned with three cards on May 9, May 13 and May 16.',\n",
       " 'List of sports events that have either been cancelled or postponed due to the outbreak:',\n",
       " 'OLYMPIC TRIALS',\n",
       " '* U.S. trials for wrestling (April 4-5) were postponed.',\n",
       " '* U.S. Rowing postponed its team trials.',\n",
       " '* U.S. diving trials (April 3-5) were postponed.',\n",
       " 'NORTH AMERICA',\n",
       " '* The MLB has further delayed its 2020 season’s opening day of March 26.',\n",
       " '* The Women’s National Basketball Association postponed the start of its 2020 regular season, originally scheduled to run from May 15-Sept. 20.',\n",
       " '* The 2019-20 American Hockey League (AHL) regular season and the 2020 Calder Cup Playoffs were cancelled. The AHL standings at the time of suspension will be used to determine league awards.',\n",
       " 'SOCCER',\n",
       " '* FIFA has agreed to delay the first edition of its revamped Club World Cup due to be held in 2021.',\n",
       " '* UEFA put all club and national team competitions for men and women on hold until further notice.',\n",
       " '* The men’s and women’s Champions League finals and Europa League final originally scheduled for May have been postponed.',\n",
       " '* South America’s two biggest club competitions, the Copa Libertadores and Copa Sudamericana, are suspended.',\n",
       " '* CONCACAF suspended all competitions, including the Champions League and men’s Olympic qualifiers.',\n",
       " '* Asian and South American qualifying matches for 2022 World Cup were postponed.',\n",
       " '* Japan’s J.League will not hold any games in May.',\n",
       " '* Barcelona’s women’s team were declared champions of Spain’s Liga Iberdrola after the national soccer federation’s executive committee agreed to end all non-professional competitions.',\n",
       " '* The Asian Football Confederation on April 14 postponed all matches and competitions scheduled for May-June until further notice.',\n",
       " '* Semi-finals of the CAF Champions league (May 1-3) and CAF Confederation Cup (May 8-10) were postponed.',\n",
       " '* This year’s International Champions Cup, a pre-season tournament featuring Europe’s top clubs, was cancelled.',\n",
       " '* Cameroon cancelled the rest of its league season and declared leaders PWD Bamenda as champions.',\n",
       " '* Wales’ top flight league was called off and Connah’s Quay Nomads were crowned champions.',\n",
       " '* Mexico cancelled the remainder of its men’s and women’s seasons. No champions will be crowned.',\n",
       " '* England’s Women’s Super League and second-tier Women’s Championship seasons were cancelled on May 25.',\n",
       " 'ATHLETICS',\n",
       " '* The Diamond League, the elite track and field competition, was forced to cancel its London meeting scheduled for July 4-5. It had previously postponed events in seven cities scheduled between April and June.',\n",
       " '* The Paris and Barcelona marathons were postponed.',\n",
       " '* The 2020 European Athletics Championship due to take place from Aug. 25-30 were cancelled.',\n",
       " 'BADMINTON',\n",
       " '* The Badminton World Federation (BWF) cancelled the last five tournaments in the qualification period for the Olympics.',\n",
       " '* The Indonesia Open (June 16-21) was among a host of events that have been cancelled while tournaments over the next three months were also suspended in Australia, Thailand and Russia.',\n",
       " '* The U.S. Open, set to be held from June 23-28 in California, was suspended.',\n",
       " 'BASEBALL',\n",
       " '* The final qualification tournament in Taiwan for the Olympics was put back from April to June 17-21, while the March 22-26 qualification event in Arizona was postponed.',\n",
       " 'BASKETBALL',\n",
       " '* The International Basketball Federation postponed the men’s Olympic qualifiers, European Championship and the Americas Championship by a year.',\n",
       " '* Turkey cancelled its basketball season on May 11.',\n",
       " '* Europe’s top two club basketball competitions, EuroLeague and EuroCup, have been terminated without naming any winners.',\n",
       " 'BOXING',\n",
       " '* Anthony Joshua’s world heavyweight title defence against Bulgarian Kubrat Pulev at Tottenham Hotspur’s stadium on June 20 was postponed.',\n",
       " 'CRICKET',\n",
       " '* The Indian Premier League, originally suspended until April 15, has been postponed indefinitely.',\n",
       " '* The last two games of Australia’s three-match one-day international series against New Zealand in Sydney and Hobart were cancelled while the limited-overs tours were postponed.',\n",
       " '* The boards of India and South Africa agreed to reschedule a three-match ODI series to a later date.',\n",
       " '* England’s test series against Sri Lanka and West Indies were postponed. The England and Wales Cricket Board extended the suspension of the professional game in the country until July 1.',\n",
       " '* South Africa’s limited-overs tour of Sri Lanka that was scheduled to take place in June has been postponed.',\n",
       " '* Australia’s proposed test tour of Bangladesh in June has been postponed.',\n",
       " '* Ireland’s home series against New Zealand and Pakistan scheduled for June and July have been postponed.',\n",
       " 'CURLING',\n",
       " '* Men’s and women’s world championships in Scotland and Canada respectively were cancelled.',\n",
       " '* World mixed doubles and senior championships in Canada, scheduled from April 18-25 were cancelled.',\n",
       " 'CYCLING',\n",
       " '* The final two stages of the UAE Tour were cancelled after two Italian participants tested positive.',\n",
       " '* The Paris-Nice cycling race ended a day early after the eighth stage into Nice was cancelled.',\n",
       " '* The Women’s Tour, scheduled to take place from June 8-13 was cancelled.',\n",
       " '* This year’s Tour of Britain scheduled for September has been cancelled.',\n",
       " 'GOLF',\n",
       " '* The British Open Championship was cancelled.',\n",
       " '* The European Tour cancelled the BMW International Open (June 25-28) and the Open de France (July 2-5). The Scottish Open (July 9-12) was postponed. The Tour had postponed or cancelled events scheduled between March and May.',\n",
       " '* The LPGA cancelled Tour qualifying “Q-schools” this year as well as the Meijer LPGA Classic in Michigan.',\n",
       " 'HANDBALL',\n",
       " '* The German handball season was cancelled after top clubs voted in favour of abandoning the campaign.',\n",
       " '* The men’s and women’s EHF Cup and Challenge Cup were cancelled.',\n",
       " '* The remaining women’s Euro 2020 qualifiers as well as European playoff matches for the 2021 men’s world championship were cancelled.',\n",
       " 'HORSE RACING',\n",
       " '* The Grand National festival (April 2-4) was cancelled.',\n",
       " '* The Dubai World Cup, one of the world’s richest horse races and a premier annual sporting event in the United Arab Emirates, will not go ahead this year.',\n",
       " '* The Guineas Festival at Newmarket in May and June’s Epsom Derby have been postponed while June’s Royal Ascot may be held without spectators.',\n",
       " '* This year’s Shergar Cup, due to take place on Aug. 8, has been cancelled.',\n",
       " 'MOTOR SPORTS',\n",
       " '* NASCAR postponed events at Kansas Speedway May 30-31, Michigan International Speedway June 5-7, the NASCAR Xfinity Series race at Mid-Ohio May 30, and the Gander Trucks Series race at Texas Motor Speedway, previously scheduled for June 5.',\n",
       " '* The Bretagne World Rallycross at Loheac, scheduled to take place on Sept. 5-6, has been cancelled.',\n",
       " '* This year’s Silverstone Classic, scheduled for July 31-Aug. 2, has been cancelled.',\n",
       " 'NETBALL',\n",
       " '* Netball Superleague fixtures were postponed until at least May 31.',\n",
       " 'ROWING',\n",
       " '* The 2020 US Rowing National Championships scheduled for July and the 2020 US Rowing Masters National Championships scheduled for August have been cancelled.',\n",
       " '* British Rowing extended the suspension of all its events to July 31. The British Rowing Offshore Championships & Beach Sprints and British Rowing Junior Championships have been cancelled.',\n",
       " 'RUGBY',\n",
       " '* Four Six Nations matches were postponed.',\n",
       " '* France’s rugby federation suspended all its competitions and will not be allowed to return until September.',\n",
       " '* The European rugby season was suspended after European Professional Club Rugby postponed Champions Cup and Challenge Cup quarter-final matches (April 3-5).',\n",
       " '* The semi-final and final of this season’s Champions Cup and Challenge Cup tournaments, which were due to take place in Marseille in May, have been postponed.',\n",
       " '* England’s Rugby Football Union and Wales’ governing body confirmed the end of the 2019-20 season for all league, cup and county rugby, but the English Premiership has been excluded.',\n",
       " '* Super Rugby suspended its season.',\n",
       " '* World Rugby has postponed all test matches scheduled for July.',\n",
       " '* This year’s Rugby League Challenge Cup final, scheduled for July 18 at Wembley Stadium, has been postponed.',\n",
       " 'SURFING',\n",
       " '* The World Surfing League extended the postponement of events through June while also announcing a major overhaul for future tours, with details on a post-season surf-off to be announced in July.',\n",
       " 'TABLE TENNIS',\n",
       " '* The International Table Tennis Federation (ITTF) scrapped all table tennis competitions until the end of July.',\n",
       " 'TENNIS',\n",
       " '* The Wimbledon championships were cancelled for the first time since World War Two.',\n",
       " '* The Fed Cup finals (Budapest; April 14-19) were postponed.',\n",
       " '* The Sept. 25-27 Laver Cup was cancelled to avoid a clash with the re-scheduled French Open.',\n",
       " '* ATP events in Hamburg, Bastad, Newport, Los Cabos, Gstaad, Umag, Atlanta and Kitzbuhel will not go ahead as scheduled while WTA events in Bastad, Lausanne, Bucharest and Jurmala scheduled for July will not be held.',\n",
       " 'VOLLEYBALL',\n",
       " '* The international volleyball federation (FIVB) cancelled this year’s Volleyball Nations League, which was scheduled to begin on May 19 for the women’s competition and May 22 for the men’s event.',\n",
       " '* Turkey cancelled its volleyball season on May 11.',\n",
       " 'WINTER SPORTS',\n",
       " '* The International Ski Federation cancelled the final races of the men’s Alpine skiing World Cup.',\n",
       " '* The World Cup finals in Cortina were cancelled along with the last three women’s races in Are.',\n",
       " '* The women’s world ice hockey championships in Canada were cancelled.',\n",
       " '* The Ice Hockey World Championship scheduled for Switzerland in May was cancelled.',\n",
       " '* The speed skating world championships in Seoul were postponed until at least October.',\n",
       " '* The March 16-22 world figure skating championships in Montreal were cancelled.',\n",
       " '* The Kontinental Hockey League (KHL) has cancelled the remainder of its season after temporarily suspending its playoffs.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e139a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 248 sentences in the string.\n",
      "The number of words in the string is: 3514\n",
      "The number of characters in the string is: 17679\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 15:26:59] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 15:27:04] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:238]))\n",
    "URL_ID_88 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_88.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_88.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_88.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_88 = re.sub(re_punt, \"\",URL_ID_88)\n",
    "\n",
    "file = open(\"88.txt\", \"w\")\n",
    "file.write(URL_ID_88)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"88.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36ac4211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3345\n",
      "WORD COUNT 2227\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/88.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "53bcee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 14.169354838709678\n",
      "560\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.25145936237090255\n",
      "FOG INDEX: 5.768325680432232\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 14.169354838709678\n",
      "COMPLEX WORD COUNT: 560\n",
      "WORD COUNT: 2227\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "95c6413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 6010\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 7\n",
      "Total count: 7\n",
      "PERSONAL PRONOUNS: 7\n",
      "AVG WORD LENGTH: 5.031018782014798\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_88.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc731f",
   "metadata": {},
   "source": [
    "# 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "364b0c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\2519834591.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "754410f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The COVID 19 pandemic has reshaped the fundamental fabric of our world. Initiating in China in late December 2019, the virus has since then spread to every corner of the world, infecting millions in its wake. Countries around the world have responded by shutting down their economies and advocating lockdowns of varying degrees. India has arguably had one of the most stringent lockdowns of all countries, restricting the movement of people, goods and effectively transforming every city into a ghost town.',\n",
       " 'Due to such stringent restrictions on movement, the economy has received a fatal blow. The virus arrived in India at a time when the country was already in strife, dealing with a slowing GDP growth rate and an ever-increasing fiscal deficit. The lockdown has simply exacerbated the economic predicament; pushing multiple businesses and industries to a moribund state. Other countries have also faced a similar predicament, particularly in the US and Europe, both being hotspots for virus transmission.',\n",
       " 'However, upon taking a closer look at the global economy, there seems to have been an upward mobilization in some of the sectors in the IT domain. These sectors seem to have exorbitantly increased their scale of operations and have overall reaped hefty profits. So what is it that differentiates these areas from the rest and what can we learn from them?',\n",
       " 'If we look at the evolving IT/ITeS industry around the world, the domains that have flourished in this strenuous time all have had one key characteristic in common; flexibility. These sectors have adopted a more flexible approach to dealing with the lockdown. Be it flexible working procedures or adopting newer, more advanced ways of working in line with the requirements of our time, they haven’t shied away from changing the rules of the game. Let’s look at some of these areas within the tech domain that have been successful in conquering the lockdown.',\n",
       " 'Lockdowns around the globe have confined people inside their homes, with nothing much to do of significance. As a result, social networking sites have reported a gigantic rise in user engagement over the lockdown period. Reportedly, there has been close to a 50% rise in daily text transmissions across messaging platforms such as Facebook, Instagram, and WhatsApp in the hardest-hit economies. Twitter has reported a 23% increase in its user base as compared to last year. The data makes it evident that social media platforms are here to reap the benefits of a lockdown situation.',\n",
       " 'Video consumption sites such as YouTube, Instagram, and TikTok are in line to reap massive profits. It’s no wonder that viewership on these platforms has increased manifolds due to lockdowns. These platforms serve to be a distraction from the tragedies of the real world in such stressing times and offer an easy escape. Be it rumors regarding the cure for COVID 19, gossips, or rap battles; these platforms provide viewers with their much-needed dose of distractions. As they say, “ignorance is bliss”.',\n",
       " 'The lockdown has proven to be a miracle for data-mining companies. With such an exorbitant increase in the number of hours spent online globally, these firms now have access to significantly larger sets of data than they otherwise could ever have. Widespread implementation of data-mining has been seen recently with most countries opting for Government-regulated surveillance applications that monitor your movement at all times. Moreover, these applications have access to your personal information as well as medical records. Countries such as South Korea and Singapore are at the helm of relying on such means to control the outbreak.',\n",
       " 'Although noble, such initiatives do raise a red flag with regards to user privacy. The public has been provided with very little information about how these applications operate and what goes on behind the scenes. This creates an atmosphere of obscurity that is frankly harmful to the premise of a democracy.',\n",
       " 'Cloud Computing',\n",
       " 'Cloud computing has been on the rise for the last couple of years. However, the pandemic has made it the de facto king in terms of computational services. With an increasing reliance on remote working, the ability to store data in one secure location has turned out to be critical.',\n",
       " 'The cloud computing services such as Amazon Web Services, Microsoft Azure, and Google Cloud have reaped hefty profits in the process. The emerging landscape in the tech world seems to suggest an upward trend in reliability on these services as far as large scale data storage and computing is concerned.',\n",
       " 'Social distancing measures have made it practically impossible for people to physically go shopping for groceries and other necessities. Moreover, a majority of retail outlets in cities have reported negligible engagement, for the fear of transmission of the virus. E-commerce sites have been the real winners in this predicament of global consumerism.',\n",
       " 'With high standards of hygiene and at-home delivery, these sites have provided an easy alternative to retail stores. Other similar businesses include food delivery apps and grocery sites that are also flourishing today amidst the pandemic. Recent weeks have made it evident that E-commerce websites are well on their way to abolish traditional shopping methods.',\n",
       " 'Online streaming platforms consist of a relatively newer approach to entertainment; having only been in existence for the past couple of years. They had already, however, established a name for themselves before the lockdowns. Sites such as Netflix and Amazon Prime had been dominating a chunk of the market share and competing heavily with movie theatres for new releases, for a while now. Now with the lockdown practically deleting theatres and cable TV from the collective psyche of the entertainment industry, they are well on their way to becoming the platform of choice as far as entertainment for the masses is concerned.',\n",
       " 'This has already become evident, with Zee5 India reporting a whopping 80% increase in subscriptions and a 50% increase in the time spent on their site, within the first couple of weeks of the lockdown itself. Another such platform MUBI reported a 28% rise in its viewership in India only a week after lockdown commenced. These facts are a clear indication of the exponential growth that is in store for these platforms, which is unlikely to change anytime soon.',\n",
       " 'The idea of working from home is all set to be the new norm in our professional culture, which requires an easy and effective way to communicate over the internet. Not just audio or text, but video conferencing is the need today. Hence it’s understandable why multiple video conferencing services are set to reap massive profits off of the new norm.',\n",
       " 'Arguably the most popular of these, Zoom has reported a 130% increase in its price share since the beginning of 2020. Another such platform known as the Microsoft Teams collaboration suite, operated by Microsoft, has reported a whopping 12 million increase in its user base in the very first week of the lockdown in the US. This data is only likely to have an upwards trajectory considering the increasing pace at which industries are going online.',\n",
       " 'The Indian Picture',\n",
       " 'The Indian IT landscape has also undergone massive cultural changes. According to Rajesh Gopinathan, chief executive officer and managing director of Tata Consultancy Services Ltd., the “work from home” model of operations is here to stay. He also claimed that the firms only requires a 25% workforce to be physically present for any project at any of the locations.',\n",
       " 'Tata Consultancy Services which is one of the major players in the Indian IT landscape has shifted almost 90% of its workforce into a remote borderless workspace model, and other smaller firms have followed suit. What it tells us is that we’re headed in a direction we’re unlikely to return from. Remote working appears to be the modern protocol for operations and is unlikely to change anytime soon.',\n",
       " 'However, a major challenge often overlooked in such circumstances is that of an adaptable culture. The culture of workspaces has to be drastically altered and members of the workforce have to dive headfirst into the new way of doing business. This is critical to ensure that the industry can combat the pandemic and recover gloriously.',\n",
       " 'The lockdown has presented us with a stark contrast unlike any other we’ve witnessed. Where on the one hand, the industries mentioned above seem to be exhibiting exponential growth with their people thriving and having every possible resource at their disposal, the unorganized sector and the MSMEs (Micro, Small and Medium Enterprises) seem to be at the crux of death.',\n",
       " 'The sector that consists of people for whom having guidelines to work from home is irrelevant as that was never really an option; people with no fixed wages or social security to fall back on during this time of crisis. As a result of the lockdown, several of these MSMEs have effectively become inoperable and have resorted to massive layoffs just to survive. This has resulted in thousands of workers losing their jobs with nowhere to go to for refuge. A chunk of these people includes migrant workers who have lost their jobs and are left with little to no avenue to feed themselves. Not receiving significant support from the government, these people have been initiating treks back to their villages. What is witnessed is a massive influx of migrant workers flooding the highways, walking weeks to find shelter and food. Truck drivers responsible for delivering goods have also resigned stating that they have no means to eat because of the closure of every food joint on the highways. Both these realities present a stark contrast and expose a deep crack in our societal framework. One I reckon won’t heal anytime soon.',\n",
       " 'The COVID 19 pandemic has restructured our social fabric in a way that is unlikely to change anytime soon. The areas that we’ve discussed are likely to become the flagbearers of the digital revolution of the decade. An upward mobilization with regards to massive scale movement of industries online seems pertinent today being led by these domains in the IT industry. An unfortunate consequence of it is that a majority of the MSMEs may soon cease to exist, having been replaced by some of the other alternatives that we’ve discussed. It seems to be a never-ending circle where the ones who are making a profit out of this situation will continue to do so, while the others will be washed out from our collective memory.']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "02198116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 sentences in the string.\n",
      "The number of words in the string is: 1755\n",
      "The number of characters in the string is: 8932\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 15:33:08] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 15:33:13] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:40]))\n",
    "URL_ID_89 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_89.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_89.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_89.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_89 = re.sub(re_punt, \"\",URL_ID_89)\n",
    "\n",
    "file = open(\"89.txt\", \"w\")\n",
    "file.write(URL_ID_89)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"89.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7c8da139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755\n",
      "WORD COUNT 1115\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/89.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1fe680bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 21.14457831325301\n",
      "381\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3417040358744395\n",
      "FOG INDEX: 8.594512939650981\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 21.14457831325301\n",
      "COMPLEX WORD COUNT: 381\n",
      "WORD COUNT: 1115\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c0f16c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3262\n",
      "i: 1\n",
      "we: 2\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 4\n",
      "Total count: 7\n",
      "PERSONAL PRONOUNS: 7\n",
      "AVG WORD LENGTH: 5.08945868945869\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_89.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ae546",
   "metadata": {},
   "source": [
    "# 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee6dc16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\1170867179.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "16ac1e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A video game is any software program that can be played on a computing device, such as a personal computer, gaming console, or mobile device. Video games have been in existence since the early 1970s and have become increasingly popular, spanning different mobile (smartphones, tablets) and stationary (computer or console) platforms. Advances, particularly in mobile devices, have given birth to social networks and group gaming',\n",
       " 'Although the nature of gaming does not require physical stamina and therefore is not limited by factors such as age, gender, or fitness, it is most popular with adolescents. In 2018, the World Health Organization (WHO) classified gaming disorder in their International Classification of Diseases (ICD-11). The ICD-11 is a list of diseases and medical conditions that aids health professionals in making diagnoses and treatment plans for patients having various disorders. It should be noted that, the inclusion of gaming disorder in the ICD-11 by WHO has generated vigorous and sometimes contentious debate and discussion within the medical and mental health community. Although recognized as an area of clinical interest, the Diagnostic and Statistical Manual of Mental Disorders (DSM-5) published by the American Psychiatric Association suggests that more clinical research is required before Gaming Disorder is formally considered as a psychiatric disorder. Similarly, the WHO notes the inclusion of gaming disorder in ICD-11, to encourage more research into excessive gaming behavior, including its prevention and treatment.',\n",
       " 'What is Online gaming disorder?',\n",
       " '2018 WHO draft 11th Revision of the ICD-11 denotes the disorder as a pattern of “digital-gaming” or “video-gaming” behavior characterized by impaired control over gaming activity, increasing priority given to gaming over other activities to the extent that gaming takes precedence over other interests and daily activities, and the continuation or escalation of gaming despite the occurrence of negative consequences.',\n",
       " 'Online Gaming disorder has the same similarities with Internet gaming disorder (IGD), which is a condition that the American Psychiatric Association (APA) noted in DSM-5 as an area in need of additional study. The APA does not currently recognize IGD as an official condition. For gaming disorder to be diagnosed, the WHO criteria require that the behavioral pattern of the gamer must be of sufficient severity that major and noticeable impairment and deterioration in personal, family, social, educational, occupational or other important areas of functioning is present for a minimum of 12 months.',\n",
       " 'According to the WHO definition, a person with online gaming disorder will demonstrate the following characteristics for at least 12 months; problems controlling control their gaming habits, seeing gaming as more important over other necessities and daily activities or work, continuing to engage in gaming even after its negative health and social problems has been identified or are evident. Further research shows that gaming disorders can also be linked to anxiety, depression, obesity, sleeping disorders, and stress. People who remain physically inactive for long periods because of gaming may also be at higher risk of obesity, sleep disorders, and other health-related issues, according to WHO [1].',\n",
       " 'Video game-related health problems can cause continuous strain injuries, skin disorders, and other health issues. Other problems according to Shoja et al. (2007), include a condition that could be termed video game-provoked seizures in patients with pre-existing epilepsy. The following health consequences of video gaming have been reported.',\n",
       " 'Video game playing is associated with eye problems. Extensive and fixed staring at a video game screen causes eyestrain because the cornea, pupil, and iris are not biologically equipped for chronic heavy viewing of digital images from electronic devices. The visual system strain from frequent video game use over extended periods may result in headaches, dizziness, and in some cases, nausea and vomiting. Interestingly, there is some research that shows that gamers have an enhancement of spatial distribution of attention, compared with non-gamers. This somewhat predictable practice effect occurs with both peripheral and central visual attention. For sufferers of amblyopia (dimness or blurring of the eyesight due to a fault in transmission from the eye to the brain) video games may be helpful.',\n",
       " 'Persistent gamers may also suffer from musculoskeletal problems. A survey of children indicated increased physical complaints associated with video game playing. Such complaints range from pain in the hands and wrists to back and neck. Furthermore, a case report involving a nine-year-old teenager referenced Playstation thumb. Playstation thumb is, characterized by numbness and a blister is caused by friction between the thumb and the controller from rapid and persistent gameplay. Using dermoscopy, dermatologists discovered hemorrhages and onycholysis (the loosening or separation of a fingernail) in a patient who presented with hyperkeratosis. Also, tendon injuries (tendinosis) of the hands and wrists from tendon overuse, is another health problem associated with video game playing. Furthermore, another case report in the New England Journal of Medicine reported a fracture of the base of the fifth metatarsal from people who play Wii video games. This condition has been termed (perhaps sarcastically), a Wii fracture. There are also postural problems associated with the persistent playing of video games, although, ergonomic measures (including chair to monitor position) could potentially improve postural problems associated with video game playing.',\n",
       " 'Playing video games consistently has been associated with obesity. This is maybe related to the lack of physical activity in players. Alternatively, it could be that those who are less physically fit because of obesity gravitate towards less physically demanding activities, such as gaming. In either case, several studies have linked television and video games and increased Body Mass Index (BMI). It has been estimated that children in the United States spend 25% of their waking hours watching either television or playing video games. Furthermore, children who watch the most hours of television or play video games have the highest incidence of obesity. If video games are replacing physical activities and young people do not participate in physical recreation or see playing of video games as a form of recreation, this may be part of the link between times spent while playing video games and a rise in BMI in teenagers. Evidence for this potential link gains some support from a German study reporting that boys who spend no more than 1.5 hours per day engaged in television watching or playing video games, were 75.4% less likely to be overweight than those who spend more than 1.5 hours engaged in the same activity.',\n",
       " 'In a 2011 study, an association between video game activity and an increase of (mostly junk) food intake was reported. Specifically, single video game sessions caused an increase in food intake, regardless of appetite. It has also been suggested that active video game play using two popular gaming platforms has the opposite effect. Other researchers found no evidence that more active video games would result in a beneficial outcome although the study did demonstrate an increase in the amount of physical activity within the children receiving the active video games.',\n",
       " 'Health concerns that video games may cause epileptic seizures started in the early 1980s. The first medically documented case of a video game-induced seizure was reported in 1981. In 1993, a story in the popular press (Sun newspaper) reported that a boy choked to death on his own vomit during a seizure triggered by playing a video game. Similar but less serious incidents were subsequently reported by news media around the world, ultimately motivating video game console manufacturers to include that epilepsy warnings in the instruction manuals for their gaming products. In 1994 it was reported that video games only cause seizures in people already predisposed to epilepsy and advised that people with a predisposition to epilepsy can greatly reduce the risk of a seizure by staying 10 feet or more away from the TV set and wearing sunglasses while playing video games. This is clearly an area in need of additional research.',\n",
       " 'The cost: benefit value of prevention versus treatment of addiction disorders has been known for many years. It is important and beneficial to make use of several types of strategies in combating gaming addictiveness or disorder. Effective strategies include: educating gamers about gaming behaviors and consequences on their mental health; treatment geared towards helping the gamer to control his/her urge for video games, recognizing and dealing with disturbing thoughts and learning how to cope without video games; intrapersonal and interpersonal counseling to help gamers to explore their identity, build self-esteem, and enhance their emotional intelligence outside the fictional world of gaming and learning communication and assertiveness skills needed in social interactions; family involvement, including counseling and discussion family and other relationships; and developing new lifestyles. The latter is particularly important and to paraphrase the well-known mantra of Alcoholics Anonymous, it’s all about, people, places, and things. To prevent the persistent playing of video games, people need to explore new activities, set new goals and metrics of achievements beyond video game scores.']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fce58d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 62 sentences in the string.\n",
      "The number of words in the string is: 1499\n",
      "The number of characters in the string is: 8434\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 15:39:43] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 15:39:49] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:29]))\n",
    "URL_ID_90 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_90.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_90.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_90.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_90 = re.sub(re_punt, \"\",URL_ID_90)\n",
    "\n",
    "file = open(\"90.txt\", \"w\")\n",
    "file.write(URL_ID_90)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"90.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7999bd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499\n",
      "WORD COUNT 1001\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/90.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6f76dd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 24.177419354838708\n",
      "412\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.4115884115884116\n",
      "FOG INDEX: 9.835603106570849\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 24.177419354838708\n",
      "COMPLEX WORD COUNT: 412\n",
      "WORD COUNT: 1001\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33cfe516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3103\n",
      "I: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 0\n",
      "PERSONAL PRONOUNS: 0\n",
      "AVG WORD LENGTH: 5.626417611741161\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_90.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc72c28a",
   "metadata": {},
   "source": [
    "# 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3f9b46d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\241253929.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/human-rights-outlook/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "194a3825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Read on to discover what our robot, Athena, has found on the future of this topic and act accordingly for you, your family, and organization in the years ahead. Make notes on issues that could affect you and them as you go.',\n",
       " 'If you are new to foresight, we recommend you view this slide presentation first to get the best out of this report',\n",
       " 'Speed read Athena’s high-level take-outs on the left of each slide, or delve deeper into her findings on the right.',\n",
       " 'For a more detailed explanation of the graphics used in this presentation please click here. All outlooks based on the time period 2020-2070 and what’s likely to be happening in 2025 at a 95% confidence level unless otherwise stated. Please contact us for longer-term outlooks.',\n",
       " 'VIDEO SUMMARY',\n",
       " 'To read more and for a video summary, click here']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7fb65861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 sentences in the string.\n",
      "The number of words in the string is: 147\n",
      "The number of characters in the string is: 691\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 15:54:13] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 15:54:17] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:22]))\n",
    "URL_ID_91 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_91.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_91.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_91.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_91 = re.sub(re_punt, \"\",URL_ID_91)\n",
    "\n",
    "file = open(\"91.txt\", \"w\")\n",
    "file.write(URL_ID_91)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"91.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "70770f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "WORD COUNT 94\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/91.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "09b8daa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 21.0\n",
      "20\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.2127659574468085\n",
      "FOG INDEX: 8.485106382978724\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 21.0\n",
      "COMPLEX WORD COUNT: 20\n",
      "WORD COUNT: 94\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a36f817f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 254\n",
      "I: 0\n",
      "we: 1\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 2\n",
      "PERSONAL PRONOUNS: 2\n",
      "AVG WORD LENGTH: 4.700680272108843\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_91.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88505722",
   "metadata": {},
   "source": [
    "# 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0b980c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\3959709349.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "31fa9aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finding ways to make using the Internet easier is something most modern consumers are passionate about. Since the rise of AI-infused technology like Amazon’s Alexa or Apple’s Siri, voice search has grown increasingly popular. In fact, nearly 60 percent of people all over the world use voice search at least once a day.',\n",
       " 'As this technology grows more popular and complex with each passing day, business owners are starting to take notice of voice search. Capitalizing on this trend is only possible when optimizing the content on your website for voice search. Are you trying to make your website more voice search-friendly? If so, check out the following tips.',\n",
       " 'In the past, if you wanted relevant answers from a voice recognition technology, well—good luck with that. But today, machine learning systems can compete with people in terms of accuracy. Google’s voice recognition, Google is now able to understand human language with 95 percent accuracy. These improvements mean that, while you can trust good voice systems to match customers with the right products, services, or information with increasing degrees of nuance, leading businesses already have set customer expectations for delivery. Thanks to machine learning algorithms that can detect speech and respond with meaningful results.',\n",
       " 'Because voice search systems are at a point where they actually can perform reliably and meet customer expectations just as well (if not better) than traditional query options, customer trust in them is growing:',\n",
       " 'Yet, only 4% of businesses are properly optimized for voice search. What’s with the disconnect? In other words, business leaders are at an ideal intersection where reliable systems are available and there are still many customers who haven’t been reached or who might want more out of the systems they currently use. Bringing those systems and customers together will help companies avoid being left behind.',\n",
       " 'When people use voice search, they don’t just want to locate a great pair of shoes or a TV. People want all kinds of other information, such as your store hours, how to connect to support specialists, and when you’re having your next sale. This is partly why some experts have predicted a “totally different internet” within the next five to 10 years, one where voice-activated chatbots have all but replaced the e-commerce channels we’re used to using.',\n",
       " 'Shoppers are also after general tips that can take some of the friction out of everyday life—think life hacks and how-tos. In fact, words like “how,” “what,” “best,” and “easy” are among the top voice search queries. This means that when it comes to online marketing, you probably need to change your entire optimization approach, taking elements like grammar and semantics, the structure of your site, and structured data markup that influences Google’s ability to find your content. Of course, optimizing from the start, not as an afterthought, is ideal.',\n",
       " 'Voice Search can be used on both desktop and mobile searches. We can see that customers want different types of information from voice systems, they also can use it at many points in the customer journey. For example, about half of shoppers use voice to research products, even “near me” searches results are mostly done by customers. Customers also use voice to:',\n",
       " 'These statistics show you should think beyond just having customers find you or your products. Voice search and commands can take your buyers from start to finish, so give your customers as much convenience and satisfaction as possible by integrating voice options into more types of interactions.',\n",
       " 'A survey showed that, once a consumer makes a local voice search, their next most common action is to call the business (28%). Customers also are highly likely to visit company websites (27%), show up at the company’s location (19%), and do more research into that business or additional businesses (14% and 12%, respectively). So, in short, while voice services can allow a customer to complete many steps without human interaction, you shouldn’t see it as a total substitute. Many people are going to take further steps after the initial search, and they still will want to hear a human voice respond back once in a while. They are going to have more questions, and they’re willing to physically connect with you and what you offer. Don’t drop the ball in other areas, like making your site aesthetically pleasing and easy to navigate, having enough staff ready to chat, listing an accurate contact number, or keeping your store well-stocked. Voice search already is shifting the way customers engage with brands, but there’s still time for companies of any size to get involved with voice systems in ways that can benefit both the customer and the business’s bottom line. The next step is to find voice search solutions. However, as with other technologies, these are not necessarily one size fits all, meaning it’s critical to shop around and be specific about your goals. If you can customize and update your options in a scalable way, they’ll be even more effective for your business.']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "629bf393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42 sentences in the string.\n",
      "The number of words in the string is: 872\n",
      "The number of characters in the string is: 4441\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 16:01:16] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 16:01:21] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:26]))\n",
    "URL_ID_92 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_92.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_92.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_92.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_92 = re.sub(re_punt, \"\",URL_ID_92)\n",
    "\n",
    "file = open(\"92.txt\", \"w\")\n",
    "file.write(URL_ID_92)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"92.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "63524770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n",
      "WORD COUNT 549\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/92.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "897cac05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 20.761904761904763\n",
      "152\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.2768670309653916\n",
      "FOG INDEX: 8.415508717148063\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 20.761904761904763\n",
      "COMPLEX WORD COUNT: 152\n",
      "WORD COUNT: 549\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b744ce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1629\n",
      "I: 0\n",
      "we: 1\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 1\n",
      "PERSONAL PRONOUNS: 1\n",
      "AVG WORD LENGTH: 5.092889908256881\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_92.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b542f",
   "metadata": {},
   "source": [
    "# 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "32a36201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\815962096.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e8e8d2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The pandemic has shaken the world in the way one had hardly imagined. The impact of it on Jobs and Services is going to be long-lasting and it will be the foundation stone of revolution in these sectors. With the work from home and social distancing norms is altering the way of work, the way we interact, what work we will do, how the work will be done, and whatnot. To just give an example, in the middle of the first lockdown, FMCG major Hindustan Unilever (HUL) went ahead with its merger. It took place online entirely. Yes, it took place online. Who could have ever imagined the merger can take place online?',\n",
       " 'Change is inevitable. But some changes are temporary and some are permanent. The pandemic is bringing changes that are going to be permanent. In fact, these changes were due for a long time and we’re coming at a slow pace. What the pandemic has done is, it has become the catalyst for these changes and raised the ante for change. So, what exactly the changes will be? Let’s look at them one by one.',\n",
       " 'The first change is going to be the extensive use of digital communication from now onwards. The Zoom, Jio Meet, Google Meet, and some derivatives like these are going to be the forever meeting rooms where the important discussions will be held. This may be bad news for the employees who are older than 40 years. They would not have pictured themselves doing such transformation at this part of life. Experts believe that the new normal in the offices are going to be hierarchy-less. The older employees would have to work with the younger ones. There would be no geographical boundaries and where the communication and software adaptability among employees is going to be crucial. The symbol of power will be less visible and the decentralization of power in the office will be prominent. There will be more egalitarianism in companies. The corporates will think much more about office space. Rather than expending too much on physical infrastructure, the online infrastructure will always be in their hindsight. The impact would be more prudent in small and mid-sized businesses. The physical offices itself might disappear from such businesses. But it’s not going to be easy for companies. The security and confidentiality of the authentic information going out of the offices’ building are going to be the largest concern in the new normal world. There would be no surprise if a lot of start-ups will bloom in the near future providing software for security for the data and information of the companies. Also, travel is going to be reduced. So, the major component of CTC where the companies fooling the employees must find the other way.',\n",
       " 'The second change is going to be struck down on employees. Already many of the companies and start-ups are reducing the workforce. It is expected that new normal offices would work with an 80% workforce of that of the current workforce. Automation is on the verge. Due to safety reasons, the companies are going to be more and more leaned towards automation with a minimal touch of human possible. This might result in a loss of jobs in some sectors, but it will also create new jobs in the automation sector. It was evident from before pandemic too but now the velocity for the same would be increased. In the new normal tech-enabled world, the job which would be at stake dominantly would be managers’ managers. The IT firms have started firing the vice presidents and assistant vice presidents who draw hefty salaries but don’t really drive the business. In the designation-less set up in the near future accelerated by Pandemic, they automatically become redundant. For the first time, the employees might be given jobs that would require more than the standard jobs. Also, when the workforce in the company would be less in the company, the employees might be given the option of working for extra time or working on the weekends and would be incentivized for the same rather than employing more staff and paying them full salary. It is a win-win situation for both employees and companies. Employees can earn more than what they usually earn and will get to learn new which would be out of their primary domain. The companies would be able to keep their costs low through this. The assessment of employees might change too. Rather than going for an annual performance review, the employees might be evaluated based on the tasks they perform. Creativity and innovation are going to be swords for the employees in the new normal world rather than designations in the office.  ',\n",
       " 'The other change might be in the services sector. The services like which involves maximum human touch will be the one which will be affected most adversely. The safety concerns and confidence of people over the system are going to be the issue for at least the next few years. It also opens the opportunity for something very new. The products which could replace the need for visiting such services centers are going to create a boom in the market. According to McKinsey, the sales for such products are multiplying rapidly.',\n",
       " 'There are speculations that the economies will tend to become Minimalist economies. Let’s dig deep into this. Minimalist economies are the economies where people tend to refrain from purchasing luxurious items and focuses on purchasing necessities more and more.  Well, this is the position we are in right now during the pandemic. People are expensing only necessary items like groceries and the demand for luxurious items is way below average. But it would be hard to stay the same as this. The minimalist economy will result in the deterioration of the economy in the short term. It is true that in the minimalist economy the demand might be low, but it would be wrong to assume the demand will be zero. The high-quality products will gather the attention of the purchasers. It is evident from past experiences that the economy always finds its way to come back from the mode of minimalist economy. Though this time may take some time, it will surely return on track.',\n",
       " 'But every trouble comes with an opportunity. This is the time for the companies to act now and grab the opportunities the pandemic has brought with him. But for that companies are required to follow plans, formulate strategies to suit their needs, and pay more attention to the innovation. The companies must form plans for the five stages from here. These stages are 5Rs: Resolve, Resilience, Return, Reimagination, and Reform.',\n",
       " 'Resolve: In the resolve phase companies need to formulate a nerve center to combat Corvid itself. The tendency of the company should not be like that, they will return only after everything becomes normal. In most parts of the country, permission is granted to the companies for their operations. If they wait for normalcy, then bankruptcy might catch them before the normalcy.',\n",
       " 'Resilience: The resilience phase includes maintaining liquidity, addressing solvency, and grow for sustainability. All businesses should know when their cash crunch is coming. Addressing these cash crunches will be crucial for the companies. Businesses must take aggressive options to remain solvent. For example, the businesses might have cash in their hand but might be poor in operational efficiency then it requires the attention of the company. Organizations solving issues of liquidity and solvency will be in a better position to grow with sustainability.',\n",
       " 'Return: In the third phase of return the companies will have to plan for the time when everything will be back on track. Given the possibility of subsequent waves of coronavirus the companies need new ways of working to prevent, identify, report, and contain future flareups. Many industries will face this problem of returning. Staying prepared for resurgence scenarios should include a multi-scenario modeling exercise. Reverting to non-COVID-19 care will require extensive planning and market testing.',\n",
       " 'Reimagine: The phase of reimagining will include the learnings from the pandemic. A small virus and the whole economy at the toss. The businesses will have to introspect them and must look for advancements in technologies such that this kind of pandemic in the future will not disturb their efficiency too much. The pandemic has taught us that the decision which took weeks and months in the normal world can be accelerated and can be taken in some days. This should become a permanent feature. Cross organizational collaboration has become much easier. This should stay in the long run.',\n",
       " 'Reform: The last phase is the reform. In this phase, the companies should look at their bottlenecks and try to fix them. Also, the companies will have to reconsider their relationship with their customers. The confidence in their brands, they must regain it.',\n",
       " 'There are three ways to shift work, talent, and skills to where and when they are needed most, thereby building the organizational resilience and agility necessary to navigate uncertain times and rebound with strength when the economy recovers.',\n",
       " 'In this dismal situation it is more important than ever most of the staff should be in the critical tasks. The tasks could be like the customer complaints redressal. We know that the customers are the ones who make the businesses successful. Thus, retaining their confidence is the utmost priority. The organizations can convert some of the staff to address the queries and concerns of customers. The organizations require to create virtual offices. There should not be the geographical boundaries within the organization. The employees from all over the world from the organization should come together and take the organization back to pre-corvid state. By breaking out of rigid job constraints, the right talent and work can be matched to solve evolving business challenges in real-time.',\n",
       " 'This was happening before the pandemic too. But accelerating it with pace has now become the need of the hour. The perception that automation is a job-killer is totally wrong and in fact, it is the mandatory capability to deal with the crisis. Organizations can increase automation in call centers. This will reduce the response time.',\n",
       " 'Temporarily moving employees from some industries like airlines, restaurants, hospitality can be moved to those organizations which have maximum work at this time like healthcare and logistics.',\n",
       " 'To conclude, the companies should understand “Lives come first, but livelihood matters”. The pandemic will have some adverse effects on jobs and services, but this is not the end. The pandemic has brought many opportunities with him and if they are grabbed then the organizations would be in much better position even compared to pre-corvid situations. The companies need to understand the pandemic is not going to be forever. The last concluding sentence will be corona will bring changes but there will not be a revolution in jobs and services.']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f50f62f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 118 sentences in the string.\n",
      "The number of words in the string is: 1826\n",
      "The number of characters in the string is: 9180\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 16:07:22] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 16:07:26] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:33]))\n",
    "URL_ID_93 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_93.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_93.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_93.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_93 = re.sub(re_punt, \"\",URL_ID_93)\n",
    "\n",
    "file = open(\"93.txt\", \"w\")\n",
    "file.write(URL_ID_93)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"93.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cbad7169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1826\n",
      "WORD COUNT 1098\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/93.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9e747d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 15.474576271186441\n",
      "377\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.34335154826958103\n",
      "FOG INDEX: 6.327171127782409\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 15.474576271186441\n",
      "COMPLEX WORD COUNT: 377\n",
      "WORD COUNT: 1098\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c7885f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3308\n",
      "I: 0\n",
      "we: 4\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 1\n",
      "Total count: 5\n",
      "PERSONAL PRONOUNS: 5\n",
      "AVG WORD LENGTH: 5.027382256297919\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"I\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_93.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacd76f",
   "metadata": {},
   "source": [
    "# 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c342ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\3037366561.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0bcbf60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Social media is such a staple of our evolving digital culture that it’s almost hard to imagine a time without updates, likes, comments, and shares. People are more concerned about how their food looks than about how it tastes. Thus, it has become necessary for any brand to have a social media presence. The phrase “Out of sight, out of mind” has never been so apt than in today’s time. Social media is as much about engagement with other people as it is about sharing content. It’s why we call it “social” media.',\n",
       " 'Social media engagement simply is the interaction between the customer and the brand on social media platforms. Where else are you going to find a huge database of your target demographic who are already in the mind frame to read, click on, and share your message?',\n",
       " 'In practicality it is not about a one-off communication but more about the construction of a long-term relationship with your target customers. Hence, when we talk about such a relationship it is imperative to consider the positive actions of users as a reaction of any brand’s engagement tactics.',\n",
       " 'A fundamental customer journey can be envisaged in the form of customer funnel. The touchpoints available at every step can be shown as: ',\n",
       " 'To understand the reach of social media by the use of numbers',\n",
       " 'Most popular social networks worldwide as of July 2020, ranked by number of active users (in millions)',\n",
       " 'How many retweets on Twitter? How many reactions to the post on Facebook? How many likes on Instagram? How many shares on Linked In? This seems to be the new age Resume.',\n",
       " 'Thus, a good question or mystery for any brand is how to measure their social media engagement. As with most online actions, it’s often difficult to measure offline benefits. More often than not the online campaigns do not drive any conversions on the same day/week, but a user may see those posts and become more familiar with the brand. That familiarity, later on, might result in him choosing that brand over an unknown competitor. Social media engagement as a result helps businesses in developing their brand’s personality, improves visibility, and becomes its voice.',\n",
       " 'Customers exhibit dynamic behavior based on the type of product. It could range from picking and variety-seeking to high involvement processes comprising extensive information search. Top of the mind recall rules due to this purchasing behavior implies that targeted advertising and marketing is extremely important. No one engagement strategy can be applied across brands. Each brand’s strategy must differ based on what the brand is trying to sell, its target customers, and the beliefs of the brand.',\n",
       " 'Some of the key aspects of marketing strategy that we have influenced as vital cogs in the digital marketing wheel are:',\n",
       " 'Influencer Marketing',\n",
       " 'Influencer marketing involves a brand collaborating with an online influencer to market one of its products or services. Here the audience doesn’t care much about your brand but the opinions of the influencers.',\n",
       " 'An influencer as being someone who has:',\n",
       " '2017 saw Chanel being named as the most influential luxury brand on social media. Since then, it has continued to grow and diversify its portfolio, while providing constant engagement to its plethora of followers, especially on Instagram. ',\n",
       " 'Cross-Channel Marketing',\n",
       " 'Cross-channel marketing or multi-channel marketing is the practice of using multiple channels to reach an audience. Because not everyone uses every single platform, it’s a good idea to have a presence on a few, and share some of the same content across the different networks. What makes a difference in this marketing strategy is the choice of platforms. Apart from using basics like Facebook, Instagram, and Twitter a clever use of Spotify, YouTube, or IGTV to showcase the brand can make a real difference.',\n",
       " 'The luxury vehicle brand, Land Rover’s cross-channel marketing includes the Google Display Network, homepage masthead and Masthead in Lightbox ads on YouTube, and visibility through mobile, search, and Google+. The brand’s digital campaign included four different influencers who created visual content for their blogs by taking trips to places like Glacier National Park and the Appalachian Mountains and Land Rover’s microsite. Their cross-channel efforts resulted in 100 million impressions from YouTube, and a 10% increase in search ad CTR. Further results found that online leads from its digital channel efforts now account for 15% of the brand’s total sales.',\n",
       " 'Informative',\n",
       " 'The content created on social media must add some value addition to the customers. The brand must constantly keep informing the customers about their existing products, new products, achievements of the brands, or even casual content. There should be “Wow, I didn’t know this” factor. Only then will they become regular followers of the brand.',\n",
       " 'An example of this would be a cosmetic brand posting make-up tutorials. Fenty Beauty is one such prime example, which has built up to 1.4m followers within just 4 days of its launch, eventually garnering close to 10m followers, with Rihanna being one of their icons.',\n",
       " 'Involving customers & engaging them:',\n",
       " '“Customer is King” is a known concept. It is the foundation of traditional marketing. So while we shift to Social platforms brands must not forget them. Understanding their needs, addressing them, inviting them to respond and take part in the brand’s online activities while keeping it interesting and entertaining for the customer is the key.',\n",
       " 'Founder and CEO of Glossier, Emily Weiss, described the brand as, “the first socially-driven beauty brand.” Glossier was certainly the pioneer in the term ‘Instagram brands’ – using the platform not only to build awareness but also to have focused conversation with the customer. Glossier often crowdsources product development, asking its Instagram followers what they’d like to see next. ',\n",
       " 'Dynamic',\n",
       " 'The content creation must be dynamic and suitable for the current season, festival, or event that is happening. People must be able to relate to the posts and they must get excited after seeing it.',\n",
       " 'Starbucks does a marvelous job when it comes to being dynamic. Their one-off recipes and continuous hype around seasonal events and related drinks have won them a silver IPA Effectiveness award for its social strategy in 2018. The launch of its now iconic ‘Unicorn Frappuccino’, spurred on the trend of brands deliberately creating ‘Instagrammable’ food and drink. As a result, there are now 557,232 posts using the hashtag #PumpkinSpiceLatte.',\n",
       " 'Product focussed',\n",
       " 'Now of course the real motive behind any marketing activity is to eventually sell the product. So it becomes extremely important to not lose the essence of the product while marketing. In simple terms, the content or strategy must not leave the customer confused about what the brand actually does or what it is trying to sell.',\n",
       " 'To support the product-centric statement, Oreo is the best example. Oreo’s social media strategy has never diverged from its original formula. Completely product-focused and yet always creative, the brand continuously finds ways to put its cookies center stage. The ‘Daily Twist’ campaign to mark its 100th birthday, saw the brand turn its Oreo cookie into something of cultural relevance for 100 days, including Elvis Presley, a baseball, and a rainbow flag in support of Pride. ',\n",
       " 'Visuals',\n",
       " '“A picture is worth 1,000 words”. This adage has never been more apt than in the age of social media.  This is why visuals are so important in any marketing strategy. You can talk about a product all day, but until you’re able to put it in front of someone’s eyes, it’s not going to have nearly the same effect. Visual content marketing is a great way to make this happen and can be broken down into six basic types- comics, memes, infographics, photos, videos and visual note-taking.',\n",
       " 'Coca-Cola has been a leader and trendsetter in the visual content marketing space for years. The 2020 initiative video paved the way for multiway communication, as opposed to the single way process that was prevalent. ',\n",
       " 'Product demonstration:',\n",
       " 'The barrier for electronic platforms has always been the loss of touch. Customers often complain that till they don’t touch, try or test the product they are not convinced if they want to purchase it. This can also be true for products that are new and the customers need to be educated about its use. Hence it becomes important for brands to bridge this gap as far as possible through their online medium.',\n",
       " 'Product demonstrations are considered one of the most promising and upcoming applications of AR technology, giving brands a way to provide an immersive experience to consumers. Gucci partnered with Snapchat for the first global branded AR shoe try on the lens, hugely increasing fanfare!',\n",
       " 'Social message',\n",
       " 'Corporate Social Responsibility should not be missed when it comes to social media engagement. If a brand has the reach to spread awareness then they must use it. Creating content to spread social awareness adds an emotional touch too. If a customer connects with a brand on an emotional level its hard for competitors to break it.',\n",
       " 'Dove’s steady and impactful social message still stands out as marketing that’s more than just marketing. The ‘Real Beauty’ campaign has been refreshed multiple times since it first launched in 2004. Dove’s latest campaign once again highlighted the core message, going far beyond surface aesthetic to focus on the beauty of real human values. The ‘Courage is Beautiful’ campaign successfully honored the healthcare workers who have been working selflessly throughout the 2020 pandemic.',\n",
       " 'The fact remains that the share of mind and voice are key elements to being the dominant force in the world today. Social media marketing has leveraged all the elements and made its presence felt in every customer engagement. Finding unique ways to really stand out among the competition is key to a successful digital marketing strategy. Newer and more customized tools to feel the pulse of the market come up every single day, to meet the ever-changing needs of marketing heads. At the end of the day, ‘customer is indeed king’. And companies would do well to remember it! ']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4c043640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 sentences in the string.\n",
      "The number of words in the string is: 1679\n",
      "The number of characters in the string is: 8648\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 16:12:57] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 16:13:02] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:55]))\n",
    "URL_ID_94 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_94.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_94.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_94.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_94 = re.sub(re_punt, \"\",URL_ID_94)\n",
    "\n",
    "file = open(\"94.txt\", \"w\")\n",
    "file.write(URL_ID_94)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"94.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "081f1080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n",
      "WORD COUNT 1078\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/94.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "64d3b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 19.523255813953487\n",
      "351\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.32560296846011133\n",
      "FOG INDEX: 7.9395435129654395\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 19.523255813953487\n",
      "COMPLEX WORD COUNT: 351\n",
      "WORD COUNT: 1078\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2a052217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3119\n",
      "i: 1\n",
      "we: 4\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 5\n",
      "PERSONAL PRONOUNS: 5\n",
      "AVG WORD LENGTH: 5.1506849315068495\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_94.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9b2ae",
   "metadata": {},
   "source": [
    "# 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "95a71b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\994376550.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6af541b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Petty Entrepreneurs like Streetside Food Stalls form an essential part of an economy that plays a significant role in balancing the development of a nation’s economy. The importance of street food vendors not only helps in increasing the country’s per capita income but also helps to make a living for the unemployed in society with a limited investment. Most of them are the sole breadwinners for their families. So, with the Covid-19 wreaking havoc, the uncertainty of the lockdown policies increased the concern of people over hygiene and the lack of investment to upgrade their businesses to provide better hygiene facilities that can take away food from their mouths.',\n",
       " ' Various states have provided relief packages and support but, in a country, as populous as ours, it has hardly been appropriately implemented. Delhi, for instance, recently announced a rupee 500 million stimulus package to nearly 500,000 rupees, recognizing the severe consequences of the loss of livelihoods. The seller’s intended remedy is a credit loan that provides all sellers with an initial working capital of Rs 10,000, but this is not enough. Instead of loans, the government should consider converting them directly into income benefits, cash subsidies to secure a livelihood in order to initiate income-generating activities on a regular basis. Sellers need income support to get back to work, and if they can’t, they will never be able to repay the loan amount. In an ever-changing crisis, organizations need to take a step forward and ensure that providers are provided with the resources they need to make a living. Pandemics have had a vast economic impact on every sector, but the most vulnerable sectors, such as street vendors, suffer the most. Decreased income can affect most necessities, such as payments to family and yourself. Due to a lack of fixed salaries, stalls cannot quit their jobs. If possible, it might be only a few days, unlike regular employees. For them, the risk of infection is far less frightening than hunger.',\n",
       " 'Unlike many of the businesses, most of these food vendors lack the infrastructure to go online and sell products through platforms like Swiggy or Zomato.',\n",
       " '“Regret not going digital before,” says Dilip Das, a Street side food stall owner at Sector V, Kolkata. Dilip Das used to run a small streetside food stall that provided meals to all the employees around the area which is filled with multinational companies. It was a booming business till the arrival of Covid. Then with the lockdown arriving, almost all the companies opted for Work from Home policies. Dilip tried to start deliveries, but with a lack of support and fear of infection, that business ended before it even started.',\n",
       " 'Citing similar reasons, Swapan Mondal, who runs a south Indian food stall at Park Street said that he did know how to operate a smartphone. And since sales were good, he did not care about learning either. But with the implementation of lockdown which took place within 4 hours, people like Swapan barely had time to cope with the changes.',\n",
       " 'Furthermore, the Covid 19 pandemic made people realize how important trains are in our life. With most of the train network suspended, the entire supply chain was disrupted. Hundreds of quintals of food products rotted away, awaiting the logistical issues to fix. Many businesses could not afford to run without proper supplies as well.',\n",
       " 'To handle such issues, vendors organizations may consider the following solutions:',\n",
       " 'Promotion of livelihood for all vendors, including sellers of non-essential goods',\n",
       " 'The impact of COVID19 was extremely severe for informal workers who ran out of capital and income and to try to feed themselves during this long embargo. Sellers need to be able to resume sales in order to survive, and governments need to take steps to reopen the market and bring sellers back to the business.',\n",
       " 'Reopening of Markets keeping in mind social distancing and hygiene',\n",
       " 'India has different types of traditionally crowded markets, even weekly markets (fresh food, cooked food, and essentials) and daily roadside markets. These markets have to reopen with the need for social distance in mind, and the government needs to publish guidelines for that. In the future, sales areas will also need to be designed with social distance and the need for adequate sanitation (running water, wash areas, toilets) in mind. Authorities need to work with the Town Bending Commission (TVC).',\n",
       " 'Provision of direct support that is devoid of existing registration requirements',\n",
       " 'Once the restrictions are lifted and the impact of Covid 19 is somewhat manageable, sellers who have been at home for months will need direct income benefits to help them to return to work. The government initiative is a welcome move, but not in terms of the type of bailout and eligibility is enough. In addition, there are very few registered providers in India, so government relief and support must be separated from the very strict registration requirements. In Delhi alone,  of the approximately 300,000 street vendors, only approximately 13100 have some sort of professional ID. If all types of cash grants or livelihood support standards relate to job identification by the state,  the government must also accept registration with workers’ organizations/unions on behalf of government-issued sales badges.',\n",
       " 'Ensuring social distancing and proper sanitation and hygiene at sites of businesses',\n",
       " 'The government and municipal corporations need to take the initiative and running water, and soap/sanitizers need to be provided for street vendors at their place of work. Moreover, the streetside food vendors should work with food safety authorities in the country to train themselves in different ways to maintain hygiene whilst working.',\n",
       " 'Taking steps to spread awareness of different government initiatives and reliefs',\n",
       " 'Many small businessmen and food vendors do not even know their rights and the benefits they can claim. If they did, many still have no idea about how to claim them. Proper awareness camps need to be set up to help these small-time food vendors to know how they can get assistance and help from the government and return back to the business.']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dac2d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 sentences in the string.\n",
      "The number of words in the string is: 1059\n",
      "The number of characters in the string is: 5512\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 16:27:50] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 16:27:55] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:33]))\n",
    "URL_ID_95 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_95.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_95.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_95.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_95 = re.sub(re_punt, \"\",URL_ID_95)\n",
    "\n",
    "file = open(\"95.txt\", \"w\")\n",
    "file.write(URL_ID_95)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"95.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "80d4abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059\n",
      "WORD COUNT 671\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/95.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e8b9828b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 23.533333333333335\n",
      "230\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.34277198211624443\n",
      "FOG INDEX: 9.550442126179831\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 23.533333333333335\n",
      "COMPLEX WORD COUNT: 230\n",
      "WORD COUNT: 671\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "92eb703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1999\n",
      "i: 0\n",
      "we: 0\n",
      "my: 0\n",
      "ours: 1\n",
      "us: 0\n",
      "Total count: 1\n",
      "PERSONAL PRONOUNS: 1\n",
      "AVG WORD LENGTH: 5.204910292728989\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_95.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d3bda",
   "metadata": {},
   "source": [
    "# 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "863147ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\3610729184.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a02a1d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The coronavirus, also known as COVID-19, is not only a global public health emergency but also a source of significant regional and increasingly global economic disruption. This impacts the energy and climate world in many ways. The economic downturn puts pressure on global oil prices leading the Organization of Petroleum Exporting Countries (OPEC) to consider further cuts to production. It hurts the demand for natural gas during a time of extremely low prices. It changes the economic, energy, and climate policymaking environment in China, one of the most consequential energy consumers and sources of greenhouse gas emissions. And it has temporarily disrupted supply chains throughout the energy industry, including renewable energy, at a time when supply chain connections with China were being revaluated due to ongoing tariff and trade disputes. How consequential or transformative any of these changes are for the energy sector or for climate efforts will depend upon the ultimate trajectory of the virus outbreak itself',\n",
       " '— Sarah Ladislaw, Senior Vice President and Director, Energy Security and Climate Change Program',\n",
       " 'The energy sector has already felt the impacts of the coronavirus. The outbreak has contributed to a dampened demand for oil, resulting in plummeting oil prices and production declines. As we move forward, then, the energy sector expects to face two headwinds: managing the issues of the health emergency all sectors face, and simultaneously coping with a low oil-price scenario, lower demand and the need to shore up revenue and manage debt obligations.',\n",
       " '                               IMPACT OF COVID-19 ON INDIAN ENERGY MARKETS',\n",
       " 'In India, distribution utilities have a lower tariff for domestic and agricultural consumers, sometimes even below the average cost of supply, as compared to that for commercial and industrial consumers. Table 1 provides the electricity tariff rates in Delhi for selected consumer categories to highlight these differences. Thus, for several distribution companies, the lower tariff-paying consumers are cross-subsidized by commercial and industrial consumers.',\n",
       " '',\n",
       " 'The COVID-19 lockdown has led to shut down of all but essential commercial activities across the country. Approximately 1.3 billion citizens are obliged to remain within the confines of their homes and, in many cases, only allowed to work from home. Consequently, the electricity demand from industrial and, commercial customers has reduced significantly while the residential demand is expected to have increased. According to the Power System Operation Corporation of India (POSOCO), The energy met on March 16th, 2020 – which can be considered as a business-as-usual scenario – was 3494 MU as compared to 3113 MU on March 23rd, 2020 a day of voluntary curfew. It further reduced to a range between 2600-2800 MU between March 25th to March 31st, 2020. This trend is illustrated in the below Figure 1.',\n",
       " 'Thus, firstly, a key risk from the COVID-19 pandemic for the already struggling distribution companies in India arises from the loss of revenues due to the reduction of demand from the commercial and industrial customers as well as the inability to cover the cross-subsidies provided to the lower-tariff paying consumer. Secondly, the utilities would also have to account for the expense to comply with any ‘must buy’ commitments that they have with generators with long-term power purchase agreements. The true and full extent of this risk would only be known once a quantitative analysis is conducted when this crisis situation is contained. Thirdly, at an operational level, distribution companies would have to account for deviation in demand and supply patterns at a temporal and locational level. Finally, during this period, critical infrastructure such as electricity networks would have to be run with minimum employees.',\n",
       " 'As seen in Figure 1, the trade on the wholesale power market comprises just 4.3 percent of the total electricity transactions. However, the transactions through the power exchanges have grown over the last decade. The Indian Energy Exchange (IEX) has seen a growth from 2616 MU in FY 2009 to 52,241 in FY 2019.',\n",
       " '',\n",
       " 'Until now, the trade in the wholesale market is in four market segments:',\n",
       " '1) Day-Ahead Market',\n",
       " ' 2) Term Ahead Market',\n",
       " ' 3) Renewable Energy Certificates',\n",
       " '4) Energy-saving certificates.',\n",
       " ' Recently, the Central Electricity Regulatory Commission (CERC) finalized the regulations for implementing real-time markets. This half-hourly market will enable the intra-day trade of electricity, allowing adjustment of generation and consumption profile during the day. Before the COVID-19 pandemic, it was announced by CERC that the real-time market would be operational from April 1st, 2020. However, the starting date has now been delayed by two months to June 1st, 2020. According to media reports, due to the COVID-19 pandemic, some required trials could not be completed. This delay in the real-time market implementation is likely to have a serious, adverse impact on the Indian power market.',\n",
       " 'Another impact of the COVID-19 pandemic on the power markets is in terms of the market dynamic. It can be observed that there is a dip in the clearing volume and the market-clearing price, which coincides with the gradually increasing shutdown measures taken by the government as a response to COVID-19 (See Figure 2). Thus, the reduction in demand due to the lockdown is reflected in the volumes traded on the electricity market and the clearing price.',\n",
       " 'Another point of reference is the price and clearing volume in 2019. On March 22nd, 2020, the day of voluntary lockdown, the clearing volume was 97.05 GWh, and the clearing price was 2195.48 ₹ /MWh. In comparison, on the same day in 2019, the clearing volume was 107.98 GWh, and the clearing price was 2816.18 ₹ /MWh. From the start of the lockdown, from March 25nd to April 1st 2020, the average clearing volume was 104.27 GWh compared to 130.24 GWh in 2019 during the same period. Similarly, the average market clearing price was 2155.93 ₹ /MWh in 2020 as compared to 3371.025 ₹ /MWh in 2019 for the same period.',\n",
       " '                              VIEWS OF THE SHAREHOLDERS IN INDIA',\n",
       " 'The lockdown has resulted in a shutdown of the industrial and commercial establishments and the stoppage of passenger railway services. This has adversely impacted the all India electricity demand, given that these segments constitute about 40% of the all India electricity demand, a statement issued by the rating firm said.',\n",
       " 'Further, these segments account for an even greater percentage of the Discoms sales revenues given that they are the subsidizing segments. This apart, with the focus of state governments being on healthcare and relief measures, the likelihood of subsidy support to the Discoms getting deferred cannot be ruled out, it added.',\n",
       " 'ICRA Ratings Group Head and Senior Vice President – Corporate ratings Sabyasachi Majumdar said, “The lockdown imposed by the government is likely to adversely impact the all India electricity demand, with demand expected to decline by about 20-25% on a year-on-year basis during the period of lockdown. This would in turn adversely impact the revenues and cash collections for distribution utilities in the near term, especially given the consumption decline from the high tariff paying industrial and commercial consumers and likely delays in cash collections from other consumer segments. The revenue deficit for the Discoms is estimated to be about Rs. 130 billion per month, on an all India basis. This would in turn adversely impact the liquidity profile of the Discoms, increase their subsidy requirement, and lead to delays in payments to the power generation and transmission companies.”\\n\\nThe power ministry on Friday issued directors to the Central Electricity Regulatory Commission to provide a moratorium of three months to Discoms on payments to power generation and transmission companies.',\n",
       " 'The power ministry on Friday issued directors to the Central Electricity Regulatory Commission to provide a moratorium of three months to Discoms on payments to power generation and transmission companies and requested state governments to issue similar directions to state electricity regulators.',\n",
       " 'The power generation companies are already suffering delays in payments by Discoms across the majority of states, with payment due of more than Rs 85000 crore as of November 2019 at all India level as per the data on PRAAPTI portal.',\n",
       " 'With COVID-19 lockdown accentuating the delays in payments, the availability of adequate liquidity buffer in the form of debt service reserve and undrawn working capital limits remains important from a credit perspective.',\n",
       " 'However, it said that relief measures such as a moratorium on debt servicing over a 3-month period as notified by Reserve Bank of India and expected moderation in the interest rate cycle would be a source of comfort in the near term. The timely approval of the moratorium by the boards of the banks and financial institutions remains crucial.',\n",
       " 'The revenues for power generation companies having long-term power purchase agreements (PPAs) with the state distribution utilities (Discoms) will be protected by the provision for capacity charges linked to plant availability in case of thermal and large hydropower projects and “must-run” status in case of nuclear and renewable power projects.\\nAverage monthly thermal PLF would further dip to 50-52% against 63% in the corresponding period of the previous year, due to a considerable drop in demand and consequently, power generation companies especially those without any long-term PPAs would be adversely impacted given the weakening of the power tariffs in the short-term / power exchange market, said ICRA Ratings Sector Head & Vice President GirishkumarKadam.\\n\\nThe under-construction renewable power projects as well as EPC and manufacturing companies in the solar segment are likely to face execution delays because of disruption in the supply chain in India and labor availability, following the lockdown. Given the import dependency on China for sourcing PV modules, the execution timelines for the ongoing solar projects are likely to be affected by delays in the delivery of PV modules following the outbreak of COVID 19 in China.',\n",
       " 'This delay in turn would increase the pre-operative expenses and the overall project cost, which in turn would have an impact on the expected returns.',\n",
       " 'In this context, the MNRE has notified that time extension can be provided for all renewable energy projects, which are impacted by the supply chain disruption due to the COVID outbreak, under the force majeure clause.',\n",
       " '“Given the execution headwinds amid COVID 19 affecting Q1 of FY2020-21 and assuming the normalcy thereafter, the capacity addition in the wind and solar segments together is likely to degrow by about 25%, thus estimated at about 8 GW against earlier estimates of 11 GW in FY2020-21,” said Kadam.']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fbdcd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74 sentences in the string.\n",
      "The number of words in the string is: 1733\n",
      "The number of characters in the string is: 9256\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 16:35:59] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 16:36:04] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:46]))\n",
    "URL_ID_96 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_96.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_96.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_96.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_96 = re.sub(re_punt, \"\",URL_ID_96)\n",
    "\n",
    "file = open(\"96.txt\", \"w\")\n",
    "file.write(URL_ID_96)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"96.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "50cb5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1723\n",
      "WORD COUNT 1130\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/96.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "95587fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 23.41891891891892\n",
      "415\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3672566371681416\n",
      "FOG INDEX: 9.514470222434824\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 23.41891891891892\n",
      "COMPLEX WORD COUNT: 415\n",
      "WORD COUNT: 1130\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2d2e6971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 3286\n",
      "i: 0\n",
      "we: 1\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 1\n",
      "PERSONAL PRONOUNS: 1\n",
      "AVG WORD LENGTH: 5.341027120600115\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_96.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b7a10b",
   "metadata": {},
   "source": [
    "# 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "42c1f7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\2704402341.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7afdfd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In December 2019, a novel coronavirus strain (SARS-CoV-2) emerged in the city of Wuhan, China. The disease called Covid-19 spread to almost every nation in the world creating widespread havoc and disruption in routine life. WHO recognized it as a pandemic on March 10, 2020. As of April 19, 2020, worldwide around 24 lakh people have been infected and more than 1.6 lakh people have succumbed to Covid-19.',\n",
       " 'Though a vaccine hasn’t been developed yet, the spread of coronavirus can be stopped by washing hands frequently, covering one’s mouth while coughing, and practicing social distancing from other people. Countries across the world are using lockdowns as an effective way to stop the spread.',\n",
       " ' 29 kb of RNA has brought the world down to its knees. One-third of the global population has been in lockdown. Schools, colleges, businesses, services that are considered non-essential have been put on hold for an indefinite period. Even after lifting restrictions, a global recession even worse than the one in 2008 is going to be expected.',\n",
       " 'Now arriving at the main field of discussion, i.e. Hospitality Industry. How COVID-19 Impact Hospitality?',\n",
       " 'Propulsion was building for 2020 to be a year of focal collective action on sustainability. The Covid-19 outbreak has emphasized more than ever, the importance of future-proofing business for growth and resilience.',\n",
       " 'The hospitality industry includes various services like lodging, food and beverage, events, tourism, transportation, theme parks, etc. Before COVID – 19 prevailed, we all know that this industry was in much demand and was also one of the major sources of the rising economy. During vacation and festive periods, these were always full of people worldwide. As of now, due to the havoc created and ongoing lockdown they are bearing many losses and is one of the main reason for the decreasing economy.',\n",
       " 'Have you ever thought of hotels been converted into hospitals, quarantine centers, and isolation centers?  Yes, my dear people! Amidst this outbreak, many of the hospitality industry properties, be it tiny or enormous have come forward to help the nation fight this life-menacing virus.',\n",
       " 'Taj hotel in Mumbai is attentively aware of its responsibility towards the community and has opened its doors for the major frontline workers, i.e. medical fraternities to stay at their place while they combat the spread of this treacherous virus.',\n",
       " 'Also, many of the government bodies have been transformed to provide shelter to the homeless. Recently, in Vadodara – Gujarat the building which was built for the employees aiming to work for the major Mumbai-Ahmedabad bullet train project has been come forward to make it an isolation center for doctors and nurses.',\n",
       " '“Railways – the lifeline of citizens.” As railways have started their service years ago, from that period they are being considered as the lifeline of citizens in many metropolitan cities. Today at the time of the global pandemic, railways haven’t backed off from the position of the lifeline. Yes, my dear friends, you have heard it right! Railway coaches in India have been turning into the hospital and isolation centers, marking their presence by helping the government to increase the number of isolation beds. Also, many special parcel express trains are running in the entire nation to fulfill the needs of people by transporting essential commodities and goods.',\n",
       " 'Hospitality has been one of the most innovative industries in the crisis so far. Connections have been rapidly formed to donate food and beverages to local charities from various hotels. Many of the hospitality bodies are standing in solidarity with the communities affected by this threatening disease by lighting their windows in the shape of a heart, seen in hotels across the world.',\n",
       " 'With this outbreak, there is a sharp drop in tourists worldwide as the aviation, railways and public transport buses have come to a standstill due to severe government restrictions.',\n",
       " 'Today it is clear that hospitality industries must be prepared for various situations like a pandemic, climate change, etc. as of now they are facing devastating and disastrous Covid-19 impact on its various sectors.',\n",
       " 'The debt being the normal capital intensive component has to be serviced by payment of interest on debt and repayment of debt. Hotels being labor-intensive, have lots of fixed costs such as wage bills, besides paying government levies, minimum load charges, etc. The earlier Indian hospitality industry was on average witnessing 65 to 70% of occupancy till the end of February. The first few days of March were fine, once things started accelerating, the occupancy has gone down to a severe minimum. Also as soon as the pandemic ends by God’s grace, the hospitality industry will still face some loss as the tourists will be much lesser in the beginning months.',\n",
       " 'As soon as the crisis gets over, the hospitality industry will have a very crucial role to play in rehabilitating lives within their local communities. Millions of people will be unemployed leaving them at high risk of poverty and exploitation. As the industry starts to recover, hospitality will be one of the sources to increase employment to the needy ones taking the poverty level to a minimum.',\n",
       " 'Within India, after the crisis over, people should travel to the less known and highly economically affected destinations to help the hospitality industry overcome the loss they bore due to Covid-19.',\n",
       " 'Hence, the hospitality industry suffered and is suffering a lot due to this pandemic and despite that, it is also helping the nation to win against this dangerous disease. thus COVID-19 Impact on Hospitality ',\n",
       " '“Let’s be grateful to all the frontline workers saving the entire nation and also be thankful to all the various sectors of the hospitality industry who have come forward to help and serve the nation.”']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "84022dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 sentences in the string.\n",
      "The number of words in the string is: 1023\n",
      "The number of characters in the string is: 5272\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 16:43:16] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 16:43:21] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[16:34]))\n",
    "URL_ID_97 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_97.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_97.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_97.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_97 = re.sub(re_punt, \"\",URL_ID_97)\n",
    "\n",
    "file = open(\"97.txt\", \"w\")\n",
    "file.write(URL_ID_97)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"97.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ae9f7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018\n",
      "WORD COUNT 652\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/97.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a8a7add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 20.058823529411764\n",
      "203\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3113496932515337\n",
      "FOG INDEX: 8.148069289065319\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 20.058823529411764\n",
      "COMPLEX WORD COUNT: 203\n",
      "WORD COUNT: 652\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "252c8861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 1921\n",
      "i: 0\n",
      "we: 2\n",
      "my: 2\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 4\n",
      "PERSONAL PRONOUNS: 4\n",
      "AVG WORD LENGTH: 5.15347018572825\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_97.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1e7ae",
   "metadata": {},
   "source": [
    "# 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "86c64e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\4080533600.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "93a4e361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As a race, we are not ready for any kind of crisis. We have fire extinguishers in buildings, but barely any knowledge of how to use it. We convince ourselves that we are prepared but in the face of adversity we stand dumbfounded and give the simplest excuse, that of being in ‘unprecedented times’. The same thing has happened with the coronavirus crisis. If we look back, we can see that this crisis was not avoidable. There was a lot we could have done, but because we underestimated it so much, the situation has now blown out of proportion and cost us thousands of lives, millions of jobs and a massive hit to the world economy. We may be in a unique condition but there is still a lot that we can apply from past experiences and previous calamities. ',\n",
       " 'First, let’s look at this in a reflective mode. What are the things we could have done to avoid this crisis in the first place? Controlling the origin of a virus is difficult but preventing it from spreading is not. One of the biggest contributors to this unforgiving crisis is the lack of communication or even worse, the propagation of fake news. Take India for example. Clear communication about the virus was only initiated after a few cases had been identified. We were aware of the hazards of this virus since before and should have acted sooner. The spread of accurate and timely information is a must. If we had spread awareness earlier, we could have controlled the number of cases better, like New Zealand and Ireland have done. Secondly, in a situation of crisis, the first thing to spread is fake news. It is imperative that the government, social media agencies and people themselves act more responsibly. Since there is no accurate and transparent information, a lot of uncertainty exists in the society. This impacts the confidence of consumers and investors in the market, which in turn leads to an economic slowdown. Past experiences with financial breakdowns and recessions have shown us that retain market trust can only occur with transparency and accuracy of information. Organisations should have acted earlier and communicated more effectively with their employees. ',\n",
       " 'Moreover, we must also understand that specific sectors take the hardest hit during lockdowns. As we have witnessed in earlier lockdowns, curfews, national emergencies and pandemics, the first segment of society to take a hit is the daily wagers and labourers. Not only do the prices of goods increase but their income also takes a decline in such a crisis. In such situations, they can’t even afford basic amenities. India witnessed a mass exodus recently, with thousands of people trying to return to their villages on foot. This only leads to more chaos and a decline in containment of the disease. The government should have accounted for such factors before announcing a lockdown with a four hour notice. They could have made better arrangements for food and water in the metro cities itself or giving them safer means to travel home. This is something that they can still include in their relief programs.',\n",
       " 'Government intervention is a must right now. This can be done in two ways. First, is to create more employment opportunities. Governments used this strategy in the SARS and Ebola Virus emergency. Health, water, sanitation and hygiene are the most services in the times of health emergencies. Intense investment for these services and infrastructure can provide immediate jobs. Secondly, if governments use fiscal and monetary policy to fuel demand and maintain current living standards, it can decrease the propensity of a huge fall in economic growth. A fiscal stimulus by the government can make all the difference. Having better avenues for cash transfers, easier loans and more exchange will automatically help. A fall in the growth rate is unavoidable as lots of sectors have no choice but to pause all work. However, industries that can provide high returns even now must be encouraged. For example, IT sector, health, food and agriculture, etc.',\n",
       " 'Moreover, governments and businesses should use the most important tool in their hand, the internet! Even in the times of physical social distancing, we are still connected to people across the world and are socialising at our normal rates. Governments should use these mediums to maintain public spirit, communicate policy strategies and inform people. Businesses should use these means to continue working and maintain employee morale. To have balanced crisis management and to prevent panic in the masses, social dialogue and engagement at every level is imperative. Use these mediums to educate people about the importance of social distancing, hygiene and steps to be followed.',\n",
       " 'All diseases are different and the scientific approach to tackle them varies. However, with most epidemics and pandemics some common steps can be followed. Our past experience with fast spreading diseases has shown that the easiest and most effective way to curb it is social distancing. Countries have taken impressive steps to ensure social distancing and must keep this up for even a few weeks after curbing the disease. Maintaining sanitary habits and hygiene can protect us from infections and increase our immunity. While governments and medical agencies look for ways to tackle the virus at a macro level, we must continue to follow all measures on an individual level too.',\n",
       " 'We must also pay a lot of attention to mental and physical well-being now. In the past, when economies took a hit due to the 2008 recession or calamities, the first thing to break was people’s self-esteem. Suicide rates, amount of domestic abuse and cases of depression increased manifold. We have to take effort and ensure that we try and live as much of a balanced life as possible. We should stay connected to our friends and not be ashamed of reaching out to others for help. Social distancing is not easy and can take a toll on many. Lots of special helplines have been set up for the same and people must use them if needed. Governments have also given code words for victims of domestic abuse to report crimes in countries like France and Spain. We must remember to stay mentally healthy and calm during a crisis as that is the most important thing.',\n",
       " 'I don’t believe that every crisis is the same. Of course, there are a lot of unique things about the coronavirus pandemic that we had not expected to ever see. Even though these are different times, there are still lots of things we can apply from our past experiences. We cannot find a cure for the virus but we can find ways to maintain the economy, our mental peace, and prevent the spread of the virus. The past has a lot to offer if we ponder. We must learn to understand the mistakes of the past and better them in the future. Our past experiences with the different crises have taught us that fiscal stimuli work, maintaining employee morale is important and that social. Engagement is imperative. If we use these tools efficiently, we can ensure that people only have to fight the virus and not worry about the multitude of repercussions that come with it.']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cfb348b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72 sentences in the string.\n",
      "The number of words in the string is: 1200\n",
      "The number of characters in the string is: 5894\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 16:50:43] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 16:50:48] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts=(' '.join(str(x) for x in texts[16:24]))\n",
    "URL_ID_98 = texts\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_98.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_98.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_98.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_98 = re.sub(re_punt, \"\",URL_ID_98)\n",
    "\n",
    "file = open(\"98.txt\", \"w\")\n",
    "file.write(URL_ID_98)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"98.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "59666584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "WORD COUNT 740\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/98.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "14c62da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 16.666666666666668\n",
      "236\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.31891891891891894\n",
      "FOG INDEX: 6.794234234234235\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 16.666666666666668\n",
      "COMPLEX WORD COUNT: 236\n",
      "WORD COUNT: 740\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e03abc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2204\n",
      "i: 1\n",
      "we: 32\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 4\n",
      "Total count: 37\n",
      "PERSONAL PRONOUNS: 37\n",
      "AVG WORD LENGTH: 4.911666666666667\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_98.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401b3b6",
   "metadata": {},
   "source": [
    "# 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "80d3c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\2281850761.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "64b5922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COVID-19 an unprecedented pandemic for us but a “Can-be” possibility for great leaders such as bill gates came into action since the rising of the year 2020. The corollary of this pandemic is so prodigious that the analysis by the UN Department of Economic and Social Affairs (DESA) stated that the COVID-19 pandemic is disrupting global supply chains and international trade which in turn could shrink the global economy by up to 1 percent in 2020, a reversal from the previous forecast of 2.5 percent growth. More than 6.6 million Americans filed unemployment claims and the economic downturn is expected to be the worst recession since the Great Depression as stated by the IMF. India is facing its biggest crisis in decades, with a three-week lockdown initially, but extending further in a nation of 1.3 billion people likely to result in an economic recession, millions of job losses and possible starvation among the poor. It can be said that economic contagion is now spreading as fast as the disease itself. On the contrary nature has pressed the reset button, the environment is having a noticeable benefit from this scenario. Water is getting clearer, the air is turning breathable and various such news and pictures can be easily heard and seen on newspapers, telly, and social media platforms on day to day basis. But this is the storyline of the present, what about the future? Are the predictions made by financial institutions and thought leaders going to be true? Or something unexpected is going to happen that will make us think of our human capabilities again?',\n",
       " 'After this storm of COVID-19, it would not be a surprise to see how digitally every business will grow to provide better digital infrastructure and customer experience along with advancement in technology which we are lacking in this present scenario. The touch screens that we are using already will find its vast applications and would be seen in most of the places including hotels, hostels, and shopping malls. All those processes which are interdependent will take an agile turn resulting in better productivity of goods, having a systematic backup giving a better experience to the consumer even in hard situations. The major focus would be making contactless systems hence Artificial intelligence and machine learning will become the most rapid and in-demand fields. Not only this, but the medical infrastructure and services will also take a boost in the race of developing the systems to handle any situation afterward. The human to machine interaction will increase facilitating fast production, delivery and surveillance inculcating many more. In each and every area the COVID will leave its mark may it be retail sector or may it be the banking sector making them modify or fully change their architectures.',\n",
       " 'Even the existing systems would be gifted with some modifications, ensuring them to work in a hard environment even with or without human intervention. The Companies will rethink their policies shaping themselves accordingly to manage the resources ensuring safety, agility, and work to be a top priority. The work from home idea will also provide a base for bigger companies ensuring to develop a better infrastructure for their resources and probably giving birth to a new concept of work culture. Various existing industries related to either delivery or travel may adopt the new idea of collaboration with other industries which will result in more options for consumers on their old routine Apps.',\n",
       " 'New businesses will root out from the existing ventures resulting in head to head competition in the business world but turning into a brownie point for consumer experience and bandwidth of choices. Start-up culture will go hand in hand and expected to take a stupendous growth in the race of providing us a legitimate opportunity to use and feel the real digital world. The various innovations will now take a pace in each field and maybe we will hear some new jargons related to tech in upcoming years. Since the global economy has fumbled, countries will now try to take a different turn to vamoose out of this phase. They will try to make new connections by nurturing a give and take relationship and several business relationships would take an unexpected move making the position of several countries sliding up and down on indexes. Even rival countries may join their hands in this hard time rather than being dismissed totally under predator countries. It would be surprising to see how these scenarios will be handled by the emperor of minds and how their opponents are going to take it as an agenda for the next elections.',\n",
       " 'Unfortunately, the nature that is at its best will start to face the ill effects after the chart of development and economy will take a pace for exponential growth. It is unfortunate that the inverse relationship between economic growth and environmental destruction exists since carbon emission increases with economic development. As shown by the graph below whenever recession took place the carbon emission decreases along with other harmful gases, turning out as a gift for nature but doom for the financial markets.',\n",
       " 'But there is a possibility that several start-ups now emerge with the idea of environment conservation collaborating with NGOs innovating and using the best of their capability to reduce the ill effect from the present origin point.',\n",
       " 'In the culmination we can say this pandemic is like “Blessing in disguise ” producing a massive impact not only on macro but also on micro-economy. The novel virus not only brought some unexpected results but also uncovered some of our loopholes and unlatched new opportunities for growth, forcing us to define ourselves in several new spheres. Quite a while ago we all were chit-chatting about the digital Era, how this is benefiting us, COVID-19 revealed making us realize this was just the beginning of digital Era and a lot is needed to happen in future. It is obvious that not only the Indian economy but the global economy is facing and going to face the aftereffects however similar to a virus, the economy will also rise from deep grounds to a green candlestick with individual collaboration!',\n",
       " 'The businesses will soon rise again, people will get back to their jobs, vendors will start getting profits and everything will fall into its places but now a megalithic competitive environment will rise which will grow till decades until nature again shows it’s color and we as a human abide with its outcomes, learning some new lessons and keeping this cycle of fall and growth running.']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[16:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a56fe7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 sentences in the string.\n",
      "The number of words in the string is: 1090\n",
      "The number of characters in the string is: 5490\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 17:48:58] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 17:49:03] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts=(' '.join(str(x) for x in texts[16:24]))\n",
    "URL_ID_99 = texts\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_99.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_99.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_99.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_99 = re.sub(re_punt, \"\",URL_ID_99)\n",
    "\n",
    "file = open(\"99.txt\", \"w\")\n",
    "file.write(URL_ID_99)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"99.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "44d7fea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089\n",
      "WORD COUNT 677\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/99.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a410653d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 29.45945945945946\n",
      "239\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.35302806499261447\n",
      "FOG INDEX: 11.92499500978083\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 29.45945945945946\n",
      "COMPLEX WORD COUNT: 239\n",
      "WORD COUNT: 677\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "43650e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2029\n",
      "i: 0\n",
      "we: 6\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 6\n",
      "Total count: 12\n",
      "PERSONAL PRONOUNS: 12\n",
      "AVG WORD LENGTH: 5.036697247706422\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_99.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b336c3",
   "metadata": {},
   "source": [
    "# 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a42dea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrush\\AppData\\Local\\Temp\\ipykernel_12820\\3212727502.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "website = 'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/'\n",
    "path = 'C:/Users/hrush/Downloads/edgedriver_win64/msedgedriver'\n",
    "driver = webdriver.Edge(path)\n",
    "driver.get(website)\n",
    "\n",
    "title=driver.find_elements(By.TAG_NAME,'strong')\n",
    "text=driver.find_elements(By.TAG_NAME,'p')\n",
    "titles=[]\n",
    "texts=[]\n",
    "\n",
    "for values in title:\n",
    "    titles.append(values.text)\n",
    "for values in text:\n",
    "    texts.append(values.text)\n",
    "    \n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "52baebf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Will COVID19 END Globalization?',\n",
       " 'Globalization:',\n",
       " 'Globalization envisages a borderless world or seeks the world as a global village • It is attributed to the accelerated flow of goods, people, capital, information, and energy across borders, often enabled by technological developments.',\n",
       " 'Globalization Trends:',\n",
       " 'Starting from 1990s globalization dominated world’s economic order.',\n",
       " 'Anti-Globalization Wave:',\n",
       " 'Globalization had already begun to stagnate since the 2008-09 Global Financial Crisis.',\n",
       " 'Slowing Down of Trade:',\n",
       " 'Trade as a percentage of global GDP increased from 39% in 1991 to 61% in 2008 but has stagnated over the past decade.',\n",
       " 'Countries Policies Reflecting the Reverse Globalization:',\n",
       " 'The following polices and steps of various countries shows the protactinium',\n",
       " '1.USA',\n",
       " 'We reject Globalism, President trump took ‘American First to the United States – Trump',\n",
       " '2. Brexit',\n",
       " 'Brexit is a rejection of globalization-Larry Elliott',\n",
       " 'Slowing Movement of People:',\n",
       " 'Though number of tourists increased in the last decade.',\n",
       " '1.Indian IT’s H-1B Visa woes could worsen in 2020',\n",
       " 'The above article reveals that Under the Trump administration, Indian IT services companies have seen rejection rates jump from 6% in 2015 to 24% in 2019.',\n",
       " '2.Racism study finds one in three school students are victims of discrimination',\n",
       " 'Trade Wars and Halting of WTO Talks: Retreat of Globalization:',\n",
       " '1.Chinese-US trade war threatens globalization',\n",
       " '2.Protectionists put brakes on trade liberalization',\n",
       " 'Due to These Factors, International Media Is Referring to The Process of Globalization By The Term ‘SLOWBALISATION’',\n",
       " 'The ongoing phase of globalization has not fully recovered, and the recent coronavirus has pushed forward the trends of reverse globalization',\n",
       " 'Globalization Is Responsible for The Spread Of Coronavirus:',\n",
       " 'Corona Virus Has Halted The Movement Of People, Goods, Service, And Capital.',\n",
       " 'More than a fifth of the world’s population has been under lockdown in the global fight against coronavirus with early sign of success.',\n",
       " 'Due to Supply Chain Break Down In China because of Coronavirus',\n",
       " 'Countries Providing Incentives To Shift Production To Their Native Country',\n",
       " 'Amid Covid-19 World Trade Has Halted, Investors Are Pulling Out Money from The Market',\n",
       " 'Other Side Of The Coin!!',\n",
       " 'Corona Virus Won’t End Globalization, But Change It Hugely for The A Better',\n",
       " 'An unregulated world can be blamed for its spread, but collective action based on evidence could be the best way to stop it.',\n",
       " 'Trade During Coronavirus:',\n",
       " '1.India Readies list of 13 countries to send hydroxychloroquine.',\n",
       " '2.China Sends doctors and masks overseas domestic coronavirus infection drop.',\n",
       " 'Movement of Ideas',\n",
       " 'Countries are converging virtually to share best practice to fight pandemic',\n",
       " 'International meeting such as G-20, SAARC summit organized virtually',\n",
       " 'Living apart, we must stand together’ to battle coronavirus pandemic-UN Rights chief.',\n",
       " 'China’s BRI Project after COVID-19',\n",
       " 'BRI Project:',\n",
       " 'The Belt and Road Initiative is a global development strategy adopted by the Chinese government in 2013 involving infrastructure development and investments in nearly 70 countries and international organizations in Asia, Europe, and Africa.',\n",
       " 'Curtailed Connectivity after Covid19:',\n",
       " 'A devastating economic collapse of potentially historic proportions after Covid19, leading to social and political turmoil in a number of countries, and curtailed connectivity. Interestingly, the pandemic has exposed the risks and weaknesses of global interconnectedness, which will affect China’s BRI.',\n",
       " 'Funding Shortfall for BRI',\n",
       " 'So far, BRI has been powered primarily by China, whose growth rates were decreasing even before the outbreak. Exports Hit: With the United States and Europe reeling from the pandemic, Chinese exports will take a big hit.',\n",
       " 'China confronts major Risk of debt on belt and road due to pandemic',\n",
       " 'China’s growth hit a near 30-year low of 6.1%',\n",
       " 'Roughly 5 Million people in china lost their jobs in the first 2 months of 2020.',\n",
       " 'Last February, China’s official urban unemployment jumped to an unprecedented 6.2 percent. Unemployed Number may go up to 9 million by the end of 2020.',\n",
       " 'China will have to choose out of two competing priorities:',\n",
       " 'So, not only may BRI be short of cash, but it will also be hard to sell at home',\n",
       " 'All Economies along BRI routes affected',\n",
       " 'Pakistan, host to the biggest BRI megaproject in the world, is poised to sustain a $8.2 billion loss, according to ADB. The respective figure for Bangladesh is $3 billion. Thailand is now bracing up for a recession. Africa is equally vulnerable, as China is the continent’s largest market.',\n",
       " 'Covid19 hit Chinese companies executing BRI contracts can rely on support from the CDB in the form of low-cost financing. Yet, Chinese policy banks will be increasingly picky and inclined to stay away from new projects that may turn out to be loss-makers.',\n",
       " 'China Development Bank to support Belt and road companies hit by coronavirus -Xinhua',\n",
       " 'The Coronavirus and Xi Jinping’s Worldview',\n",
       " 'Priority list:',\n",
       " 'No. 1 preserving the CCP’s power',\n",
       " 'No. 2 maintaining national unity',\n",
       " 'No. 3 the expansion of the economy No. 4 environmental sustainability',\n",
       " 'No. 5 modernize the Chinese military',\n",
       " 'No. 6 China’s 14 neighboring states',\n",
       " 'No. 7 weaken America’s longstanding security alliances No. 8 terrestrial Silk Road Economic Belt No. 9 Maritime Silk Road',\n",
       " 'No 10 reshape the global order',\n",
       " 'Under extreme circumstances, Beijing will not consider the BRI as important.',\n",
       " 'Is the BRI Finished then? Short Term: Yes, BRI will Face Trouble',\n",
       " 'In particular, the summer of 2020 may be a period of hibernation for several BRI projects.',\n",
       " 'The outbreak has brought Chinese labor supplies and equipment imports along BRI routes down to a trickle',\n",
       " 'Not Exactly!!! In fact, the initiative’s fuzzy content is being further enriched with the “Health Silk Road” add-on narrative and “mask diplomacy” in a major soft-power push.',\n",
       " 'Long Term: A Changed BRI will Emerge',\n",
       " 'The BRI is bound to change. Strategies will change.',\n",
       " 'It might even be Defined Properly',\n",
       " 'Seven years after this ambitious initiative was announced it remains a blurred vision in need of a comprehensive conceptual framework, international standards, and a coherent implementation strategy.',\n",
       " 'This is one of the reasons why the BRI has become controversial and has caused a backlash in many countries.',\n",
       " 'A Shift away from Roads and Bridges',\n",
       " 'BRI expenditure up to 2019 stood at $545 billion. (WB Estimate) About two-thirds of spending on BRI projects has gone into the energy sector and transport',\n",
       " 'However, developing countries in need of infrastructure will be terribly cash-strapped, there may be a shift away from roads, bridges, and coalfired power plants funded through Chinese loans.',\n",
       " 'New BRI projects will probably be more strategically chosen.',\n",
       " 'Beijing has been investing in the creation of a globe-spanning network of economic corridors, logistics zones, and financial centers, with stress laid on seaports and adjacent areas. Egypt’s Suez Canal Economic Zone and Sri Lanka’s Colombo Port City clearly show this trend.',\n",
       " 'In addition, projects are likely to focus on more sophisticated forms of connectivity, such as 5G networks or, in the wake of the pandemic, disaster management, public health-related high-tech, and even remote surgery. China will surely use the BRI for the projection of its soft power, an increasingly important battlefield in international relations.',\n",
       " 'The world has become aware of the risks of overwhelming reliance on China.',\n",
       " 'Amid of Coronavirus outbreak we can see the major economies are strengthening their authorities with their major concern']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[18:103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d01dd9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69 sentences in the string.\n",
      "The number of words in the string is: 1425\n",
      "The number of characters in the string is: 7785\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Apr/2023 17:59:17] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2023 17:59:22] \"GET /d HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles=(' '.join(str(x) for x in titles))\n",
    "texts=(' '.join(str(x) for x in texts[18:103]))\n",
    "URL_ID_100 = \" \".join((titles, texts))\n",
    "driver.quit()\n",
    "\n",
    "sentences = URL_ID_100.split(\".\")\n",
    "Sent_count = len(sentences)\n",
    "print(f\"There are {Sent_count} sentences in the string.\")\n",
    "\n",
    "word_list = URL_ID_100.split()\n",
    "num_words = len(word_list)\n",
    "print(\"The number of words in the string is:\",num_words)\n",
    "\n",
    "words = URL_ID_100.split()\n",
    "total_chars = sum(len(word) for word in words)\n",
    "print(\"The number of characters in the string is:\",total_chars)\n",
    "\n",
    "re_punt = \"[^A-Za-z0-9!?\\s]\"\n",
    "URL_ID_100 = re.sub(re_punt, \"\",URL_ID_100)\n",
    "\n",
    "file = open(\"100.txt\", \"w\")\n",
    "file.write(URL_ID_100)\n",
    "file.close()\n",
    "\n",
    "\n",
    "from flask import Flask, send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/d')\n",
    "def download_file():\n",
    "    path = \"100.txt\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "78359059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1422\n",
      "WORD COUNT 949\n",
      "POSITIVE SCORE: 0\n",
      "NEGATIVE SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/hrush/Downloads/100.txt\",header=None)\n",
    "df_lwr = df[0].str.lower()\n",
    "Tk_words = list(df_lwr.str.split())\n",
    "Tk_words\n",
    "\n",
    "tk_words = []\n",
    "\n",
    "for sublist in Tk_words:\n",
    "    tk_words.extend(sublist)\n",
    "\n",
    "print(len(tk_words))\n",
    "    \n",
    "for word in tk_words:\n",
    "    if word in sw_list:\n",
    "        tk_words.remove(word)\n",
    "                       \n",
    "WORD_COUNT=len(tk_words)\n",
    "print(\"WORD COUNT\",WORD_COUNT)\n",
    "\n",
    "POSITIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in positive_words:\n",
    "      POSITIVE_SCORE += 1\n",
    "\n",
    "print(\"POSITIVE SCORE:\", POSITIVE_SCORE)\n",
    "\n",
    "NEGATIVE_SCORE = 0\n",
    "for Tk_word in Tk_words:\n",
    "    if Tk_word in negative_words:\n",
    "      NEGATIVE_SCORE -= 1\n",
    "\n",
    "print(\"NEGATIVE SCORE:\", NEGATIVE_SCORE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1d2dc358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY SCORE : 0.0\n",
      "SUBJECTIVITY SCORE : 0.0\n",
      "AVG SENTENCE lENGTH  : 20.652173913043477\n",
      "317\n",
      "PERCENTAGE OF COMPLEX WORDS: 0.3340358271865121\n",
      "FOG INDEX: 8.394483896091996\n",
      "AVG_NUMBER_OF_WORDS_PER_SENTENCE: 20.652173913043477\n",
      "COMPLEX WORD COUNT: 317\n",
      "WORD COUNT: 949\n"
     ]
    }
   ],
   "source": [
    "POLARITY_SCORE = ((int(POSITIVE_SCORE)) - (int(NEGATIVE_SCORE)))/(((int(POSITIVE_SCORE)) + (int(NEGATIVE_SCORE))) + 0.000001)\n",
    "print(\"POLARITY SCORE :\",POLARITY_SCORE)\n",
    "\n",
    "Total_words_after_cleaning =WORD_COUNT\n",
    "Total_words_after_cleaning\n",
    "\n",
    "SUBJECTIVITY_SCORE = (POSITIVE_SCORE + NEGATIVE_SCORE)/ ((Total_words_after_cleaning) + 0.000001)\n",
    "print(\"SUBJECTIVITY SCORE :\",SUBJECTIVITY_SCORE)\n",
    "\n",
    "The_number_of_sentences= Sent_count\n",
    "The_number_of_sentences\n",
    "\n",
    "The_number_of_words = num_words\n",
    "The_number_of_words\n",
    "\n",
    "AVG_SENTENCE_LENGTH = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG SENTENCE lENGTH  :\",AVG_SENTENCE_LENGTH)\n",
    "\n",
    "\n",
    "more_than_two_syllables =len(list(filter(has_more_than_two_syllables, word_list)))\n",
    "print(more_than_two_syllables)\n",
    "\n",
    "The_number_of_complex_words = more_than_two_syllables\n",
    "The_number_of_complex_words\n",
    "\n",
    "PERCENTAGE_OF_COMPLEX_WORDS = The_number_of_complex_words/Total_words_after_cleaning\n",
    "print(\"PERCENTAGE OF COMPLEX WORDS:\",PERCENTAGE_OF_COMPLEX_WORDS)\n",
    "\n",
    "FOG_INDEX = (AVG_SENTENCE_LENGTH+PERCENTAGE_OF_COMPLEX_WORDS)*0.4\n",
    "print(\"FOG INDEX:\",FOG_INDEX)\n",
    "\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = (The_number_of_words)/(The_number_of_sentences)\n",
    "print(\"AVG_NUMBER_OF_WORDS_PER_SENTENCE:\",AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "\n",
    "COMPLEX_WORD_COUNT = more_than_two_syllables\n",
    "print(\"COMPLEX WORD COUNT:\",COMPLEX_WORD_COUNT)\n",
    "\n",
    "WORD_COUNT = Total_words_after_cleaning\n",
    "print(\"WORD COUNT:\",WORD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ff42a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYLLABLE PER WORD: 2739\n",
      "i: 0\n",
      "we: 5\n",
      "my: 0\n",
      "ours: 0\n",
      "us: 0\n",
      "Total count: 5\n",
      "PERSONAL PRONOUNS: 5\n",
      "AVG WORD LENGTH: 5.463157894736842\n"
     ]
    }
   ],
   "source": [
    "syllable_counts = [count_syllables(word) for word in word_list]\n",
    "Syllable_count_per_word = sum(syllable_counts)\n",
    "Syllable_count_per_word\n",
    "\n",
    "SYLLABLE_PER_WORD=Syllable_count_per_word\n",
    "print(\"SYLLABLE PER WORD:\",SYLLABLE_PER_WORD)\n",
    "\n",
    "word_counts = {\n",
    "    \"i\": 0,\n",
    "    \"we\": 0,\n",
    "    \"my\": 0,\n",
    "    \"ours\": 0,\n",
    "    \"us\": 0\n",
    "}\n",
    "for word in URL_ID_100.split():\n",
    "    word = word.lower()\n",
    "    if re.match(r\"\\b(i|we|my|ours|us),?\\b\", word):\n",
    "        word = word.rstrip(\",\")\n",
    "        word_counts[word] += 1\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "total_count = sum(word_counts.values())\n",
    "print(f\"Total count: {total_count}\")\n",
    "\n",
    "print(\"PERSONAL PRONOUNS:\",total_count)\n",
    "\n",
    "AVG_WORD_LENGTH = total_chars/num_words\n",
    "print(\"AVG WORD LENGTH:\",AVG_WORD_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1dcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
